<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage.info - mm/internal.h</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">mm</a> - internal.h<span style="font-size: 80%;"> (source / <a href="internal.h.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">3</td>
            <td class="headerCovTableEntry">62</td>
            <td class="headerCovTableEntryLo">4.8 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2022-12-09 01:23:36</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">6</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* SPDX-License-Identifier: GPL-2.0-or-later */</a>
<a name="2"><span class="lineNum">       2 </span>            : /* internal.h: mm/ internal definitions</a>
<a name="3"><span class="lineNum">       3 </span>            :  *</a>
<a name="4"><span class="lineNum">       4 </span>            :  * Copyright (C) 2004 Red Hat, Inc. All Rights Reserved.</a>
<a name="5"><span class="lineNum">       5 </span>            :  * Written by David Howells (dhowells@redhat.com)</a>
<a name="6"><span class="lineNum">       6 </span>            :  */</a>
<a name="7"><span class="lineNum">       7 </span>            : #ifndef __MM_INTERNAL_H</a>
<a name="8"><span class="lineNum">       8 </span>            : #define __MM_INTERNAL_H</a>
<a name="9"><span class="lineNum">       9 </span>            : </a>
<a name="10"><span class="lineNum">      10 </span>            : #include &lt;linux/fs.h&gt;</a>
<a name="11"><span class="lineNum">      11 </span>            : #include &lt;linux/mm.h&gt;</a>
<a name="12"><span class="lineNum">      12 </span>            : #include &lt;linux/pagemap.h&gt;</a>
<a name="13"><span class="lineNum">      13 </span>            : #include &lt;linux/rmap.h&gt;</a>
<a name="14"><span class="lineNum">      14 </span>            : #include &lt;linux/tracepoint-defs.h&gt;</a>
<a name="15"><span class="lineNum">      15 </span>            : </a>
<a name="16"><span class="lineNum">      16 </span>            : struct folio_batch;</a>
<a name="17"><span class="lineNum">      17 </span>            : </a>
<a name="18"><span class="lineNum">      18 </span>            : /*</a>
<a name="19"><span class="lineNum">      19 </span>            :  * The set of flags that only affect watermark checking and reclaim</a>
<a name="20"><span class="lineNum">      20 </span>            :  * behaviour. This is used by the MM to obey the caller constraints</a>
<a name="21"><span class="lineNum">      21 </span>            :  * about IO, FS and watermark checking while ignoring placement</a>
<a name="22"><span class="lineNum">      22 </span>            :  * hints such as HIGHMEM usage.</a>
<a name="23"><span class="lineNum">      23 </span>            :  */</a>
<a name="24"><span class="lineNum">      24 </span>            : #define GFP_RECLAIM_MASK (__GFP_RECLAIM|__GFP_HIGH|__GFP_IO|__GFP_FS|\</a>
<a name="25"><span class="lineNum">      25 </span>            :                         __GFP_NOWARN|__GFP_RETRY_MAYFAIL|__GFP_NOFAIL|\</a>
<a name="26"><span class="lineNum">      26 </span>            :                         __GFP_NORETRY|__GFP_MEMALLOC|__GFP_NOMEMALLOC|\</a>
<a name="27"><span class="lineNum">      27 </span>            :                         __GFP_ATOMIC|__GFP_NOLOCKDEP)</a>
<a name="28"><span class="lineNum">      28 </span>            : </a>
<a name="29"><span class="lineNum">      29 </span>            : /* The GFP flags allowed during early boot */</a>
<a name="30"><span class="lineNum">      30 </span>            : #define GFP_BOOT_MASK (__GFP_BITS_MASK &amp; ~(__GFP_RECLAIM|__GFP_IO|__GFP_FS))</a>
<a name="31"><span class="lineNum">      31 </span>            : </a>
<a name="32"><span class="lineNum">      32 </span>            : /* Control allocation cpuset and node placement constraints */</a>
<a name="33"><span class="lineNum">      33 </span>            : #define GFP_CONSTRAINT_MASK (__GFP_HARDWALL|__GFP_THISNODE)</a>
<a name="34"><span class="lineNum">      34 </span>            : </a>
<a name="35"><span class="lineNum">      35 </span>            : /* Do not use these with a slab allocator */</a>
<a name="36"><span class="lineNum">      36 </span>            : #define GFP_SLAB_BUG_MASK (__GFP_DMA32|__GFP_HIGHMEM|~__GFP_BITS_MASK)</a>
<a name="37"><span class="lineNum">      37 </span>            : </a>
<a name="38"><span class="lineNum">      38 </span>            : void page_writeback_init(void);</a>
<a name="39"><span class="lineNum">      39 </span>            : </a>
<a name="40"><span class="lineNum">      40 </span>            : static inline void *folio_raw_mapping(struct folio *folio)</a>
<a name="41"><span class="lineNum">      41 </span>            : {</a>
<a name="42"><span class="lineNum">      42 </span><span class="lineNoCov">          0 :         unsigned long mapping = (unsigned long)folio-&gt;mapping;</span></a>
<a name="43"><span class="lineNum">      43 </span>            : </a>
<a name="44"><span class="lineNum">      44 </span><span class="lineNoCov">          0 :         return (void *)(mapping &amp; ~PAGE_MAPPING_FLAGS);</span></a>
<a name="45"><span class="lineNum">      45 </span>            : }</a>
<a name="46"><span class="lineNum">      46 </span>            : </a>
<a name="47"><span class="lineNum">      47 </span>            : void __acct_reclaim_writeback(pg_data_t *pgdat, struct folio *folio,</a>
<a name="48"><span class="lineNum">      48 </span>            :                                                 int nr_throttled);</a>
<a name="49"><span class="lineNum">      49 </span>            : static inline void acct_reclaim_writeback(struct folio *folio)</a>
<a name="50"><span class="lineNum">      50 </span>            : {</a>
<a name="51"><span class="lineNum">      51 </span><span class="lineNoCov">          0 :         pg_data_t *pgdat = folio_pgdat(folio);</span></a>
<a name="52"><span class="lineNum">      52 </span><span class="lineNoCov">          0 :         int nr_throttled = atomic_read(&amp;pgdat-&gt;nr_writeback_throttled);</span></a>
<a name="53"><span class="lineNum">      53 </span>            : </a>
<a name="54"><span class="lineNum">      54 </span><span class="lineNoCov">          0 :         if (nr_throttled)</span></a>
<a name="55"><span class="lineNum">      55 </span><span class="lineNoCov">          0 :                 __acct_reclaim_writeback(pgdat, folio, nr_throttled);</span></a>
<a name="56"><span class="lineNum">      56 </span>            : }</a>
<a name="57"><span class="lineNum">      57 </span>            : </a>
<a name="58"><span class="lineNum">      58 </span>            : static inline void wake_throttle_isolated(pg_data_t *pgdat)</a>
<a name="59"><span class="lineNum">      59 </span>            : {</a>
<a name="60"><span class="lineNum">      60 </span>            :         wait_queue_head_t *wqh;</a>
<a name="61"><span class="lineNum">      61 </span>            : </a>
<a name="62"><span class="lineNum">      62 </span><span class="lineNoCov">          0 :         wqh = &amp;pgdat-&gt;reclaim_wait[VMSCAN_THROTTLE_ISOLATED];</span></a>
<a name="63"><span class="lineNum">      63 </span><span class="lineNoCov">          0 :         if (waitqueue_active(wqh))</span></a>
<a name="64"><span class="lineNum">      64 </span><span class="lineNoCov">          0 :                 wake_up(wqh);</span></a>
<a name="65"><span class="lineNum">      65 </span>            : }</a>
<a name="66"><span class="lineNum">      66 </span>            : </a>
<a name="67"><span class="lineNum">      67 </span>            : vm_fault_t do_swap_page(struct vm_fault *vmf);</a>
<a name="68"><span class="lineNum">      68 </span>            : void folio_rotate_reclaimable(struct folio *folio);</a>
<a name="69"><span class="lineNum">      69 </span>            : bool __folio_end_writeback(struct folio *folio);</a>
<a name="70"><span class="lineNum">      70 </span>            : void deactivate_file_folio(struct folio *folio);</a>
<a name="71"><span class="lineNum">      71 </span>            : </a>
<a name="72"><span class="lineNum">      72 </span>            : void free_pgtables(struct mmu_gather *tlb, struct vm_area_struct *start_vma,</a>
<a name="73"><span class="lineNum">      73 </span>            :                 unsigned long floor, unsigned long ceiling);</a>
<a name="74"><span class="lineNum">      74 </span>            : void pmd_install(struct mm_struct *mm, pmd_t *pmd, pgtable_t *pte);</a>
<a name="75"><span class="lineNum">      75 </span>            : </a>
<a name="76"><span class="lineNum">      76 </span>            : struct zap_details;</a>
<a name="77"><span class="lineNum">      77 </span>            : void unmap_page_range(struct mmu_gather *tlb,</a>
<a name="78"><span class="lineNum">      78 </span>            :                              struct vm_area_struct *vma,</a>
<a name="79"><span class="lineNum">      79 </span>            :                              unsigned long addr, unsigned long end,</a>
<a name="80"><span class="lineNum">      80 </span>            :                              struct zap_details *details);</a>
<a name="81"><span class="lineNum">      81 </span>            : </a>
<a name="82"><span class="lineNum">      82 </span>            : void page_cache_ra_order(struct readahead_control *, struct file_ra_state *,</a>
<a name="83"><span class="lineNum">      83 </span>            :                 unsigned int order);</a>
<a name="84"><span class="lineNum">      84 </span>            : void force_page_cache_ra(struct readahead_control *, unsigned long nr);</a>
<a name="85"><span class="lineNum">      85 </span>            : static inline void force_page_cache_readahead(struct address_space *mapping,</a>
<a name="86"><span class="lineNum">      86 </span>            :                 struct file *file, pgoff_t index, unsigned long nr_to_read)</a>
<a name="87"><span class="lineNum">      87 </span>            : {</a>
<a name="88"><span class="lineNum">      88 </span><span class="lineNoCov">          0 :         DEFINE_READAHEAD(ractl, file, &amp;file-&gt;f_ra, mapping, index);</span></a>
<a name="89"><span class="lineNum">      89 </span><span class="lineNoCov">          0 :         force_page_cache_ra(&amp;ractl, nr_to_read);</span></a>
<a name="90"><span class="lineNum">      90 </span>            : }</a>
<a name="91"><span class="lineNum">      91 </span>            : </a>
<a name="92"><span class="lineNum">      92 </span>            : unsigned find_lock_entries(struct address_space *mapping, pgoff_t start,</a>
<a name="93"><span class="lineNum">      93 </span>            :                 pgoff_t end, struct folio_batch *fbatch, pgoff_t *indices);</a>
<a name="94"><span class="lineNum">      94 </span>            : unsigned find_get_entries(struct address_space *mapping, pgoff_t start,</a>
<a name="95"><span class="lineNum">      95 </span>            :                 pgoff_t end, struct folio_batch *fbatch, pgoff_t *indices);</a>
<a name="96"><span class="lineNum">      96 </span>            : void filemap_free_folio(struct address_space *mapping, struct folio *folio);</a>
<a name="97"><span class="lineNum">      97 </span>            : int truncate_inode_folio(struct address_space *mapping, struct folio *folio);</a>
<a name="98"><span class="lineNum">      98 </span>            : bool truncate_inode_partial_folio(struct folio *folio, loff_t start,</a>
<a name="99"><span class="lineNum">      99 </span>            :                 loff_t end);</a>
<a name="100"><span class="lineNum">     100 </span>            : long invalidate_inode_page(struct page *page);</a>
<a name="101"><span class="lineNum">     101 </span>            : unsigned long invalidate_mapping_pagevec(struct address_space *mapping,</a>
<a name="102"><span class="lineNum">     102 </span>            :                 pgoff_t start, pgoff_t end, unsigned long *nr_pagevec);</a>
<a name="103"><span class="lineNum">     103 </span>            : </a>
<a name="104"><span class="lineNum">     104 </span>            : /**</a>
<a name="105"><span class="lineNum">     105 </span>            :  * folio_evictable - Test whether a folio is evictable.</a>
<a name="106"><span class="lineNum">     106 </span>            :  * @folio: The folio to test.</a>
<a name="107"><span class="lineNum">     107 </span>            :  *</a>
<a name="108"><span class="lineNum">     108 </span>            :  * Test whether @folio is evictable -- i.e., should be placed on</a>
<a name="109"><span class="lineNum">     109 </span>            :  * active/inactive lists vs unevictable list.</a>
<a name="110"><span class="lineNum">     110 </span>            :  *</a>
<a name="111"><span class="lineNum">     111 </span>            :  * Reasons folio might not be evictable:</a>
<a name="112"><span class="lineNum">     112 </span>            :  * 1. folio's mapping marked unevictable</a>
<a name="113"><span class="lineNum">     113 </span>            :  * 2. One of the pages in the folio is part of an mlocked VMA</a>
<a name="114"><span class="lineNum">     114 </span>            :  */</a>
<a name="115"><span class="lineNum">     115 </span><span class="lineNoCov">          0 : static inline bool folio_evictable(struct folio *folio)</span></a>
<a name="116"><span class="lineNum">     116 </span>            : {</a>
<a name="117"><span class="lineNum">     117 </span>            :         bool ret;</a>
<a name="118"><span class="lineNum">     118 </span>            : </a>
<a name="119"><span class="lineNum">     119 </span>            :         /* Prevent address_space of inode and swap cache from being freed */</a>
<a name="120"><span class="lineNum">     120 </span>            :         rcu_read_lock();</a>
<a name="121"><span class="lineNum">     121 </span><span class="lineNoCov">          0 :         ret = !mapping_unevictable(folio_mapping(folio)) &amp;&amp;</span></a>
<a name="122"><span class="lineNum">     122 </span><span class="lineNoCov">          0 :                         !folio_test_mlocked(folio);</span></a>
<a name="123"><span class="lineNum">     123 </span>            :         rcu_read_unlock();</a>
<a name="124"><span class="lineNum">     124 </span><span class="lineNoCov">          0 :         return ret;</span></a>
<a name="125"><span class="lineNum">     125 </span>            : }</a>
<a name="126"><span class="lineNum">     126 </span>            : </a>
<a name="127"><span class="lineNum">     127 </span><span class="lineNoCov">          0 : static inline bool page_evictable(struct page *page)</span></a>
<a name="128"><span class="lineNum">     128 </span>            : {</a>
<a name="129"><span class="lineNum">     129 </span>            :         bool ret;</a>
<a name="130"><span class="lineNum">     130 </span>            : </a>
<a name="131"><span class="lineNum">     131 </span>            :         /* Prevent address_space of inode and swap cache from being freed */</a>
<a name="132"><span class="lineNum">     132 </span>            :         rcu_read_lock();</a>
<a name="133"><span class="lineNum">     133 </span><span class="lineNoCov">          0 :         ret = !mapping_unevictable(page_mapping(page)) &amp;&amp; !PageMlocked(page);</span></a>
<a name="134"><span class="lineNum">     134 </span>            :         rcu_read_unlock();</a>
<a name="135"><span class="lineNum">     135 </span><span class="lineNoCov">          0 :         return ret;</span></a>
<a name="136"><span class="lineNum">     136 </span>            : }</a>
<a name="137"><span class="lineNum">     137 </span>            : </a>
<a name="138"><span class="lineNum">     138 </span>            : /*</a>
<a name="139"><span class="lineNum">     139 </span>            :  * Turn a non-refcounted page (-&gt;_refcount == 0) into refcounted with</a>
<a name="140"><span class="lineNum">     140 </span>            :  * a count of one.</a>
<a name="141"><span class="lineNum">     141 </span>            :  */</a>
<a name="142"><span class="lineNum">     142 </span>            : static inline void set_page_refcounted(struct page *page)</a>
<a name="143"><span class="lineNum">     143 </span>            : {</a>
<a name="144"><span class="lineNum">     144 </span>            :         VM_BUG_ON_PAGE(PageTail(page), page);</a>
<a name="145"><span class="lineNum">     145 </span>            :         VM_BUG_ON_PAGE(page_ref_count(page), page);</a>
<a name="146"><span class="lineNum">     146 </span><span class="lineCov">        543 :         set_page_count(page, 1);</span></a>
<a name="147"><span class="lineNum">     147 </span>            : }</a>
<a name="148"><span class="lineNum">     148 </span>            : </a>
<a name="149"><span class="lineNum">     149 </span>            : extern unsigned long highest_memmap_pfn;</a>
<a name="150"><span class="lineNum">     150 </span>            : </a>
<a name="151"><span class="lineNum">     151 </span>            : /*</a>
<a name="152"><span class="lineNum">     152 </span>            :  * Maximum number of reclaim retries without progress before the OOM</a>
<a name="153"><span class="lineNum">     153 </span>            :  * killer is consider the only way forward.</a>
<a name="154"><span class="lineNum">     154 </span>            :  */</a>
<a name="155"><span class="lineNum">     155 </span>            : #define MAX_RECLAIM_RETRIES 16</a>
<a name="156"><span class="lineNum">     156 </span>            : </a>
<a name="157"><span class="lineNum">     157 </span>            : /*</a>
<a name="158"><span class="lineNum">     158 </span>            :  * in mm/early_ioremap.c</a>
<a name="159"><span class="lineNum">     159 </span>            :  */</a>
<a name="160"><span class="lineNum">     160 </span>            : pgprot_t __init early_memremap_pgprot_adjust(resource_size_t phys_addr,</a>
<a name="161"><span class="lineNum">     161 </span>            :                                         unsigned long size, pgprot_t prot);</a>
<a name="162"><span class="lineNum">     162 </span>            : </a>
<a name="163"><span class="lineNum">     163 </span>            : /*</a>
<a name="164"><span class="lineNum">     164 </span>            :  * in mm/vmscan.c:</a>
<a name="165"><span class="lineNum">     165 </span>            :  */</a>
<a name="166"><span class="lineNum">     166 </span>            : int isolate_lru_page(struct page *page);</a>
<a name="167"><span class="lineNum">     167 </span>            : int folio_isolate_lru(struct folio *folio);</a>
<a name="168"><span class="lineNum">     168 </span>            : void putback_lru_page(struct page *page);</a>
<a name="169"><span class="lineNum">     169 </span>            : void folio_putback_lru(struct folio *folio);</a>
<a name="170"><span class="lineNum">     170 </span>            : extern void reclaim_throttle(pg_data_t *pgdat, enum vmscan_throttle_state reason);</a>
<a name="171"><span class="lineNum">     171 </span>            : </a>
<a name="172"><span class="lineNum">     172 </span>            : /*</a>
<a name="173"><span class="lineNum">     173 </span>            :  * in mm/rmap.c:</a>
<a name="174"><span class="lineNum">     174 </span>            :  */</a>
<a name="175"><span class="lineNum">     175 </span>            : extern pmd_t *mm_find_pmd(struct mm_struct *mm, unsigned long address);</a>
<a name="176"><span class="lineNum">     176 </span>            : </a>
<a name="177"><span class="lineNum">     177 </span>            : /*</a>
<a name="178"><span class="lineNum">     178 </span>            :  * in mm/page_alloc.c</a>
<a name="179"><span class="lineNum">     179 </span>            :  */</a>
<a name="180"><span class="lineNum">     180 </span>            : </a>
<a name="181"><span class="lineNum">     181 </span>            : /*</a>
<a name="182"><span class="lineNum">     182 </span>            :  * Structure for holding the mostly immutable allocation parameters passed</a>
<a name="183"><span class="lineNum">     183 </span>            :  * between functions involved in allocations, including the alloc_pages*</a>
<a name="184"><span class="lineNum">     184 </span>            :  * family of functions.</a>
<a name="185"><span class="lineNum">     185 </span>            :  *</a>
<a name="186"><span class="lineNum">     186 </span>            :  * nodemask, migratetype and highest_zoneidx are initialized only once in</a>
<a name="187"><span class="lineNum">     187 </span>            :  * __alloc_pages() and then never change.</a>
<a name="188"><span class="lineNum">     188 </span>            :  *</a>
<a name="189"><span class="lineNum">     189 </span>            :  * zonelist, preferred_zone and highest_zoneidx are set first in</a>
<a name="190"><span class="lineNum">     190 </span>            :  * __alloc_pages() for the fast path, and might be later changed</a>
<a name="191"><span class="lineNum">     191 </span>            :  * in __alloc_pages_slowpath(). All other functions pass the whole structure</a>
<a name="192"><span class="lineNum">     192 </span>            :  * by a const pointer.</a>
<a name="193"><span class="lineNum">     193 </span>            :  */</a>
<a name="194"><span class="lineNum">     194 </span>            : struct alloc_context {</a>
<a name="195"><span class="lineNum">     195 </span>            :         struct zonelist *zonelist;</a>
<a name="196"><span class="lineNum">     196 </span>            :         nodemask_t *nodemask;</a>
<a name="197"><span class="lineNum">     197 </span>            :         struct zoneref *preferred_zoneref;</a>
<a name="198"><span class="lineNum">     198 </span>            :         int migratetype;</a>
<a name="199"><span class="lineNum">     199 </span>            : </a>
<a name="200"><span class="lineNum">     200 </span>            :         /*</a>
<a name="201"><span class="lineNum">     201 </span>            :          * highest_zoneidx represents highest usable zone index of</a>
<a name="202"><span class="lineNum">     202 </span>            :          * the allocation request. Due to the nature of the zone,</a>
<a name="203"><span class="lineNum">     203 </span>            :          * memory on lower zone than the highest_zoneidx will be</a>
<a name="204"><span class="lineNum">     204 </span>            :          * protected by lowmem_reserve[highest_zoneidx].</a>
<a name="205"><span class="lineNum">     205 </span>            :          *</a>
<a name="206"><span class="lineNum">     206 </span>            :          * highest_zoneidx is also used by reclaim/compaction to limit</a>
<a name="207"><span class="lineNum">     207 </span>            :          * the target zone since higher zone than this index cannot be</a>
<a name="208"><span class="lineNum">     208 </span>            :          * usable for this allocation request.</a>
<a name="209"><span class="lineNum">     209 </span>            :          */</a>
<a name="210"><span class="lineNum">     210 </span>            :         enum zone_type highest_zoneidx;</a>
<a name="211"><span class="lineNum">     211 </span>            :         bool spread_dirty_pages;</a>
<a name="212"><span class="lineNum">     212 </span>            : };</a>
<a name="213"><span class="lineNum">     213 </span>            : </a>
<a name="214"><span class="lineNum">     214 </span>            : /*</a>
<a name="215"><span class="lineNum">     215 </span>            :  * Locate the struct page for both the matching buddy in our</a>
<a name="216"><span class="lineNum">     216 </span>            :  * pair (buddy1) and the combined O(n+1) page they form (page).</a>
<a name="217"><span class="lineNum">     217 </span>            :  *</a>
<a name="218"><span class="lineNum">     218 </span>            :  * 1) Any buddy B1 will have an order O twin B2 which satisfies</a>
<a name="219"><span class="lineNum">     219 </span>            :  * the following equation:</a>
<a name="220"><span class="lineNum">     220 </span>            :  *     B2 = B1 ^ (1 &lt;&lt; O)</a>
<a name="221"><span class="lineNum">     221 </span>            :  * For example, if the starting buddy (buddy2) is #8 its order</a>
<a name="222"><span class="lineNum">     222 </span>            :  * 1 buddy is #10:</a>
<a name="223"><span class="lineNum">     223 </span>            :  *     B2 = 8 ^ (1 &lt;&lt; 1) = 8 ^ 2 = 10</a>
<a name="224"><span class="lineNum">     224 </span>            :  *</a>
<a name="225"><span class="lineNum">     225 </span>            :  * 2) Any buddy B will have an order O+1 parent P which</a>
<a name="226"><span class="lineNum">     226 </span>            :  * satisfies the following equation:</a>
<a name="227"><span class="lineNum">     227 </span>            :  *     P = B &amp; ~(1 &lt;&lt; O)</a>
<a name="228"><span class="lineNum">     228 </span>            :  *</a>
<a name="229"><span class="lineNum">     229 </span>            :  * Assumption: *_mem_map is contiguous at least up to MAX_ORDER</a>
<a name="230"><span class="lineNum">     230 </span>            :  */</a>
<a name="231"><span class="lineNum">     231 </span>            : static inline unsigned long</a>
<a name="232"><span class="lineNum">     232 </span>            : __find_buddy_pfn(unsigned long page_pfn, unsigned int order)</a>
<a name="233"><span class="lineNum">     233 </span>            : {</a>
<a name="234"><span class="lineNum">     234 </span><span class="lineCov">         35 :         return page_pfn ^ (1 &lt;&lt; order);</span></a>
<a name="235"><span class="lineNum">     235 </span>            : }</a>
<a name="236"><span class="lineNum">     236 </span>            : </a>
<a name="237"><span class="lineNum">     237 </span>            : extern struct page *__pageblock_pfn_to_page(unsigned long start_pfn,</a>
<a name="238"><span class="lineNum">     238 </span>            :                                 unsigned long end_pfn, struct zone *zone);</a>
<a name="239"><span class="lineNum">     239 </span>            : </a>
<a name="240"><span class="lineNum">     240 </span>            : static inline struct page *pageblock_pfn_to_page(unsigned long start_pfn,</a>
<a name="241"><span class="lineNum">     241 </span>            :                                 unsigned long end_pfn, struct zone *zone)</a>
<a name="242"><span class="lineNum">     242 </span>            : {</a>
<a name="243"><span class="lineNum">     243 </span><span class="lineNoCov">          0 :         if (zone-&gt;contiguous)</span></a>
<a name="244"><span class="lineNum">     244 </span><span class="lineNoCov">          0 :                 return pfn_to_page(start_pfn);</span></a>
<a name="245"><span class="lineNum">     245 </span>            : </a>
<a name="246"><span class="lineNum">     246 </span><span class="lineNoCov">          0 :         return __pageblock_pfn_to_page(start_pfn, end_pfn, zone);</span></a>
<a name="247"><span class="lineNum">     247 </span>            : }</a>
<a name="248"><span class="lineNum">     248 </span>            : </a>
<a name="249"><span class="lineNum">     249 </span>            : extern int __isolate_free_page(struct page *page, unsigned int order);</a>
<a name="250"><span class="lineNum">     250 </span>            : extern void __putback_isolated_page(struct page *page, unsigned int order,</a>
<a name="251"><span class="lineNum">     251 </span>            :                                     int mt);</a>
<a name="252"><span class="lineNum">     252 </span>            : extern void memblock_free_pages(struct page *page, unsigned long pfn,</a>
<a name="253"><span class="lineNum">     253 </span>            :                                         unsigned int order);</a>
<a name="254"><span class="lineNum">     254 </span>            : extern void __free_pages_core(struct page *page, unsigned int order);</a>
<a name="255"><span class="lineNum">     255 </span>            : extern void prep_compound_page(struct page *page, unsigned int order);</a>
<a name="256"><span class="lineNum">     256 </span>            : extern void post_alloc_hook(struct page *page, unsigned int order,</a>
<a name="257"><span class="lineNum">     257 </span>            :                                         gfp_t gfp_flags);</a>
<a name="258"><span class="lineNum">     258 </span>            : extern int user_min_free_kbytes;</a>
<a name="259"><span class="lineNum">     259 </span>            : </a>
<a name="260"><span class="lineNum">     260 </span>            : extern void free_unref_page(struct page *page, unsigned int order);</a>
<a name="261"><span class="lineNum">     261 </span>            : extern void free_unref_page_list(struct list_head *list);</a>
<a name="262"><span class="lineNum">     262 </span>            : </a>
<a name="263"><span class="lineNum">     263 </span>            : extern void zone_pcp_update(struct zone *zone, int cpu_online);</a>
<a name="264"><span class="lineNum">     264 </span>            : extern void zone_pcp_reset(struct zone *zone);</a>
<a name="265"><span class="lineNum">     265 </span>            : extern void zone_pcp_disable(struct zone *zone);</a>
<a name="266"><span class="lineNum">     266 </span>            : extern void zone_pcp_enable(struct zone *zone);</a>
<a name="267"><span class="lineNum">     267 </span>            : </a>
<a name="268"><span class="lineNum">     268 </span>            : extern void *memmap_alloc(phys_addr_t size, phys_addr_t align,</a>
<a name="269"><span class="lineNum">     269 </span>            :                           phys_addr_t min_addr,</a>
<a name="270"><span class="lineNum">     270 </span>            :                           int nid, bool exact_nid);</a>
<a name="271"><span class="lineNum">     271 </span>            : </a>
<a name="272"><span class="lineNum">     272 </span>            : #if defined CONFIG_COMPACTION || defined CONFIG_CMA</a>
<a name="273"><span class="lineNum">     273 </span>            : </a>
<a name="274"><span class="lineNum">     274 </span>            : /*</a>
<a name="275"><span class="lineNum">     275 </span>            :  * in mm/compaction.c</a>
<a name="276"><span class="lineNum">     276 </span>            :  */</a>
<a name="277"><span class="lineNum">     277 </span>            : /*</a>
<a name="278"><span class="lineNum">     278 </span>            :  * compact_control is used to track pages being migrated and the free pages</a>
<a name="279"><span class="lineNum">     279 </span>            :  * they are being migrated to during memory compaction. The free_pfn starts</a>
<a name="280"><span class="lineNum">     280 </span>            :  * at the end of a zone and migrate_pfn begins at the start. Movable pages</a>
<a name="281"><span class="lineNum">     281 </span>            :  * are moved to the end of a zone during a compaction run and the run</a>
<a name="282"><span class="lineNum">     282 </span>            :  * completes when free_pfn &lt;= migrate_pfn</a>
<a name="283"><span class="lineNum">     283 </span>            :  */</a>
<a name="284"><span class="lineNum">     284 </span>            : struct compact_control {</a>
<a name="285"><span class="lineNum">     285 </span>            :         struct list_head freepages;     /* List of free pages to migrate to */</a>
<a name="286"><span class="lineNum">     286 </span>            :         struct list_head migratepages;  /* List of pages being migrated */</a>
<a name="287"><span class="lineNum">     287 </span>            :         unsigned int nr_freepages;      /* Number of isolated free pages */</a>
<a name="288"><span class="lineNum">     288 </span>            :         unsigned int nr_migratepages;   /* Number of pages to migrate */</a>
<a name="289"><span class="lineNum">     289 </span>            :         unsigned long free_pfn;         /* isolate_freepages search base */</a>
<a name="290"><span class="lineNum">     290 </span>            :         /*</a>
<a name="291"><span class="lineNum">     291 </span>            :          * Acts as an in/out parameter to page isolation for migration.</a>
<a name="292"><span class="lineNum">     292 </span>            :          * isolate_migratepages uses it as a search base.</a>
<a name="293"><span class="lineNum">     293 </span>            :          * isolate_migratepages_block will update the value to the next pfn</a>
<a name="294"><span class="lineNum">     294 </span>            :          * after the last isolated one.</a>
<a name="295"><span class="lineNum">     295 </span>            :          */</a>
<a name="296"><span class="lineNum">     296 </span>            :         unsigned long migrate_pfn;</a>
<a name="297"><span class="lineNum">     297 </span>            :         unsigned long fast_start_pfn;   /* a pfn to start linear scan from */</a>
<a name="298"><span class="lineNum">     298 </span>            :         struct zone *zone;</a>
<a name="299"><span class="lineNum">     299 </span>            :         unsigned long total_migrate_scanned;</a>
<a name="300"><span class="lineNum">     300 </span>            :         unsigned long total_free_scanned;</a>
<a name="301"><span class="lineNum">     301 </span>            :         unsigned short fast_search_fail;/* failures to use free list searches */</a>
<a name="302"><span class="lineNum">     302 </span>            :         short search_order;             /* order to start a fast search at */</a>
<a name="303"><span class="lineNum">     303 </span>            :         const gfp_t gfp_mask;           /* gfp mask of a direct compactor */</a>
<a name="304"><span class="lineNum">     304 </span>            :         int order;                      /* order a direct compactor needs */</a>
<a name="305"><span class="lineNum">     305 </span>            :         int migratetype;                /* migratetype of direct compactor */</a>
<a name="306"><span class="lineNum">     306 </span>            :         const unsigned int alloc_flags; /* alloc flags of a direct compactor */</a>
<a name="307"><span class="lineNum">     307 </span>            :         const int highest_zoneidx;      /* zone index of a direct compactor */</a>
<a name="308"><span class="lineNum">     308 </span>            :         enum migrate_mode mode;         /* Async or sync migration mode */</a>
<a name="309"><span class="lineNum">     309 </span>            :         bool ignore_skip_hint;          /* Scan blocks even if marked skip */</a>
<a name="310"><span class="lineNum">     310 </span>            :         bool no_set_skip_hint;          /* Don't mark blocks for skipping */</a>
<a name="311"><span class="lineNum">     311 </span>            :         bool ignore_block_suitable;     /* Scan blocks considered unsuitable */</a>
<a name="312"><span class="lineNum">     312 </span>            :         bool direct_compaction;         /* False from kcompactd or /proc/... */</a>
<a name="313"><span class="lineNum">     313 </span>            :         bool proactive_compaction;      /* kcompactd proactive compaction */</a>
<a name="314"><span class="lineNum">     314 </span>            :         bool whole_zone;                /* Whole zone should/has been scanned */</a>
<a name="315"><span class="lineNum">     315 </span>            :         bool contended;                 /* Signal lock or sched contention */</a>
<a name="316"><span class="lineNum">     316 </span>            :         bool rescan;                    /* Rescanning the same pageblock */</a>
<a name="317"><span class="lineNum">     317 </span>            :         bool alloc_contig;              /* alloc_contig_range allocation */</a>
<a name="318"><span class="lineNum">     318 </span>            : };</a>
<a name="319"><span class="lineNum">     319 </span>            : </a>
<a name="320"><span class="lineNum">     320 </span>            : /*</a>
<a name="321"><span class="lineNum">     321 </span>            :  * Used in direct compaction when a page should be taken from the freelists</a>
<a name="322"><span class="lineNum">     322 </span>            :  * immediately when one is created during the free path.</a>
<a name="323"><span class="lineNum">     323 </span>            :  */</a>
<a name="324"><span class="lineNum">     324 </span>            : struct capture_control {</a>
<a name="325"><span class="lineNum">     325 </span>            :         struct compact_control *cc;</a>
<a name="326"><span class="lineNum">     326 </span>            :         struct page *page;</a>
<a name="327"><span class="lineNum">     327 </span>            : };</a>
<a name="328"><span class="lineNum">     328 </span>            : </a>
<a name="329"><span class="lineNum">     329 </span>            : unsigned long</a>
<a name="330"><span class="lineNum">     330 </span>            : isolate_freepages_range(struct compact_control *cc,</a>
<a name="331"><span class="lineNum">     331 </span>            :                         unsigned long start_pfn, unsigned long end_pfn);</a>
<a name="332"><span class="lineNum">     332 </span>            : int</a>
<a name="333"><span class="lineNum">     333 </span>            : isolate_migratepages_range(struct compact_control *cc,</a>
<a name="334"><span class="lineNum">     334 </span>            :                            unsigned long low_pfn, unsigned long end_pfn);</a>
<a name="335"><span class="lineNum">     335 </span>            : #endif</a>
<a name="336"><span class="lineNum">     336 </span>            : int find_suitable_fallback(struct free_area *area, unsigned int order,</a>
<a name="337"><span class="lineNum">     337 </span>            :                         int migratetype, bool only_stealable, bool *can_steal);</a>
<a name="338"><span class="lineNum">     338 </span>            : </a>
<a name="339"><span class="lineNum">     339 </span>            : /*</a>
<a name="340"><span class="lineNum">     340 </span>            :  * This function returns the order of a free page in the buddy system. In</a>
<a name="341"><span class="lineNum">     341 </span>            :  * general, page_zone(page)-&gt;lock must be held by the caller to prevent the</a>
<a name="342"><span class="lineNum">     342 </span>            :  * page from being allocated in parallel and returning garbage as the order.</a>
<a name="343"><span class="lineNum">     343 </span>            :  * If a caller does not hold page_zone(page)-&gt;lock, it must guarantee that the</a>
<a name="344"><span class="lineNum">     344 </span>            :  * page cannot be allocated or merged in parallel. Alternatively, it must</a>
<a name="345"><span class="lineNum">     345 </span>            :  * handle invalid values gracefully, and use buddy_order_unsafe() below.</a>
<a name="346"><span class="lineNum">     346 </span>            :  */</a>
<a name="347"><span class="lineNum">     347 </span>            : static inline unsigned int buddy_order(struct page *page)</a>
<a name="348"><span class="lineNum">     348 </span>            : {</a>
<a name="349"><span class="lineNum">     349 </span>            :         /* PageBuddy() must be checked by the caller */</a>
<a name="350"><span class="lineNum">     350 </span><span class="lineCov">         18 :         return page_private(page);</span></a>
<a name="351"><span class="lineNum">     351 </span>            : }</a>
<a name="352"><span class="lineNum">     352 </span>            : </a>
<a name="353"><span class="lineNum">     353 </span>            : /*</a>
<a name="354"><span class="lineNum">     354 </span>            :  * Like buddy_order(), but for callers who cannot afford to hold the zone lock.</a>
<a name="355"><span class="lineNum">     355 </span>            :  * PageBuddy() should be checked first by the caller to minimize race window,</a>
<a name="356"><span class="lineNum">     356 </span>            :  * and invalid values must be handled gracefully.</a>
<a name="357"><span class="lineNum">     357 </span>            :  *</a>
<a name="358"><span class="lineNum">     358 </span>            :  * READ_ONCE is used so that if the caller assigns the result into a local</a>
<a name="359"><span class="lineNum">     359 </span>            :  * variable and e.g. tests it for valid range before using, the compiler cannot</a>
<a name="360"><span class="lineNum">     360 </span>            :  * decide to remove the variable and inline the page_private(page) multiple</a>
<a name="361"><span class="lineNum">     361 </span>            :  * times, potentially observing different values in the tests and the actual</a>
<a name="362"><span class="lineNum">     362 </span>            :  * use of the result.</a>
<a name="363"><span class="lineNum">     363 </span>            :  */</a>
<a name="364"><span class="lineNum">     364 </span>            : #define buddy_order_unsafe(page)        READ_ONCE(page_private(page))</a>
<a name="365"><span class="lineNum">     365 </span>            : </a>
<a name="366"><span class="lineNum">     366 </span>            : /*</a>
<a name="367"><span class="lineNum">     367 </span>            :  * These three helpers classifies VMAs for virtual memory accounting.</a>
<a name="368"><span class="lineNum">     368 </span>            :  */</a>
<a name="369"><span class="lineNum">     369 </span>            : </a>
<a name="370"><span class="lineNum">     370 </span>            : /*</a>
<a name="371"><span class="lineNum">     371 </span>            :  * Executable code area - executable, not writable, not stack</a>
<a name="372"><span class="lineNum">     372 </span>            :  */</a>
<a name="373"><span class="lineNum">     373 </span>            : static inline bool is_exec_mapping(vm_flags_t flags)</a>
<a name="374"><span class="lineNum">     374 </span>            : {</a>
<a name="375"><span class="lineNum">     375 </span><span class="lineNoCov">          0 :         return (flags &amp; (VM_EXEC | VM_WRITE | VM_STACK)) == VM_EXEC;</span></a>
<a name="376"><span class="lineNum">     376 </span>            : }</a>
<a name="377"><span class="lineNum">     377 </span>            : </a>
<a name="378"><span class="lineNum">     378 </span>            : /*</a>
<a name="379"><span class="lineNum">     379 </span>            :  * Stack area - automatically grows in one direction</a>
<a name="380"><span class="lineNum">     380 </span>            :  *</a>
<a name="381"><span class="lineNum">     381 </span>            :  * VM_GROWSUP / VM_GROWSDOWN VMAs are always private anonymous:</a>
<a name="382"><span class="lineNum">     382 </span>            :  * do_mmap() forbids all other combinations.</a>
<a name="383"><span class="lineNum">     383 </span>            :  */</a>
<a name="384"><span class="lineNum">     384 </span>            : static inline bool is_stack_mapping(vm_flags_t flags)</a>
<a name="385"><span class="lineNum">     385 </span>            : {</a>
<a name="386"><span class="lineNum">     386 </span><span class="lineNoCov">          0 :         return (flags &amp; VM_STACK) == VM_STACK;</span></a>
<a name="387"><span class="lineNum">     387 </span>            : }</a>
<a name="388"><span class="lineNum">     388 </span>            : </a>
<a name="389"><span class="lineNum">     389 </span>            : /*</a>
<a name="390"><span class="lineNum">     390 </span>            :  * Data area - private, writable, not stack</a>
<a name="391"><span class="lineNum">     391 </span>            :  */</a>
<a name="392"><span class="lineNum">     392 </span>            : static inline bool is_data_mapping(vm_flags_t flags)</a>
<a name="393"><span class="lineNum">     393 </span>            : {</a>
<a name="394"><span class="lineNum">     394 </span><span class="lineNoCov">          0 :         return (flags &amp; (VM_WRITE | VM_SHARED | VM_STACK)) == VM_WRITE;</span></a>
<a name="395"><span class="lineNum">     395 </span>            : }</a>
<a name="396"><span class="lineNum">     396 </span>            : </a>
<a name="397"><span class="lineNum">     397 </span>            : /* mm/util.c */</a>
<a name="398"><span class="lineNum">     398 </span>            : void __vma_link_list(struct mm_struct *mm, struct vm_area_struct *vma,</a>
<a name="399"><span class="lineNum">     399 </span>            :                 struct vm_area_struct *prev);</a>
<a name="400"><span class="lineNum">     400 </span>            : void __vma_unlink_list(struct mm_struct *mm, struct vm_area_struct *vma);</a>
<a name="401"><span class="lineNum">     401 </span>            : struct anon_vma *folio_anon_vma(struct folio *folio);</a>
<a name="402"><span class="lineNum">     402 </span>            : </a>
<a name="403"><span class="lineNum">     403 </span>            : #ifdef CONFIG_MMU</a>
<a name="404"><span class="lineNum">     404 </span>            : void unmap_mapping_folio(struct folio *folio);</a>
<a name="405"><span class="lineNum">     405 </span>            : extern long populate_vma_page_range(struct vm_area_struct *vma,</a>
<a name="406"><span class="lineNum">     406 </span>            :                 unsigned long start, unsigned long end, int *locked);</a>
<a name="407"><span class="lineNum">     407 </span>            : extern long faultin_vma_page_range(struct vm_area_struct *vma,</a>
<a name="408"><span class="lineNum">     408 </span>            :                                    unsigned long start, unsigned long end,</a>
<a name="409"><span class="lineNum">     409 </span>            :                                    bool write, int *locked);</a>
<a name="410"><span class="lineNum">     410 </span>            : extern int mlock_future_check(struct mm_struct *mm, unsigned long flags,</a>
<a name="411"><span class="lineNum">     411 </span>            :                               unsigned long len);</a>
<a name="412"><span class="lineNum">     412 </span>            : /*</a>
<a name="413"><span class="lineNum">     413 </span>            :  * mlock_vma_page() and munlock_vma_page():</a>
<a name="414"><span class="lineNum">     414 </span>            :  * should be called with vma's mmap_lock held for read or write,</a>
<a name="415"><span class="lineNum">     415 </span>            :  * under page table lock for the pte/pmd being added or removed.</a>
<a name="416"><span class="lineNum">     416 </span>            :  *</a>
<a name="417"><span class="lineNum">     417 </span>            :  * mlock is usually called at the end of page_add_*_rmap(),</a>
<a name="418"><span class="lineNum">     418 </span>            :  * munlock at the end of page_remove_rmap(); but new anon</a>
<a name="419"><span class="lineNum">     419 </span>            :  * pages are managed by lru_cache_add_inactive_or_unevictable()</a>
<a name="420"><span class="lineNum">     420 </span>            :  * calling mlock_new_page().</a>
<a name="421"><span class="lineNum">     421 </span>            :  *</a>
<a name="422"><span class="lineNum">     422 </span>            :  * @compound is used to include pmd mappings of THPs, but filter out</a>
<a name="423"><span class="lineNum">     423 </span>            :  * pte mappings of THPs, which cannot be consistently counted: a pte</a>
<a name="424"><span class="lineNum">     424 </span>            :  * mapping of the THP head cannot be distinguished by the page alone.</a>
<a name="425"><span class="lineNum">     425 </span>            :  */</a>
<a name="426"><span class="lineNum">     426 </span>            : void mlock_folio(struct folio *folio);</a>
<a name="427"><span class="lineNum">     427 </span><span class="lineNoCov">          0 : static inline void mlock_vma_folio(struct folio *folio,</span></a>
<a name="428"><span class="lineNum">     428 </span>            :                         struct vm_area_struct *vma, bool compound)</a>
<a name="429"><span class="lineNum">     429 </span>            : {</a>
<a name="430"><span class="lineNum">     430 </span>            :         /*</a>
<a name="431"><span class="lineNum">     431 </span>            :          * The VM_SPECIAL check here serves two purposes.</a>
<a name="432"><span class="lineNum">     432 </span>            :          * 1) VM_IO check prevents migration from double-counting during mlock.</a>
<a name="433"><span class="lineNum">     433 </span>            :          * 2) Although mmap_region() and mlock_fixup() take care that VM_LOCKED</a>
<a name="434"><span class="lineNum">     434 </span>            :          *    is never left set on a VM_SPECIAL vma, there is an interval while</a>
<a name="435"><span class="lineNum">     435 </span>            :          *    file-&gt;f_op-&gt;mmap() is using vm_insert_page(s), when VM_LOCKED may</a>
<a name="436"><span class="lineNum">     436 </span>            :          *    still be set while VM_SPECIAL bits are added: so ignore it then.</a>
<a name="437"><span class="lineNum">     437 </span>            :          */</a>
<a name="438"><span class="lineNum">     438 </span><span class="lineNoCov">          0 :         if (unlikely((vma-&gt;vm_flags &amp; (VM_LOCKED|VM_SPECIAL)) == VM_LOCKED) &amp;&amp;</span></a>
<a name="439"><span class="lineNum">     439 </span><span class="lineNoCov">          0 :             (compound || !folio_test_large(folio)))</span></a>
<a name="440"><span class="lineNum">     440 </span><span class="lineNoCov">          0 :                 mlock_folio(folio);</span></a>
<a name="441"><span class="lineNum">     441 </span><span class="lineNoCov">          0 : }</span></a>
<a name="442"><span class="lineNum">     442 </span>            : </a>
<a name="443"><span class="lineNum">     443 </span>            : static inline void mlock_vma_page(struct page *page,</a>
<a name="444"><span class="lineNum">     444 </span>            :                         struct vm_area_struct *vma, bool compound)</a>
<a name="445"><span class="lineNum">     445 </span>            : {</a>
<a name="446"><span class="lineNum">     446 </span><span class="lineNoCov">          0 :         mlock_vma_folio(page_folio(page), vma, compound);</span></a>
<a name="447"><span class="lineNum">     447 </span>            : }</a>
<a name="448"><span class="lineNum">     448 </span>            : </a>
<a name="449"><span class="lineNum">     449 </span>            : void munlock_page(struct page *page);</a>
<a name="450"><span class="lineNum">     450 </span>            : static inline void munlock_vma_page(struct page *page,</a>
<a name="451"><span class="lineNum">     451 </span>            :                         struct vm_area_struct *vma, bool compound)</a>
<a name="452"><span class="lineNum">     452 </span>            : {</a>
<a name="453"><span class="lineNum">     453 </span><span class="lineNoCov">          0 :         if (unlikely(vma-&gt;vm_flags &amp; VM_LOCKED) &amp;&amp;</span></a>
<a name="454"><span class="lineNum">     454 </span>            :             (compound || !PageTransCompound(page)))</a>
<a name="455"><span class="lineNum">     455 </span><span class="lineNoCov">          0 :                 munlock_page(page);</span></a>
<a name="456"><span class="lineNum">     456 </span>            : }</a>
<a name="457"><span class="lineNum">     457 </span>            : void mlock_new_page(struct page *page);</a>
<a name="458"><span class="lineNum">     458 </span>            : bool need_mlock_page_drain(int cpu);</a>
<a name="459"><span class="lineNum">     459 </span>            : void mlock_page_drain_local(void);</a>
<a name="460"><span class="lineNum">     460 </span>            : void mlock_page_drain_remote(int cpu);</a>
<a name="461"><span class="lineNum">     461 </span>            : </a>
<a name="462"><span class="lineNum">     462 </span>            : extern pmd_t maybe_pmd_mkwrite(pmd_t pmd, struct vm_area_struct *vma);</a>
<a name="463"><span class="lineNum">     463 </span>            : </a>
<a name="464"><span class="lineNum">     464 </span>            : /*</a>
<a name="465"><span class="lineNum">     465 </span>            :  * At what user virtual address is page expected in vma?</a>
<a name="466"><span class="lineNum">     466 </span>            :  * Returns -EFAULT if all of the page is outside the range of vma.</a>
<a name="467"><span class="lineNum">     467 </span>            :  * If page is a compound head, the entire compound page is considered.</a>
<a name="468"><span class="lineNum">     468 </span>            :  */</a>
<a name="469"><span class="lineNum">     469 </span>            : static inline unsigned long</a>
<a name="470"><span class="lineNum">     470 </span><span class="lineNoCov">          0 : vma_address(struct page *page, struct vm_area_struct *vma)</span></a>
<a name="471"><span class="lineNum">     471 </span>            : {</a>
<a name="472"><span class="lineNum">     472 </span>            :         pgoff_t pgoff;</a>
<a name="473"><span class="lineNum">     473 </span>            :         unsigned long address;</a>
<a name="474"><span class="lineNum">     474 </span>            : </a>
<a name="475"><span class="lineNum">     475 </span>            :         VM_BUG_ON_PAGE(PageKsm(page), page);    /* KSM page-&gt;index unusable */</a>
<a name="476"><span class="lineNum">     476 </span><span class="lineNoCov">          0 :         pgoff = page_to_pgoff(page);</span></a>
<a name="477"><span class="lineNum">     477 </span><span class="lineNoCov">          0 :         if (pgoff &gt;= vma-&gt;vm_pgoff) {</span></a>
<a name="478"><span class="lineNum">     478 </span><span class="lineNoCov">          0 :                 address = vma-&gt;vm_start +</span></a>
<a name="479"><span class="lineNum">     479 </span><span class="lineNoCov">          0 :                         ((pgoff - vma-&gt;vm_pgoff) &lt;&lt; PAGE_SHIFT);</span></a>
<a name="480"><span class="lineNum">     480 </span>            :                 /* Check for address beyond vma (or wrapped through 0?) */</a>
<a name="481"><span class="lineNum">     481 </span><span class="lineNoCov">          0 :                 if (address &lt; vma-&gt;vm_start || address &gt;= vma-&gt;vm_end)</span></a>
<a name="482"><span class="lineNum">     482 </span><span class="lineNoCov">          0 :                         address = -EFAULT;</span></a>
<a name="483"><span class="lineNum">     483 </span><span class="lineNoCov">          0 :         } else if (PageHead(page) &amp;&amp;</span></a>
<a name="484"><span class="lineNum">     484 </span><span class="lineNoCov">          0 :                    pgoff + compound_nr(page) - 1 &gt;= vma-&gt;vm_pgoff) {</span></a>
<a name="485"><span class="lineNum">     485 </span>            :                 /* Test above avoids possibility of wrap to 0 on 32-bit */</a>
<a name="486"><span class="lineNum">     486 </span><span class="lineNoCov">          0 :                 address = vma-&gt;vm_start;</span></a>
<a name="487"><span class="lineNum">     487 </span>            :         } else {</a>
<a name="488"><span class="lineNum">     488 </span>            :                 address = -EFAULT;</a>
<a name="489"><span class="lineNum">     489 </span>            :         }</a>
<a name="490"><span class="lineNum">     490 </span><span class="lineNoCov">          0 :         return address;</span></a>
<a name="491"><span class="lineNum">     491 </span>            : }</a>
<a name="492"><span class="lineNum">     492 </span>            : </a>
<a name="493"><span class="lineNum">     493 </span>            : /*</a>
<a name="494"><span class="lineNum">     494 </span>            :  * Then at what user virtual address will none of the range be found in vma?</a>
<a name="495"><span class="lineNum">     495 </span>            :  * Assumes that vma_address() already returned a good starting address.</a>
<a name="496"><span class="lineNum">     496 </span>            :  */</a>
<a name="497"><span class="lineNum">     497 </span>            : static inline unsigned long vma_address_end(struct page_vma_mapped_walk *pvmw)</a>
<a name="498"><span class="lineNum">     498 </span>            : {</a>
<a name="499"><span class="lineNum">     499 </span><span class="lineNoCov">          0 :         struct vm_area_struct *vma = pvmw-&gt;vma;</span></a>
<a name="500"><span class="lineNum">     500 </span>            :         pgoff_t pgoff;</a>
<a name="501"><span class="lineNum">     501 </span>            :         unsigned long address;</a>
<a name="502"><span class="lineNum">     502 </span>            : </a>
<a name="503"><span class="lineNum">     503 </span>            :         /* Common case, plus -&gt;pgoff is invalid for KSM */</a>
<a name="504"><span class="lineNum">     504 </span><span class="lineNoCov">          0 :         if (pvmw-&gt;nr_pages == 1)</span></a>
<a name="505"><span class="lineNum">     505 </span><span class="lineNoCov">          0 :                 return pvmw-&gt;address + PAGE_SIZE;</span></a>
<a name="506"><span class="lineNum">     506 </span>            : </a>
<a name="507"><span class="lineNum">     507 </span><span class="lineNoCov">          0 :         pgoff = pvmw-&gt;pgoff + pvmw-&gt;nr_pages;</span></a>
<a name="508"><span class="lineNum">     508 </span><span class="lineNoCov">          0 :         address = vma-&gt;vm_start + ((pgoff - vma-&gt;vm_pgoff) &lt;&lt; PAGE_SHIFT);</span></a>
<a name="509"><span class="lineNum">     509 </span>            :         /* Check for address beyond vma (or wrapped through 0?) */</a>
<a name="510"><span class="lineNum">     510 </span><span class="lineNoCov">          0 :         if (address &lt; vma-&gt;vm_start || address &gt; vma-&gt;vm_end)</span></a>
<a name="511"><span class="lineNum">     511 </span><span class="lineNoCov">          0 :                 address = vma-&gt;vm_end;</span></a>
<a name="512"><span class="lineNum">     512 </span>            :         return address;</a>
<a name="513"><span class="lineNum">     513 </span>            : }</a>
<a name="514"><span class="lineNum">     514 </span>            : </a>
<a name="515"><span class="lineNum">     515 </span><span class="lineNoCov">          0 : static inline struct file *maybe_unlock_mmap_for_io(struct vm_fault *vmf,</span></a>
<a name="516"><span class="lineNum">     516 </span>            :                                                     struct file *fpin)</a>
<a name="517"><span class="lineNum">     517 </span>            : {</a>
<a name="518"><span class="lineNum">     518 </span><span class="lineNoCov">          0 :         int flags = vmf-&gt;flags;</span></a>
<a name="519"><span class="lineNum">     519 </span>            : </a>
<a name="520"><span class="lineNum">     520 </span><span class="lineNoCov">          0 :         if (fpin)</span></a>
<a name="521"><span class="lineNum">     521 </span>            :                 return fpin;</a>
<a name="522"><span class="lineNum">     522 </span>            : </a>
<a name="523"><span class="lineNum">     523 </span>            :         /*</a>
<a name="524"><span class="lineNum">     524 </span>            :          * FAULT_FLAG_RETRY_NOWAIT means we don't want to wait on page locks or</a>
<a name="525"><span class="lineNum">     525 </span>            :          * anything, so we only pin the file and drop the mmap_lock if only</a>
<a name="526"><span class="lineNum">     526 </span>            :          * FAULT_FLAG_ALLOW_RETRY is set, while this is the first attempt.</a>
<a name="527"><span class="lineNum">     527 </span>            :          */</a>
<a name="528"><span class="lineNum">     528 </span><span class="lineNoCov">          0 :         if (fault_flag_allow_retry_first(flags) &amp;&amp;</span></a>
<a name="529"><span class="lineNum">     529 </span><span class="lineNoCov">          0 :             !(flags &amp; FAULT_FLAG_RETRY_NOWAIT)) {</span></a>
<a name="530"><span class="lineNum">     530 </span><span class="lineNoCov">          0 :                 fpin = get_file(vmf-&gt;vma-&gt;vm_file);</span></a>
<a name="531"><span class="lineNum">     531 </span><span class="lineNoCov">          0 :                 mmap_read_unlock(vmf-&gt;vma-&gt;vm_mm);</span></a>
<a name="532"><span class="lineNum">     532 </span>            :         }</a>
<a name="533"><span class="lineNum">     533 </span>            :         return fpin;</a>
<a name="534"><span class="lineNum">     534 </span>            : }</a>
<a name="535"><span class="lineNum">     535 </span>            : #else /* !CONFIG_MMU */</a>
<a name="536"><span class="lineNum">     536 </span>            : static inline void unmap_mapping_folio(struct folio *folio) { }</a>
<a name="537"><span class="lineNum">     537 </span>            : static inline void mlock_vma_page(struct page *page,</a>
<a name="538"><span class="lineNum">     538 </span>            :                         struct vm_area_struct *vma, bool compound) { }</a>
<a name="539"><span class="lineNum">     539 </span>            : static inline void munlock_vma_page(struct page *page,</a>
<a name="540"><span class="lineNum">     540 </span>            :                         struct vm_area_struct *vma, bool compound) { }</a>
<a name="541"><span class="lineNum">     541 </span>            : static inline void mlock_new_page(struct page *page) { }</a>
<a name="542"><span class="lineNum">     542 </span>            : static inline bool need_mlock_page_drain(int cpu) { return false; }</a>
<a name="543"><span class="lineNum">     543 </span>            : static inline void mlock_page_drain_local(void) { }</a>
<a name="544"><span class="lineNum">     544 </span>            : static inline void mlock_page_drain_remote(int cpu) { }</a>
<a name="545"><span class="lineNum">     545 </span>            : static inline void vunmap_range_noflush(unsigned long start, unsigned long end)</a>
<a name="546"><span class="lineNum">     546 </span>            : {</a>
<a name="547"><span class="lineNum">     547 </span>            : }</a>
<a name="548"><span class="lineNum">     548 </span>            : #endif /* !CONFIG_MMU */</a>
<a name="549"><span class="lineNum">     549 </span>            : </a>
<a name="550"><span class="lineNum">     550 </span>            : /*</a>
<a name="551"><span class="lineNum">     551 </span>            :  * Return the mem_map entry representing the 'offset' subpage within</a>
<a name="552"><span class="lineNum">     552 </span>            :  * the maximally aligned gigantic page 'base'.  Handle any discontiguity</a>
<a name="553"><span class="lineNum">     553 </span>            :  * in the mem_map at MAX_ORDER_NR_PAGES boundaries.</a>
<a name="554"><span class="lineNum">     554 </span>            :  */</a>
<a name="555"><span class="lineNum">     555 </span>            : static inline struct page *mem_map_offset(struct page *base, int offset)</a>
<a name="556"><span class="lineNum">     556 </span>            : {</a>
<a name="557"><span class="lineNum">     557 </span>            :         if (unlikely(offset &gt;= MAX_ORDER_NR_PAGES))</a>
<a name="558"><span class="lineNum">     558 </span>            :                 return nth_page(base, offset);</a>
<a name="559"><span class="lineNum">     559 </span>            :         return base + offset;</a>
<a name="560"><span class="lineNum">     560 </span>            : }</a>
<a name="561"><span class="lineNum">     561 </span>            : </a>
<a name="562"><span class="lineNum">     562 </span>            : /*</a>
<a name="563"><span class="lineNum">     563 </span>            :  * Iterator over all subpages within the maximally aligned gigantic</a>
<a name="564"><span class="lineNum">     564 </span>            :  * page 'base'.  Handle any discontiguity in the mem_map.</a>
<a name="565"><span class="lineNum">     565 </span>            :  */</a>
<a name="566"><span class="lineNum">     566 </span>            : static inline struct page *mem_map_next(struct page *iter,</a>
<a name="567"><span class="lineNum">     567 </span>            :                                                 struct page *base, int offset)</a>
<a name="568"><span class="lineNum">     568 </span>            : {</a>
<a name="569"><span class="lineNum">     569 </span>            :         if (unlikely((offset &amp; (MAX_ORDER_NR_PAGES - 1)) == 0)) {</a>
<a name="570"><span class="lineNum">     570 </span>            :                 unsigned long pfn = page_to_pfn(base) + offset;</a>
<a name="571"><span class="lineNum">     571 </span>            :                 if (!pfn_valid(pfn))</a>
<a name="572"><span class="lineNum">     572 </span>            :                         return NULL;</a>
<a name="573"><span class="lineNum">     573 </span>            :                 return pfn_to_page(pfn);</a>
<a name="574"><span class="lineNum">     574 </span>            :         }</a>
<a name="575"><span class="lineNum">     575 </span>            :         return iter + 1;</a>
<a name="576"><span class="lineNum">     576 </span>            : }</a>
<a name="577"><span class="lineNum">     577 </span>            : </a>
<a name="578"><span class="lineNum">     578 </span>            : /* Memory initialisation debug and verification */</a>
<a name="579"><span class="lineNum">     579 </span>            : enum mminit_level {</a>
<a name="580"><span class="lineNum">     580 </span>            :         MMINIT_WARNING,</a>
<a name="581"><span class="lineNum">     581 </span>            :         MMINIT_VERIFY,</a>
<a name="582"><span class="lineNum">     582 </span>            :         MMINIT_TRACE</a>
<a name="583"><span class="lineNum">     583 </span>            : };</a>
<a name="584"><span class="lineNum">     584 </span>            : </a>
<a name="585"><span class="lineNum">     585 </span>            : #ifdef CONFIG_DEBUG_MEMORY_INIT</a>
<a name="586"><span class="lineNum">     586 </span>            : </a>
<a name="587"><span class="lineNum">     587 </span>            : extern int mminit_loglevel;</a>
<a name="588"><span class="lineNum">     588 </span>            : </a>
<a name="589"><span class="lineNum">     589 </span>            : #define mminit_dprintk(level, prefix, fmt, arg...) \</a>
<a name="590"><span class="lineNum">     590 </span>            : do { \</a>
<a name="591"><span class="lineNum">     591 </span>            :         if (level &lt; mminit_loglevel) { \</a>
<a name="592"><span class="lineNum">     592 </span>            :                 if (level &lt;= MMINIT_WARNING) \</a>
<a name="593"><span class="lineNum">     593 </span>            :                         pr_warn(&quot;mminit::&quot; prefix &quot; &quot; fmt, ##arg);  \</a>
<a name="594"><span class="lineNum">     594 </span>            :                 else \</a>
<a name="595"><span class="lineNum">     595 </span>            :                         printk(KERN_DEBUG &quot;mminit::&quot; prefix &quot; &quot; fmt, ##arg); \</a>
<a name="596"><span class="lineNum">     596 </span>            :         } \</a>
<a name="597"><span class="lineNum">     597 </span>            : } while (0)</a>
<a name="598"><span class="lineNum">     598 </span>            : </a>
<a name="599"><span class="lineNum">     599 </span>            : extern void mminit_verify_pageflags_layout(void);</a>
<a name="600"><span class="lineNum">     600 </span>            : extern void mminit_verify_zonelist(void);</a>
<a name="601"><span class="lineNum">     601 </span>            : #else</a>
<a name="602"><span class="lineNum">     602 </span>            : </a>
<a name="603"><span class="lineNum">     603 </span>            : static inline void mminit_dprintk(enum mminit_level level,</a>
<a name="604"><span class="lineNum">     604 </span>            :                                 const char *prefix, const char *fmt, ...)</a>
<a name="605"><span class="lineNum">     605 </span>            : {</a>
<a name="606"><span class="lineNum">     606 </span>            : }</a>
<a name="607"><span class="lineNum">     607 </span>            : </a>
<a name="608"><span class="lineNum">     608 </span>            : static inline void mminit_verify_pageflags_layout(void)</a>
<a name="609"><span class="lineNum">     609 </span>            : {</a>
<a name="610"><span class="lineNum">     610 </span>            : }</a>
<a name="611"><span class="lineNum">     611 </span>            : </a>
<a name="612"><span class="lineNum">     612 </span>            : static inline void mminit_verify_zonelist(void)</a>
<a name="613"><span class="lineNum">     613 </span>            : {</a>
<a name="614"><span class="lineNum">     614 </span>            : }</a>
<a name="615"><span class="lineNum">     615 </span>            : #endif /* CONFIG_DEBUG_MEMORY_INIT */</a>
<a name="616"><span class="lineNum">     616 </span>            : </a>
<a name="617"><span class="lineNum">     617 </span>            : #define NODE_RECLAIM_NOSCAN     -2</a>
<a name="618"><span class="lineNum">     618 </span>            : #define NODE_RECLAIM_FULL       -1</a>
<a name="619"><span class="lineNum">     619 </span>            : #define NODE_RECLAIM_SOME       0</a>
<a name="620"><span class="lineNum">     620 </span>            : #define NODE_RECLAIM_SUCCESS    1</a>
<a name="621"><span class="lineNum">     621 </span>            : </a>
<a name="622"><span class="lineNum">     622 </span>            : #ifdef CONFIG_NUMA</a>
<a name="623"><span class="lineNum">     623 </span>            : extern int node_reclaim(struct pglist_data *, gfp_t, unsigned int);</a>
<a name="624"><span class="lineNum">     624 </span>            : extern int find_next_best_node(int node, nodemask_t *used_node_mask);</a>
<a name="625"><span class="lineNum">     625 </span>            : #else</a>
<a name="626"><span class="lineNum">     626 </span>            : static inline int node_reclaim(struct pglist_data *pgdat, gfp_t mask,</a>
<a name="627"><span class="lineNum">     627 </span>            :                                 unsigned int order)</a>
<a name="628"><span class="lineNum">     628 </span>            : {</a>
<a name="629"><span class="lineNum">     629 </span>            :         return NODE_RECLAIM_NOSCAN;</a>
<a name="630"><span class="lineNum">     630 </span>            : }</a>
<a name="631"><span class="lineNum">     631 </span>            : static inline int find_next_best_node(int node, nodemask_t *used_node_mask)</a>
<a name="632"><span class="lineNum">     632 </span>            : {</a>
<a name="633"><span class="lineNum">     633 </span>            :         return NUMA_NO_NODE;</a>
<a name="634"><span class="lineNum">     634 </span>            : }</a>
<a name="635"><span class="lineNum">     635 </span>            : #endif</a>
<a name="636"><span class="lineNum">     636 </span>            : </a>
<a name="637"><span class="lineNum">     637 </span>            : extern int hwpoison_filter(struct page *p);</a>
<a name="638"><span class="lineNum">     638 </span>            : </a>
<a name="639"><span class="lineNum">     639 </span>            : extern u32 hwpoison_filter_dev_major;</a>
<a name="640"><span class="lineNum">     640 </span>            : extern u32 hwpoison_filter_dev_minor;</a>
<a name="641"><span class="lineNum">     641 </span>            : extern u64 hwpoison_filter_flags_mask;</a>
<a name="642"><span class="lineNum">     642 </span>            : extern u64 hwpoison_filter_flags_value;</a>
<a name="643"><span class="lineNum">     643 </span>            : extern u64 hwpoison_filter_memcg;</a>
<a name="644"><span class="lineNum">     644 </span>            : extern u32 hwpoison_filter_enable;</a>
<a name="645"><span class="lineNum">     645 </span>            : </a>
<a name="646"><span class="lineNum">     646 </span>            : extern unsigned long  __must_check vm_mmap_pgoff(struct file *, unsigned long,</a>
<a name="647"><span class="lineNum">     647 </span>            :         unsigned long, unsigned long,</a>
<a name="648"><span class="lineNum">     648 </span>            :         unsigned long, unsigned long);</a>
<a name="649"><span class="lineNum">     649 </span>            : </a>
<a name="650"><span class="lineNum">     650 </span>            : extern void set_pageblock_order(void);</a>
<a name="651"><span class="lineNum">     651 </span>            : unsigned int reclaim_clean_pages_from_list(struct zone *zone,</a>
<a name="652"><span class="lineNum">     652 </span>            :                                             struct list_head *page_list);</a>
<a name="653"><span class="lineNum">     653 </span>            : /* The ALLOC_WMARK bits are used as an index to zone-&gt;watermark */</a>
<a name="654"><span class="lineNum">     654 </span>            : #define ALLOC_WMARK_MIN         WMARK_MIN</a>
<a name="655"><span class="lineNum">     655 </span>            : #define ALLOC_WMARK_LOW         WMARK_LOW</a>
<a name="656"><span class="lineNum">     656 </span>            : #define ALLOC_WMARK_HIGH        WMARK_HIGH</a>
<a name="657"><span class="lineNum">     657 </span>            : #define ALLOC_NO_WATERMARKS     0x04 /* don't check watermarks at all */</a>
<a name="658"><span class="lineNum">     658 </span>            : </a>
<a name="659"><span class="lineNum">     659 </span>            : /* Mask to get the watermark bits */</a>
<a name="660"><span class="lineNum">     660 </span>            : #define ALLOC_WMARK_MASK        (ALLOC_NO_WATERMARKS-1)</a>
<a name="661"><span class="lineNum">     661 </span>            : </a>
<a name="662"><span class="lineNum">     662 </span>            : /*</a>
<a name="663"><span class="lineNum">     663 </span>            :  * Only MMU archs have async oom victim reclaim - aka oom_reaper so we</a>
<a name="664"><span class="lineNum">     664 </span>            :  * cannot assume a reduced access to memory reserves is sufficient for</a>
<a name="665"><span class="lineNum">     665 </span>            :  * !MMU</a>
<a name="666"><span class="lineNum">     666 </span>            :  */</a>
<a name="667"><span class="lineNum">     667 </span>            : #ifdef CONFIG_MMU</a>
<a name="668"><span class="lineNum">     668 </span>            : #define ALLOC_OOM               0x08</a>
<a name="669"><span class="lineNum">     669 </span>            : #else</a>
<a name="670"><span class="lineNum">     670 </span>            : #define ALLOC_OOM               ALLOC_NO_WATERMARKS</a>
<a name="671"><span class="lineNum">     671 </span>            : #endif</a>
<a name="672"><span class="lineNum">     672 </span>            : </a>
<a name="673"><span class="lineNum">     673 </span>            : #define ALLOC_HARDER             0x10 /* try to alloc harder */</a>
<a name="674"><span class="lineNum">     674 </span>            : #define ALLOC_HIGH               0x20 /* __GFP_HIGH set */</a>
<a name="675"><span class="lineNum">     675 </span>            : #define ALLOC_CPUSET             0x40 /* check for correct cpuset */</a>
<a name="676"><span class="lineNum">     676 </span>            : #define ALLOC_CMA                0x80 /* allow allocations from CMA areas */</a>
<a name="677"><span class="lineNum">     677 </span>            : #ifdef CONFIG_ZONE_DMA32</a>
<a name="678"><span class="lineNum">     678 </span>            : #define ALLOC_NOFRAGMENT        0x100 /* avoid mixing pageblock types */</a>
<a name="679"><span class="lineNum">     679 </span>            : #else</a>
<a name="680"><span class="lineNum">     680 </span>            : #define ALLOC_NOFRAGMENT          0x0</a>
<a name="681"><span class="lineNum">     681 </span>            : #endif</a>
<a name="682"><span class="lineNum">     682 </span>            : #define ALLOC_KSWAPD            0x800 /* allow waking of kswapd, __GFP_KSWAPD_RECLAIM set */</a>
<a name="683"><span class="lineNum">     683 </span>            : </a>
<a name="684"><span class="lineNum">     684 </span>            : enum ttu_flags;</a>
<a name="685"><span class="lineNum">     685 </span>            : struct tlbflush_unmap_batch;</a>
<a name="686"><span class="lineNum">     686 </span>            : </a>
<a name="687"><span class="lineNum">     687 </span>            : </a>
<a name="688"><span class="lineNum">     688 </span>            : /*</a>
<a name="689"><span class="lineNum">     689 </span>            :  * only for MM internal work items which do not depend on</a>
<a name="690"><span class="lineNum">     690 </span>            :  * any allocations or locks which might depend on allocations</a>
<a name="691"><span class="lineNum">     691 </span>            :  */</a>
<a name="692"><span class="lineNum">     692 </span>            : extern struct workqueue_struct *mm_percpu_wq;</a>
<a name="693"><span class="lineNum">     693 </span>            : </a>
<a name="694"><span class="lineNum">     694 </span>            : #ifdef CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH</a>
<a name="695"><span class="lineNum">     695 </span>            : void try_to_unmap_flush(void);</a>
<a name="696"><span class="lineNum">     696 </span>            : void try_to_unmap_flush_dirty(void);</a>
<a name="697"><span class="lineNum">     697 </span>            : void flush_tlb_batched_pending(struct mm_struct *mm);</a>
<a name="698"><span class="lineNum">     698 </span>            : #else</a>
<a name="699"><span class="lineNum">     699 </span>            : static inline void try_to_unmap_flush(void)</a>
<a name="700"><span class="lineNum">     700 </span>            : {</a>
<a name="701"><span class="lineNum">     701 </span>            : }</a>
<a name="702"><span class="lineNum">     702 </span>            : static inline void try_to_unmap_flush_dirty(void)</a>
<a name="703"><span class="lineNum">     703 </span>            : {</a>
<a name="704"><span class="lineNum">     704 </span>            : }</a>
<a name="705"><span class="lineNum">     705 </span>            : static inline void flush_tlb_batched_pending(struct mm_struct *mm)</a>
<a name="706"><span class="lineNum">     706 </span>            : {</a>
<a name="707"><span class="lineNum">     707 </span>            : }</a>
<a name="708"><span class="lineNum">     708 </span>            : #endif /* CONFIG_ARCH_WANT_BATCHED_UNMAP_TLB_FLUSH */</a>
<a name="709"><span class="lineNum">     709 </span>            : </a>
<a name="710"><span class="lineNum">     710 </span>            : extern const struct trace_print_flags pageflag_names[];</a>
<a name="711"><span class="lineNum">     711 </span>            : extern const struct trace_print_flags vmaflag_names[];</a>
<a name="712"><span class="lineNum">     712 </span>            : extern const struct trace_print_flags gfpflag_names[];</a>
<a name="713"><span class="lineNum">     713 </span>            : </a>
<a name="714"><span class="lineNum">     714 </span>            : static inline bool is_migrate_highatomic(enum migratetype migratetype)</a>
<a name="715"><span class="lineNum">     715 </span>            : {</a>
<a name="716"><span class="lineNum">     716 </span>            :         return migratetype == MIGRATE_HIGHATOMIC;</a>
<a name="717"><span class="lineNum">     717 </span>            : }</a>
<a name="718"><span class="lineNum">     718 </span>            : </a>
<a name="719"><span class="lineNum">     719 </span><span class="lineNoCov">          0 : static inline bool is_migrate_highatomic_page(struct page *page)</span></a>
<a name="720"><span class="lineNum">     720 </span>            : {</a>
<a name="721"><span class="lineNum">     721 </span><span class="lineNoCov">          0 :         return get_pageblock_migratetype(page) == MIGRATE_HIGHATOMIC;</span></a>
<a name="722"><span class="lineNum">     722 </span>            : }</a>
<a name="723"><span class="lineNum">     723 </span>            : </a>
<a name="724"><span class="lineNum">     724 </span>            : void setup_zone_pageset(struct zone *zone);</a>
<a name="725"><span class="lineNum">     725 </span>            : </a>
<a name="726"><span class="lineNum">     726 </span>            : struct migration_target_control {</a>
<a name="727"><span class="lineNum">     727 </span>            :         int nid;                /* preferred node id */</a>
<a name="728"><span class="lineNum">     728 </span>            :         nodemask_t *nmask;</a>
<a name="729"><span class="lineNum">     729 </span>            :         gfp_t gfp_mask;</a>
<a name="730"><span class="lineNum">     730 </span>            : };</a>
<a name="731"><span class="lineNum">     731 </span>            : </a>
<a name="732"><span class="lineNum">     732 </span>            : /*</a>
<a name="733"><span class="lineNum">     733 </span>            :  * mm/vmalloc.c</a>
<a name="734"><span class="lineNum">     734 </span>            :  */</a>
<a name="735"><span class="lineNum">     735 </span>            : #ifdef CONFIG_MMU</a>
<a name="736"><span class="lineNum">     736 </span>            : int vmap_pages_range_noflush(unsigned long addr, unsigned long end,</a>
<a name="737"><span class="lineNum">     737 </span>            :                 pgprot_t prot, struct page **pages, unsigned int page_shift);</a>
<a name="738"><span class="lineNum">     738 </span>            : #else</a>
<a name="739"><span class="lineNum">     739 </span>            : static inline</a>
<a name="740"><span class="lineNum">     740 </span>            : int vmap_pages_range_noflush(unsigned long addr, unsigned long end,</a>
<a name="741"><span class="lineNum">     741 </span>            :                 pgprot_t prot, struct page **pages, unsigned int page_shift)</a>
<a name="742"><span class="lineNum">     742 </span>            : {</a>
<a name="743"><span class="lineNum">     743 </span>            :         return -EINVAL;</a>
<a name="744"><span class="lineNum">     744 </span>            : }</a>
<a name="745"><span class="lineNum">     745 </span>            : #endif</a>
<a name="746"><span class="lineNum">     746 </span>            : </a>
<a name="747"><span class="lineNum">     747 </span>            : void vunmap_range_noflush(unsigned long start, unsigned long end);</a>
<a name="748"><span class="lineNum">     748 </span>            : </a>
<a name="749"><span class="lineNum">     749 </span>            : int numa_migrate_prep(struct page *page, struct vm_area_struct *vma,</a>
<a name="750"><span class="lineNum">     750 </span>            :                       unsigned long addr, int page_nid, int *flags);</a>
<a name="751"><span class="lineNum">     751 </span>            : </a>
<a name="752"><span class="lineNum">     752 </span>            : void free_zone_device_page(struct page *page);</a>
<a name="753"><span class="lineNum">     753 </span>            : </a>
<a name="754"><span class="lineNum">     754 </span>            : /*</a>
<a name="755"><span class="lineNum">     755 </span>            :  * mm/gup.c</a>
<a name="756"><span class="lineNum">     756 </span>            :  */</a>
<a name="757"><span class="lineNum">     757 </span>            : struct folio *try_grab_folio(struct page *page, int refs, unsigned int flags);</a>
<a name="758"><span class="lineNum">     758 </span>            : </a>
<a name="759"><span class="lineNum">     759 </span>            : DECLARE_PER_CPU(struct per_cpu_nodestat, boot_nodestats);</a>
<a name="760"><span class="lineNum">     760 </span>            : </a>
<a name="761"><span class="lineNum">     761 </span>            : #endif  /* __MM_INTERNAL_H */</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
