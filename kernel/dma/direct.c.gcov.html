<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage.info - kernel/dma/direct.c</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">kernel/dma</a> - direct.c<span style="font-size: 80%;"> (source / <a href="direct.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">134</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2022-08-30 20:32:10</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">19</td>
            <td class="headerCovTableEntryLo">0.0 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : // SPDX-License-Identifier: GPL-2.0</a>
<a name="2"><span class="lineNum">       2 </span>            : /*</a>
<a name="3"><span class="lineNum">       3 </span>            :  * Copyright (C) 2018-2020 Christoph Hellwig.</a>
<a name="4"><span class="lineNum">       4 </span>            :  *</a>
<a name="5"><span class="lineNum">       5 </span>            :  * DMA operations that map physical memory directly without using an IOMMU.</a>
<a name="6"><span class="lineNum">       6 </span>            :  */</a>
<a name="7"><span class="lineNum">       7 </span>            : #include &lt;linux/memblock.h&gt; /* for max_pfn */</a>
<a name="8"><span class="lineNum">       8 </span>            : #include &lt;linux/export.h&gt;</a>
<a name="9"><span class="lineNum">       9 </span>            : #include &lt;linux/mm.h&gt;</a>
<a name="10"><span class="lineNum">      10 </span>            : #include &lt;linux/dma-map-ops.h&gt;</a>
<a name="11"><span class="lineNum">      11 </span>            : #include &lt;linux/scatterlist.h&gt;</a>
<a name="12"><span class="lineNum">      12 </span>            : #include &lt;linux/pfn.h&gt;</a>
<a name="13"><span class="lineNum">      13 </span>            : #include &lt;linux/vmalloc.h&gt;</a>
<a name="14"><span class="lineNum">      14 </span>            : #include &lt;linux/set_memory.h&gt;</a>
<a name="15"><span class="lineNum">      15 </span>            : #include &lt;linux/slab.h&gt;</a>
<a name="16"><span class="lineNum">      16 </span>            : #include &quot;direct.h&quot;</a>
<a name="17"><span class="lineNum">      17 </span>            : </a>
<a name="18"><span class="lineNum">      18 </span>            : /*</a>
<a name="19"><span class="lineNum">      19 </span>            :  * Most architectures use ZONE_DMA for the first 16 Megabytes, but some use</a>
<a name="20"><span class="lineNum">      20 </span>            :  * it for entirely different regions. In that case the arch code needs to</a>
<a name="21"><span class="lineNum">      21 </span>            :  * override the variable below for dma-direct to work properly.</a>
<a name="22"><span class="lineNum">      22 </span>            :  */</a>
<a name="23"><span class="lineNum">      23 </span>            : unsigned int zone_dma_bits __ro_after_init = 24;</a>
<a name="24"><span class="lineNum">      24 </span>            : </a>
<a name="25"><span class="lineNum">      25 </span>            : static inline dma_addr_t phys_to_dma_direct(struct device *dev,</a>
<a name="26"><span class="lineNum">      26 </span>            :                 phys_addr_t phys)</a>
<a name="27"><span class="lineNum">      27 </span>            : {</a>
<a name="28"><span class="lineNum">      28 </span><span class="lineNoCov">          0 :         if (force_dma_unencrypted(dev))</span></a>
<a name="29"><span class="lineNum">      29 </span>            :                 return phys_to_dma_unencrypted(dev, phys);</a>
<a name="30"><span class="lineNum">      30 </span><span class="lineNoCov">          0 :         return phys_to_dma(dev, phys);</span></a>
<a name="31"><span class="lineNum">      31 </span>            : }</a>
<a name="32"><span class="lineNum">      32 </span>            : </a>
<a name="33"><span class="lineNum">      33 </span><span class="lineNoCov">          0 : static inline struct page *dma_direct_to_page(struct device *dev,</span></a>
<a name="34"><span class="lineNum">      34 </span>            :                 dma_addr_t dma_addr)</a>
<a name="35"><span class="lineNum">      35 </span>            : {</a>
<a name="36"><span class="lineNum">      36 </span><span class="lineNoCov">          0 :         return pfn_to_page(PHYS_PFN(dma_to_phys(dev, dma_addr)));</span></a>
<a name="37"><span class="lineNum">      37 </span>            : }</a>
<a name="38"><span class="lineNum">      38 </span>            : </a>
<a name="39"><span class="lineNum">      39 </span><span class="lineNoCov">          0 : u64 dma_direct_get_required_mask(struct device *dev)</span></a>
<a name="40"><span class="lineNum">      40 </span>            : {</a>
<a name="41"><span class="lineNum">      41 </span><span class="lineNoCov">          0 :         phys_addr_t phys = (phys_addr_t)(max_pfn - 1) &lt;&lt; PAGE_SHIFT;</span></a>
<a name="42"><span class="lineNum">      42 </span><span class="lineNoCov">          0 :         u64 max_dma = phys_to_dma_direct(dev, phys);</span></a>
<a name="43"><span class="lineNum">      43 </span>            : </a>
<a name="44"><span class="lineNum">      44 </span><span class="lineNoCov">          0 :         return (1ULL &lt;&lt; (fls64(max_dma) - 1)) * 2 - 1;</span></a>
<a name="45"><span class="lineNum">      45 </span>            : }</a>
<a name="46"><span class="lineNum">      46 </span>            : </a>
<a name="47"><span class="lineNum">      47 </span><span class="lineNoCov">          0 : static gfp_t dma_direct_optimal_gfp_mask(struct device *dev, u64 dma_mask,</span></a>
<a name="48"><span class="lineNum">      48 </span>            :                                   u64 *phys_limit)</a>
<a name="49"><span class="lineNum">      49 </span>            : {</a>
<a name="50"><span class="lineNum">      50 </span><span class="lineNoCov">          0 :         u64 dma_limit = min_not_zero(dma_mask, dev-&gt;bus_dma_limit);</span></a>
<a name="51"><span class="lineNum">      51 </span>            : </a>
<a name="52"><span class="lineNum">      52 </span>            :         /*</a>
<a name="53"><span class="lineNum">      53 </span>            :          * Optimistically try the zone that the physical address mask falls</a>
<a name="54"><span class="lineNum">      54 </span>            :          * into first.  If that returns memory that isn't actually addressable</a>
<a name="55"><span class="lineNum">      55 </span>            :          * we will fallback to the next lower zone and try again.</a>
<a name="56"><span class="lineNum">      56 </span>            :          *</a>
<a name="57"><span class="lineNum">      57 </span>            :          * Note that GFP_DMA32 and GFP_DMA are no ops without the corresponding</a>
<a name="58"><span class="lineNum">      58 </span>            :          * zones.</a>
<a name="59"><span class="lineNum">      59 </span>            :          */</a>
<a name="60"><span class="lineNum">      60 </span><span class="lineNoCov">          0 :         *phys_limit = dma_to_phys(dev, dma_limit);</span></a>
<a name="61"><span class="lineNum">      61 </span><span class="lineNoCov">          0 :         if (*phys_limit &lt;= DMA_BIT_MASK(zone_dma_bits))</span></a>
<a name="62"><span class="lineNum">      62 </span>            :                 return GFP_DMA;</a>
<a name="63"><span class="lineNum">      63 </span><span class="lineNoCov">          0 :         if (*phys_limit &lt;= DMA_BIT_MASK(32))</span></a>
<a name="64"><span class="lineNum">      64 </span>            :                 return GFP_DMA32;</a>
<a name="65"><span class="lineNum">      65 </span><span class="lineNoCov">          0 :         return 0;</span></a>
<a name="66"><span class="lineNum">      66 </span>            : }</a>
<a name="67"><span class="lineNum">      67 </span>            : </a>
<a name="68"><span class="lineNum">      68 </span><span class="lineNoCov">          0 : static bool dma_coherent_ok(struct device *dev, phys_addr_t phys, size_t size)</span></a>
<a name="69"><span class="lineNum">      69 </span>            : {</a>
<a name="70"><span class="lineNum">      70 </span><span class="lineNoCov">          0 :         dma_addr_t dma_addr = phys_to_dma_direct(dev, phys);</span></a>
<a name="71"><span class="lineNum">      71 </span>            : </a>
<a name="72"><span class="lineNum">      72 </span><span class="lineNoCov">          0 :         if (dma_addr == DMA_MAPPING_ERROR)</span></a>
<a name="73"><span class="lineNum">      73 </span>            :                 return false;</a>
<a name="74"><span class="lineNum">      74 </span><span class="lineNoCov">          0 :         return dma_addr + size - 1 &lt;=</span></a>
<a name="75"><span class="lineNum">      75 </span><span class="lineNoCov">          0 :                 min_not_zero(dev-&gt;coherent_dma_mask, dev-&gt;bus_dma_limit);</span></a>
<a name="76"><span class="lineNum">      76 </span>            : }</a>
<a name="77"><span class="lineNum">      77 </span>            : </a>
<a name="78"><span class="lineNum">      78 </span>            : static int dma_set_decrypted(struct device *dev, void *vaddr, size_t size)</a>
<a name="79"><span class="lineNum">      79 </span>            : {</a>
<a name="80"><span class="lineNum">      80 </span><span class="lineNoCov">          0 :         if (!force_dma_unencrypted(dev))</span></a>
<a name="81"><span class="lineNum">      81 </span>            :                 return 0;</a>
<a name="82"><span class="lineNum">      82 </span>            :         return set_memory_decrypted((unsigned long)vaddr, 1 &lt;&lt; get_order(size));</a>
<a name="83"><span class="lineNum">      83 </span>            : }</a>
<a name="84"><span class="lineNum">      84 </span>            : </a>
<a name="85"><span class="lineNum">      85 </span>            : static int dma_set_encrypted(struct device *dev, void *vaddr, size_t size)</a>
<a name="86"><span class="lineNum">      86 </span>            : {</a>
<a name="87"><span class="lineNum">      87 </span>            :         int ret;</a>
<a name="88"><span class="lineNum">      88 </span>            : </a>
<a name="89"><span class="lineNum">      89 </span><span class="lineNoCov">          0 :         if (!force_dma_unencrypted(dev))</span></a>
<a name="90"><span class="lineNum">      90 </span>            :                 return 0;</a>
<a name="91"><span class="lineNum">      91 </span>            :         ret = set_memory_encrypted((unsigned long)vaddr, 1 &lt;&lt; get_order(size));</a>
<a name="92"><span class="lineNum">      92 </span>            :         if (ret)</a>
<a name="93"><span class="lineNum">      93 </span>            :                 pr_warn_ratelimited(&quot;leaking DMA memory that can't be re-encrypted\n&quot;);</a>
<a name="94"><span class="lineNum">      94 </span>            :         return ret;</a>
<a name="95"><span class="lineNum">      95 </span>            : }</a>
<a name="96"><span class="lineNum">      96 </span>            : </a>
<a name="97"><span class="lineNum">      97 </span>            : static void __dma_direct_free_pages(struct device *dev, struct page *page,</a>
<a name="98"><span class="lineNum">      98 </span>            :                                     size_t size)</a>
<a name="99"><span class="lineNum">      99 </span>            : {</a>
<a name="100"><span class="lineNum">     100 </span><span class="lineNoCov">          0 :         if (swiotlb_free(dev, page, size))</span></a>
<a name="101"><span class="lineNum">     101 </span>            :                 return;</a>
<a name="102"><span class="lineNum">     102 </span><span class="lineNoCov">          0 :         dma_free_contiguous(dev, page, size);</span></a>
<a name="103"><span class="lineNum">     103 </span>            : }</a>
<a name="104"><span class="lineNum">     104 </span>            : </a>
<a name="105"><span class="lineNum">     105 </span>            : static struct page *dma_direct_alloc_swiotlb(struct device *dev, size_t size)</a>
<a name="106"><span class="lineNum">     106 </span>            : {</a>
<a name="107"><span class="lineNum">     107 </span>            :         struct page *page = swiotlb_alloc(dev, size);</a>
<a name="108"><span class="lineNum">     108 </span>            : </a>
<a name="109"><span class="lineNum">     109 </span>            :         if (page &amp;&amp; !dma_coherent_ok(dev, page_to_phys(page), size)) {</a>
<a name="110"><span class="lineNum">     110 </span>            :                 swiotlb_free(dev, page, size);</a>
<a name="111"><span class="lineNum">     111 </span>            :                 return NULL;</a>
<a name="112"><span class="lineNum">     112 </span>            :         }</a>
<a name="113"><span class="lineNum">     113 </span>            : </a>
<a name="114"><span class="lineNum">     114 </span>            :         return page;</a>
<a name="115"><span class="lineNum">     115 </span>            : }</a>
<a name="116"><span class="lineNum">     116 </span>            : </a>
<a name="117"><span class="lineNum">     117 </span><span class="lineNoCov">          0 : static struct page *__dma_direct_alloc_pages(struct device *dev, size_t size,</span></a>
<a name="118"><span class="lineNum">     118 </span>            :                 gfp_t gfp)</a>
<a name="119"><span class="lineNum">     119 </span>            : {</a>
<a name="120"><span class="lineNum">     120 </span><span class="lineNoCov">          0 :         int node = dev_to_node(dev);</span></a>
<a name="121"><span class="lineNum">     121 </span><span class="lineNoCov">          0 :         struct page *page = NULL;</span></a>
<a name="122"><span class="lineNum">     122 </span>            :         u64 phys_limit;</a>
<a name="123"><span class="lineNum">     123 </span>            : </a>
<a name="124"><span class="lineNum">     124 </span><span class="lineNoCov">          0 :         WARN_ON_ONCE(!PAGE_ALIGNED(size));</span></a>
<a name="125"><span class="lineNum">     125 </span>            : </a>
<a name="126"><span class="lineNum">     126 </span><span class="lineNoCov">          0 :         if (is_swiotlb_for_alloc(dev))</span></a>
<a name="127"><span class="lineNum">     127 </span>            :                 return dma_direct_alloc_swiotlb(dev, size);</a>
<a name="128"><span class="lineNum">     128 </span>            : </a>
<a name="129"><span class="lineNum">     129 </span><span class="lineNoCov">          0 :         gfp |= dma_direct_optimal_gfp_mask(dev, dev-&gt;coherent_dma_mask,</span></a>
<a name="130"><span class="lineNum">     130 </span>            :                                            &amp;phys_limit);</a>
<a name="131"><span class="lineNum">     131 </span><span class="lineNoCov">          0 :         page = dma_alloc_contiguous(dev, size, gfp);</span></a>
<a name="132"><span class="lineNum">     132 </span>            :         if (page &amp;&amp; !dma_coherent_ok(dev, page_to_phys(page), size)) {</a>
<a name="133"><span class="lineNum">     133 </span>            :                 dma_free_contiguous(dev, page, size);</a>
<a name="134"><span class="lineNum">     134 </span>            :                 page = NULL;</a>
<a name="135"><span class="lineNum">     135 </span>            :         }</a>
<a name="136"><span class="lineNum">     136 </span>            : again:</a>
<a name="137"><span class="lineNum">     137 </span>            :         if (!page)</a>
<a name="138"><span class="lineNum">     138 </span><span class="lineNoCov">          0 :                 page = alloc_pages_node(node, gfp, get_order(size));</span></a>
<a name="139"><span class="lineNum">     139 </span><span class="lineNoCov">          0 :         if (page &amp;&amp; !dma_coherent_ok(dev, page_to_phys(page), size)) {</span></a>
<a name="140"><span class="lineNum">     140 </span><span class="lineNoCov">          0 :                 dma_free_contiguous(dev, page, size);</span></a>
<a name="141"><span class="lineNum">     141 </span><span class="lineNoCov">          0 :                 page = NULL;</span></a>
<a name="142"><span class="lineNum">     142 </span>            : </a>
<a name="143"><span class="lineNum">     143 </span>            :                 if (IS_ENABLED(CONFIG_ZONE_DMA32) &amp;&amp;</a>
<a name="144"><span class="lineNum">     144 </span>            :                     phys_limit &lt; DMA_BIT_MASK(64) &amp;&amp;</a>
<a name="145"><span class="lineNum">     145 </span>            :                     !(gfp &amp; (GFP_DMA32 | GFP_DMA))) {</a>
<a name="146"><span class="lineNum">     146 </span>            :                         gfp |= GFP_DMA32;</a>
<a name="147"><span class="lineNum">     147 </span>            :                         goto again;</a>
<a name="148"><span class="lineNum">     148 </span>            :                 }</a>
<a name="149"><span class="lineNum">     149 </span>            : </a>
<a name="150"><span class="lineNum">     150 </span>            :                 if (IS_ENABLED(CONFIG_ZONE_DMA) &amp;&amp; !(gfp &amp; GFP_DMA)) {</a>
<a name="151"><span class="lineNum">     151 </span>            :                         gfp = (gfp &amp; ~GFP_DMA32) | GFP_DMA;</a>
<a name="152"><span class="lineNum">     152 </span>            :                         goto again;</a>
<a name="153"><span class="lineNum">     153 </span>            :                 }</a>
<a name="154"><span class="lineNum">     154 </span>            :         }</a>
<a name="155"><span class="lineNum">     155 </span>            : </a>
<a name="156"><span class="lineNum">     156 </span>            :         return page;</a>
<a name="157"><span class="lineNum">     157 </span>            : }</a>
<a name="158"><span class="lineNum">     158 </span>            : </a>
<a name="159"><span class="lineNum">     159 </span>            : /*</a>
<a name="160"><span class="lineNum">     160 </span>            :  * Check if a potentially blocking operations needs to dip into the atomic</a>
<a name="161"><span class="lineNum">     161 </span>            :  * pools for the given device/gfp.</a>
<a name="162"><span class="lineNum">     162 </span>            :  */</a>
<a name="163"><span class="lineNum">     163 </span>            : static bool dma_direct_use_pool(struct device *dev, gfp_t gfp)</a>
<a name="164"><span class="lineNum">     164 </span>            : {</a>
<a name="165"><span class="lineNum">     165 </span>            :         return !gfpflags_allow_blocking(gfp) &amp;&amp; !is_swiotlb_for_alloc(dev);</a>
<a name="166"><span class="lineNum">     166 </span>            : }</a>
<a name="167"><span class="lineNum">     167 </span>            : </a>
<a name="168"><span class="lineNum">     168 </span>            : static void *dma_direct_alloc_from_pool(struct device *dev, size_t size,</a>
<a name="169"><span class="lineNum">     169 </span>            :                 dma_addr_t *dma_handle, gfp_t gfp)</a>
<a name="170"><span class="lineNum">     170 </span>            : {</a>
<a name="171"><span class="lineNum">     171 </span>            :         struct page *page;</a>
<a name="172"><span class="lineNum">     172 </span>            :         u64 phys_mask;</a>
<a name="173"><span class="lineNum">     173 </span>            :         void *ret;</a>
<a name="174"><span class="lineNum">     174 </span>            : </a>
<a name="175"><span class="lineNum">     175 </span>            :         if (WARN_ON_ONCE(!IS_ENABLED(CONFIG_DMA_COHERENT_POOL)))</a>
<a name="176"><span class="lineNum">     176 </span>            :                 return NULL;</a>
<a name="177"><span class="lineNum">     177 </span>            : </a>
<a name="178"><span class="lineNum">     178 </span>            :         gfp |= dma_direct_optimal_gfp_mask(dev, dev-&gt;coherent_dma_mask,</a>
<a name="179"><span class="lineNum">     179 </span>            :                                            &amp;phys_mask);</a>
<a name="180"><span class="lineNum">     180 </span>            :         page = dma_alloc_from_pool(dev, size, &amp;ret, gfp, dma_coherent_ok);</a>
<a name="181"><span class="lineNum">     181 </span>            :         if (!page)</a>
<a name="182"><span class="lineNum">     182 </span>            :                 return NULL;</a>
<a name="183"><span class="lineNum">     183 </span>            :         *dma_handle = phys_to_dma_direct(dev, page_to_phys(page));</a>
<a name="184"><span class="lineNum">     184 </span>            :         return ret;</a>
<a name="185"><span class="lineNum">     185 </span>            : }</a>
<a name="186"><span class="lineNum">     186 </span>            : </a>
<a name="187"><span class="lineNum">     187 </span><span class="lineNoCov">          0 : static void *dma_direct_alloc_no_mapping(struct device *dev, size_t size,</span></a>
<a name="188"><span class="lineNum">     188 </span>            :                 dma_addr_t *dma_handle, gfp_t gfp)</a>
<a name="189"><span class="lineNum">     189 </span>            : {</a>
<a name="190"><span class="lineNum">     190 </span>            :         struct page *page;</a>
<a name="191"><span class="lineNum">     191 </span>            : </a>
<a name="192"><span class="lineNum">     192 </span><span class="lineNoCov">          0 :         page = __dma_direct_alloc_pages(dev, size, gfp &amp; ~__GFP_ZERO);</span></a>
<a name="193"><span class="lineNum">     193 </span><span class="lineNoCov">          0 :         if (!page)</span></a>
<a name="194"><span class="lineNum">     194 </span>            :                 return NULL;</a>
<a name="195"><span class="lineNum">     195 </span>            : </a>
<a name="196"><span class="lineNum">     196 </span>            :         /* remove any dirty cache lines on the kernel alias */</a>
<a name="197"><span class="lineNum">     197 </span><span class="lineNoCov">          0 :         if (!PageHighMem(page))</span></a>
<a name="198"><span class="lineNum">     198 </span>            :                 arch_dma_prep_coherent(page, size);</a>
<a name="199"><span class="lineNum">     199 </span>            : </a>
<a name="200"><span class="lineNum">     200 </span>            :         /* return the page pointer as the opaque cookie */</a>
<a name="201"><span class="lineNum">     201 </span><span class="lineNoCov">          0 :         *dma_handle = phys_to_dma_direct(dev, page_to_phys(page));</span></a>
<a name="202"><span class="lineNum">     202 </span><span class="lineNoCov">          0 :         return page;</span></a>
<a name="203"><span class="lineNum">     203 </span>            : }</a>
<a name="204"><span class="lineNum">     204 </span>            : </a>
<a name="205"><span class="lineNum">     205 </span><span class="lineNoCov">          0 : void *dma_direct_alloc(struct device *dev, size_t size,</span></a>
<a name="206"><span class="lineNum">     206 </span>            :                 dma_addr_t *dma_handle, gfp_t gfp, unsigned long attrs)</a>
<a name="207"><span class="lineNum">     207 </span>            : {</a>
<a name="208"><span class="lineNum">     208 </span><span class="lineNoCov">          0 :         bool remap = false, set_uncached = false;</span></a>
<a name="209"><span class="lineNum">     209 </span>            :         struct page *page;</a>
<a name="210"><span class="lineNum">     210 </span>            :         void *ret;</a>
<a name="211"><span class="lineNum">     211 </span>            : </a>
<a name="212"><span class="lineNum">     212 </span><span class="lineNoCov">          0 :         size = PAGE_ALIGN(size);</span></a>
<a name="213"><span class="lineNum">     213 </span><span class="lineNoCov">          0 :         if (attrs &amp; DMA_ATTR_NO_WARN)</span></a>
<a name="214"><span class="lineNum">     214 </span><span class="lineNoCov">          0 :                 gfp |= __GFP_NOWARN;</span></a>
<a name="215"><span class="lineNum">     215 </span>            : </a>
<a name="216"><span class="lineNum">     216 </span><span class="lineNoCov">          0 :         if ((attrs &amp; DMA_ATTR_NO_KERNEL_MAPPING) &amp;&amp;</span></a>
<a name="217"><span class="lineNum">     217 </span><span class="lineNoCov">          0 :             !force_dma_unencrypted(dev) &amp;&amp; !is_swiotlb_for_alloc(dev))</span></a>
<a name="218"><span class="lineNum">     218 </span><span class="lineNoCov">          0 :                 return dma_direct_alloc_no_mapping(dev, size, dma_handle, gfp);</span></a>
<a name="219"><span class="lineNum">     219 </span>            : </a>
<a name="220"><span class="lineNum">     220 </span><span class="lineNoCov">          0 :         if (!dev_is_dma_coherent(dev)) {</span></a>
<a name="221"><span class="lineNum">     221 </span>            :                 /*</a>
<a name="222"><span class="lineNum">     222 </span>            :                  * Fallback to the arch handler if it exists.  This should</a>
<a name="223"><span class="lineNum">     223 </span>            :                  * eventually go away.</a>
<a name="224"><span class="lineNum">     224 </span>            :                  */</a>
<a name="225"><span class="lineNum">     225 </span>            :                 if (!IS_ENABLED(CONFIG_ARCH_HAS_DMA_SET_UNCACHED) &amp;&amp;</a>
<a name="226"><span class="lineNum">     226 </span>            :                     !IS_ENABLED(CONFIG_DMA_DIRECT_REMAP) &amp;&amp;</a>
<a name="227"><span class="lineNum">     227 </span>            :                     !IS_ENABLED(CONFIG_DMA_GLOBAL_POOL) &amp;&amp;</a>
<a name="228"><span class="lineNum">     228 </span>            :                     !is_swiotlb_for_alloc(dev))</a>
<a name="229"><span class="lineNum">     229 </span>            :                         return arch_dma_alloc(dev, size, dma_handle, gfp,</a>
<a name="230"><span class="lineNum">     230 </span>            :                                               attrs);</a>
<a name="231"><span class="lineNum">     231 </span>            : </a>
<a name="232"><span class="lineNum">     232 </span>            :                 /*</a>
<a name="233"><span class="lineNum">     233 </span>            :                  * If there is a global pool, always allocate from it for</a>
<a name="234"><span class="lineNum">     234 </span>            :                  * non-coherent devices.</a>
<a name="235"><span class="lineNum">     235 </span>            :                  */</a>
<a name="236"><span class="lineNum">     236 </span>            :                 if (IS_ENABLED(CONFIG_DMA_GLOBAL_POOL))</a>
<a name="237"><span class="lineNum">     237 </span>            :                         return dma_alloc_from_global_coherent(dev, size,</a>
<a name="238"><span class="lineNum">     238 </span>            :                                         dma_handle);</a>
<a name="239"><span class="lineNum">     239 </span>            : </a>
<a name="240"><span class="lineNum">     240 </span>            :                 /*</a>
<a name="241"><span class="lineNum">     241 </span>            :                  * Otherwise remap if the architecture is asking for it.  But</a>
<a name="242"><span class="lineNum">     242 </span>            :                  * given that remapping memory is a blocking operation we'll</a>
<a name="243"><span class="lineNum">     243 </span>            :                  * instead have to dip into the atomic pools.</a>
<a name="244"><span class="lineNum">     244 </span>            :                  */</a>
<a name="245"><span class="lineNum">     245 </span>            :                 remap = IS_ENABLED(CONFIG_DMA_DIRECT_REMAP);</a>
<a name="246"><span class="lineNum">     246 </span>            :                 if (remap) {</a>
<a name="247"><span class="lineNum">     247 </span>            :                         if (dma_direct_use_pool(dev, gfp))</a>
<a name="248"><span class="lineNum">     248 </span>            :                                 return dma_direct_alloc_from_pool(dev, size,</a>
<a name="249"><span class="lineNum">     249 </span>            :                                                 dma_handle, gfp);</a>
<a name="250"><span class="lineNum">     250 </span>            :                 } else {</a>
<a name="251"><span class="lineNum">     251 </span>            :                         if (!IS_ENABLED(CONFIG_ARCH_HAS_DMA_SET_UNCACHED))</a>
<a name="252"><span class="lineNum">     252 </span>            :                                 return NULL;</a>
<a name="253"><span class="lineNum">     253 </span>            :                         set_uncached = true;</a>
<a name="254"><span class="lineNum">     254 </span>            :                 }</a>
<a name="255"><span class="lineNum">     255 </span>            :         }</a>
<a name="256"><span class="lineNum">     256 </span>            : </a>
<a name="257"><span class="lineNum">     257 </span>            :         /*</a>
<a name="258"><span class="lineNum">     258 </span>            :          * Decrypting memory may block, so allocate the memory from the atomic</a>
<a name="259"><span class="lineNum">     259 </span>            :          * pools if we can't block.</a>
<a name="260"><span class="lineNum">     260 </span>            :          */</a>
<a name="261"><span class="lineNum">     261 </span><span class="lineNoCov">          0 :         if (force_dma_unencrypted(dev) &amp;&amp; dma_direct_use_pool(dev, gfp))</span></a>
<a name="262"><span class="lineNum">     262 </span>            :                 return dma_direct_alloc_from_pool(dev, size, dma_handle, gfp);</a>
<a name="263"><span class="lineNum">     263 </span>            : </a>
<a name="264"><span class="lineNum">     264 </span>            :         /* we always manually zero the memory once we are done */</a>
<a name="265"><span class="lineNum">     265 </span><span class="lineNoCov">          0 :         page = __dma_direct_alloc_pages(dev, size, gfp &amp; ~__GFP_ZERO);</span></a>
<a name="266"><span class="lineNum">     266 </span><span class="lineNoCov">          0 :         if (!page)</span></a>
<a name="267"><span class="lineNum">     267 </span>            :                 return NULL;</a>
<a name="268"><span class="lineNum">     268 </span>            : </a>
<a name="269"><span class="lineNum">     269 </span>            :         /*</a>
<a name="270"><span class="lineNum">     270 </span>            :          * dma_alloc_contiguous can return highmem pages depending on a</a>
<a name="271"><span class="lineNum">     271 </span>            :          * combination the cma= arguments and per-arch setup.  These need to be</a>
<a name="272"><span class="lineNum">     272 </span>            :          * remapped to return a kernel virtual address.</a>
<a name="273"><span class="lineNum">     273 </span>            :          */</a>
<a name="274"><span class="lineNum">     274 </span><span class="lineNoCov">          0 :         if (PageHighMem(page)) {</span></a>
<a name="275"><span class="lineNum">     275 </span>            :                 remap = true;</a>
<a name="276"><span class="lineNum">     276 </span>            :                 set_uncached = false;</a>
<a name="277"><span class="lineNum">     277 </span>            :         }</a>
<a name="278"><span class="lineNum">     278 </span>            : </a>
<a name="279"><span class="lineNum">     279 </span>            :         if (remap) {</a>
<a name="280"><span class="lineNum">     280 </span>            :                 pgprot_t prot = dma_pgprot(dev, PAGE_KERNEL, attrs);</a>
<a name="281"><span class="lineNum">     281 </span>            : </a>
<a name="282"><span class="lineNum">     282 </span>            :                 if (force_dma_unencrypted(dev))</a>
<a name="283"><span class="lineNum">     283 </span>            :                         prot = pgprot_decrypted(prot);</a>
<a name="284"><span class="lineNum">     284 </span>            : </a>
<a name="285"><span class="lineNum">     285 </span>            :                 /* remove any dirty cache lines on the kernel alias */</a>
<a name="286"><span class="lineNum">     286 </span>            :                 arch_dma_prep_coherent(page, size);</a>
<a name="287"><span class="lineNum">     287 </span>            : </a>
<a name="288"><span class="lineNum">     288 </span>            :                 /* create a coherent mapping */</a>
<a name="289"><span class="lineNum">     289 </span>            :                 ret = dma_common_contiguous_remap(page, size, prot,</a>
<a name="290"><span class="lineNum">     290 </span>            :                                 __builtin_return_address(0));</a>
<a name="291"><span class="lineNum">     291 </span>            :                 if (!ret)</a>
<a name="292"><span class="lineNum">     292 </span>            :                         goto out_free_pages;</a>
<a name="293"><span class="lineNum">     293 </span>            :         } else {</a>
<a name="294"><span class="lineNum">     294 </span><span class="lineNoCov">          0 :                 ret = page_address(page);</span></a>
<a name="295"><span class="lineNum">     295 </span><span class="lineNoCov">          0 :                 if (dma_set_decrypted(dev, ret, size))</span></a>
<a name="296"><span class="lineNum">     296 </span>            :                         goto out_free_pages;</a>
<a name="297"><span class="lineNum">     297 </span>            :         }</a>
<a name="298"><span class="lineNum">     298 </span>            : </a>
<a name="299"><span class="lineNum">     299 </span><span class="lineNoCov">          0 :         memset(ret, 0, size);</span></a>
<a name="300"><span class="lineNum">     300 </span>            : </a>
<a name="301"><span class="lineNum">     301 </span>            :         if (set_uncached) {</a>
<a name="302"><span class="lineNum">     302 </span>            :                 arch_dma_prep_coherent(page, size);</a>
<a name="303"><span class="lineNum">     303 </span>            :                 ret = arch_dma_set_uncached(ret, size);</a>
<a name="304"><span class="lineNum">     304 </span>            :                 if (IS_ERR(ret))</a>
<a name="305"><span class="lineNum">     305 </span>            :                         goto out_encrypt_pages;</a>
<a name="306"><span class="lineNum">     306 </span>            :         }</a>
<a name="307"><span class="lineNum">     307 </span>            : </a>
<a name="308"><span class="lineNum">     308 </span><span class="lineNoCov">          0 :         *dma_handle = phys_to_dma_direct(dev, page_to_phys(page));</span></a>
<a name="309"><span class="lineNum">     309 </span><span class="lineNoCov">          0 :         return ret;</span></a>
<a name="310"><span class="lineNum">     310 </span>            : </a>
<a name="311"><span class="lineNum">     311 </span>            : out_encrypt_pages:</a>
<a name="312"><span class="lineNum">     312 </span>            :         if (dma_set_encrypted(dev, page_address(page), size))</a>
<a name="313"><span class="lineNum">     313 </span>            :                 return NULL;</a>
<a name="314"><span class="lineNum">     314 </span>            : out_free_pages:</a>
<a name="315"><span class="lineNum">     315 </span>            :         __dma_direct_free_pages(dev, page, size);</a>
<a name="316"><span class="lineNum">     316 </span>            :         return NULL;</a>
<a name="317"><span class="lineNum">     317 </span>            : }</a>
<a name="318"><span class="lineNum">     318 </span>            : </a>
<a name="319"><span class="lineNum">     319 </span><span class="lineNoCov">          0 : void dma_direct_free(struct device *dev, size_t size,</span></a>
<a name="320"><span class="lineNum">     320 </span>            :                 void *cpu_addr, dma_addr_t dma_addr, unsigned long attrs)</a>
<a name="321"><span class="lineNum">     321 </span>            : {</a>
<a name="322"><span class="lineNum">     322 </span><span class="lineNoCov">          0 :         unsigned int page_order = get_order(size);</span></a>
<a name="323"><span class="lineNum">     323 </span>            : </a>
<a name="324"><span class="lineNum">     324 </span><span class="lineNoCov">          0 :         if ((attrs &amp; DMA_ATTR_NO_KERNEL_MAPPING) &amp;&amp;</span></a>
<a name="325"><span class="lineNum">     325 </span><span class="lineNoCov">          0 :             !force_dma_unencrypted(dev) &amp;&amp; !is_swiotlb_for_alloc(dev)) {</span></a>
<a name="326"><span class="lineNum">     326 </span>            :                 /* cpu_addr is a struct page cookie, not a kernel address */</a>
<a name="327"><span class="lineNum">     327 </span><span class="lineNoCov">          0 :                 dma_free_contiguous(dev, cpu_addr, size);</span></a>
<a name="328"><span class="lineNum">     328 </span><span class="lineNoCov">          0 :                 return;</span></a>
<a name="329"><span class="lineNum">     329 </span>            :         }</a>
<a name="330"><span class="lineNum">     330 </span>            : </a>
<a name="331"><span class="lineNum">     331 </span>            :         if (!IS_ENABLED(CONFIG_ARCH_HAS_DMA_SET_UNCACHED) &amp;&amp;</a>
<a name="332"><span class="lineNum">     332 </span>            :             !IS_ENABLED(CONFIG_DMA_DIRECT_REMAP) &amp;&amp;</a>
<a name="333"><span class="lineNum">     333 </span>            :             !IS_ENABLED(CONFIG_DMA_GLOBAL_POOL) &amp;&amp;</a>
<a name="334"><span class="lineNum">     334 </span><span class="lineNoCov">          0 :             !dev_is_dma_coherent(dev) &amp;&amp;</span></a>
<a name="335"><span class="lineNum">     335 </span>            :             !is_swiotlb_for_alloc(dev)) {</a>
<a name="336"><span class="lineNum">     336 </span>            :                 arch_dma_free(dev, size, cpu_addr, dma_addr, attrs);</a>
<a name="337"><span class="lineNum">     337 </span>            :                 return;</a>
<a name="338"><span class="lineNum">     338 </span>            :         }</a>
<a name="339"><span class="lineNum">     339 </span>            : </a>
<a name="340"><span class="lineNum">     340 </span>            :         if (IS_ENABLED(CONFIG_DMA_GLOBAL_POOL) &amp;&amp;</a>
<a name="341"><span class="lineNum">     341 </span>            :             !dev_is_dma_coherent(dev)) {</a>
<a name="342"><span class="lineNum">     342 </span>            :                 if (!dma_release_from_global_coherent(page_order, cpu_addr))</a>
<a name="343"><span class="lineNum">     343 </span>            :                         WARN_ON_ONCE(1);</a>
<a name="344"><span class="lineNum">     344 </span>            :                 return;</a>
<a name="345"><span class="lineNum">     345 </span>            :         }</a>
<a name="346"><span class="lineNum">     346 </span>            : </a>
<a name="347"><span class="lineNum">     347 </span>            :         /* If cpu_addr is not from an atomic pool, dma_free_from_pool() fails */</a>
<a name="348"><span class="lineNum">     348 </span>            :         if (IS_ENABLED(CONFIG_DMA_COHERENT_POOL) &amp;&amp;</a>
<a name="349"><span class="lineNum">     349 </span>            :             dma_free_from_pool(dev, cpu_addr, PAGE_ALIGN(size)))</a>
<a name="350"><span class="lineNum">     350 </span>            :                 return;</a>
<a name="351"><span class="lineNum">     351 </span>            : </a>
<a name="352"><span class="lineNum">     352 </span><span class="lineNoCov">          0 :         if (is_vmalloc_addr(cpu_addr)) {</span></a>
<a name="353"><span class="lineNum">     353 </span><span class="lineNoCov">          0 :                 vunmap(cpu_addr);</span></a>
<a name="354"><span class="lineNum">     354 </span>            :         } else {</a>
<a name="355"><span class="lineNum">     355 </span>            :                 if (IS_ENABLED(CONFIG_ARCH_HAS_DMA_CLEAR_UNCACHED))</a>
<a name="356"><span class="lineNum">     356 </span>            :                         arch_dma_clear_uncached(cpu_addr, size);</a>
<a name="357"><span class="lineNum">     357 </span>            :                 if (dma_set_encrypted(dev, cpu_addr, 1 &lt;&lt; page_order))</a>
<a name="358"><span class="lineNum">     358 </span>            :                         return;</a>
<a name="359"><span class="lineNum">     359 </span>            :         }</a>
<a name="360"><span class="lineNum">     360 </span>            : </a>
<a name="361"><span class="lineNum">     361 </span><span class="lineNoCov">          0 :         __dma_direct_free_pages(dev, dma_direct_to_page(dev, dma_addr), size);</span></a>
<a name="362"><span class="lineNum">     362 </span>            : }</a>
<a name="363"><span class="lineNum">     363 </span>            : </a>
<a name="364"><span class="lineNum">     364 </span><span class="lineNoCov">          0 : struct page *dma_direct_alloc_pages(struct device *dev, size_t size,</span></a>
<a name="365"><span class="lineNum">     365 </span>            :                 dma_addr_t *dma_handle, enum dma_data_direction dir, gfp_t gfp)</a>
<a name="366"><span class="lineNum">     366 </span>            : {</a>
<a name="367"><span class="lineNum">     367 </span>            :         struct page *page;</a>
<a name="368"><span class="lineNum">     368 </span>            :         void *ret;</a>
<a name="369"><span class="lineNum">     369 </span>            : </a>
<a name="370"><span class="lineNum">     370 </span><span class="lineNoCov">          0 :         if (force_dma_unencrypted(dev) &amp;&amp; dma_direct_use_pool(dev, gfp))</span></a>
<a name="371"><span class="lineNum">     371 </span>            :                 return dma_direct_alloc_from_pool(dev, size, dma_handle, gfp);</a>
<a name="372"><span class="lineNum">     372 </span>            : </a>
<a name="373"><span class="lineNum">     373 </span><span class="lineNoCov">          0 :         page = __dma_direct_alloc_pages(dev, size, gfp);</span></a>
<a name="374"><span class="lineNum">     374 </span><span class="lineNoCov">          0 :         if (!page)</span></a>
<a name="375"><span class="lineNum">     375 </span>            :                 return NULL;</a>
<a name="376"><span class="lineNum">     376 </span><span class="lineNoCov">          0 :         if (PageHighMem(page)) {</span></a>
<a name="377"><span class="lineNum">     377 </span>            :                 /*</a>
<a name="378"><span class="lineNum">     378 </span>            :                  * Depending on the cma= arguments and per-arch setup</a>
<a name="379"><span class="lineNum">     379 </span>            :                  * dma_alloc_contiguous could return highmem pages.</a>
<a name="380"><span class="lineNum">     380 </span>            :                  * Without remapping there is no way to return them here,</a>
<a name="381"><span class="lineNum">     381 </span>            :                  * so log an error and fail.</a>
<a name="382"><span class="lineNum">     382 </span>            :                  */</a>
<a name="383"><span class="lineNum">     383 </span>            :                 dev_info(dev, &quot;Rejecting highmem page from CMA.\n&quot;);</a>
<a name="384"><span class="lineNum">     384 </span>            :                 goto out_free_pages;</a>
<a name="385"><span class="lineNum">     385 </span>            :         }</a>
<a name="386"><span class="lineNum">     386 </span>            : </a>
<a name="387"><span class="lineNum">     387 </span><span class="lineNoCov">          0 :         ret = page_address(page);</span></a>
<a name="388"><span class="lineNum">     388 </span><span class="lineNoCov">          0 :         if (dma_set_decrypted(dev, ret, size))</span></a>
<a name="389"><span class="lineNum">     389 </span>            :                 goto out_free_pages;</a>
<a name="390"><span class="lineNum">     390 </span><span class="lineNoCov">          0 :         memset(ret, 0, size);</span></a>
<a name="391"><span class="lineNum">     391 </span><span class="lineNoCov">          0 :         *dma_handle = phys_to_dma_direct(dev, page_to_phys(page));</span></a>
<a name="392"><span class="lineNum">     392 </span><span class="lineNoCov">          0 :         return page;</span></a>
<a name="393"><span class="lineNum">     393 </span>            : out_free_pages:</a>
<a name="394"><span class="lineNum">     394 </span>            :         __dma_direct_free_pages(dev, page, size);</a>
<a name="395"><span class="lineNum">     395 </span>            :         return NULL;</a>
<a name="396"><span class="lineNum">     396 </span>            : }</a>
<a name="397"><span class="lineNum">     397 </span>            : </a>
<a name="398"><span class="lineNum">     398 </span><span class="lineNoCov">          0 : void dma_direct_free_pages(struct device *dev, size_t size,</span></a>
<a name="399"><span class="lineNum">     399 </span>            :                 struct page *page, dma_addr_t dma_addr,</a>
<a name="400"><span class="lineNum">     400 </span>            :                 enum dma_data_direction dir)</a>
<a name="401"><span class="lineNum">     401 </span>            : {</a>
<a name="402"><span class="lineNum">     402 </span><span class="lineNoCov">          0 :         unsigned int page_order = get_order(size);</span></a>
<a name="403"><span class="lineNum">     403 </span><span class="lineNoCov">          0 :         void *vaddr = page_address(page);</span></a>
<a name="404"><span class="lineNum">     404 </span>            : </a>
<a name="405"><span class="lineNum">     405 </span>            :         /* If cpu_addr is not from an atomic pool, dma_free_from_pool() fails */</a>
<a name="406"><span class="lineNum">     406 </span>            :         if (IS_ENABLED(CONFIG_DMA_COHERENT_POOL) &amp;&amp;</a>
<a name="407"><span class="lineNum">     407 </span>            :             dma_free_from_pool(dev, vaddr, size))</a>
<a name="408"><span class="lineNum">     408 </span>            :                 return;</a>
<a name="409"><span class="lineNum">     409 </span>            : </a>
<a name="410"><span class="lineNum">     410 </span><span class="lineNoCov">          0 :         if (dma_set_encrypted(dev, vaddr, 1 &lt;&lt; page_order))</span></a>
<a name="411"><span class="lineNum">     411 </span>            :                 return;</a>
<a name="412"><span class="lineNum">     412 </span><span class="lineNoCov">          0 :         __dma_direct_free_pages(dev, page, size);</span></a>
<a name="413"><span class="lineNum">     413 </span>            : }</a>
<a name="414"><span class="lineNum">     414 </span>            : </a>
<a name="415"><span class="lineNum">     415 </span>            : #if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE) || \</a>
<a name="416"><span class="lineNum">     416 </span>            :     defined(CONFIG_SWIOTLB)</a>
<a name="417"><span class="lineNum">     417 </span>            : void dma_direct_sync_sg_for_device(struct device *dev,</a>
<a name="418"><span class="lineNum">     418 </span>            :                 struct scatterlist *sgl, int nents, enum dma_data_direction dir)</a>
<a name="419"><span class="lineNum">     419 </span>            : {</a>
<a name="420"><span class="lineNum">     420 </span>            :         struct scatterlist *sg;</a>
<a name="421"><span class="lineNum">     421 </span>            :         int i;</a>
<a name="422"><span class="lineNum">     422 </span>            : </a>
<a name="423"><span class="lineNum">     423 </span>            :         for_each_sg(sgl, sg, nents, i) {</a>
<a name="424"><span class="lineNum">     424 </span>            :                 phys_addr_t paddr = dma_to_phys(dev, sg_dma_address(sg));</a>
<a name="425"><span class="lineNum">     425 </span>            : </a>
<a name="426"><span class="lineNum">     426 </span>            :                 if (unlikely(is_swiotlb_buffer(dev, paddr)))</a>
<a name="427"><span class="lineNum">     427 </span>            :                         swiotlb_sync_single_for_device(dev, paddr, sg-&gt;length,</a>
<a name="428"><span class="lineNum">     428 </span>            :                                                        dir);</a>
<a name="429"><span class="lineNum">     429 </span>            : </a>
<a name="430"><span class="lineNum">     430 </span>            :                 if (!dev_is_dma_coherent(dev))</a>
<a name="431"><span class="lineNum">     431 </span>            :                         arch_sync_dma_for_device(paddr, sg-&gt;length,</a>
<a name="432"><span class="lineNum">     432 </span>            :                                         dir);</a>
<a name="433"><span class="lineNum">     433 </span>            :         }</a>
<a name="434"><span class="lineNum">     434 </span>            : }</a>
<a name="435"><span class="lineNum">     435 </span>            : #endif</a>
<a name="436"><span class="lineNum">     436 </span>            : </a>
<a name="437"><span class="lineNum">     437 </span>            : #if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \</a>
<a name="438"><span class="lineNum">     438 </span>            :     defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL) || \</a>
<a name="439"><span class="lineNum">     439 </span>            :     defined(CONFIG_SWIOTLB)</a>
<a name="440"><span class="lineNum">     440 </span>            : void dma_direct_sync_sg_for_cpu(struct device *dev,</a>
<a name="441"><span class="lineNum">     441 </span>            :                 struct scatterlist *sgl, int nents, enum dma_data_direction dir)</a>
<a name="442"><span class="lineNum">     442 </span>            : {</a>
<a name="443"><span class="lineNum">     443 </span>            :         struct scatterlist *sg;</a>
<a name="444"><span class="lineNum">     444 </span>            :         int i;</a>
<a name="445"><span class="lineNum">     445 </span>            : </a>
<a name="446"><span class="lineNum">     446 </span>            :         for_each_sg(sgl, sg, nents, i) {</a>
<a name="447"><span class="lineNum">     447 </span>            :                 phys_addr_t paddr = dma_to_phys(dev, sg_dma_address(sg));</a>
<a name="448"><span class="lineNum">     448 </span>            : </a>
<a name="449"><span class="lineNum">     449 </span>            :                 if (!dev_is_dma_coherent(dev))</a>
<a name="450"><span class="lineNum">     450 </span>            :                         arch_sync_dma_for_cpu(paddr, sg-&gt;length, dir);</a>
<a name="451"><span class="lineNum">     451 </span>            : </a>
<a name="452"><span class="lineNum">     452 </span>            :                 if (unlikely(is_swiotlb_buffer(dev, paddr)))</a>
<a name="453"><span class="lineNum">     453 </span>            :                         swiotlb_sync_single_for_cpu(dev, paddr, sg-&gt;length,</a>
<a name="454"><span class="lineNum">     454 </span>            :                                                     dir);</a>
<a name="455"><span class="lineNum">     455 </span>            : </a>
<a name="456"><span class="lineNum">     456 </span>            :                 if (dir == DMA_FROM_DEVICE)</a>
<a name="457"><span class="lineNum">     457 </span>            :                         arch_dma_mark_clean(paddr, sg-&gt;length);</a>
<a name="458"><span class="lineNum">     458 </span>            :         }</a>
<a name="459"><span class="lineNum">     459 </span>            : </a>
<a name="460"><span class="lineNum">     460 </span>            :         if (!dev_is_dma_coherent(dev))</a>
<a name="461"><span class="lineNum">     461 </span>            :                 arch_sync_dma_for_cpu_all();</a>
<a name="462"><span class="lineNum">     462 </span>            : }</a>
<a name="463"><span class="lineNum">     463 </span>            : </a>
<a name="464"><span class="lineNum">     464 </span>            : void dma_direct_unmap_sg(struct device *dev, struct scatterlist *sgl,</a>
<a name="465"><span class="lineNum">     465 </span>            :                 int nents, enum dma_data_direction dir, unsigned long attrs)</a>
<a name="466"><span class="lineNum">     466 </span>            : {</a>
<a name="467"><span class="lineNum">     467 </span>            :         struct scatterlist *sg;</a>
<a name="468"><span class="lineNum">     468 </span>            :         int i;</a>
<a name="469"><span class="lineNum">     469 </span>            : </a>
<a name="470"><span class="lineNum">     470 </span>            :         for_each_sg(sgl, sg, nents, i)</a>
<a name="471"><span class="lineNum">     471 </span>            :                 dma_direct_unmap_page(dev, sg-&gt;dma_address, sg_dma_len(sg), dir,</a>
<a name="472"><span class="lineNum">     472 </span>            :                              attrs);</a>
<a name="473"><span class="lineNum">     473 </span>            : }</a>
<a name="474"><span class="lineNum">     474 </span>            : #endif</a>
<a name="475"><span class="lineNum">     475 </span>            : </a>
<a name="476"><span class="lineNum">     476 </span><span class="lineNoCov">          0 : int dma_direct_map_sg(struct device *dev, struct scatterlist *sgl, int nents,</span></a>
<a name="477"><span class="lineNum">     477 </span>            :                 enum dma_data_direction dir, unsigned long attrs)</a>
<a name="478"><span class="lineNum">     478 </span>            : {</a>
<a name="479"><span class="lineNum">     479 </span>            :         int i;</a>
<a name="480"><span class="lineNum">     480 </span>            :         struct scatterlist *sg;</a>
<a name="481"><span class="lineNum">     481 </span>            : </a>
<a name="482"><span class="lineNum">     482 </span><span class="lineNoCov">          0 :         for_each_sg(sgl, sg, nents, i) {</span></a>
<a name="483"><span class="lineNum">     483 </span><span class="lineNoCov">          0 :                 sg-&gt;dma_address = dma_direct_map_page(dev, sg_page(sg),</span></a>
<a name="484"><span class="lineNum">     484 </span><span class="lineNoCov">          0 :                                 sg-&gt;offset, sg-&gt;length, dir, attrs);</span></a>
<a name="485"><span class="lineNum">     485 </span><span class="lineNoCov">          0 :                 if (sg-&gt;dma_address == DMA_MAPPING_ERROR)</span></a>
<a name="486"><span class="lineNum">     486 </span>            :                         goto out_unmap;</a>
<a name="487"><span class="lineNum">     487 </span>            :                 sg_dma_len(sg) = sg-&gt;length;</a>
<a name="488"><span class="lineNum">     488 </span>            :         }</a>
<a name="489"><span class="lineNum">     489 </span>            : </a>
<a name="490"><span class="lineNum">     490 </span>            :         return nents;</a>
<a name="491"><span class="lineNum">     491 </span>            : </a>
<a name="492"><span class="lineNum">     492 </span>            : out_unmap:</a>
<a name="493"><span class="lineNum">     493 </span>            :         dma_direct_unmap_sg(dev, sgl, i, dir, attrs | DMA_ATTR_SKIP_CPU_SYNC);</a>
<a name="494"><span class="lineNum">     494 </span>            :         return -EIO;</a>
<a name="495"><span class="lineNum">     495 </span>            : }</a>
<a name="496"><span class="lineNum">     496 </span>            : </a>
<a name="497"><span class="lineNum">     497 </span><span class="lineNoCov">          0 : dma_addr_t dma_direct_map_resource(struct device *dev, phys_addr_t paddr,</span></a>
<a name="498"><span class="lineNum">     498 </span>            :                 size_t size, enum dma_data_direction dir, unsigned long attrs)</a>
<a name="499"><span class="lineNum">     499 </span>            : {</a>
<a name="500"><span class="lineNum">     500 </span><span class="lineNoCov">          0 :         dma_addr_t dma_addr = paddr;</span></a>
<a name="501"><span class="lineNum">     501 </span>            : </a>
<a name="502"><span class="lineNum">     502 </span><span class="lineNoCov">          0 :         if (unlikely(!dma_capable(dev, dma_addr, size, false))) {</span></a>
<a name="503"><span class="lineNum">     503 </span><span class="lineNoCov">          0 :                 dev_err_once(dev,</span></a>
<a name="504"><span class="lineNum">     504 </span>            :                              &quot;DMA addr %pad+%zu overflow (mask %llx, bus limit %llx).\n&quot;,</a>
<a name="505"><span class="lineNum">     505 </span>            :                              &amp;dma_addr, size, *dev-&gt;dma_mask, dev-&gt;bus_dma_limit);</a>
<a name="506"><span class="lineNum">     506 </span><span class="lineNoCov">          0 :                 WARN_ON_ONCE(1);</span></a>
<a name="507"><span class="lineNum">     507 </span>            :                 return DMA_MAPPING_ERROR;</a>
<a name="508"><span class="lineNum">     508 </span>            :         }</a>
<a name="509"><span class="lineNum">     509 </span>            : </a>
<a name="510"><span class="lineNum">     510 </span>            :         return dma_addr;</a>
<a name="511"><span class="lineNum">     511 </span>            : }</a>
<a name="512"><span class="lineNum">     512 </span>            : </a>
<a name="513"><span class="lineNum">     513 </span><span class="lineNoCov">          0 : int dma_direct_get_sgtable(struct device *dev, struct sg_table *sgt,</span></a>
<a name="514"><span class="lineNum">     514 </span>            :                 void *cpu_addr, dma_addr_t dma_addr, size_t size,</a>
<a name="515"><span class="lineNum">     515 </span>            :                 unsigned long attrs)</a>
<a name="516"><span class="lineNum">     516 </span>            : {</a>
<a name="517"><span class="lineNum">     517 </span><span class="lineNoCov">          0 :         struct page *page = dma_direct_to_page(dev, dma_addr);</span></a>
<a name="518"><span class="lineNum">     518 </span>            :         int ret;</a>
<a name="519"><span class="lineNum">     519 </span>            : </a>
<a name="520"><span class="lineNum">     520 </span><span class="lineNoCov">          0 :         ret = sg_alloc_table(sgt, 1, GFP_KERNEL);</span></a>
<a name="521"><span class="lineNum">     521 </span><span class="lineNoCov">          0 :         if (!ret)</span></a>
<a name="522"><span class="lineNum">     522 </span><span class="lineNoCov">          0 :                 sg_set_page(sgt-&gt;sgl, page, PAGE_ALIGN(size), 0);</span></a>
<a name="523"><span class="lineNum">     523 </span><span class="lineNoCov">          0 :         return ret;</span></a>
<a name="524"><span class="lineNum">     524 </span>            : }</a>
<a name="525"><span class="lineNum">     525 </span>            : </a>
<a name="526"><span class="lineNum">     526 </span><span class="lineNoCov">          0 : bool dma_direct_can_mmap(struct device *dev)</span></a>
<a name="527"><span class="lineNum">     527 </span>            : {</a>
<a name="528"><span class="lineNum">     528 </span><span class="lineNoCov">          0 :         return dev_is_dma_coherent(dev) ||</span></a>
<a name="529"><span class="lineNum">     529 </span>            :                 IS_ENABLED(CONFIG_DMA_NONCOHERENT_MMAP);</a>
<a name="530"><span class="lineNum">     530 </span>            : }</a>
<a name="531"><span class="lineNum">     531 </span>            : </a>
<a name="532"><span class="lineNum">     532 </span><span class="lineNoCov">          0 : int dma_direct_mmap(struct device *dev, struct vm_area_struct *vma,</span></a>
<a name="533"><span class="lineNum">     533 </span>            :                 void *cpu_addr, dma_addr_t dma_addr, size_t size,</a>
<a name="534"><span class="lineNum">     534 </span>            :                 unsigned long attrs)</a>
<a name="535"><span class="lineNum">     535 </span>            : {</a>
<a name="536"><span class="lineNum">     536 </span><span class="lineNoCov">          0 :         unsigned long user_count = vma_pages(vma);</span></a>
<a name="537"><span class="lineNum">     537 </span><span class="lineNoCov">          0 :         unsigned long count = PAGE_ALIGN(size) &gt;&gt; PAGE_SHIFT;</span></a>
<a name="538"><span class="lineNum">     538 </span><span class="lineNoCov">          0 :         unsigned long pfn = PHYS_PFN(dma_to_phys(dev, dma_addr));</span></a>
<a name="539"><span class="lineNum">     539 </span><span class="lineNoCov">          0 :         int ret = -ENXIO;</span></a>
<a name="540"><span class="lineNum">     540 </span>            : </a>
<a name="541"><span class="lineNum">     541 </span><span class="lineNoCov">          0 :         vma-&gt;vm_page_prot = dma_pgprot(dev, vma-&gt;vm_page_prot, attrs);</span></a>
<a name="542"><span class="lineNum">     542 </span><span class="lineNoCov">          0 :         if (force_dma_unencrypted(dev))</span></a>
<a name="543"><span class="lineNum">     543 </span>            :                 vma-&gt;vm_page_prot = pgprot_decrypted(vma-&gt;vm_page_prot);</a>
<a name="544"><span class="lineNum">     544 </span>            : </a>
<a name="545"><span class="lineNum">     545 </span>            :         if (dma_mmap_from_dev_coherent(dev, vma, cpu_addr, size, &amp;ret))</a>
<a name="546"><span class="lineNum">     546 </span>            :                 return ret;</a>
<a name="547"><span class="lineNum">     547 </span><span class="lineNoCov">          0 :         if (dma_mmap_from_global_coherent(vma, cpu_addr, size, &amp;ret))</span></a>
<a name="548"><span class="lineNum">     548 </span>            :                 return ret;</a>
<a name="549"><span class="lineNum">     549 </span>            : </a>
<a name="550"><span class="lineNum">     550 </span><span class="lineNoCov">          0 :         if (vma-&gt;vm_pgoff &gt;= count || user_count &gt; count - vma-&gt;vm_pgoff)</span></a>
<a name="551"><span class="lineNum">     551 </span>            :                 return -ENXIO;</a>
<a name="552"><span class="lineNum">     552 </span><span class="lineNoCov">          0 :         return remap_pfn_range(vma, vma-&gt;vm_start, pfn + vma-&gt;vm_pgoff,</span></a>
<a name="553"><span class="lineNum">     553 </span>            :                         user_count &lt;&lt; PAGE_SHIFT, vma-&gt;vm_page_prot);</a>
<a name="554"><span class="lineNum">     554 </span>            : }</a>
<a name="555"><span class="lineNum">     555 </span>            : </a>
<a name="556"><span class="lineNum">     556 </span><span class="lineNoCov">          0 : int dma_direct_supported(struct device *dev, u64 mask)</span></a>
<a name="557"><span class="lineNum">     557 </span>            : {</a>
<a name="558"><span class="lineNum">     558 </span><span class="lineNoCov">          0 :         u64 min_mask = (max_pfn - 1) &lt;&lt; PAGE_SHIFT;</span></a>
<a name="559"><span class="lineNum">     559 </span>            : </a>
<a name="560"><span class="lineNum">     560 </span>            :         /*</a>
<a name="561"><span class="lineNum">     561 </span>            :          * Because 32-bit DMA masks are so common we expect every architecture</a>
<a name="562"><span class="lineNum">     562 </span>            :          * to be able to satisfy them - either by not supporting more physical</a>
<a name="563"><span class="lineNum">     563 </span>            :          * memory, or by providing a ZONE_DMA32.  If neither is the case, the</a>
<a name="564"><span class="lineNum">     564 </span>            :          * architecture needs to use an IOMMU instead of the direct mapping.</a>
<a name="565"><span class="lineNum">     565 </span>            :          */</a>
<a name="566"><span class="lineNum">     566 </span><span class="lineNoCov">          0 :         if (mask &gt;= DMA_BIT_MASK(32))</span></a>
<a name="567"><span class="lineNum">     567 </span>            :                 return 1;</a>
<a name="568"><span class="lineNum">     568 </span>            : </a>
<a name="569"><span class="lineNum">     569 </span>            :         /*</a>
<a name="570"><span class="lineNum">     570 </span>            :          * This check needs to be against the actual bit mask value, so use</a>
<a name="571"><span class="lineNum">     571 </span>            :          * phys_to_dma_unencrypted() here so that the SME encryption mask isn't</a>
<a name="572"><span class="lineNum">     572 </span>            :          * part of the check.</a>
<a name="573"><span class="lineNum">     573 </span>            :          */</a>
<a name="574"><span class="lineNum">     574 </span>            :         if (IS_ENABLED(CONFIG_ZONE_DMA))</a>
<a name="575"><span class="lineNum">     575 </span>            :                 min_mask = min_t(u64, min_mask, DMA_BIT_MASK(zone_dma_bits));</a>
<a name="576"><span class="lineNum">     576 </span><span class="lineNoCov">          0 :         return mask &gt;= phys_to_dma_unencrypted(dev, min_mask);</span></a>
<a name="577"><span class="lineNum">     577 </span>            : }</a>
<a name="578"><span class="lineNum">     578 </span>            : </a>
<a name="579"><span class="lineNum">     579 </span><span class="lineNoCov">          0 : size_t dma_direct_max_mapping_size(struct device *dev)</span></a>
<a name="580"><span class="lineNum">     580 </span>            : {</a>
<a name="581"><span class="lineNum">     581 </span>            :         /* If SWIOTLB is active, use its maximum mapping size */</a>
<a name="582"><span class="lineNum">     582 </span><span class="lineNoCov">          0 :         if (is_swiotlb_active(dev) &amp;&amp;</span></a>
<a name="583"><span class="lineNum">     583 </span>            :             (dma_addressing_limited(dev) || is_swiotlb_force_bounce(dev)))</a>
<a name="584"><span class="lineNum">     584 </span>            :                 return swiotlb_max_mapping_size(dev);</a>
<a name="585"><span class="lineNum">     585 </span>            :         return SIZE_MAX;</a>
<a name="586"><span class="lineNum">     586 </span>            : }</a>
<a name="587"><span class="lineNum">     587 </span>            : </a>
<a name="588"><span class="lineNum">     588 </span><span class="lineNoCov">          0 : bool dma_direct_need_sync(struct device *dev, dma_addr_t dma_addr)</span></a>
<a name="589"><span class="lineNum">     589 </span>            : {</a>
<a name="590"><span class="lineNum">     590 </span><span class="lineNoCov">          0 :         return !dev_is_dma_coherent(dev) ||</span></a>
<a name="591"><span class="lineNum">     591 </span><span class="lineNoCov">          0 :                is_swiotlb_buffer(dev, dma_to_phys(dev, dma_addr));</span></a>
<a name="592"><span class="lineNum">     592 </span>            : }</a>
<a name="593"><span class="lineNum">     593 </span>            : </a>
<a name="594"><span class="lineNum">     594 </span>            : /**</a>
<a name="595"><span class="lineNum">     595 </span>            :  * dma_direct_set_offset - Assign scalar offset for a single DMA range.</a>
<a name="596"><span class="lineNum">     596 </span>            :  * @dev:        device pointer; needed to &quot;own&quot; the alloced memory.</a>
<a name="597"><span class="lineNum">     597 </span>            :  * @cpu_start:  beginning of memory region covered by this offset.</a>
<a name="598"><span class="lineNum">     598 </span>            :  * @dma_start:  beginning of DMA/PCI region covered by this offset.</a>
<a name="599"><span class="lineNum">     599 </span>            :  * @size:       size of the region.</a>
<a name="600"><span class="lineNum">     600 </span>            :  *</a>
<a name="601"><span class="lineNum">     601 </span>            :  * This is for the simple case of a uniform offset which cannot</a>
<a name="602"><span class="lineNum">     602 </span>            :  * be discovered by &quot;dma-ranges&quot;.</a>
<a name="603"><span class="lineNum">     603 </span>            :  *</a>
<a name="604"><span class="lineNum">     604 </span>            :  * It returns -ENOMEM if out of memory, -EINVAL if a map</a>
<a name="605"><span class="lineNum">     605 </span>            :  * already exists, 0 otherwise.</a>
<a name="606"><span class="lineNum">     606 </span>            :  *</a>
<a name="607"><span class="lineNum">     607 </span>            :  * Note: any call to this from a driver is a bug.  The mapping needs</a>
<a name="608"><span class="lineNum">     608 </span>            :  * to be described by the device tree or other firmware interfaces.</a>
<a name="609"><span class="lineNum">     609 </span>            :  */</a>
<a name="610"><span class="lineNum">     610 </span><span class="lineNoCov">          0 : int dma_direct_set_offset(struct device *dev, phys_addr_t cpu_start,</span></a>
<a name="611"><span class="lineNum">     611 </span>            :                          dma_addr_t dma_start, u64 size)</a>
<a name="612"><span class="lineNum">     612 </span>            : {</a>
<a name="613"><span class="lineNum">     613 </span>            :         struct bus_dma_region *map;</a>
<a name="614"><span class="lineNum">     614 </span><span class="lineNoCov">          0 :         u64 offset = (u64)cpu_start - (u64)dma_start;</span></a>
<a name="615"><span class="lineNum">     615 </span>            : </a>
<a name="616"><span class="lineNum">     616 </span><span class="lineNoCov">          0 :         if (dev-&gt;dma_range_map) {</span></a>
<a name="617"><span class="lineNum">     617 </span><span class="lineNoCov">          0 :                 dev_err(dev, &quot;attempt to add DMA range to existing map\n&quot;);</span></a>
<a name="618"><span class="lineNum">     618 </span><span class="lineNoCov">          0 :                 return -EINVAL;</span></a>
<a name="619"><span class="lineNum">     619 </span>            :         }</a>
<a name="620"><span class="lineNum">     620 </span>            : </a>
<a name="621"><span class="lineNum">     621 </span><span class="lineNoCov">          0 :         if (!offset)</span></a>
<a name="622"><span class="lineNum">     622 </span>            :                 return 0;</a>
<a name="623"><span class="lineNum">     623 </span>            : </a>
<a name="624"><span class="lineNum">     624 </span><span class="lineNoCov">          0 :         map = kcalloc(2, sizeof(*map), GFP_KERNEL);</span></a>
<a name="625"><span class="lineNum">     625 </span><span class="lineNoCov">          0 :         if (!map)</span></a>
<a name="626"><span class="lineNum">     626 </span>            :                 return -ENOMEM;</a>
<a name="627"><span class="lineNum">     627 </span><span class="lineNoCov">          0 :         map[0].cpu_start = cpu_start;</span></a>
<a name="628"><span class="lineNum">     628 </span><span class="lineNoCov">          0 :         map[0].dma_start = dma_start;</span></a>
<a name="629"><span class="lineNum">     629 </span><span class="lineNoCov">          0 :         map[0].offset = offset;</span></a>
<a name="630"><span class="lineNum">     630 </span><span class="lineNoCov">          0 :         map[0].size = size;</span></a>
<a name="631"><span class="lineNum">     631 </span><span class="lineNoCov">          0 :         dev-&gt;dma_range_map = map;</span></a>
<a name="632"><span class="lineNum">     632 </span><span class="lineNoCov">          0 :         return 0;</span></a>
<a name="633"><span class="lineNum">     633 </span>            : }</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
