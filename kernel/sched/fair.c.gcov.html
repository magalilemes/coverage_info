<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage.info - kernel/sched/fair.c</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">kernel/sched</a> - fair.c<span style="font-size: 80%;"> (source / <a href="fair.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">354</td>
            <td class="headerCovTableEntry">536</td>
            <td class="headerCovTableEntryLo">66.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2022-08-30 20:32:10</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">33</td>
            <td class="headerCovTableEntry">62</td>
            <td class="headerCovTableEntryLo">53.2 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : // SPDX-License-Identifier: GPL-2.0</a>
<a name="2"><span class="lineNum">       2 </span>            : /*</a>
<a name="3"><span class="lineNum">       3 </span>            :  * Completely Fair Scheduling (CFS) Class (SCHED_NORMAL/SCHED_BATCH)</a>
<a name="4"><span class="lineNum">       4 </span>            :  *</a>
<a name="5"><span class="lineNum">       5 </span>            :  *  Copyright (C) 2007 Red Hat, Inc., Ingo Molnar &lt;mingo@redhat.com&gt;</a>
<a name="6"><span class="lineNum">       6 </span>            :  *</a>
<a name="7"><span class="lineNum">       7 </span>            :  *  Interactivity improvements by Mike Galbraith</a>
<a name="8"><span class="lineNum">       8 </span>            :  *  (C) 2007 Mike Galbraith &lt;efault@gmx.de&gt;</a>
<a name="9"><span class="lineNum">       9 </span>            :  *</a>
<a name="10"><span class="lineNum">      10 </span>            :  *  Various enhancements by Dmitry Adamushko.</a>
<a name="11"><span class="lineNum">      11 </span>            :  *  (C) 2007 Dmitry Adamushko &lt;dmitry.adamushko@gmail.com&gt;</a>
<a name="12"><span class="lineNum">      12 </span>            :  *</a>
<a name="13"><span class="lineNum">      13 </span>            :  *  Group scheduling enhancements by Srivatsa Vaddagiri</a>
<a name="14"><span class="lineNum">      14 </span>            :  *  Copyright IBM Corporation, 2007</a>
<a name="15"><span class="lineNum">      15 </span>            :  *  Author: Srivatsa Vaddagiri &lt;vatsa@linux.vnet.ibm.com&gt;</a>
<a name="16"><span class="lineNum">      16 </span>            :  *</a>
<a name="17"><span class="lineNum">      17 </span>            :  *  Scaled math optimizations by Thomas Gleixner</a>
<a name="18"><span class="lineNum">      18 </span>            :  *  Copyright (C) 2007, Thomas Gleixner &lt;tglx@linutronix.de&gt;</a>
<a name="19"><span class="lineNum">      19 </span>            :  *</a>
<a name="20"><span class="lineNum">      20 </span>            :  *  Adaptive scheduling granularity, math enhancements by Peter Zijlstra</a>
<a name="21"><span class="lineNum">      21 </span>            :  *  Copyright (C) 2007 Red Hat, Inc., Peter Zijlstra</a>
<a name="22"><span class="lineNum">      22 </span>            :  */</a>
<a name="23"><span class="lineNum">      23 </span>            : #include &lt;linux/energy_model.h&gt;</a>
<a name="24"><span class="lineNum">      24 </span>            : #include &lt;linux/mmap_lock.h&gt;</a>
<a name="25"><span class="lineNum">      25 </span>            : #include &lt;linux/hugetlb_inline.h&gt;</a>
<a name="26"><span class="lineNum">      26 </span>            : #include &lt;linux/jiffies.h&gt;</a>
<a name="27"><span class="lineNum">      27 </span>            : #include &lt;linux/mm_api.h&gt;</a>
<a name="28"><span class="lineNum">      28 </span>            : #include &lt;linux/highmem.h&gt;</a>
<a name="29"><span class="lineNum">      29 </span>            : #include &lt;linux/spinlock_api.h&gt;</a>
<a name="30"><span class="lineNum">      30 </span>            : #include &lt;linux/cpumask_api.h&gt;</a>
<a name="31"><span class="lineNum">      31 </span>            : #include &lt;linux/lockdep_api.h&gt;</a>
<a name="32"><span class="lineNum">      32 </span>            : #include &lt;linux/softirq.h&gt;</a>
<a name="33"><span class="lineNum">      33 </span>            : #include &lt;linux/refcount_api.h&gt;</a>
<a name="34"><span class="lineNum">      34 </span>            : #include &lt;linux/topology.h&gt;</a>
<a name="35"><span class="lineNum">      35 </span>            : #include &lt;linux/sched/clock.h&gt;</a>
<a name="36"><span class="lineNum">      36 </span>            : #include &lt;linux/sched/cond_resched.h&gt;</a>
<a name="37"><span class="lineNum">      37 </span>            : #include &lt;linux/sched/cputime.h&gt;</a>
<a name="38"><span class="lineNum">      38 </span>            : #include &lt;linux/sched/isolation.h&gt;</a>
<a name="39"><span class="lineNum">      39 </span>            : </a>
<a name="40"><span class="lineNum">      40 </span>            : #include &lt;linux/cpuidle.h&gt;</a>
<a name="41"><span class="lineNum">      41 </span>            : #include &lt;linux/interrupt.h&gt;</a>
<a name="42"><span class="lineNum">      42 </span>            : #include &lt;linux/mempolicy.h&gt;</a>
<a name="43"><span class="lineNum">      43 </span>            : #include &lt;linux/mutex_api.h&gt;</a>
<a name="44"><span class="lineNum">      44 </span>            : #include &lt;linux/profile.h&gt;</a>
<a name="45"><span class="lineNum">      45 </span>            : #include &lt;linux/psi.h&gt;</a>
<a name="46"><span class="lineNum">      46 </span>            : #include &lt;linux/ratelimit.h&gt;</a>
<a name="47"><span class="lineNum">      47 </span>            : #include &lt;linux/task_work.h&gt;</a>
<a name="48"><span class="lineNum">      48 </span>            : </a>
<a name="49"><span class="lineNum">      49 </span>            : #include &lt;asm/switch_to.h&gt;</a>
<a name="50"><span class="lineNum">      50 </span>            : </a>
<a name="51"><span class="lineNum">      51 </span>            : #include &lt;linux/sched/cond_resched.h&gt;</a>
<a name="52"><span class="lineNum">      52 </span>            : </a>
<a name="53"><span class="lineNum">      53 </span>            : #include &quot;sched.h&quot;</a>
<a name="54"><span class="lineNum">      54 </span>            : #include &quot;stats.h&quot;</a>
<a name="55"><span class="lineNum">      55 </span>            : #include &quot;autogroup.h&quot;</a>
<a name="56"><span class="lineNum">      56 </span>            : </a>
<a name="57"><span class="lineNum">      57 </span>            : /*</a>
<a name="58"><span class="lineNum">      58 </span>            :  * Targeted preemption latency for CPU-bound tasks:</a>
<a name="59"><span class="lineNum">      59 </span>            :  *</a>
<a name="60"><span class="lineNum">      60 </span>            :  * NOTE: this latency value is not the same as the concept of</a>
<a name="61"><span class="lineNum">      61 </span>            :  * 'timeslice length' - timeslices in CFS are of variable length</a>
<a name="62"><span class="lineNum">      62 </span>            :  * and have no persistent notion like in traditional, time-slice</a>
<a name="63"><span class="lineNum">      63 </span>            :  * based scheduling concepts.</a>
<a name="64"><span class="lineNum">      64 </span>            :  *</a>
<a name="65"><span class="lineNum">      65 </span>            :  * (to see the precise effective timeslice length of your workload,</a>
<a name="66"><span class="lineNum">      66 </span>            :  *  run vmstat and monitor the context-switches (cs) field)</a>
<a name="67"><span class="lineNum">      67 </span>            :  *</a>
<a name="68"><span class="lineNum">      68 </span>            :  * (default: 6ms * (1 + ilog(ncpus)), units: nanoseconds)</a>
<a name="69"><span class="lineNum">      69 </span>            :  */</a>
<a name="70"><span class="lineNum">      70 </span>            : unsigned int sysctl_sched_latency                       = 6000000ULL;</a>
<a name="71"><span class="lineNum">      71 </span>            : static unsigned int normalized_sysctl_sched_latency     = 6000000ULL;</a>
<a name="72"><span class="lineNum">      72 </span>            : </a>
<a name="73"><span class="lineNum">      73 </span>            : /*</a>
<a name="74"><span class="lineNum">      74 </span>            :  * The initial- and re-scaling of tunables is configurable</a>
<a name="75"><span class="lineNum">      75 </span>            :  *</a>
<a name="76"><span class="lineNum">      76 </span>            :  * Options are:</a>
<a name="77"><span class="lineNum">      77 </span>            :  *</a>
<a name="78"><span class="lineNum">      78 </span>            :  *   SCHED_TUNABLESCALING_NONE - unscaled, always *1</a>
<a name="79"><span class="lineNum">      79 </span>            :  *   SCHED_TUNABLESCALING_LOG - scaled logarithmical, *1+ilog(ncpus)</a>
<a name="80"><span class="lineNum">      80 </span>            :  *   SCHED_TUNABLESCALING_LINEAR - scaled linear, *ncpus</a>
<a name="81"><span class="lineNum">      81 </span>            :  *</a>
<a name="82"><span class="lineNum">      82 </span>            :  * (default SCHED_TUNABLESCALING_LOG = *(1+ilog(ncpus))</a>
<a name="83"><span class="lineNum">      83 </span>            :  */</a>
<a name="84"><span class="lineNum">      84 </span>            : unsigned int sysctl_sched_tunable_scaling = SCHED_TUNABLESCALING_LOG;</a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span>            : /*</a>
<a name="87"><span class="lineNum">      87 </span>            :  * Minimal preemption granularity for CPU-bound tasks:</a>
<a name="88"><span class="lineNum">      88 </span>            :  *</a>
<a name="89"><span class="lineNum">      89 </span>            :  * (default: 0.75 msec * (1 + ilog(ncpus)), units: nanoseconds)</a>
<a name="90"><span class="lineNum">      90 </span>            :  */</a>
<a name="91"><span class="lineNum">      91 </span>            : unsigned int sysctl_sched_min_granularity                       = 750000ULL;</a>
<a name="92"><span class="lineNum">      92 </span>            : static unsigned int normalized_sysctl_sched_min_granularity     = 750000ULL;</a>
<a name="93"><span class="lineNum">      93 </span>            : </a>
<a name="94"><span class="lineNum">      94 </span>            : /*</a>
<a name="95"><span class="lineNum">      95 </span>            :  * Minimal preemption granularity for CPU-bound SCHED_IDLE tasks.</a>
<a name="96"><span class="lineNum">      96 </span>            :  * Applies only when SCHED_IDLE tasks compete with normal tasks.</a>
<a name="97"><span class="lineNum">      97 </span>            :  *</a>
<a name="98"><span class="lineNum">      98 </span>            :  * (default: 0.75 msec)</a>
<a name="99"><span class="lineNum">      99 </span>            :  */</a>
<a name="100"><span class="lineNum">     100 </span>            : unsigned int sysctl_sched_idle_min_granularity                  = 750000ULL;</a>
<a name="101"><span class="lineNum">     101 </span>            : </a>
<a name="102"><span class="lineNum">     102 </span>            : /*</a>
<a name="103"><span class="lineNum">     103 </span>            :  * This value is kept at sysctl_sched_latency/sysctl_sched_min_granularity</a>
<a name="104"><span class="lineNum">     104 </span>            :  */</a>
<a name="105"><span class="lineNum">     105 </span>            : static unsigned int sched_nr_latency = 8;</a>
<a name="106"><span class="lineNum">     106 </span>            : </a>
<a name="107"><span class="lineNum">     107 </span>            : /*</a>
<a name="108"><span class="lineNum">     108 </span>            :  * After fork, child runs first. If set to 0 (default) then</a>
<a name="109"><span class="lineNum">     109 </span>            :  * parent will (try to) run first.</a>
<a name="110"><span class="lineNum">     110 </span>            :  */</a>
<a name="111"><span class="lineNum">     111 </span>            : unsigned int sysctl_sched_child_runs_first __read_mostly;</a>
<a name="112"><span class="lineNum">     112 </span>            : </a>
<a name="113"><span class="lineNum">     113 </span>            : /*</a>
<a name="114"><span class="lineNum">     114 </span>            :  * SCHED_OTHER wake-up granularity.</a>
<a name="115"><span class="lineNum">     115 </span>            :  *</a>
<a name="116"><span class="lineNum">     116 </span>            :  * This option delays the preemption effects of decoupled workloads</a>
<a name="117"><span class="lineNum">     117 </span>            :  * and reduces their over-scheduling. Synchronous workloads will still</a>
<a name="118"><span class="lineNum">     118 </span>            :  * have immediate wakeup/sleep latencies.</a>
<a name="119"><span class="lineNum">     119 </span>            :  *</a>
<a name="120"><span class="lineNum">     120 </span>            :  * (default: 1 msec * (1 + ilog(ncpus)), units: nanoseconds)</a>
<a name="121"><span class="lineNum">     121 </span>            :  */</a>
<a name="122"><span class="lineNum">     122 </span>            : unsigned int sysctl_sched_wakeup_granularity                    = 1000000UL;</a>
<a name="123"><span class="lineNum">     123 </span>            : static unsigned int normalized_sysctl_sched_wakeup_granularity  = 1000000UL;</a>
<a name="124"><span class="lineNum">     124 </span>            : </a>
<a name="125"><span class="lineNum">     125 </span>            : const_debug unsigned int sysctl_sched_migration_cost    = 500000UL;</a>
<a name="126"><span class="lineNum">     126 </span>            : </a>
<a name="127"><span class="lineNum">     127 </span>            : int sched_thermal_decay_shift;</a>
<a name="128"><span class="lineNum">     128 </span><span class="lineNoCov">          0 : static int __init setup_sched_thermal_decay_shift(char *str)</span></a>
<a name="129"><span class="lineNum">     129 </span>            : {</a>
<a name="130"><span class="lineNum">     130 </span><span class="lineNoCov">          0 :         int _shift = 0;</span></a>
<a name="131"><span class="lineNum">     131 </span>            : </a>
<a name="132"><span class="lineNum">     132 </span><span class="lineNoCov">          0 :         if (kstrtoint(str, 0, &amp;_shift))</span></a>
<a name="133"><span class="lineNum">     133 </span><span class="lineNoCov">          0 :                 pr_warn(&quot;Unable to set scheduler thermal pressure decay shift parameter\n&quot;);</span></a>
<a name="134"><span class="lineNum">     134 </span>            : </a>
<a name="135"><span class="lineNum">     135 </span><span class="lineNoCov">          0 :         sched_thermal_decay_shift = clamp(_shift, 0, 10);</span></a>
<a name="136"><span class="lineNum">     136 </span><span class="lineNoCov">          0 :         return 1;</span></a>
<a name="137"><span class="lineNum">     137 </span>            : }</a>
<a name="138"><span class="lineNum">     138 </span>            : __setup(&quot;sched_thermal_decay_shift=&quot;, setup_sched_thermal_decay_shift);</a>
<a name="139"><span class="lineNum">     139 </span>            : </a>
<a name="140"><span class="lineNum">     140 </span>            : #ifdef CONFIG_SMP</a>
<a name="141"><span class="lineNum">     141 </span>            : /*</a>
<a name="142"><span class="lineNum">     142 </span>            :  * For asym packing, by default the lower numbered CPU has higher priority.</a>
<a name="143"><span class="lineNum">     143 </span>            :  */</a>
<a name="144"><span class="lineNum">     144 </span>            : int __weak arch_asym_cpu_priority(int cpu)</a>
<a name="145"><span class="lineNum">     145 </span>            : {</a>
<a name="146"><span class="lineNum">     146 </span>            :         return -cpu;</a>
<a name="147"><span class="lineNum">     147 </span>            : }</a>
<a name="148"><span class="lineNum">     148 </span>            : </a>
<a name="149"><span class="lineNum">     149 </span>            : /*</a>
<a name="150"><span class="lineNum">     150 </span>            :  * The margin used when comparing utilization with CPU capacity.</a>
<a name="151"><span class="lineNum">     151 </span>            :  *</a>
<a name="152"><span class="lineNum">     152 </span>            :  * (default: ~20%)</a>
<a name="153"><span class="lineNum">     153 </span>            :  */</a>
<a name="154"><span class="lineNum">     154 </span>            : #define fits_capacity(cap, max) ((cap) * 1280 &lt; (max) * 1024)</a>
<a name="155"><span class="lineNum">     155 </span>            : </a>
<a name="156"><span class="lineNum">     156 </span>            : /*</a>
<a name="157"><span class="lineNum">     157 </span>            :  * The margin used when comparing CPU capacities.</a>
<a name="158"><span class="lineNum">     158 </span>            :  * is 'cap1' noticeably greater than 'cap2'</a>
<a name="159"><span class="lineNum">     159 </span>            :  *</a>
<a name="160"><span class="lineNum">     160 </span>            :  * (default: ~5%)</a>
<a name="161"><span class="lineNum">     161 </span>            :  */</a>
<a name="162"><span class="lineNum">     162 </span>            : #define capacity_greater(cap1, cap2) ((cap1) * 1024 &gt; (cap2) * 1078)</a>
<a name="163"><span class="lineNum">     163 </span>            : #endif</a>
<a name="164"><span class="lineNum">     164 </span>            : </a>
<a name="165"><span class="lineNum">     165 </span>            : #ifdef CONFIG_CFS_BANDWIDTH</a>
<a name="166"><span class="lineNum">     166 </span>            : /*</a>
<a name="167"><span class="lineNum">     167 </span>            :  * Amount of runtime to allocate from global (tg) to local (per-cfs_rq) pool</a>
<a name="168"><span class="lineNum">     168 </span>            :  * each time a cfs_rq requests quota.</a>
<a name="169"><span class="lineNum">     169 </span>            :  *</a>
<a name="170"><span class="lineNum">     170 </span>            :  * Note: in the case that the slice exceeds the runtime remaining (either due</a>
<a name="171"><span class="lineNum">     171 </span>            :  * to consumption or the quota being specified to be smaller than the slice)</a>
<a name="172"><span class="lineNum">     172 </span>            :  * we will always only issue the remaining available time.</a>
<a name="173"><span class="lineNum">     173 </span>            :  *</a>
<a name="174"><span class="lineNum">     174 </span>            :  * (default: 5 msec, units: microseconds)</a>
<a name="175"><span class="lineNum">     175 </span>            :  */</a>
<a name="176"><span class="lineNum">     176 </span>            : unsigned int sysctl_sched_cfs_bandwidth_slice           = 5000UL;</a>
<a name="177"><span class="lineNum">     177 </span>            : #endif</a>
<a name="178"><span class="lineNum">     178 </span>            : </a>
<a name="179"><span class="lineNum">     179 </span>            : static inline void update_load_add(struct load_weight *lw, unsigned long inc)</a>
<a name="180"><span class="lineNum">     180 </span>            : {</a>
<a name="181"><span class="lineNum">     181 </span><span class="lineCov">        725 :         lw-&gt;weight += inc;</span></a>
<a name="182"><span class="lineNum">     182 </span><span class="lineCov">        725 :         lw-&gt;inv_weight = 0;</span></a>
<a name="183"><span class="lineNum">     183 </span>            : }</a>
<a name="184"><span class="lineNum">     184 </span>            : </a>
<a name="185"><span class="lineNum">     185 </span>            : static inline void update_load_sub(struct load_weight *lw, unsigned long dec)</a>
<a name="186"><span class="lineNum">     186 </span>            : {</a>
<a name="187"><span class="lineNum">     187 </span><span class="lineCov">        616 :         lw-&gt;weight -= dec;</span></a>
<a name="188"><span class="lineNum">     188 </span><span class="lineCov">        616 :         lw-&gt;inv_weight = 0;</span></a>
<a name="189"><span class="lineNum">     189 </span>            : }</a>
<a name="190"><span class="lineNum">     190 </span>            : </a>
<a name="191"><span class="lineNum">     191 </span>            : static inline void update_load_set(struct load_weight *lw, unsigned long w)</a>
<a name="192"><span class="lineNum">     192 </span>            : {</a>
<a name="193"><span class="lineNum">     193 </span><span class="lineCov">          4 :         lw-&gt;weight = w;</span></a>
<a name="194"><span class="lineNum">     194 </span><span class="lineCov">          4 :         lw-&gt;inv_weight = 0;</span></a>
<a name="195"><span class="lineNum">     195 </span>            : }</a>
<a name="196"><span class="lineNum">     196 </span>            : </a>
<a name="197"><span class="lineNum">     197 </span>            : /*</a>
<a name="198"><span class="lineNum">     198 </span>            :  * Increase the granularity value when there are more CPUs,</a>
<a name="199"><span class="lineNum">     199 </span>            :  * because with more CPUs the 'effective latency' as visible</a>
<a name="200"><span class="lineNum">     200 </span>            :  * to users decreases. But the relationship is not linear,</a>
<a name="201"><span class="lineNum">     201 </span>            :  * so pick a second-best guess by going with the log2 of the</a>
<a name="202"><span class="lineNum">     202 </span>            :  * number of CPUs.</a>
<a name="203"><span class="lineNum">     203 </span>            :  *</a>
<a name="204"><span class="lineNum">     204 </span>            :  * This idea comes from the SD scheduler of Con Kolivas:</a>
<a name="205"><span class="lineNum">     205 </span>            :  */</a>
<a name="206"><span class="lineNum">     206 </span>            : static unsigned int get_update_sysctl_factor(void)</a>
<a name="207"><span class="lineNum">     207 </span>            : {</a>
<a name="208"><span class="lineNum">     208 </span><span class="lineCov">          1 :         unsigned int cpus = min_t(unsigned int, num_online_cpus(), 8);</span></a>
<a name="209"><span class="lineNum">     209 </span>            :         unsigned int factor;</a>
<a name="210"><span class="lineNum">     210 </span>            : </a>
<a name="211"><span class="lineNum">     211 </span>            :         switch (sysctl_sched_tunable_scaling) {</a>
<a name="212"><span class="lineNum">     212 </span>            :         case SCHED_TUNABLESCALING_NONE:</a>
<a name="213"><span class="lineNum">     213 </span>            :                 factor = 1;</a>
<a name="214"><span class="lineNum">     214 </span>            :                 break;</a>
<a name="215"><span class="lineNum">     215 </span>            :         case SCHED_TUNABLESCALING_LINEAR:</a>
<a name="216"><span class="lineNum">     216 </span>            :                 factor = cpus;</a>
<a name="217"><span class="lineNum">     217 </span>            :                 break;</a>
<a name="218"><span class="lineNum">     218 </span>            :         case SCHED_TUNABLESCALING_LOG:</a>
<a name="219"><span class="lineNum">     219 </span>            :         default:</a>
<a name="220"><span class="lineNum">     220 </span>            :                 factor = 1 + ilog2(cpus);</a>
<a name="221"><span class="lineNum">     221 </span>            :                 break;</a>
<a name="222"><span class="lineNum">     222 </span>            :         }</a>
<a name="223"><span class="lineNum">     223 </span>            : </a>
<a name="224"><span class="lineNum">     224 </span>            :         return factor;</a>
<a name="225"><span class="lineNum">     225 </span>            : }</a>
<a name="226"><span class="lineNum">     226 </span>            : </a>
<a name="227"><span class="lineNum">     227 </span>            : static void update_sysctl(void)</a>
<a name="228"><span class="lineNum">     228 </span>            : {</a>
<a name="229"><span class="lineNum">     229 </span><span class="lineCov">          1 :         unsigned int factor = get_update_sysctl_factor();</span></a>
<a name="230"><span class="lineNum">     230 </span>            : </a>
<a name="231"><span class="lineNum">     231 </span>            : #define SET_SYSCTL(name) \</a>
<a name="232"><span class="lineNum">     232 </span>            :         (sysctl_##name = (factor) * normalized_sysctl_##name)</a>
<a name="233"><span class="lineNum">     233 </span><span class="lineCov">          1 :         SET_SYSCTL(sched_min_granularity);</span></a>
<a name="234"><span class="lineNum">     234 </span><span class="lineCov">          1 :         SET_SYSCTL(sched_latency);</span></a>
<a name="235"><span class="lineNum">     235 </span><span class="lineCov">          1 :         SET_SYSCTL(sched_wakeup_granularity);</span></a>
<a name="236"><span class="lineNum">     236 </span>            : #undef SET_SYSCTL</a>
<a name="237"><span class="lineNum">     237 </span>            : }</a>
<a name="238"><span class="lineNum">     238 </span>            : </a>
<a name="239"><span class="lineNum">     239 </span><span class="lineCov">          1 : void __init sched_init_granularity(void)</span></a>
<a name="240"><span class="lineNum">     240 </span>            : {</a>
<a name="241"><span class="lineNum">     241 </span>            :         update_sysctl();</a>
<a name="242"><span class="lineNum">     242 </span><span class="lineCov">          1 : }</span></a>
<a name="243"><span class="lineNum">     243 </span>            : </a>
<a name="244"><span class="lineNum">     244 </span>            : #define WMULT_CONST     (~0U)</a>
<a name="245"><span class="lineNum">     245 </span>            : #define WMULT_SHIFT     32</a>
<a name="246"><span class="lineNum">     246 </span>            : </a>
<a name="247"><span class="lineNum">     247 </span>            : static void __update_inv_weight(struct load_weight *lw)</a>
<a name="248"><span class="lineNum">     248 </span>            : {</a>
<a name="249"><span class="lineNum">     249 </span>            :         unsigned long w;</a>
<a name="250"><span class="lineNum">     250 </span>            : </a>
<a name="251"><span class="lineNum">     251 </span><span class="lineCov">        108 :         if (likely(lw-&gt;inv_weight))</span></a>
<a name="252"><span class="lineNum">     252 </span>            :                 return;</a>
<a name="253"><span class="lineNum">     253 </span>            : </a>
<a name="254"><span class="lineNum">     254 </span><span class="lineCov">        108 :         w = scale_load_down(lw-&gt;weight);</span></a>
<a name="255"><span class="lineNum">     255 </span>            : </a>
<a name="256"><span class="lineNum">     256 </span><span class="lineCov">        108 :         if (BITS_PER_LONG &gt; 32 &amp;&amp; unlikely(w &gt;= WMULT_CONST))</span></a>
<a name="257"><span class="lineNum">     257 </span><span class="lineNoCov">          0 :                 lw-&gt;inv_weight = 1;</span></a>
<a name="258"><span class="lineNum">     258 </span><span class="lineCov">        108 :         else if (unlikely(!w))</span></a>
<a name="259"><span class="lineNum">     259 </span><span class="lineNoCov">          0 :                 lw-&gt;inv_weight = WMULT_CONST;</span></a>
<a name="260"><span class="lineNum">     260 </span>            :         else</a>
<a name="261"><span class="lineNum">     261 </span><span class="lineCov">        108 :                 lw-&gt;inv_weight = WMULT_CONST / w;</span></a>
<a name="262"><span class="lineNum">     262 </span>            : }</a>
<a name="263"><span class="lineNum">     263 </span>            : </a>
<a name="264"><span class="lineNum">     264 </span>            : /*</a>
<a name="265"><span class="lineNum">     265 </span>            :  * delta_exec * weight / lw.weight</a>
<a name="266"><span class="lineNum">     266 </span>            :  *   OR</a>
<a name="267"><span class="lineNum">     267 </span>            :  * (delta_exec * (weight * lw-&gt;inv_weight)) &gt;&gt; WMULT_SHIFT</a>
<a name="268"><span class="lineNum">     268 </span>            :  *</a>
<a name="269"><span class="lineNum">     269 </span>            :  * Either weight := NICE_0_LOAD and lw \e sched_prio_to_wmult[], in which case</a>
<a name="270"><span class="lineNum">     270 </span>            :  * we're guaranteed shift stays positive because inv_weight is guaranteed to</a>
<a name="271"><span class="lineNum">     271 </span>            :  * fit 32 bits, and NICE_0_LOAD gives another 10 bits; therefore shift &gt;= 22.</a>
<a name="272"><span class="lineNum">     272 </span>            :  *</a>
<a name="273"><span class="lineNum">     273 </span>            :  * Or, weight =&lt; lw.weight (because lw.weight is the runqueue weight), thus</a>
<a name="274"><span class="lineNum">     274 </span>            :  * weight/lw.weight &lt;= 1, and therefore our shift will also be positive.</a>
<a name="275"><span class="lineNum">     275 </span>            :  */</a>
<a name="276"><span class="lineNum">     276 </span><span class="lineCov">        108 : static u64 __calc_delta(u64 delta_exec, unsigned long weight, struct load_weight *lw)</span></a>
<a name="277"><span class="lineNum">     277 </span>            : {</a>
<a name="278"><span class="lineNum">     278 </span><span class="lineCov">        108 :         u64 fact = scale_load_down(weight);</span></a>
<a name="279"><span class="lineNum">     279 </span><span class="lineCov">        108 :         u32 fact_hi = (u32)(fact &gt;&gt; 32);</span></a>
<a name="280"><span class="lineNum">     280 </span><span class="lineCov">        108 :         int shift = WMULT_SHIFT;</span></a>
<a name="281"><span class="lineNum">     281 </span>            :         int fs;</a>
<a name="282"><span class="lineNum">     282 </span>            : </a>
<a name="283"><span class="lineNum">     283 </span><span class="lineCov">        108 :         __update_inv_weight(lw);</span></a>
<a name="284"><span class="lineNum">     284 </span>            : </a>
<a name="285"><span class="lineNum">     285 </span><span class="lineCov">        108 :         if (unlikely(fact_hi)) {</span></a>
<a name="286"><span class="lineNum">     286 </span><span class="lineNoCov">          0 :                 fs = fls(fact_hi);</span></a>
<a name="287"><span class="lineNum">     287 </span><span class="lineNoCov">          0 :                 shift -= fs;</span></a>
<a name="288"><span class="lineNum">     288 </span><span class="lineNoCov">          0 :                 fact &gt;&gt;= fs;</span></a>
<a name="289"><span class="lineNum">     289 </span>            :         }</a>
<a name="290"><span class="lineNum">     290 </span>            : </a>
<a name="291"><span class="lineNum">     291 </span><span class="lineCov">        216 :         fact = mul_u32_u32(fact, lw-&gt;inv_weight);</span></a>
<a name="292"><span class="lineNum">     292 </span>            : </a>
<a name="293"><span class="lineNum">     293 </span><span class="lineCov">        108 :         fact_hi = (u32)(fact &gt;&gt; 32);</span></a>
<a name="294"><span class="lineNum">     294 </span><span class="lineCov">        108 :         if (fact_hi) {</span></a>
<a name="295"><span class="lineNum">     295 </span><span class="lineNoCov">          0 :                 fs = fls(fact_hi);</span></a>
<a name="296"><span class="lineNum">     296 </span><span class="lineNoCov">          0 :                 shift -= fs;</span></a>
<a name="297"><span class="lineNum">     297 </span><span class="lineNoCov">          0 :                 fact &gt;&gt;= fs;</span></a>
<a name="298"><span class="lineNum">     298 </span>            :         }</a>
<a name="299"><span class="lineNum">     299 </span>            : </a>
<a name="300"><span class="lineNum">     300 </span><span class="lineCov">        216 :         return mul_u64_u32_shr(delta_exec, fact, shift);</span></a>
<a name="301"><span class="lineNum">     301 </span>            : }</a>
<a name="302"><span class="lineNum">     302 </span>            : </a>
<a name="303"><span class="lineNum">     303 </span>            : </a>
<a name="304"><span class="lineNum">     304 </span>            : const struct sched_class fair_sched_class;</a>
<a name="305"><span class="lineNum">     305 </span>            : </a>
<a name="306"><span class="lineNum">     306 </span>            : /**************************************************************</a>
<a name="307"><span class="lineNum">     307 </span>            :  * CFS operations on generic schedulable entities:</a>
<a name="308"><span class="lineNum">     308 </span>            :  */</a>
<a name="309"><span class="lineNum">     309 </span>            : </a>
<a name="310"><span class="lineNum">     310 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="311"><span class="lineNum">     311 </span>            : </a>
<a name="312"><span class="lineNum">     312 </span>            : /* Walk up scheduling entities hierarchy */</a>
<a name="313"><span class="lineNum">     313 </span>            : #define for_each_sched_entity(se) \</a>
<a name="314"><span class="lineNum">     314 </span>            :                 for (; se; se = se-&gt;parent)</a>
<a name="315"><span class="lineNum">     315 </span>            : </a>
<a name="316"><span class="lineNum">     316 </span>            : static inline void cfs_rq_tg_path(struct cfs_rq *cfs_rq, char *path, int len)</a>
<a name="317"><span class="lineNum">     317 </span>            : {</a>
<a name="318"><span class="lineNum">     318 </span>            :         if (!path)</a>
<a name="319"><span class="lineNum">     319 </span>            :                 return;</a>
<a name="320"><span class="lineNum">     320 </span>            : </a>
<a name="321"><span class="lineNum">     321 </span>            :         if (cfs_rq &amp;&amp; task_group_is_autogroup(cfs_rq-&gt;tg))</a>
<a name="322"><span class="lineNum">     322 </span>            :                 autogroup_path(cfs_rq-&gt;tg, path, len);</a>
<a name="323"><span class="lineNum">     323 </span>            :         else if (cfs_rq &amp;&amp; cfs_rq-&gt;tg-&gt;css.cgroup)</a>
<a name="324"><span class="lineNum">     324 </span>            :                 cgroup_path(cfs_rq-&gt;tg-&gt;css.cgroup, path, len);</a>
<a name="325"><span class="lineNum">     325 </span>            :         else</a>
<a name="326"><span class="lineNum">     326 </span>            :                 strlcpy(path, &quot;(null)&quot;, len);</a>
<a name="327"><span class="lineNum">     327 </span>            : }</a>
<a name="328"><span class="lineNum">     328 </span>            : </a>
<a name="329"><span class="lineNum">     329 </span>            : static inline bool list_add_leaf_cfs_rq(struct cfs_rq *cfs_rq)</a>
<a name="330"><span class="lineNum">     330 </span>            : {</a>
<a name="331"><span class="lineNum">     331 </span>            :         struct rq *rq = rq_of(cfs_rq);</a>
<a name="332"><span class="lineNum">     332 </span>            :         int cpu = cpu_of(rq);</a>
<a name="333"><span class="lineNum">     333 </span>            : </a>
<a name="334"><span class="lineNum">     334 </span>            :         if (cfs_rq-&gt;on_list)</a>
<a name="335"><span class="lineNum">     335 </span>            :                 return rq-&gt;tmp_alone_branch == &amp;rq-&gt;leaf_cfs_rq_list;</a>
<a name="336"><span class="lineNum">     336 </span>            : </a>
<a name="337"><span class="lineNum">     337 </span>            :         cfs_rq-&gt;on_list = 1;</a>
<a name="338"><span class="lineNum">     338 </span>            : </a>
<a name="339"><span class="lineNum">     339 </span>            :         /*</a>
<a name="340"><span class="lineNum">     340 </span>            :          * Ensure we either appear before our parent (if already</a>
<a name="341"><span class="lineNum">     341 </span>            :          * enqueued) or force our parent to appear after us when it is</a>
<a name="342"><span class="lineNum">     342 </span>            :          * enqueued. The fact that we always enqueue bottom-up</a>
<a name="343"><span class="lineNum">     343 </span>            :          * reduces this to two cases and a special case for the root</a>
<a name="344"><span class="lineNum">     344 </span>            :          * cfs_rq. Furthermore, it also means that we will always reset</a>
<a name="345"><span class="lineNum">     345 </span>            :          * tmp_alone_branch either when the branch is connected</a>
<a name="346"><span class="lineNum">     346 </span>            :          * to a tree or when we reach the top of the tree</a>
<a name="347"><span class="lineNum">     347 </span>            :          */</a>
<a name="348"><span class="lineNum">     348 </span>            :         if (cfs_rq-&gt;tg-&gt;parent &amp;&amp;</a>
<a name="349"><span class="lineNum">     349 </span>            :             cfs_rq-&gt;tg-&gt;parent-&gt;cfs_rq[cpu]-&gt;on_list) {</a>
<a name="350"><span class="lineNum">     350 </span>            :                 /*</a>
<a name="351"><span class="lineNum">     351 </span>            :                  * If parent is already on the list, we add the child</a>
<a name="352"><span class="lineNum">     352 </span>            :                  * just before. Thanks to circular linked property of</a>
<a name="353"><span class="lineNum">     353 </span>            :                  * the list, this means to put the child at the tail</a>
<a name="354"><span class="lineNum">     354 </span>            :                  * of the list that starts by parent.</a>
<a name="355"><span class="lineNum">     355 </span>            :                  */</a>
<a name="356"><span class="lineNum">     356 </span>            :                 list_add_tail_rcu(&amp;cfs_rq-&gt;leaf_cfs_rq_list,</a>
<a name="357"><span class="lineNum">     357 </span>            :                         &amp;(cfs_rq-&gt;tg-&gt;parent-&gt;cfs_rq[cpu]-&gt;leaf_cfs_rq_list));</a>
<a name="358"><span class="lineNum">     358 </span>            :                 /*</a>
<a name="359"><span class="lineNum">     359 </span>            :                  * The branch is now connected to its tree so we can</a>
<a name="360"><span class="lineNum">     360 </span>            :                  * reset tmp_alone_branch to the beginning of the</a>
<a name="361"><span class="lineNum">     361 </span>            :                  * list.</a>
<a name="362"><span class="lineNum">     362 </span>            :                  */</a>
<a name="363"><span class="lineNum">     363 </span>            :                 rq-&gt;tmp_alone_branch = &amp;rq-&gt;leaf_cfs_rq_list;</a>
<a name="364"><span class="lineNum">     364 </span>            :                 return true;</a>
<a name="365"><span class="lineNum">     365 </span>            :         }</a>
<a name="366"><span class="lineNum">     366 </span>            : </a>
<a name="367"><span class="lineNum">     367 </span>            :         if (!cfs_rq-&gt;tg-&gt;parent) {</a>
<a name="368"><span class="lineNum">     368 </span>            :                 /*</a>
<a name="369"><span class="lineNum">     369 </span>            :                  * cfs rq without parent should be put</a>
<a name="370"><span class="lineNum">     370 </span>            :                  * at the tail of the list.</a>
<a name="371"><span class="lineNum">     371 </span>            :                  */</a>
<a name="372"><span class="lineNum">     372 </span>            :                 list_add_tail_rcu(&amp;cfs_rq-&gt;leaf_cfs_rq_list,</a>
<a name="373"><span class="lineNum">     373 </span>            :                         &amp;rq-&gt;leaf_cfs_rq_list);</a>
<a name="374"><span class="lineNum">     374 </span>            :                 /*</a>
<a name="375"><span class="lineNum">     375 </span>            :                  * We have reach the top of a tree so we can reset</a>
<a name="376"><span class="lineNum">     376 </span>            :                  * tmp_alone_branch to the beginning of the list.</a>
<a name="377"><span class="lineNum">     377 </span>            :                  */</a>
<a name="378"><span class="lineNum">     378 </span>            :                 rq-&gt;tmp_alone_branch = &amp;rq-&gt;leaf_cfs_rq_list;</a>
<a name="379"><span class="lineNum">     379 </span>            :                 return true;</a>
<a name="380"><span class="lineNum">     380 </span>            :         }</a>
<a name="381"><span class="lineNum">     381 </span>            : </a>
<a name="382"><span class="lineNum">     382 </span>            :         /*</a>
<a name="383"><span class="lineNum">     383 </span>            :          * The parent has not already been added so we want to</a>
<a name="384"><span class="lineNum">     384 </span>            :          * make sure that it will be put after us.</a>
<a name="385"><span class="lineNum">     385 </span>            :          * tmp_alone_branch points to the begin of the branch</a>
<a name="386"><span class="lineNum">     386 </span>            :          * where we will add parent.</a>
<a name="387"><span class="lineNum">     387 </span>            :          */</a>
<a name="388"><span class="lineNum">     388 </span>            :         list_add_rcu(&amp;cfs_rq-&gt;leaf_cfs_rq_list, rq-&gt;tmp_alone_branch);</a>
<a name="389"><span class="lineNum">     389 </span>            :         /*</a>
<a name="390"><span class="lineNum">     390 </span>            :          * update tmp_alone_branch to points to the new begin</a>
<a name="391"><span class="lineNum">     391 </span>            :          * of the branch</a>
<a name="392"><span class="lineNum">     392 </span>            :          */</a>
<a name="393"><span class="lineNum">     393 </span>            :         rq-&gt;tmp_alone_branch = &amp;cfs_rq-&gt;leaf_cfs_rq_list;</a>
<a name="394"><span class="lineNum">     394 </span>            :         return false;</a>
<a name="395"><span class="lineNum">     395 </span>            : }</a>
<a name="396"><span class="lineNum">     396 </span>            : </a>
<a name="397"><span class="lineNum">     397 </span>            : static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)</a>
<a name="398"><span class="lineNum">     398 </span>            : {</a>
<a name="399"><span class="lineNum">     399 </span>            :         if (cfs_rq-&gt;on_list) {</a>
<a name="400"><span class="lineNum">     400 </span>            :                 struct rq *rq = rq_of(cfs_rq);</a>
<a name="401"><span class="lineNum">     401 </span>            : </a>
<a name="402"><span class="lineNum">     402 </span>            :                 /*</a>
<a name="403"><span class="lineNum">     403 </span>            :                  * With cfs_rq being unthrottled/throttled during an enqueue,</a>
<a name="404"><span class="lineNum">     404 </span>            :                  * it can happen the tmp_alone_branch points the a leaf that</a>
<a name="405"><span class="lineNum">     405 </span>            :                  * we finally want to del. In this case, tmp_alone_branch moves</a>
<a name="406"><span class="lineNum">     406 </span>            :                  * to the prev element but it will point to rq-&gt;leaf_cfs_rq_list</a>
<a name="407"><span class="lineNum">     407 </span>            :                  * at the end of the enqueue.</a>
<a name="408"><span class="lineNum">     408 </span>            :                  */</a>
<a name="409"><span class="lineNum">     409 </span>            :                 if (rq-&gt;tmp_alone_branch == &amp;cfs_rq-&gt;leaf_cfs_rq_list)</a>
<a name="410"><span class="lineNum">     410 </span>            :                         rq-&gt;tmp_alone_branch = cfs_rq-&gt;leaf_cfs_rq_list.prev;</a>
<a name="411"><span class="lineNum">     411 </span>            : </a>
<a name="412"><span class="lineNum">     412 </span>            :                 list_del_rcu(&amp;cfs_rq-&gt;leaf_cfs_rq_list);</a>
<a name="413"><span class="lineNum">     413 </span>            :                 cfs_rq-&gt;on_list = 0;</a>
<a name="414"><span class="lineNum">     414 </span>            :         }</a>
<a name="415"><span class="lineNum">     415 </span>            : }</a>
<a name="416"><span class="lineNum">     416 </span>            : </a>
<a name="417"><span class="lineNum">     417 </span>            : static inline void assert_list_leaf_cfs_rq(struct rq *rq)</a>
<a name="418"><span class="lineNum">     418 </span>            : {</a>
<a name="419"><span class="lineNum">     419 </span>            :         SCHED_WARN_ON(rq-&gt;tmp_alone_branch != &amp;rq-&gt;leaf_cfs_rq_list);</a>
<a name="420"><span class="lineNum">     420 </span>            : }</a>
<a name="421"><span class="lineNum">     421 </span>            : </a>
<a name="422"><span class="lineNum">     422 </span>            : /* Iterate thr' all leaf cfs_rq's on a runqueue */</a>
<a name="423"><span class="lineNum">     423 </span>            : #define for_each_leaf_cfs_rq_safe(rq, cfs_rq, pos)                      \</a>
<a name="424"><span class="lineNum">     424 </span>            :         list_for_each_entry_safe(cfs_rq, pos, &amp;rq-&gt;leaf_cfs_rq_list,     \</a>
<a name="425"><span class="lineNum">     425 </span>            :                                  leaf_cfs_rq_list)</a>
<a name="426"><span class="lineNum">     426 </span>            : </a>
<a name="427"><span class="lineNum">     427 </span>            : /* Do the two (enqueued) entities belong to the same group ? */</a>
<a name="428"><span class="lineNum">     428 </span>            : static inline struct cfs_rq *</a>
<a name="429"><span class="lineNum">     429 </span>            : is_same_group(struct sched_entity *se, struct sched_entity *pse)</a>
<a name="430"><span class="lineNum">     430 </span>            : {</a>
<a name="431"><span class="lineNum">     431 </span>            :         if (se-&gt;cfs_rq == pse-&gt;cfs_rq)</a>
<a name="432"><span class="lineNum">     432 </span>            :                 return se-&gt;cfs_rq;</a>
<a name="433"><span class="lineNum">     433 </span>            : </a>
<a name="434"><span class="lineNum">     434 </span>            :         return NULL;</a>
<a name="435"><span class="lineNum">     435 </span>            : }</a>
<a name="436"><span class="lineNum">     436 </span>            : </a>
<a name="437"><span class="lineNum">     437 </span>            : static inline struct sched_entity *parent_entity(struct sched_entity *se)</a>
<a name="438"><span class="lineNum">     438 </span>            : {</a>
<a name="439"><span class="lineNum">     439 </span>            :         return se-&gt;parent;</a>
<a name="440"><span class="lineNum">     440 </span>            : }</a>
<a name="441"><span class="lineNum">     441 </span>            : </a>
<a name="442"><span class="lineNum">     442 </span>            : static void</a>
<a name="443"><span class="lineNum">     443 </span>            : find_matching_se(struct sched_entity **se, struct sched_entity **pse)</a>
<a name="444"><span class="lineNum">     444 </span>            : {</a>
<a name="445"><span class="lineNum">     445 </span>            :         int se_depth, pse_depth;</a>
<a name="446"><span class="lineNum">     446 </span>            : </a>
<a name="447"><span class="lineNum">     447 </span>            :         /*</a>
<a name="448"><span class="lineNum">     448 </span>            :          * preemption test can be made between sibling entities who are in the</a>
<a name="449"><span class="lineNum">     449 </span>            :          * same cfs_rq i.e who have a common parent. Walk up the hierarchy of</a>
<a name="450"><span class="lineNum">     450 </span>            :          * both tasks until we find their ancestors who are siblings of common</a>
<a name="451"><span class="lineNum">     451 </span>            :          * parent.</a>
<a name="452"><span class="lineNum">     452 </span>            :          */</a>
<a name="453"><span class="lineNum">     453 </span>            : </a>
<a name="454"><span class="lineNum">     454 </span>            :         /* First walk up until both entities are at same depth */</a>
<a name="455"><span class="lineNum">     455 </span>            :         se_depth = (*se)-&gt;depth;</a>
<a name="456"><span class="lineNum">     456 </span>            :         pse_depth = (*pse)-&gt;depth;</a>
<a name="457"><span class="lineNum">     457 </span>            : </a>
<a name="458"><span class="lineNum">     458 </span>            :         while (se_depth &gt; pse_depth) {</a>
<a name="459"><span class="lineNum">     459 </span>            :                 se_depth--;</a>
<a name="460"><span class="lineNum">     460 </span>            :                 *se = parent_entity(*se);</a>
<a name="461"><span class="lineNum">     461 </span>            :         }</a>
<a name="462"><span class="lineNum">     462 </span>            : </a>
<a name="463"><span class="lineNum">     463 </span>            :         while (pse_depth &gt; se_depth) {</a>
<a name="464"><span class="lineNum">     464 </span>            :                 pse_depth--;</a>
<a name="465"><span class="lineNum">     465 </span>            :                 *pse = parent_entity(*pse);</a>
<a name="466"><span class="lineNum">     466 </span>            :         }</a>
<a name="467"><span class="lineNum">     467 </span>            : </a>
<a name="468"><span class="lineNum">     468 </span>            :         while (!is_same_group(*se, *pse)) {</a>
<a name="469"><span class="lineNum">     469 </span>            :                 *se = parent_entity(*se);</a>
<a name="470"><span class="lineNum">     470 </span>            :                 *pse = parent_entity(*pse);</a>
<a name="471"><span class="lineNum">     471 </span>            :         }</a>
<a name="472"><span class="lineNum">     472 </span>            : }</a>
<a name="473"><span class="lineNum">     473 </span>            : </a>
<a name="474"><span class="lineNum">     474 </span>            : static int tg_is_idle(struct task_group *tg)</a>
<a name="475"><span class="lineNum">     475 </span>            : {</a>
<a name="476"><span class="lineNum">     476 </span>            :         return tg-&gt;idle &gt; 0;</a>
<a name="477"><span class="lineNum">     477 </span>            : }</a>
<a name="478"><span class="lineNum">     478 </span>            : </a>
<a name="479"><span class="lineNum">     479 </span>            : static int cfs_rq_is_idle(struct cfs_rq *cfs_rq)</a>
<a name="480"><span class="lineNum">     480 </span>            : {</a>
<a name="481"><span class="lineNum">     481 </span>            :         return cfs_rq-&gt;idle &gt; 0;</a>
<a name="482"><span class="lineNum">     482 </span>            : }</a>
<a name="483"><span class="lineNum">     483 </span>            : </a>
<a name="484"><span class="lineNum">     484 </span>            : static int se_is_idle(struct sched_entity *se)</a>
<a name="485"><span class="lineNum">     485 </span>            : {</a>
<a name="486"><span class="lineNum">     486 </span>            :         if (entity_is_task(se))</a>
<a name="487"><span class="lineNum">     487 </span>            :                 return task_has_idle_policy(task_of(se));</a>
<a name="488"><span class="lineNum">     488 </span>            :         return cfs_rq_is_idle(group_cfs_rq(se));</a>
<a name="489"><span class="lineNum">     489 </span>            : }</a>
<a name="490"><span class="lineNum">     490 </span>            : </a>
<a name="491"><span class="lineNum">     491 </span>            : #else   /* !CONFIG_FAIR_GROUP_SCHED */</a>
<a name="492"><span class="lineNum">     492 </span>            : </a>
<a name="493"><span class="lineNum">     493 </span>            : #define for_each_sched_entity(se) \</a>
<a name="494"><span class="lineNum">     494 </span>            :                 for (; se; se = NULL)</a>
<a name="495"><span class="lineNum">     495 </span>            : </a>
<a name="496"><span class="lineNum">     496 </span>            : static inline void cfs_rq_tg_path(struct cfs_rq *cfs_rq, char *path, int len)</a>
<a name="497"><span class="lineNum">     497 </span>            : {</a>
<a name="498"><span class="lineNum">     498 </span><span class="lineNoCov">          0 :         if (path)</span></a>
<a name="499"><span class="lineNum">     499 </span><span class="lineNoCov">          0 :                 strlcpy(path, &quot;(null)&quot;, len);</span></a>
<a name="500"><span class="lineNum">     500 </span>            : }</a>
<a name="501"><span class="lineNum">     501 </span>            : </a>
<a name="502"><span class="lineNum">     502 </span>            : static inline bool list_add_leaf_cfs_rq(struct cfs_rq *cfs_rq)</a>
<a name="503"><span class="lineNum">     503 </span>            : {</a>
<a name="504"><span class="lineNum">     504 </span>            :         return true;</a>
<a name="505"><span class="lineNum">     505 </span>            : }</a>
<a name="506"><span class="lineNum">     506 </span>            : </a>
<a name="507"><span class="lineNum">     507 </span>            : static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)</a>
<a name="508"><span class="lineNum">     508 </span>            : {</a>
<a name="509"><span class="lineNum">     509 </span>            : }</a>
<a name="510"><span class="lineNum">     510 </span>            : </a>
<a name="511"><span class="lineNum">     511 </span>            : static inline void assert_list_leaf_cfs_rq(struct rq *rq)</a>
<a name="512"><span class="lineNum">     512 </span>            : {</a>
<a name="513"><span class="lineNum">     513 </span>            : }</a>
<a name="514"><span class="lineNum">     514 </span>            : </a>
<a name="515"><span class="lineNum">     515 </span>            : #define for_each_leaf_cfs_rq_safe(rq, cfs_rq, pos)      \</a>
<a name="516"><span class="lineNum">     516 </span>            :                 for (cfs_rq = &amp;rq-&gt;cfs, pos = NULL; cfs_rq; cfs_rq = pos)</a>
<a name="517"><span class="lineNum">     517 </span>            : </a>
<a name="518"><span class="lineNum">     518 </span>            : static inline struct sched_entity *parent_entity(struct sched_entity *se)</a>
<a name="519"><span class="lineNum">     519 </span>            : {</a>
<a name="520"><span class="lineNum">     520 </span>            :         return NULL;</a>
<a name="521"><span class="lineNum">     521 </span>            : }</a>
<a name="522"><span class="lineNum">     522 </span>            : </a>
<a name="523"><span class="lineNum">     523 </span>            : static inline void</a>
<a name="524"><span class="lineNum">     524 </span>            : find_matching_se(struct sched_entity **se, struct sched_entity **pse)</a>
<a name="525"><span class="lineNum">     525 </span>            : {</a>
<a name="526"><span class="lineNum">     526 </span>            : }</a>
<a name="527"><span class="lineNum">     527 </span>            : </a>
<a name="528"><span class="lineNum">     528 </span>            : static inline int tg_is_idle(struct task_group *tg)</a>
<a name="529"><span class="lineNum">     529 </span>            : {</a>
<a name="530"><span class="lineNum">     530 </span>            :         return 0;</a>
<a name="531"><span class="lineNum">     531 </span>            : }</a>
<a name="532"><span class="lineNum">     532 </span>            : </a>
<a name="533"><span class="lineNum">     533 </span>            : static int cfs_rq_is_idle(struct cfs_rq *cfs_rq)</a>
<a name="534"><span class="lineNum">     534 </span>            : {</a>
<a name="535"><span class="lineNum">     535 </span>            :         return 0;</a>
<a name="536"><span class="lineNum">     536 </span>            : }</a>
<a name="537"><span class="lineNum">     537 </span>            : </a>
<a name="538"><span class="lineNum">     538 </span>            : static int se_is_idle(struct sched_entity *se)</a>
<a name="539"><span class="lineNum">     539 </span>            : {</a>
<a name="540"><span class="lineNum">     540 </span>            :         return 0;</a>
<a name="541"><span class="lineNum">     541 </span>            : }</a>
<a name="542"><span class="lineNum">     542 </span>            : </a>
<a name="543"><span class="lineNum">     543 </span>            : #endif  /* CONFIG_FAIR_GROUP_SCHED */</a>
<a name="544"><span class="lineNum">     544 </span>            : </a>
<a name="545"><span class="lineNum">     545 </span>            : static __always_inline</a>
<a name="546"><span class="lineNum">     546 </span>            : void account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec);</a>
<a name="547"><span class="lineNum">     547 </span>            : </a>
<a name="548"><span class="lineNum">     548 </span>            : /**************************************************************</a>
<a name="549"><span class="lineNum">     549 </span>            :  * Scheduling class tree data structure manipulation methods:</a>
<a name="550"><span class="lineNum">     550 </span>            :  */</a>
<a name="551"><span class="lineNum">     551 </span>            : </a>
<a name="552"><span class="lineNum">     552 </span>            : static inline u64 max_vruntime(u64 max_vruntime, u64 vruntime)</a>
<a name="553"><span class="lineNum">     553 </span>            : {</a>
<a name="554"><span class="lineNum">     554 </span><span class="lineCov">       1230 :         s64 delta = (s64)(vruntime - max_vruntime);</span></a>
<a name="555"><span class="lineNum">     555 </span><span class="lineCov">       1230 :         if (delta &gt; 0)</span></a>
<a name="556"><span class="lineNum">     556 </span><span class="lineCov">        515 :                 max_vruntime = vruntime;</span></a>
<a name="557"><span class="lineNum">     557 </span>            : </a>
<a name="558"><span class="lineNum">     558 </span>            :         return max_vruntime;</a>
<a name="559"><span class="lineNum">     559 </span>            : }</a>
<a name="560"><span class="lineNum">     560 </span>            : </a>
<a name="561"><span class="lineNum">     561 </span>            : static inline u64 min_vruntime(u64 min_vruntime, u64 vruntime)</a>
<a name="562"><span class="lineNum">     562 </span>            : {</a>
<a name="563"><span class="lineNum">     563 </span><span class="lineCov">          1 :         s64 delta = (s64)(vruntime - min_vruntime);</span></a>
<a name="564"><span class="lineNum">     564 </span><span class="lineCov">          1 :         if (delta &lt; 0)</span></a>
<a name="565"><span class="lineNum">     565 </span><span class="lineCov">          1 :                 min_vruntime = vruntime;</span></a>
<a name="566"><span class="lineNum">     566 </span>            : </a>
<a name="567"><span class="lineNum">     567 </span>            :         return min_vruntime;</a>
<a name="568"><span class="lineNum">     568 </span>            : }</a>
<a name="569"><span class="lineNum">     569 </span>            : </a>
<a name="570"><span class="lineNum">     570 </span>            : static inline bool entity_before(struct sched_entity *a,</a>
<a name="571"><span class="lineNum">     571 </span>            :                                 struct sched_entity *b)</a>
<a name="572"><span class="lineNum">     572 </span>            : {</a>
<a name="573"><span class="lineNum">     573 </span><span class="lineCov">        226 :         return (s64)(a-&gt;vruntime - b-&gt;vruntime) &lt; 0;</span></a>
<a name="574"><span class="lineNum">     574 </span>            : }</a>
<a name="575"><span class="lineNum">     575 </span>            : </a>
<a name="576"><span class="lineNum">     576 </span>            : #define __node_2_se(node) \</a>
<a name="577"><span class="lineNum">     577 </span>            :         rb_entry((node), struct sched_entity, run_node)</a>
<a name="578"><span class="lineNum">     578 </span>            : </a>
<a name="579"><span class="lineNum">     579 </span><span class="lineCov">        615 : static void update_min_vruntime(struct cfs_rq *cfs_rq)</span></a>
<a name="580"><span class="lineNum">     580 </span>            : {</a>
<a name="581"><span class="lineNum">     581 </span><span class="lineCov">        615 :         struct sched_entity *curr = cfs_rq-&gt;curr;</span></a>
<a name="582"><span class="lineNum">     582 </span><span class="lineCov">        615 :         struct rb_node *leftmost = rb_first_cached(&amp;cfs_rq-&gt;tasks_timeline);</span></a>
<a name="583"><span class="lineNum">     583 </span>            : </a>
<a name="584"><span class="lineNum">     584 </span><span class="lineCov">        615 :         u64 vruntime = cfs_rq-&gt;min_vruntime;</span></a>
<a name="585"><span class="lineNum">     585 </span>            : </a>
<a name="586"><span class="lineNum">     586 </span><span class="lineCov">        615 :         if (curr) {</span></a>
<a name="587"><span class="lineNum">     587 </span><span class="lineCov">        615 :                 if (curr-&gt;on_rq)</span></a>
<a name="588"><span class="lineNum">     588 </span><span class="lineCov">          2 :                         vruntime = curr-&gt;vruntime;</span></a>
<a name="589"><span class="lineNum">     589 </span>            :                 else</a>
<a name="590"><span class="lineNum">     590 </span>            :                         curr = NULL;</a>
<a name="591"><span class="lineNum">     591 </span>            :         }</a>
<a name="592"><span class="lineNum">     592 </span>            : </a>
<a name="593"><span class="lineNum">     593 </span><span class="lineCov">        615 :         if (leftmost) { /* non-empty tree */</span></a>
<a name="594"><span class="lineNum">     594 </span><span class="lineCov">        613 :                 struct sched_entity *se = __node_2_se(leftmost);</span></a>
<a name="595"><span class="lineNum">     595 </span>            : </a>
<a name="596"><span class="lineNum">     596 </span><span class="lineCov">        613 :                 if (!curr)</span></a>
<a name="597"><span class="lineNum">     597 </span><span class="lineCov">        612 :                         vruntime = se-&gt;vruntime;</span></a>
<a name="598"><span class="lineNum">     598 </span>            :                 else</a>
<a name="599"><span class="lineNum">     599 </span><span class="lineCov">          1 :                         vruntime = min_vruntime(vruntime, se-&gt;vruntime);</span></a>
<a name="600"><span class="lineNum">     600 </span>            :         }</a>
<a name="601"><span class="lineNum">     601 </span>            : </a>
<a name="602"><span class="lineNum">     602 </span>            :         /* ensure we never gain time by being placed backwards. */</a>
<a name="603"><span class="lineNum">     603 </span><span class="lineCov">       1230 :         cfs_rq-&gt;min_vruntime = max_vruntime(cfs_rq-&gt;min_vruntime, vruntime);</span></a>
<a name="604"><span class="lineNum">     604 </span>            : #ifndef CONFIG_64BIT</a>
<a name="605"><span class="lineNum">     605 </span>            :         smp_wmb();</a>
<a name="606"><span class="lineNum">     606 </span>            :         cfs_rq-&gt;min_vruntime_copy = cfs_rq-&gt;min_vruntime;</a>
<a name="607"><span class="lineNum">     607 </span>            : #endif</a>
<a name="608"><span class="lineNum">     608 </span><span class="lineCov">        615 : }</span></a>
<a name="609"><span class="lineNum">     609 </span>            : </a>
<a name="610"><span class="lineNum">     610 </span>            : static inline bool __entity_less(struct rb_node *a, const struct rb_node *b)</a>
<a name="611"><span class="lineNum">     611 </span>            : {</a>
<a name="612"><span class="lineNum">     612 </span><span class="lineCov">        226 :         return entity_before(__node_2_se(a), __node_2_se(b));</span></a>
<a name="613"><span class="lineNum">     613 </span>            : }</a>
<a name="614"><span class="lineNum">     614 </span>            : </a>
<a name="615"><span class="lineNum">     615 </span>            : /*</a>
<a name="616"><span class="lineNum">     616 </span>            :  * Enqueue an entity into the rb-tree:</a>
<a name="617"><span class="lineNum">     617 </span>            :  */</a>
<a name="618"><span class="lineNum">     618 </span><span class="lineCov">        619 : static void __enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)</span></a>
<a name="619"><span class="lineNum">     619 </span>            : {</a>
<a name="620"><span class="lineNum">     620 </span><span class="lineCov">       1238 :         rb_add_cached(&amp;se-&gt;run_node, &amp;cfs_rq-&gt;tasks_timeline, __entity_less);</span></a>
<a name="621"><span class="lineNum">     621 </span><span class="lineCov">        619 : }</span></a>
<a name="622"><span class="lineNum">     622 </span>            : </a>
<a name="623"><span class="lineNum">     623 </span>            : static void __dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="624"><span class="lineNum">     624 </span>            : {</a>
<a name="625"><span class="lineNum">     625 </span><span class="lineCov">        618 :         rb_erase_cached(&amp;se-&gt;run_node, &amp;cfs_rq-&gt;tasks_timeline);</span></a>
<a name="626"><span class="lineNum">     626 </span>            : }</a>
<a name="627"><span class="lineNum">     627 </span>            : </a>
<a name="628"><span class="lineNum">     628 </span><span class="lineNoCov">          0 : struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq)</span></a>
<a name="629"><span class="lineNum">     629 </span>            : {</a>
<a name="630"><span class="lineNum">     630 </span><span class="lineCov">        615 :         struct rb_node *left = rb_first_cached(&amp;cfs_rq-&gt;tasks_timeline);</span></a>
<a name="631"><span class="lineNum">     631 </span>            : </a>
<a name="632"><span class="lineNum">     632 </span><span class="lineCov">        615 :         if (!left)</span></a>
<a name="633"><span class="lineNum">     633 </span>            :                 return NULL;</a>
<a name="634"><span class="lineNum">     634 </span>            : </a>
<a name="635"><span class="lineNum">     635 </span><span class="lineCov">        615 :         return __node_2_se(left);</span></a>
<a name="636"><span class="lineNum">     636 </span>            : }</a>
<a name="637"><span class="lineNum">     637 </span>            : </a>
<a name="638"><span class="lineNum">     638 </span>            : static struct sched_entity *__pick_next_entity(struct sched_entity *se)</a>
<a name="639"><span class="lineNum">     639 </span>            : {</a>
<a name="640"><span class="lineNum">     640 </span><span class="lineNoCov">          0 :         struct rb_node *next = rb_next(&amp;se-&gt;run_node);</span></a>
<a name="641"><span class="lineNum">     641 </span>            : </a>
<a name="642"><span class="lineNum">     642 </span><span class="lineNoCov">          0 :         if (!next)</span></a>
<a name="643"><span class="lineNum">     643 </span>            :                 return NULL;</a>
<a name="644"><span class="lineNum">     644 </span>            : </a>
<a name="645"><span class="lineNum">     645 </span><span class="lineNoCov">          0 :         return __node_2_se(next);</span></a>
<a name="646"><span class="lineNum">     646 </span>            : }</a>
<a name="647"><span class="lineNum">     647 </span>            : </a>
<a name="648"><span class="lineNum">     648 </span>            : #ifdef CONFIG_SCHED_DEBUG</a>
<a name="649"><span class="lineNum">     649 </span><span class="lineNoCov">          0 : struct sched_entity *__pick_last_entity(struct cfs_rq *cfs_rq)</span></a>
<a name="650"><span class="lineNum">     650 </span>            : {</a>
<a name="651"><span class="lineNum">     651 </span><span class="lineNoCov">          0 :         struct rb_node *last = rb_last(&amp;cfs_rq-&gt;tasks_timeline.rb_root);</span></a>
<a name="652"><span class="lineNum">     652 </span>            : </a>
<a name="653"><span class="lineNum">     653 </span><span class="lineNoCov">          0 :         if (!last)</span></a>
<a name="654"><span class="lineNum">     654 </span>            :                 return NULL;</a>
<a name="655"><span class="lineNum">     655 </span>            : </a>
<a name="656"><span class="lineNum">     656 </span><span class="lineNoCov">          0 :         return __node_2_se(last);</span></a>
<a name="657"><span class="lineNum">     657 </span>            : }</a>
<a name="658"><span class="lineNum">     658 </span>            : </a>
<a name="659"><span class="lineNum">     659 </span>            : /**************************************************************</a>
<a name="660"><span class="lineNum">     660 </span>            :  * Scheduling class statistics methods:</a>
<a name="661"><span class="lineNum">     661 </span>            :  */</a>
<a name="662"><span class="lineNum">     662 </span>            : </a>
<a name="663"><span class="lineNum">     663 </span><span class="lineNoCov">          0 : int sched_update_scaling(void)</span></a>
<a name="664"><span class="lineNum">     664 </span>            : {</a>
<a name="665"><span class="lineNum">     665 </span><span class="lineNoCov">          0 :         unsigned int factor = get_update_sysctl_factor();</span></a>
<a name="666"><span class="lineNum">     666 </span>            : </a>
<a name="667"><span class="lineNum">     667 </span><span class="lineNoCov">          0 :         sched_nr_latency = DIV_ROUND_UP(sysctl_sched_latency,</span></a>
<a name="668"><span class="lineNum">     668 </span>            :                                         sysctl_sched_min_granularity);</a>
<a name="669"><span class="lineNum">     669 </span>            : </a>
<a name="670"><span class="lineNum">     670 </span>            : #define WRT_SYSCTL(name) \</a>
<a name="671"><span class="lineNum">     671 </span>            :         (normalized_sysctl_##name = sysctl_##name / (factor))</a>
<a name="672"><span class="lineNum">     672 </span><span class="lineNoCov">          0 :         WRT_SYSCTL(sched_min_granularity);</span></a>
<a name="673"><span class="lineNum">     673 </span><span class="lineNoCov">          0 :         WRT_SYSCTL(sched_latency);</span></a>
<a name="674"><span class="lineNum">     674 </span><span class="lineNoCov">          0 :         WRT_SYSCTL(sched_wakeup_granularity);</span></a>
<a name="675"><span class="lineNum">     675 </span>            : #undef WRT_SYSCTL</a>
<a name="676"><span class="lineNum">     676 </span>            : </a>
<a name="677"><span class="lineNum">     677 </span><span class="lineNoCov">          0 :         return 0;</span></a>
<a name="678"><span class="lineNum">     678 </span>            : }</a>
<a name="679"><span class="lineNum">     679 </span>            : #endif</a>
<a name="680"><span class="lineNum">     680 </span>            : </a>
<a name="681"><span class="lineNum">     681 </span>            : /*</a>
<a name="682"><span class="lineNum">     682 </span>            :  * delta /= w</a>
<a name="683"><span class="lineNum">     683 </span>            :  */</a>
<a name="684"><span class="lineNum">     684 </span>            : static inline u64 calc_delta_fair(u64 delta, struct sched_entity *se)</a>
<a name="685"><span class="lineNum">     685 </span>            : {</a>
<a name="686"><span class="lineNum">     686 </span><span class="lineCov">        308 :         if (unlikely(se-&gt;load.weight != NICE_0_LOAD))</span></a>
<a name="687"><span class="lineNum">     687 </span><span class="lineNoCov">          0 :                 delta = __calc_delta(delta, NICE_0_LOAD, &amp;se-&gt;load);</span></a>
<a name="688"><span class="lineNum">     688 </span>            : </a>
<a name="689"><span class="lineNum">     689 </span>            :         return delta;</a>
<a name="690"><span class="lineNum">     690 </span>            : }</a>
<a name="691"><span class="lineNum">     691 </span>            : </a>
<a name="692"><span class="lineNum">     692 </span>            : /*</a>
<a name="693"><span class="lineNum">     693 </span>            :  * The idea is to set a period in which each task runs once.</a>
<a name="694"><span class="lineNum">     694 </span>            :  *</a>
<a name="695"><span class="lineNum">     695 </span>            :  * When there are too many tasks (sched_nr_latency) we have to stretch</a>
<a name="696"><span class="lineNum">     696 </span>            :  * this period because otherwise the slices get too small.</a>
<a name="697"><span class="lineNum">     697 </span>            :  *</a>
<a name="698"><span class="lineNum">     698 </span>            :  * p = (nr &lt;= nl) ? l : l*nr/nl</a>
<a name="699"><span class="lineNum">     699 </span>            :  */</a>
<a name="700"><span class="lineNum">     700 </span>            : static u64 __sched_period(unsigned long nr_running)</a>
<a name="701"><span class="lineNum">     701 </span>            : {</a>
<a name="702"><span class="lineNum">     702 </span><span class="lineCov">        108 :         if (unlikely(nr_running &gt; sched_nr_latency))</span></a>
<a name="703"><span class="lineNum">     703 </span><span class="lineNoCov">          0 :                 return nr_running * sysctl_sched_min_granularity;</span></a>
<a name="704"><span class="lineNum">     704 </span>            :         else</a>
<a name="705"><span class="lineNum">     705 </span><span class="lineCov">        108 :                 return sysctl_sched_latency;</span></a>
<a name="706"><span class="lineNum">     706 </span>            : }</a>
<a name="707"><span class="lineNum">     707 </span>            : </a>
<a name="708"><span class="lineNum">     708 </span>            : static bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);</a>
<a name="709"><span class="lineNum">     709 </span>            : </a>
<a name="710"><span class="lineNum">     710 </span>            : /*</a>
<a name="711"><span class="lineNum">     711 </span>            :  * We calculate the wall-time slice from the period by taking a part</a>
<a name="712"><span class="lineNum">     712 </span>            :  * proportional to the weight.</a>
<a name="713"><span class="lineNum">     713 </span>            :  *</a>
<a name="714"><span class="lineNum">     714 </span>            :  * s = p*P[w/rw]</a>
<a name="715"><span class="lineNum">     715 </span>            :  */</a>
<a name="716"><span class="lineNum">     716 </span><span class="lineCov">        108 : static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se)</span></a>
<a name="717"><span class="lineNum">     717 </span>            : {</a>
<a name="718"><span class="lineNum">     718 </span><span class="lineCov">        108 :         unsigned int nr_running = cfs_rq-&gt;nr_running;</span></a>
<a name="719"><span class="lineNum">     719 </span><span class="lineCov">        108 :         struct sched_entity *init_se = se;</span></a>
<a name="720"><span class="lineNum">     720 </span>            :         unsigned int min_gran;</a>
<a name="721"><span class="lineNum">     721 </span>            :         u64 slice;</a>
<a name="722"><span class="lineNum">     722 </span>            : </a>
<a name="723"><span class="lineNum">     723 </span><span class="lineCov">        108 :         if (sched_feat(ALT_PERIOD))</span></a>
<a name="724"><span class="lineNum">     724 </span><span class="lineCov">        108 :                 nr_running = rq_of(cfs_rq)-&gt;cfs.h_nr_running;</span></a>
<a name="725"><span class="lineNum">     725 </span>            : </a>
<a name="726"><span class="lineNum">     726 </span><span class="lineCov">        108 :         slice = __sched_period(nr_running + !se-&gt;on_rq);</span></a>
<a name="727"><span class="lineNum">     727 </span>            : </a>
<a name="728"><span class="lineNum">     728 </span><span class="lineCov">        108 :         for_each_sched_entity(se) {</span></a>
<a name="729"><span class="lineNum">     729 </span>            :                 struct load_weight *load;</a>
<a name="730"><span class="lineNum">     730 </span>            :                 struct load_weight lw;</a>
<a name="731"><span class="lineNum">     731 </span>            :                 struct cfs_rq *qcfs_rq;</a>
<a name="732"><span class="lineNum">     732 </span>            : </a>
<a name="733"><span class="lineNum">     733 </span><span class="lineCov">        216 :                 qcfs_rq = cfs_rq_of(se);</span></a>
<a name="734"><span class="lineNum">     734 </span><span class="lineCov">        108 :                 load = &amp;qcfs_rq-&gt;load;</span></a>
<a name="735"><span class="lineNum">     735 </span>            : </a>
<a name="736"><span class="lineNum">     736 </span><span class="lineCov">        108 :                 if (unlikely(!se-&gt;on_rq)) {</span></a>
<a name="737"><span class="lineNum">     737 </span><span class="lineCov">        107 :                         lw = qcfs_rq-&gt;load;</span></a>
<a name="738"><span class="lineNum">     738 </span>            : </a>
<a name="739"><span class="lineNum">     739 </span><span class="lineCov">        214 :                         update_load_add(&amp;lw, se-&gt;load.weight);</span></a>
<a name="740"><span class="lineNum">     740 </span><span class="lineCov">        107 :                         load = &amp;lw;</span></a>
<a name="741"><span class="lineNum">     741 </span>            :                 }</a>
<a name="742"><span class="lineNum">     742 </span><span class="lineCov">        108 :                 slice = __calc_delta(slice, se-&gt;load.weight, load);</span></a>
<a name="743"><span class="lineNum">     743 </span>            :         }</a>
<a name="744"><span class="lineNum">     744 </span>            : </a>
<a name="745"><span class="lineNum">     745 </span><span class="lineCov">        108 :         if (sched_feat(BASE_SLICE)) {</span></a>
<a name="746"><span class="lineNum">     746 </span><span class="lineCov">        108 :                 if (se_is_idle(init_se) &amp;&amp; !sched_idle_cfs_rq(cfs_rq))</span></a>
<a name="747"><span class="lineNum">     747 </span>            :                         min_gran = sysctl_sched_idle_min_granularity;</a>
<a name="748"><span class="lineNum">     748 </span>            :                 else</a>
<a name="749"><span class="lineNum">     749 </span><span class="lineCov">        108 :                         min_gran = sysctl_sched_min_granularity;</span></a>
<a name="750"><span class="lineNum">     750 </span>            : </a>
<a name="751"><span class="lineNum">     751 </span><span class="lineCov">        108 :                 slice = max_t(u64, slice, min_gran);</span></a>
<a name="752"><span class="lineNum">     752 </span>            :         }</a>
<a name="753"><span class="lineNum">     753 </span>            : </a>
<a name="754"><span class="lineNum">     754 </span><span class="lineCov">        108 :         return slice;</span></a>
<a name="755"><span class="lineNum">     755 </span>            : }</a>
<a name="756"><span class="lineNum">     756 </span>            : </a>
<a name="757"><span class="lineNum">     757 </span>            : /*</a>
<a name="758"><span class="lineNum">     758 </span>            :  * We calculate the vruntime slice of a to-be-inserted task.</a>
<a name="759"><span class="lineNum">     759 </span>            :  *</a>
<a name="760"><span class="lineNum">     760 </span>            :  * vs = s/w</a>
<a name="761"><span class="lineNum">     761 </span>            :  */</a>
<a name="762"><span class="lineNum">     762 </span><span class="lineCov">        107 : static u64 sched_vslice(struct cfs_rq *cfs_rq, struct sched_entity *se)</span></a>
<a name="763"><span class="lineNum">     763 </span>            : {</a>
<a name="764"><span class="lineNum">     764 </span><span class="lineCov">        214 :         return calc_delta_fair(sched_slice(cfs_rq, se), se);</span></a>
<a name="765"><span class="lineNum">     765 </span>            : }</a>
<a name="766"><span class="lineNum">     766 </span>            : </a>
<a name="767"><span class="lineNum">     767 </span>            : #include &quot;pelt.h&quot;</a>
<a name="768"><span class="lineNum">     768 </span>            : #ifdef CONFIG_SMP</a>
<a name="769"><span class="lineNum">     769 </span>            : </a>
<a name="770"><span class="lineNum">     770 </span>            : static int select_idle_sibling(struct task_struct *p, int prev_cpu, int cpu);</a>
<a name="771"><span class="lineNum">     771 </span>            : static unsigned long task_h_load(struct task_struct *p);</a>
<a name="772"><span class="lineNum">     772 </span>            : static unsigned long capacity_of(int cpu);</a>
<a name="773"><span class="lineNum">     773 </span>            : </a>
<a name="774"><span class="lineNum">     774 </span>            : /* Give new sched_entity start runnable values to heavy its load in infant time */</a>
<a name="775"><span class="lineNum">     775 </span>            : void init_entity_runnable_average(struct sched_entity *se)</a>
<a name="776"><span class="lineNum">     776 </span>            : {</a>
<a name="777"><span class="lineNum">     777 </span>            :         struct sched_avg *sa = &amp;se-&gt;avg;</a>
<a name="778"><span class="lineNum">     778 </span>            : </a>
<a name="779"><span class="lineNum">     779 </span>            :         memset(sa, 0, sizeof(*sa));</a>
<a name="780"><span class="lineNum">     780 </span>            : </a>
<a name="781"><span class="lineNum">     781 </span>            :         /*</a>
<a name="782"><span class="lineNum">     782 </span>            :          * Tasks are initialized with full load to be seen as heavy tasks until</a>
<a name="783"><span class="lineNum">     783 </span>            :          * they get a chance to stabilize to their real load level.</a>
<a name="784"><span class="lineNum">     784 </span>            :          * Group entities are initialized with zero load to reflect the fact that</a>
<a name="785"><span class="lineNum">     785 </span>            :          * nothing has been attached to the task group yet.</a>
<a name="786"><span class="lineNum">     786 </span>            :          */</a>
<a name="787"><span class="lineNum">     787 </span>            :         if (entity_is_task(se))</a>
<a name="788"><span class="lineNum">     788 </span>            :                 sa-&gt;load_avg = scale_load_down(se-&gt;load.weight);</a>
<a name="789"><span class="lineNum">     789 </span>            : </a>
<a name="790"><span class="lineNum">     790 </span>            :         /* when this task enqueue'ed, it will contribute to its cfs_rq's load_avg */</a>
<a name="791"><span class="lineNum">     791 </span>            : }</a>
<a name="792"><span class="lineNum">     792 </span>            : </a>
<a name="793"><span class="lineNum">     793 </span>            : static void attach_entity_cfs_rq(struct sched_entity *se);</a>
<a name="794"><span class="lineNum">     794 </span>            : </a>
<a name="795"><span class="lineNum">     795 </span>            : /*</a>
<a name="796"><span class="lineNum">     796 </span>            :  * With new tasks being created, their initial util_avgs are extrapolated</a>
<a name="797"><span class="lineNum">     797 </span>            :  * based on the cfs_rq's current util_avg:</a>
<a name="798"><span class="lineNum">     798 </span>            :  *</a>
<a name="799"><span class="lineNum">     799 </span>            :  *   util_avg = cfs_rq-&gt;util_avg / (cfs_rq-&gt;load_avg + 1) * se.load.weight</a>
<a name="800"><span class="lineNum">     800 </span>            :  *</a>
<a name="801"><span class="lineNum">     801 </span>            :  * However, in many cases, the above util_avg does not give a desired</a>
<a name="802"><span class="lineNum">     802 </span>            :  * value. Moreover, the sum of the util_avgs may be divergent, such</a>
<a name="803"><span class="lineNum">     803 </span>            :  * as when the series is a harmonic series.</a>
<a name="804"><span class="lineNum">     804 </span>            :  *</a>
<a name="805"><span class="lineNum">     805 </span>            :  * To solve this problem, we also cap the util_avg of successive tasks to</a>
<a name="806"><span class="lineNum">     806 </span>            :  * only 1/2 of the left utilization budget:</a>
<a name="807"><span class="lineNum">     807 </span>            :  *</a>
<a name="808"><span class="lineNum">     808 </span>            :  *   util_avg_cap = (cpu_scale - cfs_rq-&gt;avg.util_avg) / 2^n</a>
<a name="809"><span class="lineNum">     809 </span>            :  *</a>
<a name="810"><span class="lineNum">     810 </span>            :  * where n denotes the nth task and cpu_scale the CPU capacity.</a>
<a name="811"><span class="lineNum">     811 </span>            :  *</a>
<a name="812"><span class="lineNum">     812 </span>            :  * For example, for a CPU with 1024 of capacity, a simplest series from</a>
<a name="813"><span class="lineNum">     813 </span>            :  * the beginning would be like:</a>
<a name="814"><span class="lineNum">     814 </span>            :  *</a>
<a name="815"><span class="lineNum">     815 </span>            :  *  task  util_avg: 512, 256, 128,  64,  32,   16,    8, ...</a>
<a name="816"><span class="lineNum">     816 </span>            :  * cfs_rq util_avg: 512, 768, 896, 960, 992, 1008, 1016, ...</a>
<a name="817"><span class="lineNum">     817 </span>            :  *</a>
<a name="818"><span class="lineNum">     818 </span>            :  * Finally, that extrapolated util_avg is clamped to the cap (util_avg_cap)</a>
<a name="819"><span class="lineNum">     819 </span>            :  * if util_avg &gt; util_avg_cap.</a>
<a name="820"><span class="lineNum">     820 </span>            :  */</a>
<a name="821"><span class="lineNum">     821 </span>            : void post_init_entity_util_avg(struct task_struct *p)</a>
<a name="822"><span class="lineNum">     822 </span>            : {</a>
<a name="823"><span class="lineNum">     823 </span>            :         struct sched_entity *se = &amp;p-&gt;se;</a>
<a name="824"><span class="lineNum">     824 </span>            :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</a>
<a name="825"><span class="lineNum">     825 </span>            :         struct sched_avg *sa = &amp;se-&gt;avg;</a>
<a name="826"><span class="lineNum">     826 </span>            :         long cpu_scale = arch_scale_cpu_capacity(cpu_of(rq_of(cfs_rq)));</a>
<a name="827"><span class="lineNum">     827 </span>            :         long cap = (long)(cpu_scale - cfs_rq-&gt;avg.util_avg) / 2;</a>
<a name="828"><span class="lineNum">     828 </span>            : </a>
<a name="829"><span class="lineNum">     829 </span>            :         if (cap &gt; 0) {</a>
<a name="830"><span class="lineNum">     830 </span>            :                 if (cfs_rq-&gt;avg.util_avg != 0) {</a>
<a name="831"><span class="lineNum">     831 </span>            :                         sa-&gt;util_avg  = cfs_rq-&gt;avg.util_avg * se-&gt;load.weight;</a>
<a name="832"><span class="lineNum">     832 </span>            :                         sa-&gt;util_avg /= (cfs_rq-&gt;avg.load_avg + 1);</a>
<a name="833"><span class="lineNum">     833 </span>            : </a>
<a name="834"><span class="lineNum">     834 </span>            :                         if (sa-&gt;util_avg &gt; cap)</a>
<a name="835"><span class="lineNum">     835 </span>            :                                 sa-&gt;util_avg = cap;</a>
<a name="836"><span class="lineNum">     836 </span>            :                 } else {</a>
<a name="837"><span class="lineNum">     837 </span>            :                         sa-&gt;util_avg = cap;</a>
<a name="838"><span class="lineNum">     838 </span>            :                 }</a>
<a name="839"><span class="lineNum">     839 </span>            :         }</a>
<a name="840"><span class="lineNum">     840 </span>            : </a>
<a name="841"><span class="lineNum">     841 </span>            :         sa-&gt;runnable_avg = sa-&gt;util_avg;</a>
<a name="842"><span class="lineNum">     842 </span>            : </a>
<a name="843"><span class="lineNum">     843 </span>            :         if (p-&gt;sched_class != &amp;fair_sched_class) {</a>
<a name="844"><span class="lineNum">     844 </span>            :                 /*</a>
<a name="845"><span class="lineNum">     845 </span>            :                  * For !fair tasks do:</a>
<a name="846"><span class="lineNum">     846 </span>            :                  *</a>
<a name="847"><span class="lineNum">     847 </span>            :                 update_cfs_rq_load_avg(now, cfs_rq);</a>
<a name="848"><span class="lineNum">     848 </span>            :                 attach_entity_load_avg(cfs_rq, se);</a>
<a name="849"><span class="lineNum">     849 </span>            :                 switched_from_fair(rq, p);</a>
<a name="850"><span class="lineNum">     850 </span>            :                  *</a>
<a name="851"><span class="lineNum">     851 </span>            :                  * such that the next switched_to_fair() has the</a>
<a name="852"><span class="lineNum">     852 </span>            :                  * expected state.</a>
<a name="853"><span class="lineNum">     853 </span>            :                  */</a>
<a name="854"><span class="lineNum">     854 </span>            :                 se-&gt;avg.last_update_time = cfs_rq_clock_pelt(cfs_rq);</a>
<a name="855"><span class="lineNum">     855 </span>            :                 return;</a>
<a name="856"><span class="lineNum">     856 </span>            :         }</a>
<a name="857"><span class="lineNum">     857 </span>            : </a>
<a name="858"><span class="lineNum">     858 </span>            :         attach_entity_cfs_rq(se);</a>
<a name="859"><span class="lineNum">     859 </span>            : }</a>
<a name="860"><span class="lineNum">     860 </span>            : </a>
<a name="861"><span class="lineNum">     861 </span>            : #else /* !CONFIG_SMP */</a>
<a name="862"><span class="lineNum">     862 </span><span class="lineCov">        107 : void init_entity_runnable_average(struct sched_entity *se)</span></a>
<a name="863"><span class="lineNum">     863 </span>            : {</a>
<a name="864"><span class="lineNum">     864 </span><span class="lineCov">        107 : }</span></a>
<a name="865"><span class="lineNum">     865 </span><span class="lineCov">        107 : void post_init_entity_util_avg(struct task_struct *p)</span></a>
<a name="866"><span class="lineNum">     866 </span>            : {</a>
<a name="867"><span class="lineNum">     867 </span><span class="lineCov">        107 : }</span></a>
<a name="868"><span class="lineNum">     868 </span>            : static void update_tg_load_avg(struct cfs_rq *cfs_rq)</a>
<a name="869"><span class="lineNum">     869 </span>            : {</a>
<a name="870"><span class="lineNum">     870 </span>            : }</a>
<a name="871"><span class="lineNum">     871 </span>            : #endif /* CONFIG_SMP */</a>
<a name="872"><span class="lineNum">     872 </span>            : </a>
<a name="873"><span class="lineNum">     873 </span>            : /*</a>
<a name="874"><span class="lineNum">     874 </span>            :  * Update the current task's runtime statistics.</a>
<a name="875"><span class="lineNum">     875 </span>            :  */</a>
<a name="876"><span class="lineNum">     876 </span><span class="lineCov">       1861 : static void update_curr(struct cfs_rq *cfs_rq)</span></a>
<a name="877"><span class="lineNum">     877 </span>            : {</a>
<a name="878"><span class="lineNum">     878 </span><span class="lineCov">       1861 :         struct sched_entity *curr = cfs_rq-&gt;curr;</span></a>
<a name="879"><span class="lineNum">     879 </span><span class="lineCov">       3722 :         u64 now = rq_clock_task(rq_of(cfs_rq));</span></a>
<a name="880"><span class="lineNum">     880 </span>            :         u64 delta_exec;</a>
<a name="881"><span class="lineNum">     881 </span>            : </a>
<a name="882"><span class="lineNum">     882 </span><span class="lineCov">       1861 :         if (unlikely(!curr))</span></a>
<a name="883"><span class="lineNum">     883 </span>            :                 return;</a>
<a name="884"><span class="lineNum">     884 </span>            : </a>
<a name="885"><span class="lineNum">     885 </span><span class="lineCov">       1855 :         delta_exec = now - curr-&gt;exec_start;</span></a>
<a name="886"><span class="lineNum">     886 </span><span class="lineCov">       1855 :         if (unlikely((s64)delta_exec &lt;= 0))</span></a>
<a name="887"><span class="lineNum">     887 </span>            :                 return;</a>
<a name="888"><span class="lineNum">     888 </span>            : </a>
<a name="889"><span class="lineNum">     889 </span><span class="lineCov">          2 :         curr-&gt;exec_start = now;</span></a>
<a name="890"><span class="lineNum">     890 </span>            : </a>
<a name="891"><span class="lineNum">     891 </span>            :         if (schedstat_enabled()) {</a>
<a name="892"><span class="lineNum">     892 </span>            :                 struct sched_statistics *stats;</a>
<a name="893"><span class="lineNum">     893 </span>            : </a>
<a name="894"><span class="lineNum">     894 </span>            :                 stats = __schedstats_from_se(curr);</a>
<a name="895"><span class="lineNum">     895 </span>            :                 __schedstat_set(stats-&gt;exec_max,</a>
<a name="896"><span class="lineNum">     896 </span>            :                                 max(delta_exec, stats-&gt;exec_max));</a>
<a name="897"><span class="lineNum">     897 </span>            :         }</a>
<a name="898"><span class="lineNum">     898 </span>            : </a>
<a name="899"><span class="lineNum">     899 </span><span class="lineCov">          2 :         curr-&gt;sum_exec_runtime += delta_exec;</span></a>
<a name="900"><span class="lineNum">     900 </span>            :         schedstat_add(cfs_rq-&gt;exec_clock, delta_exec);</a>
<a name="901"><span class="lineNum">     901 </span>            : </a>
<a name="902"><span class="lineNum">     902 </span><span class="lineCov">          2 :         curr-&gt;vruntime += calc_delta_fair(delta_exec, curr);</span></a>
<a name="903"><span class="lineNum">     903 </span><span class="lineCov">          2 :         update_min_vruntime(cfs_rq);</span></a>
<a name="904"><span class="lineNum">     904 </span>            : </a>
<a name="905"><span class="lineNum">     905 </span>            :         if (entity_is_task(curr)) {</a>
<a name="906"><span class="lineNum">     906 </span><span class="lineCov">          2 :                 struct task_struct *curtask = task_of(curr);</span></a>
<a name="907"><span class="lineNum">     907 </span>            : </a>
<a name="908"><span class="lineNum">     908 </span><span class="lineCov">          2 :                 trace_sched_stat_runtime(curtask, delta_exec, curr-&gt;vruntime);</span></a>
<a name="909"><span class="lineNum">     909 </span><span class="lineCov">          2 :                 cgroup_account_cputime(curtask, delta_exec);</span></a>
<a name="910"><span class="lineNum">     910 </span>            :                 account_group_exec_runtime(curtask, delta_exec);</a>
<a name="911"><span class="lineNum">     911 </span>            :         }</a>
<a name="912"><span class="lineNum">     912 </span>            : </a>
<a name="913"><span class="lineNum">     913 </span>            :         account_cfs_rq_runtime(cfs_rq, delta_exec);</a>
<a name="914"><span class="lineNum">     914 </span>            : }</a>
<a name="915"><span class="lineNum">     915 </span>            : </a>
<a name="916"><span class="lineNum">     916 </span><span class="lineNoCov">          0 : static void update_curr_fair(struct rq *rq)</span></a>
<a name="917"><span class="lineNum">     917 </span>            : {</a>
<a name="918"><span class="lineNum">     918 </span><span class="lineNoCov">          0 :         update_curr(cfs_rq_of(&amp;rq-&gt;curr-&gt;se));</span></a>
<a name="919"><span class="lineNum">     919 </span><span class="lineNoCov">          0 : }</span></a>
<a name="920"><span class="lineNum">     920 </span>            : </a>
<a name="921"><span class="lineNum">     921 </span>            : static inline void</a>
<a name="922"><span class="lineNum">     922 </span>            : update_stats_wait_start_fair(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="923"><span class="lineNum">     923 </span>            : {</a>
<a name="924"><span class="lineNum">     924 </span>            :         struct sched_statistics *stats;</a>
<a name="925"><span class="lineNum">     925 </span><span class="lineCov">          1 :         struct task_struct *p = NULL;</span></a>
<a name="926"><span class="lineNum">     926 </span>            : </a>
<a name="927"><span class="lineNum">     927 </span>            :         if (!schedstat_enabled())</a>
<a name="928"><span class="lineNum">     928 </span>            :                 return;</a>
<a name="929"><span class="lineNum">     929 </span>            : </a>
<a name="930"><span class="lineNum">     930 </span>            :         stats = __schedstats_from_se(se);</a>
<a name="931"><span class="lineNum">     931 </span>            : </a>
<a name="932"><span class="lineNum">     932 </span>            :         if (entity_is_task(se))</a>
<a name="933"><span class="lineNum">     933 </span>            :                 p = task_of(se);</a>
<a name="934"><span class="lineNum">     934 </span>            : </a>
<a name="935"><span class="lineNum">     935 </span>            :         __update_stats_wait_start(rq_of(cfs_rq), p, stats);</a>
<a name="936"><span class="lineNum">     936 </span>            : }</a>
<a name="937"><span class="lineNum">     937 </span>            : </a>
<a name="938"><span class="lineNum">     938 </span>            : static inline void</a>
<a name="939"><span class="lineNum">     939 </span>            : update_stats_wait_end_fair(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="940"><span class="lineNum">     940 </span>            : {</a>
<a name="941"><span class="lineNum">     941 </span>            :         struct sched_statistics *stats;</a>
<a name="942"><span class="lineNum">     942 </span><span class="lineCov">        618 :         struct task_struct *p = NULL;</span></a>
<a name="943"><span class="lineNum">     943 </span>            : </a>
<a name="944"><span class="lineNum">     944 </span>            :         if (!schedstat_enabled())</a>
<a name="945"><span class="lineNum">     945 </span>            :                 return;</a>
<a name="946"><span class="lineNum">     946 </span>            : </a>
<a name="947"><span class="lineNum">     947 </span>            :         stats = __schedstats_from_se(se);</a>
<a name="948"><span class="lineNum">     948 </span>            : </a>
<a name="949"><span class="lineNum">     949 </span>            :         /*</a>
<a name="950"><span class="lineNum">     950 </span>            :          * When the sched_schedstat changes from 0 to 1, some sched se</a>
<a name="951"><span class="lineNum">     951 </span>            :          * maybe already in the runqueue, the se-&gt;statistics.wait_start</a>
<a name="952"><span class="lineNum">     952 </span>            :          * will be 0.So it will let the delta wrong. We need to avoid this</a>
<a name="953"><span class="lineNum">     953 </span>            :          * scenario.</a>
<a name="954"><span class="lineNum">     954 </span>            :          */</a>
<a name="955"><span class="lineNum">     955 </span>            :         if (unlikely(!schedstat_val(stats-&gt;wait_start)))</a>
<a name="956"><span class="lineNum">     956 </span>            :                 return;</a>
<a name="957"><span class="lineNum">     957 </span>            : </a>
<a name="958"><span class="lineNum">     958 </span>            :         if (entity_is_task(se))</a>
<a name="959"><span class="lineNum">     959 </span>            :                 p = task_of(se);</a>
<a name="960"><span class="lineNum">     960 </span>            : </a>
<a name="961"><span class="lineNum">     961 </span>            :         __update_stats_wait_end(rq_of(cfs_rq), p, stats);</a>
<a name="962"><span class="lineNum">     962 </span>            : }</a>
<a name="963"><span class="lineNum">     963 </span>            : </a>
<a name="964"><span class="lineNum">     964 </span>            : static inline void</a>
<a name="965"><span class="lineNum">     965 </span>            : update_stats_enqueue_sleeper_fair(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="966"><span class="lineNum">     966 </span>            : {</a>
<a name="967"><span class="lineNum">     967 </span>            :         struct sched_statistics *stats;</a>
<a name="968"><span class="lineNum">     968 </span>            :         struct task_struct *tsk = NULL;</a>
<a name="969"><span class="lineNum">     969 </span>            : </a>
<a name="970"><span class="lineNum">     970 </span>            :         if (!schedstat_enabled())</a>
<a name="971"><span class="lineNum">     971 </span>            :                 return;</a>
<a name="972"><span class="lineNum">     972 </span>            : </a>
<a name="973"><span class="lineNum">     973 </span>            :         stats = __schedstats_from_se(se);</a>
<a name="974"><span class="lineNum">     974 </span>            : </a>
<a name="975"><span class="lineNum">     975 </span>            :         if (entity_is_task(se))</a>
<a name="976"><span class="lineNum">     976 </span>            :                 tsk = task_of(se);</a>
<a name="977"><span class="lineNum">     977 </span>            : </a>
<a name="978"><span class="lineNum">     978 </span>            :         __update_stats_enqueue_sleeper(rq_of(cfs_rq), tsk, stats);</a>
<a name="979"><span class="lineNum">     979 </span>            : }</a>
<a name="980"><span class="lineNum">     980 </span>            : </a>
<a name="981"><span class="lineNum">     981 </span>            : /*</a>
<a name="982"><span class="lineNum">     982 </span>            :  * Task is being enqueued - update stats:</a>
<a name="983"><span class="lineNum">     983 </span>            :  */</a>
<a name="984"><span class="lineNum">     984 </span>            : static inline void</a>
<a name="985"><span class="lineNum">     985 </span>            : update_stats_enqueue_fair(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)</a>
<a name="986"><span class="lineNum">     986 </span>            : {</a>
<a name="987"><span class="lineNum">     987 </span>            :         if (!schedstat_enabled())</a>
<a name="988"><span class="lineNum">     988 </span>            :                 return;</a>
<a name="989"><span class="lineNum">     989 </span>            : </a>
<a name="990"><span class="lineNum">     990 </span>            :         /*</a>
<a name="991"><span class="lineNum">     991 </span>            :          * Are we enqueueing a waiting task? (for current tasks</a>
<a name="992"><span class="lineNum">     992 </span>            :          * a dequeue/enqueue event is a NOP)</a>
<a name="993"><span class="lineNum">     993 </span>            :          */</a>
<a name="994"><span class="lineNum">     994 </span>            :         if (se != cfs_rq-&gt;curr)</a>
<a name="995"><span class="lineNum">     995 </span>            :                 update_stats_wait_start_fair(cfs_rq, se);</a>
<a name="996"><span class="lineNum">     996 </span>            : </a>
<a name="997"><span class="lineNum">     997 </span>            :         if (flags &amp; ENQUEUE_WAKEUP)</a>
<a name="998"><span class="lineNum">     998 </span>            :                 update_stats_enqueue_sleeper_fair(cfs_rq, se);</a>
<a name="999"><span class="lineNum">     999 </span>            : }</a>
<a name="1000"><span class="lineNum">    1000 </span>            : </a>
<a name="1001"><span class="lineNum">    1001 </span>            : static inline void</a>
<a name="1002"><span class="lineNum">    1002 </span>            : update_stats_dequeue_fair(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)</a>
<a name="1003"><span class="lineNum">    1003 </span>            : {</a>
<a name="1004"><span class="lineNum">    1004 </span>            : </a>
<a name="1005"><span class="lineNum">    1005 </span>            :         if (!schedstat_enabled())</a>
<a name="1006"><span class="lineNum">    1006 </span>            :                 return;</a>
<a name="1007"><span class="lineNum">    1007 </span>            : </a>
<a name="1008"><span class="lineNum">    1008 </span>            :         /*</a>
<a name="1009"><span class="lineNum">    1009 </span>            :          * Mark the end of the wait period if dequeueing a</a>
<a name="1010"><span class="lineNum">    1010 </span>            :          * waiting task:</a>
<a name="1011"><span class="lineNum">    1011 </span>            :          */</a>
<a name="1012"><span class="lineNum">    1012 </span>            :         if (se != cfs_rq-&gt;curr)</a>
<a name="1013"><span class="lineNum">    1013 </span>            :                 update_stats_wait_end_fair(cfs_rq, se);</a>
<a name="1014"><span class="lineNum">    1014 </span>            : </a>
<a name="1015"><span class="lineNum">    1015 </span>            :         if ((flags &amp; DEQUEUE_SLEEP) &amp;&amp; entity_is_task(se)) {</a>
<a name="1016"><span class="lineNum">    1016 </span>            :                 struct task_struct *tsk = task_of(se);</a>
<a name="1017"><span class="lineNum">    1017 </span>            :                 unsigned int state;</a>
<a name="1018"><span class="lineNum">    1018 </span>            : </a>
<a name="1019"><span class="lineNum">    1019 </span>            :                 /* XXX racy against TTWU */</a>
<a name="1020"><span class="lineNum">    1020 </span>            :                 state = READ_ONCE(tsk-&gt;__state);</a>
<a name="1021"><span class="lineNum">    1021 </span>            :                 if (state &amp; TASK_INTERRUPTIBLE)</a>
<a name="1022"><span class="lineNum">    1022 </span>            :                         __schedstat_set(tsk-&gt;stats.sleep_start,</a>
<a name="1023"><span class="lineNum">    1023 </span>            :                                       rq_clock(rq_of(cfs_rq)));</a>
<a name="1024"><span class="lineNum">    1024 </span>            :                 if (state &amp; TASK_UNINTERRUPTIBLE)</a>
<a name="1025"><span class="lineNum">    1025 </span>            :                         __schedstat_set(tsk-&gt;stats.block_start,</a>
<a name="1026"><span class="lineNum">    1026 </span>            :                                       rq_clock(rq_of(cfs_rq)));</a>
<a name="1027"><span class="lineNum">    1027 </span>            :         }</a>
<a name="1028"><span class="lineNum">    1028 </span>            : }</a>
<a name="1029"><span class="lineNum">    1029 </span>            : </a>
<a name="1030"><span class="lineNum">    1030 </span>            : /*</a>
<a name="1031"><span class="lineNum">    1031 </span>            :  * We are picking a new current task - update its stats:</a>
<a name="1032"><span class="lineNum">    1032 </span>            :  */</a>
<a name="1033"><span class="lineNum">    1033 </span>            : static inline void</a>
<a name="1034"><span class="lineNum">    1034 </span>            : update_stats_curr_start(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="1035"><span class="lineNum">    1035 </span>            : {</a>
<a name="1036"><span class="lineNum">    1036 </span>            :         /*</a>
<a name="1037"><span class="lineNum">    1037 </span>            :          * We are starting a new run period:</a>
<a name="1038"><span class="lineNum">    1038 </span>            :          */</a>
<a name="1039"><span class="lineNum">    1039 </span><span class="lineCov">       1236 :         se-&gt;exec_start = rq_clock_task(rq_of(cfs_rq));</span></a>
<a name="1040"><span class="lineNum">    1040 </span>            : }</a>
<a name="1041"><span class="lineNum">    1041 </span>            : </a>
<a name="1042"><span class="lineNum">    1042 </span>            : /**************************************************</a>
<a name="1043"><span class="lineNum">    1043 </span>            :  * Scheduling class queueing methods:</a>
<a name="1044"><span class="lineNum">    1044 </span>            :  */</a>
<a name="1045"><span class="lineNum">    1045 </span>            : </a>
<a name="1046"><span class="lineNum">    1046 </span>            : #ifdef CONFIG_NUMA_BALANCING</a>
<a name="1047"><span class="lineNum">    1047 </span>            : /*</a>
<a name="1048"><span class="lineNum">    1048 </span>            :  * Approximate time to scan a full NUMA task in ms. The task scan period is</a>
<a name="1049"><span class="lineNum">    1049 </span>            :  * calculated based on the tasks virtual memory size and</a>
<a name="1050"><span class="lineNum">    1050 </span>            :  * numa_balancing_scan_size.</a>
<a name="1051"><span class="lineNum">    1051 </span>            :  */</a>
<a name="1052"><span class="lineNum">    1052 </span>            : unsigned int sysctl_numa_balancing_scan_period_min = 1000;</a>
<a name="1053"><span class="lineNum">    1053 </span>            : unsigned int sysctl_numa_balancing_scan_period_max = 60000;</a>
<a name="1054"><span class="lineNum">    1054 </span>            : </a>
<a name="1055"><span class="lineNum">    1055 </span>            : /* Portion of address space to scan in MB */</a>
<a name="1056"><span class="lineNum">    1056 </span>            : unsigned int sysctl_numa_balancing_scan_size = 256;</a>
<a name="1057"><span class="lineNum">    1057 </span>            : </a>
<a name="1058"><span class="lineNum">    1058 </span>            : /* Scan @scan_size MB every @scan_period after an initial @scan_delay in ms */</a>
<a name="1059"><span class="lineNum">    1059 </span>            : unsigned int sysctl_numa_balancing_scan_delay = 1000;</a>
<a name="1060"><span class="lineNum">    1060 </span>            : </a>
<a name="1061"><span class="lineNum">    1061 </span>            : struct numa_group {</a>
<a name="1062"><span class="lineNum">    1062 </span>            :         refcount_t refcount;</a>
<a name="1063"><span class="lineNum">    1063 </span>            : </a>
<a name="1064"><span class="lineNum">    1064 </span>            :         spinlock_t lock; /* nr_tasks, tasks */</a>
<a name="1065"><span class="lineNum">    1065 </span>            :         int nr_tasks;</a>
<a name="1066"><span class="lineNum">    1066 </span>            :         pid_t gid;</a>
<a name="1067"><span class="lineNum">    1067 </span>            :         int active_nodes;</a>
<a name="1068"><span class="lineNum">    1068 </span>            : </a>
<a name="1069"><span class="lineNum">    1069 </span>            :         struct rcu_head rcu;</a>
<a name="1070"><span class="lineNum">    1070 </span>            :         unsigned long total_faults;</a>
<a name="1071"><span class="lineNum">    1071 </span>            :         unsigned long max_faults_cpu;</a>
<a name="1072"><span class="lineNum">    1072 </span>            :         /*</a>
<a name="1073"><span class="lineNum">    1073 </span>            :          * faults[] array is split into two regions: faults_mem and faults_cpu.</a>
<a name="1074"><span class="lineNum">    1074 </span>            :          *</a>
<a name="1075"><span class="lineNum">    1075 </span>            :          * Faults_cpu is used to decide whether memory should move</a>
<a name="1076"><span class="lineNum">    1076 </span>            :          * towards the CPU. As a consequence, these stats are weighted</a>
<a name="1077"><span class="lineNum">    1077 </span>            :          * more by CPU use than by memory faults.</a>
<a name="1078"><span class="lineNum">    1078 </span>            :          */</a>
<a name="1079"><span class="lineNum">    1079 </span>            :         unsigned long faults[];</a>
<a name="1080"><span class="lineNum">    1080 </span>            : };</a>
<a name="1081"><span class="lineNum">    1081 </span>            : </a>
<a name="1082"><span class="lineNum">    1082 </span>            : /*</a>
<a name="1083"><span class="lineNum">    1083 </span>            :  * For functions that can be called in multiple contexts that permit reading</a>
<a name="1084"><span class="lineNum">    1084 </span>            :  * -&gt;numa_group (see struct task_struct for locking rules).</a>
<a name="1085"><span class="lineNum">    1085 </span>            :  */</a>
<a name="1086"><span class="lineNum">    1086 </span>            : static struct numa_group *deref_task_numa_group(struct task_struct *p)</a>
<a name="1087"><span class="lineNum">    1087 </span>            : {</a>
<a name="1088"><span class="lineNum">    1088 </span>            :         return rcu_dereference_check(p-&gt;numa_group, p == current ||</a>
<a name="1089"><span class="lineNum">    1089 </span>            :                 (lockdep_is_held(__rq_lockp(task_rq(p))) &amp;&amp; !READ_ONCE(p-&gt;on_cpu)));</a>
<a name="1090"><span class="lineNum">    1090 </span>            : }</a>
<a name="1091"><span class="lineNum">    1091 </span>            : </a>
<a name="1092"><span class="lineNum">    1092 </span>            : static struct numa_group *deref_curr_numa_group(struct task_struct *p)</a>
<a name="1093"><span class="lineNum">    1093 </span>            : {</a>
<a name="1094"><span class="lineNum">    1094 </span>            :         return rcu_dereference_protected(p-&gt;numa_group, p == current);</a>
<a name="1095"><span class="lineNum">    1095 </span>            : }</a>
<a name="1096"><span class="lineNum">    1096 </span>            : </a>
<a name="1097"><span class="lineNum">    1097 </span>            : static inline unsigned long group_faults_priv(struct numa_group *ng);</a>
<a name="1098"><span class="lineNum">    1098 </span>            : static inline unsigned long group_faults_shared(struct numa_group *ng);</a>
<a name="1099"><span class="lineNum">    1099 </span>            : </a>
<a name="1100"><span class="lineNum">    1100 </span>            : static unsigned int task_nr_scan_windows(struct task_struct *p)</a>
<a name="1101"><span class="lineNum">    1101 </span>            : {</a>
<a name="1102"><span class="lineNum">    1102 </span>            :         unsigned long rss = 0;</a>
<a name="1103"><span class="lineNum">    1103 </span>            :         unsigned long nr_scan_pages;</a>
<a name="1104"><span class="lineNum">    1104 </span>            : </a>
<a name="1105"><span class="lineNum">    1105 </span>            :         /*</a>
<a name="1106"><span class="lineNum">    1106 </span>            :          * Calculations based on RSS as non-present and empty pages are skipped</a>
<a name="1107"><span class="lineNum">    1107 </span>            :          * by the PTE scanner and NUMA hinting faults should be trapped based</a>
<a name="1108"><span class="lineNum">    1108 </span>            :          * on resident pages</a>
<a name="1109"><span class="lineNum">    1109 </span>            :          */</a>
<a name="1110"><span class="lineNum">    1110 </span>            :         nr_scan_pages = sysctl_numa_balancing_scan_size &lt;&lt; (20 - PAGE_SHIFT);</a>
<a name="1111"><span class="lineNum">    1111 </span>            :         rss = get_mm_rss(p-&gt;mm);</a>
<a name="1112"><span class="lineNum">    1112 </span>            :         if (!rss)</a>
<a name="1113"><span class="lineNum">    1113 </span>            :                 rss = nr_scan_pages;</a>
<a name="1114"><span class="lineNum">    1114 </span>            : </a>
<a name="1115"><span class="lineNum">    1115 </span>            :         rss = round_up(rss, nr_scan_pages);</a>
<a name="1116"><span class="lineNum">    1116 </span>            :         return rss / nr_scan_pages;</a>
<a name="1117"><span class="lineNum">    1117 </span>            : }</a>
<a name="1118"><span class="lineNum">    1118 </span>            : </a>
<a name="1119"><span class="lineNum">    1119 </span>            : /* For sanity's sake, never scan more PTEs than MAX_SCAN_WINDOW MB/sec. */</a>
<a name="1120"><span class="lineNum">    1120 </span>            : #define MAX_SCAN_WINDOW 2560</a>
<a name="1121"><span class="lineNum">    1121 </span>            : </a>
<a name="1122"><span class="lineNum">    1122 </span>            : static unsigned int task_scan_min(struct task_struct *p)</a>
<a name="1123"><span class="lineNum">    1123 </span>            : {</a>
<a name="1124"><span class="lineNum">    1124 </span>            :         unsigned int scan_size = READ_ONCE(sysctl_numa_balancing_scan_size);</a>
<a name="1125"><span class="lineNum">    1125 </span>            :         unsigned int scan, floor;</a>
<a name="1126"><span class="lineNum">    1126 </span>            :         unsigned int windows = 1;</a>
<a name="1127"><span class="lineNum">    1127 </span>            : </a>
<a name="1128"><span class="lineNum">    1128 </span>            :         if (scan_size &lt; MAX_SCAN_WINDOW)</a>
<a name="1129"><span class="lineNum">    1129 </span>            :                 windows = MAX_SCAN_WINDOW / scan_size;</a>
<a name="1130"><span class="lineNum">    1130 </span>            :         floor = 1000 / windows;</a>
<a name="1131"><span class="lineNum">    1131 </span>            : </a>
<a name="1132"><span class="lineNum">    1132 </span>            :         scan = sysctl_numa_balancing_scan_period_min / task_nr_scan_windows(p);</a>
<a name="1133"><span class="lineNum">    1133 </span>            :         return max_t(unsigned int, floor, scan);</a>
<a name="1134"><span class="lineNum">    1134 </span>            : }</a>
<a name="1135"><span class="lineNum">    1135 </span>            : </a>
<a name="1136"><span class="lineNum">    1136 </span>            : static unsigned int task_scan_start(struct task_struct *p)</a>
<a name="1137"><span class="lineNum">    1137 </span>            : {</a>
<a name="1138"><span class="lineNum">    1138 </span>            :         unsigned long smin = task_scan_min(p);</a>
<a name="1139"><span class="lineNum">    1139 </span>            :         unsigned long period = smin;</a>
<a name="1140"><span class="lineNum">    1140 </span>            :         struct numa_group *ng;</a>
<a name="1141"><span class="lineNum">    1141 </span>            : </a>
<a name="1142"><span class="lineNum">    1142 </span>            :         /* Scale the maximum scan period with the amount of shared memory. */</a>
<a name="1143"><span class="lineNum">    1143 </span>            :         rcu_read_lock();</a>
<a name="1144"><span class="lineNum">    1144 </span>            :         ng = rcu_dereference(p-&gt;numa_group);</a>
<a name="1145"><span class="lineNum">    1145 </span>            :         if (ng) {</a>
<a name="1146"><span class="lineNum">    1146 </span>            :                 unsigned long shared = group_faults_shared(ng);</a>
<a name="1147"><span class="lineNum">    1147 </span>            :                 unsigned long private = group_faults_priv(ng);</a>
<a name="1148"><span class="lineNum">    1148 </span>            : </a>
<a name="1149"><span class="lineNum">    1149 </span>            :                 period *= refcount_read(&amp;ng-&gt;refcount);</a>
<a name="1150"><span class="lineNum">    1150 </span>            :                 period *= shared + 1;</a>
<a name="1151"><span class="lineNum">    1151 </span>            :                 period /= private + shared + 1;</a>
<a name="1152"><span class="lineNum">    1152 </span>            :         }</a>
<a name="1153"><span class="lineNum">    1153 </span>            :         rcu_read_unlock();</a>
<a name="1154"><span class="lineNum">    1154 </span>            : </a>
<a name="1155"><span class="lineNum">    1155 </span>            :         return max(smin, period);</a>
<a name="1156"><span class="lineNum">    1156 </span>            : }</a>
<a name="1157"><span class="lineNum">    1157 </span>            : </a>
<a name="1158"><span class="lineNum">    1158 </span>            : static unsigned int task_scan_max(struct task_struct *p)</a>
<a name="1159"><span class="lineNum">    1159 </span>            : {</a>
<a name="1160"><span class="lineNum">    1160 </span>            :         unsigned long smin = task_scan_min(p);</a>
<a name="1161"><span class="lineNum">    1161 </span>            :         unsigned long smax;</a>
<a name="1162"><span class="lineNum">    1162 </span>            :         struct numa_group *ng;</a>
<a name="1163"><span class="lineNum">    1163 </span>            : </a>
<a name="1164"><span class="lineNum">    1164 </span>            :         /* Watch for min being lower than max due to floor calculations */</a>
<a name="1165"><span class="lineNum">    1165 </span>            :         smax = sysctl_numa_balancing_scan_period_max / task_nr_scan_windows(p);</a>
<a name="1166"><span class="lineNum">    1166 </span>            : </a>
<a name="1167"><span class="lineNum">    1167 </span>            :         /* Scale the maximum scan period with the amount of shared memory. */</a>
<a name="1168"><span class="lineNum">    1168 </span>            :         ng = deref_curr_numa_group(p);</a>
<a name="1169"><span class="lineNum">    1169 </span>            :         if (ng) {</a>
<a name="1170"><span class="lineNum">    1170 </span>            :                 unsigned long shared = group_faults_shared(ng);</a>
<a name="1171"><span class="lineNum">    1171 </span>            :                 unsigned long private = group_faults_priv(ng);</a>
<a name="1172"><span class="lineNum">    1172 </span>            :                 unsigned long period = smax;</a>
<a name="1173"><span class="lineNum">    1173 </span>            : </a>
<a name="1174"><span class="lineNum">    1174 </span>            :                 period *= refcount_read(&amp;ng-&gt;refcount);</a>
<a name="1175"><span class="lineNum">    1175 </span>            :                 period *= shared + 1;</a>
<a name="1176"><span class="lineNum">    1176 </span>            :                 period /= private + shared + 1;</a>
<a name="1177"><span class="lineNum">    1177 </span>            : </a>
<a name="1178"><span class="lineNum">    1178 </span>            :                 smax = max(smax, period);</a>
<a name="1179"><span class="lineNum">    1179 </span>            :         }</a>
<a name="1180"><span class="lineNum">    1180 </span>            : </a>
<a name="1181"><span class="lineNum">    1181 </span>            :         return max(smin, smax);</a>
<a name="1182"><span class="lineNum">    1182 </span>            : }</a>
<a name="1183"><span class="lineNum">    1183 </span>            : </a>
<a name="1184"><span class="lineNum">    1184 </span>            : static void account_numa_enqueue(struct rq *rq, struct task_struct *p)</a>
<a name="1185"><span class="lineNum">    1185 </span>            : {</a>
<a name="1186"><span class="lineNum">    1186 </span>            :         rq-&gt;nr_numa_running += (p-&gt;numa_preferred_nid != NUMA_NO_NODE);</a>
<a name="1187"><span class="lineNum">    1187 </span>            :         rq-&gt;nr_preferred_running += (p-&gt;numa_preferred_nid == task_node(p));</a>
<a name="1188"><span class="lineNum">    1188 </span>            : }</a>
<a name="1189"><span class="lineNum">    1189 </span>            : </a>
<a name="1190"><span class="lineNum">    1190 </span>            : static void account_numa_dequeue(struct rq *rq, struct task_struct *p)</a>
<a name="1191"><span class="lineNum">    1191 </span>            : {</a>
<a name="1192"><span class="lineNum">    1192 </span>            :         rq-&gt;nr_numa_running -= (p-&gt;numa_preferred_nid != NUMA_NO_NODE);</a>
<a name="1193"><span class="lineNum">    1193 </span>            :         rq-&gt;nr_preferred_running -= (p-&gt;numa_preferred_nid == task_node(p));</a>
<a name="1194"><span class="lineNum">    1194 </span>            : }</a>
<a name="1195"><span class="lineNum">    1195 </span>            : </a>
<a name="1196"><span class="lineNum">    1196 </span>            : /* Shared or private faults. */</a>
<a name="1197"><span class="lineNum">    1197 </span>            : #define NR_NUMA_HINT_FAULT_TYPES 2</a>
<a name="1198"><span class="lineNum">    1198 </span>            : </a>
<a name="1199"><span class="lineNum">    1199 </span>            : /* Memory and CPU locality */</a>
<a name="1200"><span class="lineNum">    1200 </span>            : #define NR_NUMA_HINT_FAULT_STATS (NR_NUMA_HINT_FAULT_TYPES * 2)</a>
<a name="1201"><span class="lineNum">    1201 </span>            : </a>
<a name="1202"><span class="lineNum">    1202 </span>            : /* Averaged statistics, and temporary buffers. */</a>
<a name="1203"><span class="lineNum">    1203 </span>            : #define NR_NUMA_HINT_FAULT_BUCKETS (NR_NUMA_HINT_FAULT_STATS * 2)</a>
<a name="1204"><span class="lineNum">    1204 </span>            : </a>
<a name="1205"><span class="lineNum">    1205 </span>            : pid_t task_numa_group_id(struct task_struct *p)</a>
<a name="1206"><span class="lineNum">    1206 </span>            : {</a>
<a name="1207"><span class="lineNum">    1207 </span>            :         struct numa_group *ng;</a>
<a name="1208"><span class="lineNum">    1208 </span>            :         pid_t gid = 0;</a>
<a name="1209"><span class="lineNum">    1209 </span>            : </a>
<a name="1210"><span class="lineNum">    1210 </span>            :         rcu_read_lock();</a>
<a name="1211"><span class="lineNum">    1211 </span>            :         ng = rcu_dereference(p-&gt;numa_group);</a>
<a name="1212"><span class="lineNum">    1212 </span>            :         if (ng)</a>
<a name="1213"><span class="lineNum">    1213 </span>            :                 gid = ng-&gt;gid;</a>
<a name="1214"><span class="lineNum">    1214 </span>            :         rcu_read_unlock();</a>
<a name="1215"><span class="lineNum">    1215 </span>            : </a>
<a name="1216"><span class="lineNum">    1216 </span>            :         return gid;</a>
<a name="1217"><span class="lineNum">    1217 </span>            : }</a>
<a name="1218"><span class="lineNum">    1218 </span>            : </a>
<a name="1219"><span class="lineNum">    1219 </span>            : /*</a>
<a name="1220"><span class="lineNum">    1220 </span>            :  * The averaged statistics, shared &amp; private, memory &amp; CPU,</a>
<a name="1221"><span class="lineNum">    1221 </span>            :  * occupy the first half of the array. The second half of the</a>
<a name="1222"><span class="lineNum">    1222 </span>            :  * array is for current counters, which are averaged into the</a>
<a name="1223"><span class="lineNum">    1223 </span>            :  * first set by task_numa_placement.</a>
<a name="1224"><span class="lineNum">    1224 </span>            :  */</a>
<a name="1225"><span class="lineNum">    1225 </span>            : static inline int task_faults_idx(enum numa_faults_stats s, int nid, int priv)</a>
<a name="1226"><span class="lineNum">    1226 </span>            : {</a>
<a name="1227"><span class="lineNum">    1227 </span>            :         return NR_NUMA_HINT_FAULT_TYPES * (s * nr_node_ids + nid) + priv;</a>
<a name="1228"><span class="lineNum">    1228 </span>            : }</a>
<a name="1229"><span class="lineNum">    1229 </span>            : </a>
<a name="1230"><span class="lineNum">    1230 </span>            : static inline unsigned long task_faults(struct task_struct *p, int nid)</a>
<a name="1231"><span class="lineNum">    1231 </span>            : {</a>
<a name="1232"><span class="lineNum">    1232 </span>            :         if (!p-&gt;numa_faults)</a>
<a name="1233"><span class="lineNum">    1233 </span>            :                 return 0;</a>
<a name="1234"><span class="lineNum">    1234 </span>            : </a>
<a name="1235"><span class="lineNum">    1235 </span>            :         return p-&gt;numa_faults[task_faults_idx(NUMA_MEM, nid, 0)] +</a>
<a name="1236"><span class="lineNum">    1236 </span>            :                 p-&gt;numa_faults[task_faults_idx(NUMA_MEM, nid, 1)];</a>
<a name="1237"><span class="lineNum">    1237 </span>            : }</a>
<a name="1238"><span class="lineNum">    1238 </span>            : </a>
<a name="1239"><span class="lineNum">    1239 </span>            : static inline unsigned long group_faults(struct task_struct *p, int nid)</a>
<a name="1240"><span class="lineNum">    1240 </span>            : {</a>
<a name="1241"><span class="lineNum">    1241 </span>            :         struct numa_group *ng = deref_task_numa_group(p);</a>
<a name="1242"><span class="lineNum">    1242 </span>            : </a>
<a name="1243"><span class="lineNum">    1243 </span>            :         if (!ng)</a>
<a name="1244"><span class="lineNum">    1244 </span>            :                 return 0;</a>
<a name="1245"><span class="lineNum">    1245 </span>            : </a>
<a name="1246"><span class="lineNum">    1246 </span>            :         return ng-&gt;faults[task_faults_idx(NUMA_MEM, nid, 0)] +</a>
<a name="1247"><span class="lineNum">    1247 </span>            :                 ng-&gt;faults[task_faults_idx(NUMA_MEM, nid, 1)];</a>
<a name="1248"><span class="lineNum">    1248 </span>            : }</a>
<a name="1249"><span class="lineNum">    1249 </span>            : </a>
<a name="1250"><span class="lineNum">    1250 </span>            : static inline unsigned long group_faults_cpu(struct numa_group *group, int nid)</a>
<a name="1251"><span class="lineNum">    1251 </span>            : {</a>
<a name="1252"><span class="lineNum">    1252 </span>            :         return group-&gt;faults[task_faults_idx(NUMA_CPU, nid, 0)] +</a>
<a name="1253"><span class="lineNum">    1253 </span>            :                 group-&gt;faults[task_faults_idx(NUMA_CPU, nid, 1)];</a>
<a name="1254"><span class="lineNum">    1254 </span>            : }</a>
<a name="1255"><span class="lineNum">    1255 </span>            : </a>
<a name="1256"><span class="lineNum">    1256 </span>            : static inline unsigned long group_faults_priv(struct numa_group *ng)</a>
<a name="1257"><span class="lineNum">    1257 </span>            : {</a>
<a name="1258"><span class="lineNum">    1258 </span>            :         unsigned long faults = 0;</a>
<a name="1259"><span class="lineNum">    1259 </span>            :         int node;</a>
<a name="1260"><span class="lineNum">    1260 </span>            : </a>
<a name="1261"><span class="lineNum">    1261 </span>            :         for_each_online_node(node) {</a>
<a name="1262"><span class="lineNum">    1262 </span>            :                 faults += ng-&gt;faults[task_faults_idx(NUMA_MEM, node, 1)];</a>
<a name="1263"><span class="lineNum">    1263 </span>            :         }</a>
<a name="1264"><span class="lineNum">    1264 </span>            : </a>
<a name="1265"><span class="lineNum">    1265 </span>            :         return faults;</a>
<a name="1266"><span class="lineNum">    1266 </span>            : }</a>
<a name="1267"><span class="lineNum">    1267 </span>            : </a>
<a name="1268"><span class="lineNum">    1268 </span>            : static inline unsigned long group_faults_shared(struct numa_group *ng)</a>
<a name="1269"><span class="lineNum">    1269 </span>            : {</a>
<a name="1270"><span class="lineNum">    1270 </span>            :         unsigned long faults = 0;</a>
<a name="1271"><span class="lineNum">    1271 </span>            :         int node;</a>
<a name="1272"><span class="lineNum">    1272 </span>            : </a>
<a name="1273"><span class="lineNum">    1273 </span>            :         for_each_online_node(node) {</a>
<a name="1274"><span class="lineNum">    1274 </span>            :                 faults += ng-&gt;faults[task_faults_idx(NUMA_MEM, node, 0)];</a>
<a name="1275"><span class="lineNum">    1275 </span>            :         }</a>
<a name="1276"><span class="lineNum">    1276 </span>            : </a>
<a name="1277"><span class="lineNum">    1277 </span>            :         return faults;</a>
<a name="1278"><span class="lineNum">    1278 </span>            : }</a>
<a name="1279"><span class="lineNum">    1279 </span>            : </a>
<a name="1280"><span class="lineNum">    1280 </span>            : /*</a>
<a name="1281"><span class="lineNum">    1281 </span>            :  * A node triggering more than 1/3 as many NUMA faults as the maximum is</a>
<a name="1282"><span class="lineNum">    1282 </span>            :  * considered part of a numa group's pseudo-interleaving set. Migrations</a>
<a name="1283"><span class="lineNum">    1283 </span>            :  * between these nodes are slowed down, to allow things to settle down.</a>
<a name="1284"><span class="lineNum">    1284 </span>            :  */</a>
<a name="1285"><span class="lineNum">    1285 </span>            : #define ACTIVE_NODE_FRACTION 3</a>
<a name="1286"><span class="lineNum">    1286 </span>            : </a>
<a name="1287"><span class="lineNum">    1287 </span>            : static bool numa_is_active_node(int nid, struct numa_group *ng)</a>
<a name="1288"><span class="lineNum">    1288 </span>            : {</a>
<a name="1289"><span class="lineNum">    1289 </span>            :         return group_faults_cpu(ng, nid) * ACTIVE_NODE_FRACTION &gt; ng-&gt;max_faults_cpu;</a>
<a name="1290"><span class="lineNum">    1290 </span>            : }</a>
<a name="1291"><span class="lineNum">    1291 </span>            : </a>
<a name="1292"><span class="lineNum">    1292 </span>            : /* Handle placement on systems where not all nodes are directly connected. */</a>
<a name="1293"><span class="lineNum">    1293 </span>            : static unsigned long score_nearby_nodes(struct task_struct *p, int nid,</a>
<a name="1294"><span class="lineNum">    1294 </span>            :                                         int lim_dist, bool task)</a>
<a name="1295"><span class="lineNum">    1295 </span>            : {</a>
<a name="1296"><span class="lineNum">    1296 </span>            :         unsigned long score = 0;</a>
<a name="1297"><span class="lineNum">    1297 </span>            :         int node, max_dist;</a>
<a name="1298"><span class="lineNum">    1298 </span>            : </a>
<a name="1299"><span class="lineNum">    1299 </span>            :         /*</a>
<a name="1300"><span class="lineNum">    1300 </span>            :          * All nodes are directly connected, and the same distance</a>
<a name="1301"><span class="lineNum">    1301 </span>            :          * from each other. No need for fancy placement algorithms.</a>
<a name="1302"><span class="lineNum">    1302 </span>            :          */</a>
<a name="1303"><span class="lineNum">    1303 </span>            :         if (sched_numa_topology_type == NUMA_DIRECT)</a>
<a name="1304"><span class="lineNum">    1304 </span>            :                 return 0;</a>
<a name="1305"><span class="lineNum">    1305 </span>            : </a>
<a name="1306"><span class="lineNum">    1306 </span>            :         /* sched_max_numa_distance may be changed in parallel. */</a>
<a name="1307"><span class="lineNum">    1307 </span>            :         max_dist = READ_ONCE(sched_max_numa_distance);</a>
<a name="1308"><span class="lineNum">    1308 </span>            :         /*</a>
<a name="1309"><span class="lineNum">    1309 </span>            :          * This code is called for each node, introducing N^2 complexity,</a>
<a name="1310"><span class="lineNum">    1310 </span>            :          * which should be ok given the number of nodes rarely exceeds 8.</a>
<a name="1311"><span class="lineNum">    1311 </span>            :          */</a>
<a name="1312"><span class="lineNum">    1312 </span>            :         for_each_online_node(node) {</a>
<a name="1313"><span class="lineNum">    1313 </span>            :                 unsigned long faults;</a>
<a name="1314"><span class="lineNum">    1314 </span>            :                 int dist = node_distance(nid, node);</a>
<a name="1315"><span class="lineNum">    1315 </span>            : </a>
<a name="1316"><span class="lineNum">    1316 </span>            :                 /*</a>
<a name="1317"><span class="lineNum">    1317 </span>            :                  * The furthest away nodes in the system are not interesting</a>
<a name="1318"><span class="lineNum">    1318 </span>            :                  * for placement; nid was already counted.</a>
<a name="1319"><span class="lineNum">    1319 </span>            :                  */</a>
<a name="1320"><span class="lineNum">    1320 </span>            :                 if (dist &gt;= max_dist || node == nid)</a>
<a name="1321"><span class="lineNum">    1321 </span>            :                         continue;</a>
<a name="1322"><span class="lineNum">    1322 </span>            : </a>
<a name="1323"><span class="lineNum">    1323 </span>            :                 /*</a>
<a name="1324"><span class="lineNum">    1324 </span>            :                  * On systems with a backplane NUMA topology, compare groups</a>
<a name="1325"><span class="lineNum">    1325 </span>            :                  * of nodes, and move tasks towards the group with the most</a>
<a name="1326"><span class="lineNum">    1326 </span>            :                  * memory accesses. When comparing two nodes at distance</a>
<a name="1327"><span class="lineNum">    1327 </span>            :                  * &quot;hoplimit&quot;, only nodes closer by than &quot;hoplimit&quot; are part</a>
<a name="1328"><span class="lineNum">    1328 </span>            :                  * of each group. Skip other nodes.</a>
<a name="1329"><span class="lineNum">    1329 </span>            :                  */</a>
<a name="1330"><span class="lineNum">    1330 </span>            :                 if (sched_numa_topology_type == NUMA_BACKPLANE &amp;&amp; dist &gt;= lim_dist)</a>
<a name="1331"><span class="lineNum">    1331 </span>            :                         continue;</a>
<a name="1332"><span class="lineNum">    1332 </span>            : </a>
<a name="1333"><span class="lineNum">    1333 </span>            :                 /* Add up the faults from nearby nodes. */</a>
<a name="1334"><span class="lineNum">    1334 </span>            :                 if (task)</a>
<a name="1335"><span class="lineNum">    1335 </span>            :                         faults = task_faults(p, node);</a>
<a name="1336"><span class="lineNum">    1336 </span>            :                 else</a>
<a name="1337"><span class="lineNum">    1337 </span>            :                         faults = group_faults(p, node);</a>
<a name="1338"><span class="lineNum">    1338 </span>            : </a>
<a name="1339"><span class="lineNum">    1339 </span>            :                 /*</a>
<a name="1340"><span class="lineNum">    1340 </span>            :                  * On systems with a glueless mesh NUMA topology, there are</a>
<a name="1341"><span class="lineNum">    1341 </span>            :                  * no fixed &quot;groups of nodes&quot;. Instead, nodes that are not</a>
<a name="1342"><span class="lineNum">    1342 </span>            :                  * directly connected bounce traffic through intermediate</a>
<a name="1343"><span class="lineNum">    1343 </span>            :                  * nodes; a numa_group can occupy any set of nodes.</a>
<a name="1344"><span class="lineNum">    1344 </span>            :                  * The further away a node is, the less the faults count.</a>
<a name="1345"><span class="lineNum">    1345 </span>            :                  * This seems to result in good task placement.</a>
<a name="1346"><span class="lineNum">    1346 </span>            :                  */</a>
<a name="1347"><span class="lineNum">    1347 </span>            :                 if (sched_numa_topology_type == NUMA_GLUELESS_MESH) {</a>
<a name="1348"><span class="lineNum">    1348 </span>            :                         faults *= (max_dist - dist);</a>
<a name="1349"><span class="lineNum">    1349 </span>            :                         faults /= (max_dist - LOCAL_DISTANCE);</a>
<a name="1350"><span class="lineNum">    1350 </span>            :                 }</a>
<a name="1351"><span class="lineNum">    1351 </span>            : </a>
<a name="1352"><span class="lineNum">    1352 </span>            :                 score += faults;</a>
<a name="1353"><span class="lineNum">    1353 </span>            :         }</a>
<a name="1354"><span class="lineNum">    1354 </span>            : </a>
<a name="1355"><span class="lineNum">    1355 </span>            :         return score;</a>
<a name="1356"><span class="lineNum">    1356 </span>            : }</a>
<a name="1357"><span class="lineNum">    1357 </span>            : </a>
<a name="1358"><span class="lineNum">    1358 </span>            : /*</a>
<a name="1359"><span class="lineNum">    1359 </span>            :  * These return the fraction of accesses done by a particular task, or</a>
<a name="1360"><span class="lineNum">    1360 </span>            :  * task group, on a particular numa node.  The group weight is given a</a>
<a name="1361"><span class="lineNum">    1361 </span>            :  * larger multiplier, in order to group tasks together that are almost</a>
<a name="1362"><span class="lineNum">    1362 </span>            :  * evenly spread out between numa nodes.</a>
<a name="1363"><span class="lineNum">    1363 </span>            :  */</a>
<a name="1364"><span class="lineNum">    1364 </span>            : static inline unsigned long task_weight(struct task_struct *p, int nid,</a>
<a name="1365"><span class="lineNum">    1365 </span>            :                                         int dist)</a>
<a name="1366"><span class="lineNum">    1366 </span>            : {</a>
<a name="1367"><span class="lineNum">    1367 </span>            :         unsigned long faults, total_faults;</a>
<a name="1368"><span class="lineNum">    1368 </span>            : </a>
<a name="1369"><span class="lineNum">    1369 </span>            :         if (!p-&gt;numa_faults)</a>
<a name="1370"><span class="lineNum">    1370 </span>            :                 return 0;</a>
<a name="1371"><span class="lineNum">    1371 </span>            : </a>
<a name="1372"><span class="lineNum">    1372 </span>            :         total_faults = p-&gt;total_numa_faults;</a>
<a name="1373"><span class="lineNum">    1373 </span>            : </a>
<a name="1374"><span class="lineNum">    1374 </span>            :         if (!total_faults)</a>
<a name="1375"><span class="lineNum">    1375 </span>            :                 return 0;</a>
<a name="1376"><span class="lineNum">    1376 </span>            : </a>
<a name="1377"><span class="lineNum">    1377 </span>            :         faults = task_faults(p, nid);</a>
<a name="1378"><span class="lineNum">    1378 </span>            :         faults += score_nearby_nodes(p, nid, dist, true);</a>
<a name="1379"><span class="lineNum">    1379 </span>            : </a>
<a name="1380"><span class="lineNum">    1380 </span>            :         return 1000 * faults / total_faults;</a>
<a name="1381"><span class="lineNum">    1381 </span>            : }</a>
<a name="1382"><span class="lineNum">    1382 </span>            : </a>
<a name="1383"><span class="lineNum">    1383 </span>            : static inline unsigned long group_weight(struct task_struct *p, int nid,</a>
<a name="1384"><span class="lineNum">    1384 </span>            :                                          int dist)</a>
<a name="1385"><span class="lineNum">    1385 </span>            : {</a>
<a name="1386"><span class="lineNum">    1386 </span>            :         struct numa_group *ng = deref_task_numa_group(p);</a>
<a name="1387"><span class="lineNum">    1387 </span>            :         unsigned long faults, total_faults;</a>
<a name="1388"><span class="lineNum">    1388 </span>            : </a>
<a name="1389"><span class="lineNum">    1389 </span>            :         if (!ng)</a>
<a name="1390"><span class="lineNum">    1390 </span>            :                 return 0;</a>
<a name="1391"><span class="lineNum">    1391 </span>            : </a>
<a name="1392"><span class="lineNum">    1392 </span>            :         total_faults = ng-&gt;total_faults;</a>
<a name="1393"><span class="lineNum">    1393 </span>            : </a>
<a name="1394"><span class="lineNum">    1394 </span>            :         if (!total_faults)</a>
<a name="1395"><span class="lineNum">    1395 </span>            :                 return 0;</a>
<a name="1396"><span class="lineNum">    1396 </span>            : </a>
<a name="1397"><span class="lineNum">    1397 </span>            :         faults = group_faults(p, nid);</a>
<a name="1398"><span class="lineNum">    1398 </span>            :         faults += score_nearby_nodes(p, nid, dist, false);</a>
<a name="1399"><span class="lineNum">    1399 </span>            : </a>
<a name="1400"><span class="lineNum">    1400 </span>            :         return 1000 * faults / total_faults;</a>
<a name="1401"><span class="lineNum">    1401 </span>            : }</a>
<a name="1402"><span class="lineNum">    1402 </span>            : </a>
<a name="1403"><span class="lineNum">    1403 </span>            : bool should_numa_migrate_memory(struct task_struct *p, struct page * page,</a>
<a name="1404"><span class="lineNum">    1404 </span>            :                                 int src_nid, int dst_cpu)</a>
<a name="1405"><span class="lineNum">    1405 </span>            : {</a>
<a name="1406"><span class="lineNum">    1406 </span>            :         struct numa_group *ng = deref_curr_numa_group(p);</a>
<a name="1407"><span class="lineNum">    1407 </span>            :         int dst_nid = cpu_to_node(dst_cpu);</a>
<a name="1408"><span class="lineNum">    1408 </span>            :         int last_cpupid, this_cpupid;</a>
<a name="1409"><span class="lineNum">    1409 </span>            : </a>
<a name="1410"><span class="lineNum">    1410 </span>            :         this_cpupid = cpu_pid_to_cpupid(dst_cpu, current-&gt;pid);</a>
<a name="1411"><span class="lineNum">    1411 </span>            :         last_cpupid = page_cpupid_xchg_last(page, this_cpupid);</a>
<a name="1412"><span class="lineNum">    1412 </span>            : </a>
<a name="1413"><span class="lineNum">    1413 </span>            :         /*</a>
<a name="1414"><span class="lineNum">    1414 </span>            :          * Allow first faults or private faults to migrate immediately early in</a>
<a name="1415"><span class="lineNum">    1415 </span>            :          * the lifetime of a task. The magic number 4 is based on waiting for</a>
<a name="1416"><span class="lineNum">    1416 </span>            :          * two full passes of the &quot;multi-stage node selection&quot; test that is</a>
<a name="1417"><span class="lineNum">    1417 </span>            :          * executed below.</a>
<a name="1418"><span class="lineNum">    1418 </span>            :          */</a>
<a name="1419"><span class="lineNum">    1419 </span>            :         if ((p-&gt;numa_preferred_nid == NUMA_NO_NODE || p-&gt;numa_scan_seq &lt;= 4) &amp;&amp;</a>
<a name="1420"><span class="lineNum">    1420 </span>            :             (cpupid_pid_unset(last_cpupid) || cpupid_match_pid(p, last_cpupid)))</a>
<a name="1421"><span class="lineNum">    1421 </span>            :                 return true;</a>
<a name="1422"><span class="lineNum">    1422 </span>            : </a>
<a name="1423"><span class="lineNum">    1423 </span>            :         /*</a>
<a name="1424"><span class="lineNum">    1424 </span>            :          * Multi-stage node selection is used in conjunction with a periodic</a>
<a name="1425"><span class="lineNum">    1425 </span>            :          * migration fault to build a temporal task&lt;-&gt;page relation. By using</a>
<a name="1426"><span class="lineNum">    1426 </span>            :          * a two-stage filter we remove short/unlikely relations.</a>
<a name="1427"><span class="lineNum">    1427 </span>            :          *</a>
<a name="1428"><span class="lineNum">    1428 </span>            :          * Using P(p) ~ n_p / n_t as per frequentist probability, we can equate</a>
<a name="1429"><span class="lineNum">    1429 </span>            :          * a task's usage of a particular page (n_p) per total usage of this</a>
<a name="1430"><span class="lineNum">    1430 </span>            :          * page (n_t) (in a given time-span) to a probability.</a>
<a name="1431"><span class="lineNum">    1431 </span>            :          *</a>
<a name="1432"><span class="lineNum">    1432 </span>            :          * Our periodic faults will sample this probability and getting the</a>
<a name="1433"><span class="lineNum">    1433 </span>            :          * same result twice in a row, given these samples are fully</a>
<a name="1434"><span class="lineNum">    1434 </span>            :          * independent, is then given by P(n)^2, provided our sample period</a>
<a name="1435"><span class="lineNum">    1435 </span>            :          * is sufficiently short compared to the usage pattern.</a>
<a name="1436"><span class="lineNum">    1436 </span>            :          *</a>
<a name="1437"><span class="lineNum">    1437 </span>            :          * This quadric squishes small probabilities, making it less likely we</a>
<a name="1438"><span class="lineNum">    1438 </span>            :          * act on an unlikely task&lt;-&gt;page relation.</a>
<a name="1439"><span class="lineNum">    1439 </span>            :          */</a>
<a name="1440"><span class="lineNum">    1440 </span>            :         if (!cpupid_pid_unset(last_cpupid) &amp;&amp;</a>
<a name="1441"><span class="lineNum">    1441 </span>            :                                 cpupid_to_nid(last_cpupid) != dst_nid)</a>
<a name="1442"><span class="lineNum">    1442 </span>            :                 return false;</a>
<a name="1443"><span class="lineNum">    1443 </span>            : </a>
<a name="1444"><span class="lineNum">    1444 </span>            :         /* Always allow migrate on private faults */</a>
<a name="1445"><span class="lineNum">    1445 </span>            :         if (cpupid_match_pid(p, last_cpupid))</a>
<a name="1446"><span class="lineNum">    1446 </span>            :                 return true;</a>
<a name="1447"><span class="lineNum">    1447 </span>            : </a>
<a name="1448"><span class="lineNum">    1448 </span>            :         /* A shared fault, but p-&gt;numa_group has not been set up yet. */</a>
<a name="1449"><span class="lineNum">    1449 </span>            :         if (!ng)</a>
<a name="1450"><span class="lineNum">    1450 </span>            :                 return true;</a>
<a name="1451"><span class="lineNum">    1451 </span>            : </a>
<a name="1452"><span class="lineNum">    1452 </span>            :         /*</a>
<a name="1453"><span class="lineNum">    1453 </span>            :          * Destination node is much more heavily used than the source</a>
<a name="1454"><span class="lineNum">    1454 </span>            :          * node? Allow migration.</a>
<a name="1455"><span class="lineNum">    1455 </span>            :          */</a>
<a name="1456"><span class="lineNum">    1456 </span>            :         if (group_faults_cpu(ng, dst_nid) &gt; group_faults_cpu(ng, src_nid) *</a>
<a name="1457"><span class="lineNum">    1457 </span>            :                                         ACTIVE_NODE_FRACTION)</a>
<a name="1458"><span class="lineNum">    1458 </span>            :                 return true;</a>
<a name="1459"><span class="lineNum">    1459 </span>            : </a>
<a name="1460"><span class="lineNum">    1460 </span>            :         /*</a>
<a name="1461"><span class="lineNum">    1461 </span>            :          * Distribute memory according to CPU &amp; memory use on each node,</a>
<a name="1462"><span class="lineNum">    1462 </span>            :          * with 3/4 hysteresis to avoid unnecessary memory migrations:</a>
<a name="1463"><span class="lineNum">    1463 </span>            :          *</a>
<a name="1464"><span class="lineNum">    1464 </span>            :          * faults_cpu(dst)   3   faults_cpu(src)</a>
<a name="1465"><span class="lineNum">    1465 </span>            :          * --------------- * - &gt; ---------------</a>
<a name="1466"><span class="lineNum">    1466 </span>            :          * faults_mem(dst)   4   faults_mem(src)</a>
<a name="1467"><span class="lineNum">    1467 </span>            :          */</a>
<a name="1468"><span class="lineNum">    1468 </span>            :         return group_faults_cpu(ng, dst_nid) * group_faults(p, src_nid) * 3 &gt;</a>
<a name="1469"><span class="lineNum">    1469 </span>            :                group_faults_cpu(ng, src_nid) * group_faults(p, dst_nid) * 4;</a>
<a name="1470"><span class="lineNum">    1470 </span>            : }</a>
<a name="1471"><span class="lineNum">    1471 </span>            : </a>
<a name="1472"><span class="lineNum">    1472 </span>            : /*</a>
<a name="1473"><span class="lineNum">    1473 </span>            :  * 'numa_type' describes the node at the moment of load balancing.</a>
<a name="1474"><span class="lineNum">    1474 </span>            :  */</a>
<a name="1475"><span class="lineNum">    1475 </span>            : enum numa_type {</a>
<a name="1476"><span class="lineNum">    1476 </span>            :         /* The node has spare capacity that can be used to run more tasks.  */</a>
<a name="1477"><span class="lineNum">    1477 </span>            :         node_has_spare = 0,</a>
<a name="1478"><span class="lineNum">    1478 </span>            :         /*</a>
<a name="1479"><span class="lineNum">    1479 </span>            :          * The node is fully used and the tasks don't compete for more CPU</a>
<a name="1480"><span class="lineNum">    1480 </span>            :          * cycles. Nevertheless, some tasks might wait before running.</a>
<a name="1481"><span class="lineNum">    1481 </span>            :          */</a>
<a name="1482"><span class="lineNum">    1482 </span>            :         node_fully_busy,</a>
<a name="1483"><span class="lineNum">    1483 </span>            :         /*</a>
<a name="1484"><span class="lineNum">    1484 </span>            :          * The node is overloaded and can't provide expected CPU cycles to all</a>
<a name="1485"><span class="lineNum">    1485 </span>            :          * tasks.</a>
<a name="1486"><span class="lineNum">    1486 </span>            :          */</a>
<a name="1487"><span class="lineNum">    1487 </span>            :         node_overloaded</a>
<a name="1488"><span class="lineNum">    1488 </span>            : };</a>
<a name="1489"><span class="lineNum">    1489 </span>            : </a>
<a name="1490"><span class="lineNum">    1490 </span>            : /* Cached statistics for all CPUs within a node */</a>
<a name="1491"><span class="lineNum">    1491 </span>            : struct numa_stats {</a>
<a name="1492"><span class="lineNum">    1492 </span>            :         unsigned long load;</a>
<a name="1493"><span class="lineNum">    1493 </span>            :         unsigned long runnable;</a>
<a name="1494"><span class="lineNum">    1494 </span>            :         unsigned long util;</a>
<a name="1495"><span class="lineNum">    1495 </span>            :         /* Total compute capacity of CPUs on a node */</a>
<a name="1496"><span class="lineNum">    1496 </span>            :         unsigned long compute_capacity;</a>
<a name="1497"><span class="lineNum">    1497 </span>            :         unsigned int nr_running;</a>
<a name="1498"><span class="lineNum">    1498 </span>            :         unsigned int weight;</a>
<a name="1499"><span class="lineNum">    1499 </span>            :         enum numa_type node_type;</a>
<a name="1500"><span class="lineNum">    1500 </span>            :         int idle_cpu;</a>
<a name="1501"><span class="lineNum">    1501 </span>            : };</a>
<a name="1502"><span class="lineNum">    1502 </span>            : </a>
<a name="1503"><span class="lineNum">    1503 </span>            : static inline bool is_core_idle(int cpu)</a>
<a name="1504"><span class="lineNum">    1504 </span>            : {</a>
<a name="1505"><span class="lineNum">    1505 </span>            : #ifdef CONFIG_SCHED_SMT</a>
<a name="1506"><span class="lineNum">    1506 </span>            :         int sibling;</a>
<a name="1507"><span class="lineNum">    1507 </span>            : </a>
<a name="1508"><span class="lineNum">    1508 </span>            :         for_each_cpu(sibling, cpu_smt_mask(cpu)) {</a>
<a name="1509"><span class="lineNum">    1509 </span>            :                 if (cpu == sibling)</a>
<a name="1510"><span class="lineNum">    1510 </span>            :                         continue;</a>
<a name="1511"><span class="lineNum">    1511 </span>            : </a>
<a name="1512"><span class="lineNum">    1512 </span>            :                 if (!idle_cpu(sibling))</a>
<a name="1513"><span class="lineNum">    1513 </span>            :                         return false;</a>
<a name="1514"><span class="lineNum">    1514 </span>            :         }</a>
<a name="1515"><span class="lineNum">    1515 </span>            : #endif</a>
<a name="1516"><span class="lineNum">    1516 </span>            : </a>
<a name="1517"><span class="lineNum">    1517 </span>            :         return true;</a>
<a name="1518"><span class="lineNum">    1518 </span>            : }</a>
<a name="1519"><span class="lineNum">    1519 </span>            : </a>
<a name="1520"><span class="lineNum">    1520 </span>            : struct task_numa_env {</a>
<a name="1521"><span class="lineNum">    1521 </span>            :         struct task_struct *p;</a>
<a name="1522"><span class="lineNum">    1522 </span>            : </a>
<a name="1523"><span class="lineNum">    1523 </span>            :         int src_cpu, src_nid;</a>
<a name="1524"><span class="lineNum">    1524 </span>            :         int dst_cpu, dst_nid;</a>
<a name="1525"><span class="lineNum">    1525 </span>            :         int imb_numa_nr;</a>
<a name="1526"><span class="lineNum">    1526 </span>            : </a>
<a name="1527"><span class="lineNum">    1527 </span>            :         struct numa_stats src_stats, dst_stats;</a>
<a name="1528"><span class="lineNum">    1528 </span>            : </a>
<a name="1529"><span class="lineNum">    1529 </span>            :         int imbalance_pct;</a>
<a name="1530"><span class="lineNum">    1530 </span>            :         int dist;</a>
<a name="1531"><span class="lineNum">    1531 </span>            : </a>
<a name="1532"><span class="lineNum">    1532 </span>            :         struct task_struct *best_task;</a>
<a name="1533"><span class="lineNum">    1533 </span>            :         long best_imp;</a>
<a name="1534"><span class="lineNum">    1534 </span>            :         int best_cpu;</a>
<a name="1535"><span class="lineNum">    1535 </span>            : };</a>
<a name="1536"><span class="lineNum">    1536 </span>            : </a>
<a name="1537"><span class="lineNum">    1537 </span>            : static unsigned long cpu_load(struct rq *rq);</a>
<a name="1538"><span class="lineNum">    1538 </span>            : static unsigned long cpu_runnable(struct rq *rq);</a>
<a name="1539"><span class="lineNum">    1539 </span>            : static inline long adjust_numa_imbalance(int imbalance,</a>
<a name="1540"><span class="lineNum">    1540 </span>            :                                         int dst_running, int imb_numa_nr);</a>
<a name="1541"><span class="lineNum">    1541 </span>            : </a>
<a name="1542"><span class="lineNum">    1542 </span>            : static inline enum</a>
<a name="1543"><span class="lineNum">    1543 </span>            : numa_type numa_classify(unsigned int imbalance_pct,</a>
<a name="1544"><span class="lineNum">    1544 </span>            :                          struct numa_stats *ns)</a>
<a name="1545"><span class="lineNum">    1545 </span>            : {</a>
<a name="1546"><span class="lineNum">    1546 </span>            :         if ((ns-&gt;nr_running &gt; ns-&gt;weight) &amp;&amp;</a>
<a name="1547"><span class="lineNum">    1547 </span>            :             (((ns-&gt;compute_capacity * 100) &lt; (ns-&gt;util * imbalance_pct)) ||</a>
<a name="1548"><span class="lineNum">    1548 </span>            :              ((ns-&gt;compute_capacity * imbalance_pct) &lt; (ns-&gt;runnable * 100))))</a>
<a name="1549"><span class="lineNum">    1549 </span>            :                 return node_overloaded;</a>
<a name="1550"><span class="lineNum">    1550 </span>            : </a>
<a name="1551"><span class="lineNum">    1551 </span>            :         if ((ns-&gt;nr_running &lt; ns-&gt;weight) ||</a>
<a name="1552"><span class="lineNum">    1552 </span>            :             (((ns-&gt;compute_capacity * 100) &gt; (ns-&gt;util * imbalance_pct)) &amp;&amp;</a>
<a name="1553"><span class="lineNum">    1553 </span>            :              ((ns-&gt;compute_capacity * imbalance_pct) &gt; (ns-&gt;runnable * 100))))</a>
<a name="1554"><span class="lineNum">    1554 </span>            :                 return node_has_spare;</a>
<a name="1555"><span class="lineNum">    1555 </span>            : </a>
<a name="1556"><span class="lineNum">    1556 </span>            :         return node_fully_busy;</a>
<a name="1557"><span class="lineNum">    1557 </span>            : }</a>
<a name="1558"><span class="lineNum">    1558 </span>            : </a>
<a name="1559"><span class="lineNum">    1559 </span>            : #ifdef CONFIG_SCHED_SMT</a>
<a name="1560"><span class="lineNum">    1560 </span>            : /* Forward declarations of select_idle_sibling helpers */</a>
<a name="1561"><span class="lineNum">    1561 </span>            : static inline bool test_idle_cores(int cpu, bool def);</a>
<a name="1562"><span class="lineNum">    1562 </span>            : static inline int numa_idle_core(int idle_core, int cpu)</a>
<a name="1563"><span class="lineNum">    1563 </span>            : {</a>
<a name="1564"><span class="lineNum">    1564 </span>            :         if (!static_branch_likely(&amp;sched_smt_present) ||</a>
<a name="1565"><span class="lineNum">    1565 </span>            :             idle_core &gt;= 0 || !test_idle_cores(cpu, false))</a>
<a name="1566"><span class="lineNum">    1566 </span>            :                 return idle_core;</a>
<a name="1567"><span class="lineNum">    1567 </span>            : </a>
<a name="1568"><span class="lineNum">    1568 </span>            :         /*</a>
<a name="1569"><span class="lineNum">    1569 </span>            :          * Prefer cores instead of packing HT siblings</a>
<a name="1570"><span class="lineNum">    1570 </span>            :          * and triggering future load balancing.</a>
<a name="1571"><span class="lineNum">    1571 </span>            :          */</a>
<a name="1572"><span class="lineNum">    1572 </span>            :         if (is_core_idle(cpu))</a>
<a name="1573"><span class="lineNum">    1573 </span>            :                 idle_core = cpu;</a>
<a name="1574"><span class="lineNum">    1574 </span>            : </a>
<a name="1575"><span class="lineNum">    1575 </span>            :         return idle_core;</a>
<a name="1576"><span class="lineNum">    1576 </span>            : }</a>
<a name="1577"><span class="lineNum">    1577 </span>            : #else</a>
<a name="1578"><span class="lineNum">    1578 </span>            : static inline int numa_idle_core(int idle_core, int cpu)</a>
<a name="1579"><span class="lineNum">    1579 </span>            : {</a>
<a name="1580"><span class="lineNum">    1580 </span>            :         return idle_core;</a>
<a name="1581"><span class="lineNum">    1581 </span>            : }</a>
<a name="1582"><span class="lineNum">    1582 </span>            : #endif</a>
<a name="1583"><span class="lineNum">    1583 </span>            : </a>
<a name="1584"><span class="lineNum">    1584 </span>            : /*</a>
<a name="1585"><span class="lineNum">    1585 </span>            :  * Gather all necessary information to make NUMA balancing placement</a>
<a name="1586"><span class="lineNum">    1586 </span>            :  * decisions that are compatible with standard load balancer. This</a>
<a name="1587"><span class="lineNum">    1587 </span>            :  * borrows code and logic from update_sg_lb_stats but sharing a</a>
<a name="1588"><span class="lineNum">    1588 </span>            :  * common implementation is impractical.</a>
<a name="1589"><span class="lineNum">    1589 </span>            :  */</a>
<a name="1590"><span class="lineNum">    1590 </span>            : static void update_numa_stats(struct task_numa_env *env,</a>
<a name="1591"><span class="lineNum">    1591 </span>            :                               struct numa_stats *ns, int nid,</a>
<a name="1592"><span class="lineNum">    1592 </span>            :                               bool find_idle)</a>
<a name="1593"><span class="lineNum">    1593 </span>            : {</a>
<a name="1594"><span class="lineNum">    1594 </span>            :         int cpu, idle_core = -1;</a>
<a name="1595"><span class="lineNum">    1595 </span>            : </a>
<a name="1596"><span class="lineNum">    1596 </span>            :         memset(ns, 0, sizeof(*ns));</a>
<a name="1597"><span class="lineNum">    1597 </span>            :         ns-&gt;idle_cpu = -1;</a>
<a name="1598"><span class="lineNum">    1598 </span>            : </a>
<a name="1599"><span class="lineNum">    1599 </span>            :         rcu_read_lock();</a>
<a name="1600"><span class="lineNum">    1600 </span>            :         for_each_cpu(cpu, cpumask_of_node(nid)) {</a>
<a name="1601"><span class="lineNum">    1601 </span>            :                 struct rq *rq = cpu_rq(cpu);</a>
<a name="1602"><span class="lineNum">    1602 </span>            : </a>
<a name="1603"><span class="lineNum">    1603 </span>            :                 ns-&gt;load += cpu_load(rq);</a>
<a name="1604"><span class="lineNum">    1604 </span>            :                 ns-&gt;runnable += cpu_runnable(rq);</a>
<a name="1605"><span class="lineNum">    1605 </span>            :                 ns-&gt;util += cpu_util_cfs(cpu);</a>
<a name="1606"><span class="lineNum">    1606 </span>            :                 ns-&gt;nr_running += rq-&gt;cfs.h_nr_running;</a>
<a name="1607"><span class="lineNum">    1607 </span>            :                 ns-&gt;compute_capacity += capacity_of(cpu);</a>
<a name="1608"><span class="lineNum">    1608 </span>            : </a>
<a name="1609"><span class="lineNum">    1609 </span>            :                 if (find_idle &amp;&amp; !rq-&gt;nr_running &amp;&amp; idle_cpu(cpu)) {</a>
<a name="1610"><span class="lineNum">    1610 </span>            :                         if (READ_ONCE(rq-&gt;numa_migrate_on) ||</a>
<a name="1611"><span class="lineNum">    1611 </span>            :                             !cpumask_test_cpu(cpu, env-&gt;p-&gt;cpus_ptr))</a>
<a name="1612"><span class="lineNum">    1612 </span>            :                                 continue;</a>
<a name="1613"><span class="lineNum">    1613 </span>            : </a>
<a name="1614"><span class="lineNum">    1614 </span>            :                         if (ns-&gt;idle_cpu == -1)</a>
<a name="1615"><span class="lineNum">    1615 </span>            :                                 ns-&gt;idle_cpu = cpu;</a>
<a name="1616"><span class="lineNum">    1616 </span>            : </a>
<a name="1617"><span class="lineNum">    1617 </span>            :                         idle_core = numa_idle_core(idle_core, cpu);</a>
<a name="1618"><span class="lineNum">    1618 </span>            :                 }</a>
<a name="1619"><span class="lineNum">    1619 </span>            :         }</a>
<a name="1620"><span class="lineNum">    1620 </span>            :         rcu_read_unlock();</a>
<a name="1621"><span class="lineNum">    1621 </span>            : </a>
<a name="1622"><span class="lineNum">    1622 </span>            :         ns-&gt;weight = cpumask_weight(cpumask_of_node(nid));</a>
<a name="1623"><span class="lineNum">    1623 </span>            : </a>
<a name="1624"><span class="lineNum">    1624 </span>            :         ns-&gt;node_type = numa_classify(env-&gt;imbalance_pct, ns);</a>
<a name="1625"><span class="lineNum">    1625 </span>            : </a>
<a name="1626"><span class="lineNum">    1626 </span>            :         if (idle_core &gt;= 0)</a>
<a name="1627"><span class="lineNum">    1627 </span>            :                 ns-&gt;idle_cpu = idle_core;</a>
<a name="1628"><span class="lineNum">    1628 </span>            : }</a>
<a name="1629"><span class="lineNum">    1629 </span>            : </a>
<a name="1630"><span class="lineNum">    1630 </span>            : static void task_numa_assign(struct task_numa_env *env,</a>
<a name="1631"><span class="lineNum">    1631 </span>            :                              struct task_struct *p, long imp)</a>
<a name="1632"><span class="lineNum">    1632 </span>            : {</a>
<a name="1633"><span class="lineNum">    1633 </span>            :         struct rq *rq = cpu_rq(env-&gt;dst_cpu);</a>
<a name="1634"><span class="lineNum">    1634 </span>            : </a>
<a name="1635"><span class="lineNum">    1635 </span>            :         /* Check if run-queue part of active NUMA balance. */</a>
<a name="1636"><span class="lineNum">    1636 </span>            :         if (env-&gt;best_cpu != env-&gt;dst_cpu &amp;&amp; xchg(&amp;rq-&gt;numa_migrate_on, 1)) {</a>
<a name="1637"><span class="lineNum">    1637 </span>            :                 int cpu;</a>
<a name="1638"><span class="lineNum">    1638 </span>            :                 int start = env-&gt;dst_cpu;</a>
<a name="1639"><span class="lineNum">    1639 </span>            : </a>
<a name="1640"><span class="lineNum">    1640 </span>            :                 /* Find alternative idle CPU. */</a>
<a name="1641"><span class="lineNum">    1641 </span>            :                 for_each_cpu_wrap(cpu, cpumask_of_node(env-&gt;dst_nid), start) {</a>
<a name="1642"><span class="lineNum">    1642 </span>            :                         if (cpu == env-&gt;best_cpu || !idle_cpu(cpu) ||</a>
<a name="1643"><span class="lineNum">    1643 </span>            :                             !cpumask_test_cpu(cpu, env-&gt;p-&gt;cpus_ptr)) {</a>
<a name="1644"><span class="lineNum">    1644 </span>            :                                 continue;</a>
<a name="1645"><span class="lineNum">    1645 </span>            :                         }</a>
<a name="1646"><span class="lineNum">    1646 </span>            : </a>
<a name="1647"><span class="lineNum">    1647 </span>            :                         env-&gt;dst_cpu = cpu;</a>
<a name="1648"><span class="lineNum">    1648 </span>            :                         rq = cpu_rq(env-&gt;dst_cpu);</a>
<a name="1649"><span class="lineNum">    1649 </span>            :                         if (!xchg(&amp;rq-&gt;numa_migrate_on, 1))</a>
<a name="1650"><span class="lineNum">    1650 </span>            :                                 goto assign;</a>
<a name="1651"><span class="lineNum">    1651 </span>            :                 }</a>
<a name="1652"><span class="lineNum">    1652 </span>            : </a>
<a name="1653"><span class="lineNum">    1653 </span>            :                 /* Failed to find an alternative idle CPU */</a>
<a name="1654"><span class="lineNum">    1654 </span>            :                 return;</a>
<a name="1655"><span class="lineNum">    1655 </span>            :         }</a>
<a name="1656"><span class="lineNum">    1656 </span>            : </a>
<a name="1657"><span class="lineNum">    1657 </span>            : assign:</a>
<a name="1658"><span class="lineNum">    1658 </span>            :         /*</a>
<a name="1659"><span class="lineNum">    1659 </span>            :          * Clear previous best_cpu/rq numa-migrate flag, since task now</a>
<a name="1660"><span class="lineNum">    1660 </span>            :          * found a better CPU to move/swap.</a>
<a name="1661"><span class="lineNum">    1661 </span>            :          */</a>
<a name="1662"><span class="lineNum">    1662 </span>            :         if (env-&gt;best_cpu != -1 &amp;&amp; env-&gt;best_cpu != env-&gt;dst_cpu) {</a>
<a name="1663"><span class="lineNum">    1663 </span>            :                 rq = cpu_rq(env-&gt;best_cpu);</a>
<a name="1664"><span class="lineNum">    1664 </span>            :                 WRITE_ONCE(rq-&gt;numa_migrate_on, 0);</a>
<a name="1665"><span class="lineNum">    1665 </span>            :         }</a>
<a name="1666"><span class="lineNum">    1666 </span>            : </a>
<a name="1667"><span class="lineNum">    1667 </span>            :         if (env-&gt;best_task)</a>
<a name="1668"><span class="lineNum">    1668 </span>            :                 put_task_struct(env-&gt;best_task);</a>
<a name="1669"><span class="lineNum">    1669 </span>            :         if (p)</a>
<a name="1670"><span class="lineNum">    1670 </span>            :                 get_task_struct(p);</a>
<a name="1671"><span class="lineNum">    1671 </span>            : </a>
<a name="1672"><span class="lineNum">    1672 </span>            :         env-&gt;best_task = p;</a>
<a name="1673"><span class="lineNum">    1673 </span>            :         env-&gt;best_imp = imp;</a>
<a name="1674"><span class="lineNum">    1674 </span>            :         env-&gt;best_cpu = env-&gt;dst_cpu;</a>
<a name="1675"><span class="lineNum">    1675 </span>            : }</a>
<a name="1676"><span class="lineNum">    1676 </span>            : </a>
<a name="1677"><span class="lineNum">    1677 </span>            : static bool load_too_imbalanced(long src_load, long dst_load,</a>
<a name="1678"><span class="lineNum">    1678 </span>            :                                 struct task_numa_env *env)</a>
<a name="1679"><span class="lineNum">    1679 </span>            : {</a>
<a name="1680"><span class="lineNum">    1680 </span>            :         long imb, old_imb;</a>
<a name="1681"><span class="lineNum">    1681 </span>            :         long orig_src_load, orig_dst_load;</a>
<a name="1682"><span class="lineNum">    1682 </span>            :         long src_capacity, dst_capacity;</a>
<a name="1683"><span class="lineNum">    1683 </span>            : </a>
<a name="1684"><span class="lineNum">    1684 </span>            :         /*</a>
<a name="1685"><span class="lineNum">    1685 </span>            :          * The load is corrected for the CPU capacity available on each node.</a>
<a name="1686"><span class="lineNum">    1686 </span>            :          *</a>
<a name="1687"><span class="lineNum">    1687 </span>            :          * src_load        dst_load</a>
<a name="1688"><span class="lineNum">    1688 </span>            :          * ------------ vs ---------</a>
<a name="1689"><span class="lineNum">    1689 </span>            :          * src_capacity    dst_capacity</a>
<a name="1690"><span class="lineNum">    1690 </span>            :          */</a>
<a name="1691"><span class="lineNum">    1691 </span>            :         src_capacity = env-&gt;src_stats.compute_capacity;</a>
<a name="1692"><span class="lineNum">    1692 </span>            :         dst_capacity = env-&gt;dst_stats.compute_capacity;</a>
<a name="1693"><span class="lineNum">    1693 </span>            : </a>
<a name="1694"><span class="lineNum">    1694 </span>            :         imb = abs(dst_load * src_capacity - src_load * dst_capacity);</a>
<a name="1695"><span class="lineNum">    1695 </span>            : </a>
<a name="1696"><span class="lineNum">    1696 </span>            :         orig_src_load = env-&gt;src_stats.load;</a>
<a name="1697"><span class="lineNum">    1697 </span>            :         orig_dst_load = env-&gt;dst_stats.load;</a>
<a name="1698"><span class="lineNum">    1698 </span>            : </a>
<a name="1699"><span class="lineNum">    1699 </span>            :         old_imb = abs(orig_dst_load * src_capacity - orig_src_load * dst_capacity);</a>
<a name="1700"><span class="lineNum">    1700 </span>            : </a>
<a name="1701"><span class="lineNum">    1701 </span>            :         /* Would this change make things worse? */</a>
<a name="1702"><span class="lineNum">    1702 </span>            :         return (imb &gt; old_imb);</a>
<a name="1703"><span class="lineNum">    1703 </span>            : }</a>
<a name="1704"><span class="lineNum">    1704 </span>            : </a>
<a name="1705"><span class="lineNum">    1705 </span>            : /*</a>
<a name="1706"><span class="lineNum">    1706 </span>            :  * Maximum NUMA importance can be 1998 (2*999);</a>
<a name="1707"><span class="lineNum">    1707 </span>            :  * SMALLIMP @ 30 would be close to 1998/64.</a>
<a name="1708"><span class="lineNum">    1708 </span>            :  * Used to deter task migration.</a>
<a name="1709"><span class="lineNum">    1709 </span>            :  */</a>
<a name="1710"><span class="lineNum">    1710 </span>            : #define SMALLIMP        30</a>
<a name="1711"><span class="lineNum">    1711 </span>            : </a>
<a name="1712"><span class="lineNum">    1712 </span>            : /*</a>
<a name="1713"><span class="lineNum">    1713 </span>            :  * This checks if the overall compute and NUMA accesses of the system would</a>
<a name="1714"><span class="lineNum">    1714 </span>            :  * be improved if the source tasks was migrated to the target dst_cpu taking</a>
<a name="1715"><span class="lineNum">    1715 </span>            :  * into account that it might be best if task running on the dst_cpu should</a>
<a name="1716"><span class="lineNum">    1716 </span>            :  * be exchanged with the source task</a>
<a name="1717"><span class="lineNum">    1717 </span>            :  */</a>
<a name="1718"><span class="lineNum">    1718 </span>            : static bool task_numa_compare(struct task_numa_env *env,</a>
<a name="1719"><span class="lineNum">    1719 </span>            :                               long taskimp, long groupimp, bool maymove)</a>
<a name="1720"><span class="lineNum">    1720 </span>            : {</a>
<a name="1721"><span class="lineNum">    1721 </span>            :         struct numa_group *cur_ng, *p_ng = deref_curr_numa_group(env-&gt;p);</a>
<a name="1722"><span class="lineNum">    1722 </span>            :         struct rq *dst_rq = cpu_rq(env-&gt;dst_cpu);</a>
<a name="1723"><span class="lineNum">    1723 </span>            :         long imp = p_ng ? groupimp : taskimp;</a>
<a name="1724"><span class="lineNum">    1724 </span>            :         struct task_struct *cur;</a>
<a name="1725"><span class="lineNum">    1725 </span>            :         long src_load, dst_load;</a>
<a name="1726"><span class="lineNum">    1726 </span>            :         int dist = env-&gt;dist;</a>
<a name="1727"><span class="lineNum">    1727 </span>            :         long moveimp = imp;</a>
<a name="1728"><span class="lineNum">    1728 </span>            :         long load;</a>
<a name="1729"><span class="lineNum">    1729 </span>            :         bool stopsearch = false;</a>
<a name="1730"><span class="lineNum">    1730 </span>            : </a>
<a name="1731"><span class="lineNum">    1731 </span>            :         if (READ_ONCE(dst_rq-&gt;numa_migrate_on))</a>
<a name="1732"><span class="lineNum">    1732 </span>            :                 return false;</a>
<a name="1733"><span class="lineNum">    1733 </span>            : </a>
<a name="1734"><span class="lineNum">    1734 </span>            :         rcu_read_lock();</a>
<a name="1735"><span class="lineNum">    1735 </span>            :         cur = rcu_dereference(dst_rq-&gt;curr);</a>
<a name="1736"><span class="lineNum">    1736 </span>            :         if (cur &amp;&amp; ((cur-&gt;flags &amp; PF_EXITING) || is_idle_task(cur)))</a>
<a name="1737"><span class="lineNum">    1737 </span>            :                 cur = NULL;</a>
<a name="1738"><span class="lineNum">    1738 </span>            : </a>
<a name="1739"><span class="lineNum">    1739 </span>            :         /*</a>
<a name="1740"><span class="lineNum">    1740 </span>            :          * Because we have preemption enabled we can get migrated around and</a>
<a name="1741"><span class="lineNum">    1741 </span>            :          * end try selecting ourselves (current == env-&gt;p) as a swap candidate.</a>
<a name="1742"><span class="lineNum">    1742 </span>            :          */</a>
<a name="1743"><span class="lineNum">    1743 </span>            :         if (cur == env-&gt;p) {</a>
<a name="1744"><span class="lineNum">    1744 </span>            :                 stopsearch = true;</a>
<a name="1745"><span class="lineNum">    1745 </span>            :                 goto unlock;</a>
<a name="1746"><span class="lineNum">    1746 </span>            :         }</a>
<a name="1747"><span class="lineNum">    1747 </span>            : </a>
<a name="1748"><span class="lineNum">    1748 </span>            :         if (!cur) {</a>
<a name="1749"><span class="lineNum">    1749 </span>            :                 if (maymove &amp;&amp; moveimp &gt;= env-&gt;best_imp)</a>
<a name="1750"><span class="lineNum">    1750 </span>            :                         goto assign;</a>
<a name="1751"><span class="lineNum">    1751 </span>            :                 else</a>
<a name="1752"><span class="lineNum">    1752 </span>            :                         goto unlock;</a>
<a name="1753"><span class="lineNum">    1753 </span>            :         }</a>
<a name="1754"><span class="lineNum">    1754 </span>            : </a>
<a name="1755"><span class="lineNum">    1755 </span>            :         /* Skip this swap candidate if cannot move to the source cpu. */</a>
<a name="1756"><span class="lineNum">    1756 </span>            :         if (!cpumask_test_cpu(env-&gt;src_cpu, cur-&gt;cpus_ptr))</a>
<a name="1757"><span class="lineNum">    1757 </span>            :                 goto unlock;</a>
<a name="1758"><span class="lineNum">    1758 </span>            : </a>
<a name="1759"><span class="lineNum">    1759 </span>            :         /*</a>
<a name="1760"><span class="lineNum">    1760 </span>            :          * Skip this swap candidate if it is not moving to its preferred</a>
<a name="1761"><span class="lineNum">    1761 </span>            :          * node and the best task is.</a>
<a name="1762"><span class="lineNum">    1762 </span>            :          */</a>
<a name="1763"><span class="lineNum">    1763 </span>            :         if (env-&gt;best_task &amp;&amp;</a>
<a name="1764"><span class="lineNum">    1764 </span>            :             env-&gt;best_task-&gt;numa_preferred_nid == env-&gt;src_nid &amp;&amp;</a>
<a name="1765"><span class="lineNum">    1765 </span>            :             cur-&gt;numa_preferred_nid != env-&gt;src_nid) {</a>
<a name="1766"><span class="lineNum">    1766 </span>            :                 goto unlock;</a>
<a name="1767"><span class="lineNum">    1767 </span>            :         }</a>
<a name="1768"><span class="lineNum">    1768 </span>            : </a>
<a name="1769"><span class="lineNum">    1769 </span>            :         /*</a>
<a name="1770"><span class="lineNum">    1770 </span>            :          * &quot;imp&quot; is the fault differential for the source task between the</a>
<a name="1771"><span class="lineNum">    1771 </span>            :          * source and destination node. Calculate the total differential for</a>
<a name="1772"><span class="lineNum">    1772 </span>            :          * the source task and potential destination task. The more negative</a>
<a name="1773"><span class="lineNum">    1773 </span>            :          * the value is, the more remote accesses that would be expected to</a>
<a name="1774"><span class="lineNum">    1774 </span>            :          * be incurred if the tasks were swapped.</a>
<a name="1775"><span class="lineNum">    1775 </span>            :          *</a>
<a name="1776"><span class="lineNum">    1776 </span>            :          * If dst and source tasks are in the same NUMA group, or not</a>
<a name="1777"><span class="lineNum">    1777 </span>            :          * in any group then look only at task weights.</a>
<a name="1778"><span class="lineNum">    1778 </span>            :          */</a>
<a name="1779"><span class="lineNum">    1779 </span>            :         cur_ng = rcu_dereference(cur-&gt;numa_group);</a>
<a name="1780"><span class="lineNum">    1780 </span>            :         if (cur_ng == p_ng) {</a>
<a name="1781"><span class="lineNum">    1781 </span>            :                 imp = taskimp + task_weight(cur, env-&gt;src_nid, dist) -</a>
<a name="1782"><span class="lineNum">    1782 </span>            :                       task_weight(cur, env-&gt;dst_nid, dist);</a>
<a name="1783"><span class="lineNum">    1783 </span>            :                 /*</a>
<a name="1784"><span class="lineNum">    1784 </span>            :                  * Add some hysteresis to prevent swapping the</a>
<a name="1785"><span class="lineNum">    1785 </span>            :                  * tasks within a group over tiny differences.</a>
<a name="1786"><span class="lineNum">    1786 </span>            :                  */</a>
<a name="1787"><span class="lineNum">    1787 </span>            :                 if (cur_ng)</a>
<a name="1788"><span class="lineNum">    1788 </span>            :                         imp -= imp / 16;</a>
<a name="1789"><span class="lineNum">    1789 </span>            :         } else {</a>
<a name="1790"><span class="lineNum">    1790 </span>            :                 /*</a>
<a name="1791"><span class="lineNum">    1791 </span>            :                  * Compare the group weights. If a task is all by itself</a>
<a name="1792"><span class="lineNum">    1792 </span>            :                  * (not part of a group), use the task weight instead.</a>
<a name="1793"><span class="lineNum">    1793 </span>            :                  */</a>
<a name="1794"><span class="lineNum">    1794 </span>            :                 if (cur_ng &amp;&amp; p_ng)</a>
<a name="1795"><span class="lineNum">    1795 </span>            :                         imp += group_weight(cur, env-&gt;src_nid, dist) -</a>
<a name="1796"><span class="lineNum">    1796 </span>            :                                group_weight(cur, env-&gt;dst_nid, dist);</a>
<a name="1797"><span class="lineNum">    1797 </span>            :                 else</a>
<a name="1798"><span class="lineNum">    1798 </span>            :                         imp += task_weight(cur, env-&gt;src_nid, dist) -</a>
<a name="1799"><span class="lineNum">    1799 </span>            :                                task_weight(cur, env-&gt;dst_nid, dist);</a>
<a name="1800"><span class="lineNum">    1800 </span>            :         }</a>
<a name="1801"><span class="lineNum">    1801 </span>            : </a>
<a name="1802"><span class="lineNum">    1802 </span>            :         /* Discourage picking a task already on its preferred node */</a>
<a name="1803"><span class="lineNum">    1803 </span>            :         if (cur-&gt;numa_preferred_nid == env-&gt;dst_nid)</a>
<a name="1804"><span class="lineNum">    1804 </span>            :                 imp -= imp / 16;</a>
<a name="1805"><span class="lineNum">    1805 </span>            : </a>
<a name="1806"><span class="lineNum">    1806 </span>            :         /*</a>
<a name="1807"><span class="lineNum">    1807 </span>            :          * Encourage picking a task that moves to its preferred node.</a>
<a name="1808"><span class="lineNum">    1808 </span>            :          * This potentially makes imp larger than it's maximum of</a>
<a name="1809"><span class="lineNum">    1809 </span>            :          * 1998 (see SMALLIMP and task_weight for why) but in this</a>
<a name="1810"><span class="lineNum">    1810 </span>            :          * case, it does not matter.</a>
<a name="1811"><span class="lineNum">    1811 </span>            :          */</a>
<a name="1812"><span class="lineNum">    1812 </span>            :         if (cur-&gt;numa_preferred_nid == env-&gt;src_nid)</a>
<a name="1813"><span class="lineNum">    1813 </span>            :                 imp += imp / 8;</a>
<a name="1814"><span class="lineNum">    1814 </span>            : </a>
<a name="1815"><span class="lineNum">    1815 </span>            :         if (maymove &amp;&amp; moveimp &gt; imp &amp;&amp; moveimp &gt; env-&gt;best_imp) {</a>
<a name="1816"><span class="lineNum">    1816 </span>            :                 imp = moveimp;</a>
<a name="1817"><span class="lineNum">    1817 </span>            :                 cur = NULL;</a>
<a name="1818"><span class="lineNum">    1818 </span>            :                 goto assign;</a>
<a name="1819"><span class="lineNum">    1819 </span>            :         }</a>
<a name="1820"><span class="lineNum">    1820 </span>            : </a>
<a name="1821"><span class="lineNum">    1821 </span>            :         /*</a>
<a name="1822"><span class="lineNum">    1822 </span>            :          * Prefer swapping with a task moving to its preferred node over a</a>
<a name="1823"><span class="lineNum">    1823 </span>            :          * task that is not.</a>
<a name="1824"><span class="lineNum">    1824 </span>            :          */</a>
<a name="1825"><span class="lineNum">    1825 </span>            :         if (env-&gt;best_task &amp;&amp; cur-&gt;numa_preferred_nid == env-&gt;src_nid &amp;&amp;</a>
<a name="1826"><span class="lineNum">    1826 </span>            :             env-&gt;best_task-&gt;numa_preferred_nid != env-&gt;src_nid) {</a>
<a name="1827"><span class="lineNum">    1827 </span>            :                 goto assign;</a>
<a name="1828"><span class="lineNum">    1828 </span>            :         }</a>
<a name="1829"><span class="lineNum">    1829 </span>            : </a>
<a name="1830"><span class="lineNum">    1830 </span>            :         /*</a>
<a name="1831"><span class="lineNum">    1831 </span>            :          * If the NUMA importance is less than SMALLIMP,</a>
<a name="1832"><span class="lineNum">    1832 </span>            :          * task migration might only result in ping pong</a>
<a name="1833"><span class="lineNum">    1833 </span>            :          * of tasks and also hurt performance due to cache</a>
<a name="1834"><span class="lineNum">    1834 </span>            :          * misses.</a>
<a name="1835"><span class="lineNum">    1835 </span>            :          */</a>
<a name="1836"><span class="lineNum">    1836 </span>            :         if (imp &lt; SMALLIMP || imp &lt;= env-&gt;best_imp + SMALLIMP / 2)</a>
<a name="1837"><span class="lineNum">    1837 </span>            :                 goto unlock;</a>
<a name="1838"><span class="lineNum">    1838 </span>            : </a>
<a name="1839"><span class="lineNum">    1839 </span>            :         /*</a>
<a name="1840"><span class="lineNum">    1840 </span>            :          * In the overloaded case, try and keep the load balanced.</a>
<a name="1841"><span class="lineNum">    1841 </span>            :          */</a>
<a name="1842"><span class="lineNum">    1842 </span>            :         load = task_h_load(env-&gt;p) - task_h_load(cur);</a>
<a name="1843"><span class="lineNum">    1843 </span>            :         if (!load)</a>
<a name="1844"><span class="lineNum">    1844 </span>            :                 goto assign;</a>
<a name="1845"><span class="lineNum">    1845 </span>            : </a>
<a name="1846"><span class="lineNum">    1846 </span>            :         dst_load = env-&gt;dst_stats.load + load;</a>
<a name="1847"><span class="lineNum">    1847 </span>            :         src_load = env-&gt;src_stats.load - load;</a>
<a name="1848"><span class="lineNum">    1848 </span>            : </a>
<a name="1849"><span class="lineNum">    1849 </span>            :         if (load_too_imbalanced(src_load, dst_load, env))</a>
<a name="1850"><span class="lineNum">    1850 </span>            :                 goto unlock;</a>
<a name="1851"><span class="lineNum">    1851 </span>            : </a>
<a name="1852"><span class="lineNum">    1852 </span>            : assign:</a>
<a name="1853"><span class="lineNum">    1853 </span>            :         /* Evaluate an idle CPU for a task numa move. */</a>
<a name="1854"><span class="lineNum">    1854 </span>            :         if (!cur) {</a>
<a name="1855"><span class="lineNum">    1855 </span>            :                 int cpu = env-&gt;dst_stats.idle_cpu;</a>
<a name="1856"><span class="lineNum">    1856 </span>            : </a>
<a name="1857"><span class="lineNum">    1857 </span>            :                 /* Nothing cached so current CPU went idle since the search. */</a>
<a name="1858"><span class="lineNum">    1858 </span>            :                 if (cpu &lt; 0)</a>
<a name="1859"><span class="lineNum">    1859 </span>            :                         cpu = env-&gt;dst_cpu;</a>
<a name="1860"><span class="lineNum">    1860 </span>            : </a>
<a name="1861"><span class="lineNum">    1861 </span>            :                 /*</a>
<a name="1862"><span class="lineNum">    1862 </span>            :                  * If the CPU is no longer truly idle and the previous best CPU</a>
<a name="1863"><span class="lineNum">    1863 </span>            :                  * is, keep using it.</a>
<a name="1864"><span class="lineNum">    1864 </span>            :                  */</a>
<a name="1865"><span class="lineNum">    1865 </span>            :                 if (!idle_cpu(cpu) &amp;&amp; env-&gt;best_cpu &gt;= 0 &amp;&amp;</a>
<a name="1866"><span class="lineNum">    1866 </span>            :                     idle_cpu(env-&gt;best_cpu)) {</a>
<a name="1867"><span class="lineNum">    1867 </span>            :                         cpu = env-&gt;best_cpu;</a>
<a name="1868"><span class="lineNum">    1868 </span>            :                 }</a>
<a name="1869"><span class="lineNum">    1869 </span>            : </a>
<a name="1870"><span class="lineNum">    1870 </span>            :                 env-&gt;dst_cpu = cpu;</a>
<a name="1871"><span class="lineNum">    1871 </span>            :         }</a>
<a name="1872"><span class="lineNum">    1872 </span>            : </a>
<a name="1873"><span class="lineNum">    1873 </span>            :         task_numa_assign(env, cur, imp);</a>
<a name="1874"><span class="lineNum">    1874 </span>            : </a>
<a name="1875"><span class="lineNum">    1875 </span>            :         /*</a>
<a name="1876"><span class="lineNum">    1876 </span>            :          * If a move to idle is allowed because there is capacity or load</a>
<a name="1877"><span class="lineNum">    1877 </span>            :          * balance improves then stop the search. While a better swap</a>
<a name="1878"><span class="lineNum">    1878 </span>            :          * candidate may exist, a search is not free.</a>
<a name="1879"><span class="lineNum">    1879 </span>            :          */</a>
<a name="1880"><span class="lineNum">    1880 </span>            :         if (maymove &amp;&amp; !cur &amp;&amp; env-&gt;best_cpu &gt;= 0 &amp;&amp; idle_cpu(env-&gt;best_cpu))</a>
<a name="1881"><span class="lineNum">    1881 </span>            :                 stopsearch = true;</a>
<a name="1882"><span class="lineNum">    1882 </span>            : </a>
<a name="1883"><span class="lineNum">    1883 </span>            :         /*</a>
<a name="1884"><span class="lineNum">    1884 </span>            :          * If a swap candidate must be identified and the current best task</a>
<a name="1885"><span class="lineNum">    1885 </span>            :          * moves its preferred node then stop the search.</a>
<a name="1886"><span class="lineNum">    1886 </span>            :          */</a>
<a name="1887"><span class="lineNum">    1887 </span>            :         if (!maymove &amp;&amp; env-&gt;best_task &amp;&amp;</a>
<a name="1888"><span class="lineNum">    1888 </span>            :             env-&gt;best_task-&gt;numa_preferred_nid == env-&gt;src_nid) {</a>
<a name="1889"><span class="lineNum">    1889 </span>            :                 stopsearch = true;</a>
<a name="1890"><span class="lineNum">    1890 </span>            :         }</a>
<a name="1891"><span class="lineNum">    1891 </span>            : unlock:</a>
<a name="1892"><span class="lineNum">    1892 </span>            :         rcu_read_unlock();</a>
<a name="1893"><span class="lineNum">    1893 </span>            : </a>
<a name="1894"><span class="lineNum">    1894 </span>            :         return stopsearch;</a>
<a name="1895"><span class="lineNum">    1895 </span>            : }</a>
<a name="1896"><span class="lineNum">    1896 </span>            : </a>
<a name="1897"><span class="lineNum">    1897 </span>            : static void task_numa_find_cpu(struct task_numa_env *env,</a>
<a name="1898"><span class="lineNum">    1898 </span>            :                                 long taskimp, long groupimp)</a>
<a name="1899"><span class="lineNum">    1899 </span>            : {</a>
<a name="1900"><span class="lineNum">    1900 </span>            :         bool maymove = false;</a>
<a name="1901"><span class="lineNum">    1901 </span>            :         int cpu;</a>
<a name="1902"><span class="lineNum">    1902 </span>            : </a>
<a name="1903"><span class="lineNum">    1903 </span>            :         /*</a>
<a name="1904"><span class="lineNum">    1904 </span>            :          * If dst node has spare capacity, then check if there is an</a>
<a name="1905"><span class="lineNum">    1905 </span>            :          * imbalance that would be overruled by the load balancer.</a>
<a name="1906"><span class="lineNum">    1906 </span>            :          */</a>
<a name="1907"><span class="lineNum">    1907 </span>            :         if (env-&gt;dst_stats.node_type == node_has_spare) {</a>
<a name="1908"><span class="lineNum">    1908 </span>            :                 unsigned int imbalance;</a>
<a name="1909"><span class="lineNum">    1909 </span>            :                 int src_running, dst_running;</a>
<a name="1910"><span class="lineNum">    1910 </span>            : </a>
<a name="1911"><span class="lineNum">    1911 </span>            :                 /*</a>
<a name="1912"><span class="lineNum">    1912 </span>            :                  * Would movement cause an imbalance? Note that if src has</a>
<a name="1913"><span class="lineNum">    1913 </span>            :                  * more running tasks that the imbalance is ignored as the</a>
<a name="1914"><span class="lineNum">    1914 </span>            :                  * move improves the imbalance from the perspective of the</a>
<a name="1915"><span class="lineNum">    1915 </span>            :                  * CPU load balancer.</a>
<a name="1916"><span class="lineNum">    1916 </span>            :                  * */</a>
<a name="1917"><span class="lineNum">    1917 </span>            :                 src_running = env-&gt;src_stats.nr_running - 1;</a>
<a name="1918"><span class="lineNum">    1918 </span>            :                 dst_running = env-&gt;dst_stats.nr_running + 1;</a>
<a name="1919"><span class="lineNum">    1919 </span>            :                 imbalance = max(0, dst_running - src_running);</a>
<a name="1920"><span class="lineNum">    1920 </span>            :                 imbalance = adjust_numa_imbalance(imbalance, dst_running,</a>
<a name="1921"><span class="lineNum">    1921 </span>            :                                                   env-&gt;imb_numa_nr);</a>
<a name="1922"><span class="lineNum">    1922 </span>            : </a>
<a name="1923"><span class="lineNum">    1923 </span>            :                 /* Use idle CPU if there is no imbalance */</a>
<a name="1924"><span class="lineNum">    1924 </span>            :                 if (!imbalance) {</a>
<a name="1925"><span class="lineNum">    1925 </span>            :                         maymove = true;</a>
<a name="1926"><span class="lineNum">    1926 </span>            :                         if (env-&gt;dst_stats.idle_cpu &gt;= 0) {</a>
<a name="1927"><span class="lineNum">    1927 </span>            :                                 env-&gt;dst_cpu = env-&gt;dst_stats.idle_cpu;</a>
<a name="1928"><span class="lineNum">    1928 </span>            :                                 task_numa_assign(env, NULL, 0);</a>
<a name="1929"><span class="lineNum">    1929 </span>            :                                 return;</a>
<a name="1930"><span class="lineNum">    1930 </span>            :                         }</a>
<a name="1931"><span class="lineNum">    1931 </span>            :                 }</a>
<a name="1932"><span class="lineNum">    1932 </span>            :         } else {</a>
<a name="1933"><span class="lineNum">    1933 </span>            :                 long src_load, dst_load, load;</a>
<a name="1934"><span class="lineNum">    1934 </span>            :                 /*</a>
<a name="1935"><span class="lineNum">    1935 </span>            :                  * If the improvement from just moving env-&gt;p direction is better</a>
<a name="1936"><span class="lineNum">    1936 </span>            :                  * than swapping tasks around, check if a move is possible.</a>
<a name="1937"><span class="lineNum">    1937 </span>            :                  */</a>
<a name="1938"><span class="lineNum">    1938 </span>            :                 load = task_h_load(env-&gt;p);</a>
<a name="1939"><span class="lineNum">    1939 </span>            :                 dst_load = env-&gt;dst_stats.load + load;</a>
<a name="1940"><span class="lineNum">    1940 </span>            :                 src_load = env-&gt;src_stats.load - load;</a>
<a name="1941"><span class="lineNum">    1941 </span>            :                 maymove = !load_too_imbalanced(src_load, dst_load, env);</a>
<a name="1942"><span class="lineNum">    1942 </span>            :         }</a>
<a name="1943"><span class="lineNum">    1943 </span>            : </a>
<a name="1944"><span class="lineNum">    1944 </span>            :         for_each_cpu(cpu, cpumask_of_node(env-&gt;dst_nid)) {</a>
<a name="1945"><span class="lineNum">    1945 </span>            :                 /* Skip this CPU if the source task cannot migrate */</a>
<a name="1946"><span class="lineNum">    1946 </span>            :                 if (!cpumask_test_cpu(cpu, env-&gt;p-&gt;cpus_ptr))</a>
<a name="1947"><span class="lineNum">    1947 </span>            :                         continue;</a>
<a name="1948"><span class="lineNum">    1948 </span>            : </a>
<a name="1949"><span class="lineNum">    1949 </span>            :                 env-&gt;dst_cpu = cpu;</a>
<a name="1950"><span class="lineNum">    1950 </span>            :                 if (task_numa_compare(env, taskimp, groupimp, maymove))</a>
<a name="1951"><span class="lineNum">    1951 </span>            :                         break;</a>
<a name="1952"><span class="lineNum">    1952 </span>            :         }</a>
<a name="1953"><span class="lineNum">    1953 </span>            : }</a>
<a name="1954"><span class="lineNum">    1954 </span>            : </a>
<a name="1955"><span class="lineNum">    1955 </span>            : static int task_numa_migrate(struct task_struct *p)</a>
<a name="1956"><span class="lineNum">    1956 </span>            : {</a>
<a name="1957"><span class="lineNum">    1957 </span>            :         struct task_numa_env env = {</a>
<a name="1958"><span class="lineNum">    1958 </span>            :                 .p = p,</a>
<a name="1959"><span class="lineNum">    1959 </span>            : </a>
<a name="1960"><span class="lineNum">    1960 </span>            :                 .src_cpu = task_cpu(p),</a>
<a name="1961"><span class="lineNum">    1961 </span>            :                 .src_nid = task_node(p),</a>
<a name="1962"><span class="lineNum">    1962 </span>            : </a>
<a name="1963"><span class="lineNum">    1963 </span>            :                 .imbalance_pct = 112,</a>
<a name="1964"><span class="lineNum">    1964 </span>            : </a>
<a name="1965"><span class="lineNum">    1965 </span>            :                 .best_task = NULL,</a>
<a name="1966"><span class="lineNum">    1966 </span>            :                 .best_imp = 0,</a>
<a name="1967"><span class="lineNum">    1967 </span>            :                 .best_cpu = -1,</a>
<a name="1968"><span class="lineNum">    1968 </span>            :         };</a>
<a name="1969"><span class="lineNum">    1969 </span>            :         unsigned long taskweight, groupweight;</a>
<a name="1970"><span class="lineNum">    1970 </span>            :         struct sched_domain *sd;</a>
<a name="1971"><span class="lineNum">    1971 </span>            :         long taskimp, groupimp;</a>
<a name="1972"><span class="lineNum">    1972 </span>            :         struct numa_group *ng;</a>
<a name="1973"><span class="lineNum">    1973 </span>            :         struct rq *best_rq;</a>
<a name="1974"><span class="lineNum">    1974 </span>            :         int nid, ret, dist;</a>
<a name="1975"><span class="lineNum">    1975 </span>            : </a>
<a name="1976"><span class="lineNum">    1976 </span>            :         /*</a>
<a name="1977"><span class="lineNum">    1977 </span>            :          * Pick the lowest SD_NUMA domain, as that would have the smallest</a>
<a name="1978"><span class="lineNum">    1978 </span>            :          * imbalance and would be the first to start moving tasks about.</a>
<a name="1979"><span class="lineNum">    1979 </span>            :          *</a>
<a name="1980"><span class="lineNum">    1980 </span>            :          * And we want to avoid any moving of tasks about, as that would create</a>
<a name="1981"><span class="lineNum">    1981 </span>            :          * random movement of tasks -- counter the numa conditions we're trying</a>
<a name="1982"><span class="lineNum">    1982 </span>            :          * to satisfy here.</a>
<a name="1983"><span class="lineNum">    1983 </span>            :          */</a>
<a name="1984"><span class="lineNum">    1984 </span>            :         rcu_read_lock();</a>
<a name="1985"><span class="lineNum">    1985 </span>            :         sd = rcu_dereference(per_cpu(sd_numa, env.src_cpu));</a>
<a name="1986"><span class="lineNum">    1986 </span>            :         if (sd) {</a>
<a name="1987"><span class="lineNum">    1987 </span>            :                 env.imbalance_pct = 100 + (sd-&gt;imbalance_pct - 100) / 2;</a>
<a name="1988"><span class="lineNum">    1988 </span>            :                 env.imb_numa_nr = sd-&gt;imb_numa_nr;</a>
<a name="1989"><span class="lineNum">    1989 </span>            :         }</a>
<a name="1990"><span class="lineNum">    1990 </span>            :         rcu_read_unlock();</a>
<a name="1991"><span class="lineNum">    1991 </span>            : </a>
<a name="1992"><span class="lineNum">    1992 </span>            :         /*</a>
<a name="1993"><span class="lineNum">    1993 </span>            :          * Cpusets can break the scheduler domain tree into smaller</a>
<a name="1994"><span class="lineNum">    1994 </span>            :          * balance domains, some of which do not cross NUMA boundaries.</a>
<a name="1995"><span class="lineNum">    1995 </span>            :          * Tasks that are &quot;trapped&quot; in such domains cannot be migrated</a>
<a name="1996"><span class="lineNum">    1996 </span>            :          * elsewhere, so there is no point in (re)trying.</a>
<a name="1997"><span class="lineNum">    1997 </span>            :          */</a>
<a name="1998"><span class="lineNum">    1998 </span>            :         if (unlikely(!sd)) {</a>
<a name="1999"><span class="lineNum">    1999 </span>            :                 sched_setnuma(p, task_node(p));</a>
<a name="2000"><span class="lineNum">    2000 </span>            :                 return -EINVAL;</a>
<a name="2001"><span class="lineNum">    2001 </span>            :         }</a>
<a name="2002"><span class="lineNum">    2002 </span>            : </a>
<a name="2003"><span class="lineNum">    2003 </span>            :         env.dst_nid = p-&gt;numa_preferred_nid;</a>
<a name="2004"><span class="lineNum">    2004 </span>            :         dist = env.dist = node_distance(env.src_nid, env.dst_nid);</a>
<a name="2005"><span class="lineNum">    2005 </span>            :         taskweight = task_weight(p, env.src_nid, dist);</a>
<a name="2006"><span class="lineNum">    2006 </span>            :         groupweight = group_weight(p, env.src_nid, dist);</a>
<a name="2007"><span class="lineNum">    2007 </span>            :         update_numa_stats(&amp;env, &amp;env.src_stats, env.src_nid, false);</a>
<a name="2008"><span class="lineNum">    2008 </span>            :         taskimp = task_weight(p, env.dst_nid, dist) - taskweight;</a>
<a name="2009"><span class="lineNum">    2009 </span>            :         groupimp = group_weight(p, env.dst_nid, dist) - groupweight;</a>
<a name="2010"><span class="lineNum">    2010 </span>            :         update_numa_stats(&amp;env, &amp;env.dst_stats, env.dst_nid, true);</a>
<a name="2011"><span class="lineNum">    2011 </span>            : </a>
<a name="2012"><span class="lineNum">    2012 </span>            :         /* Try to find a spot on the preferred nid. */</a>
<a name="2013"><span class="lineNum">    2013 </span>            :         task_numa_find_cpu(&amp;env, taskimp, groupimp);</a>
<a name="2014"><span class="lineNum">    2014 </span>            : </a>
<a name="2015"><span class="lineNum">    2015 </span>            :         /*</a>
<a name="2016"><span class="lineNum">    2016 </span>            :          * Look at other nodes in these cases:</a>
<a name="2017"><span class="lineNum">    2017 </span>            :          * - there is no space available on the preferred_nid</a>
<a name="2018"><span class="lineNum">    2018 </span>            :          * - the task is part of a numa_group that is interleaved across</a>
<a name="2019"><span class="lineNum">    2019 </span>            :          *   multiple NUMA nodes; in order to better consolidate the group,</a>
<a name="2020"><span class="lineNum">    2020 </span>            :          *   we need to check other locations.</a>
<a name="2021"><span class="lineNum">    2021 </span>            :          */</a>
<a name="2022"><span class="lineNum">    2022 </span>            :         ng = deref_curr_numa_group(p);</a>
<a name="2023"><span class="lineNum">    2023 </span>            :         if (env.best_cpu == -1 || (ng &amp;&amp; ng-&gt;active_nodes &gt; 1)) {</a>
<a name="2024"><span class="lineNum">    2024 </span>            :                 for_each_node_state(nid, N_CPU) {</a>
<a name="2025"><span class="lineNum">    2025 </span>            :                         if (nid == env.src_nid || nid == p-&gt;numa_preferred_nid)</a>
<a name="2026"><span class="lineNum">    2026 </span>            :                                 continue;</a>
<a name="2027"><span class="lineNum">    2027 </span>            : </a>
<a name="2028"><span class="lineNum">    2028 </span>            :                         dist = node_distance(env.src_nid, env.dst_nid);</a>
<a name="2029"><span class="lineNum">    2029 </span>            :                         if (sched_numa_topology_type == NUMA_BACKPLANE &amp;&amp;</a>
<a name="2030"><span class="lineNum">    2030 </span>            :                                                 dist != env.dist) {</a>
<a name="2031"><span class="lineNum">    2031 </span>            :                                 taskweight = task_weight(p, env.src_nid, dist);</a>
<a name="2032"><span class="lineNum">    2032 </span>            :                                 groupweight = group_weight(p, env.src_nid, dist);</a>
<a name="2033"><span class="lineNum">    2033 </span>            :                         }</a>
<a name="2034"><span class="lineNum">    2034 </span>            : </a>
<a name="2035"><span class="lineNum">    2035 </span>            :                         /* Only consider nodes where both task and groups benefit */</a>
<a name="2036"><span class="lineNum">    2036 </span>            :                         taskimp = task_weight(p, nid, dist) - taskweight;</a>
<a name="2037"><span class="lineNum">    2037 </span>            :                         groupimp = group_weight(p, nid, dist) - groupweight;</a>
<a name="2038"><span class="lineNum">    2038 </span>            :                         if (taskimp &lt; 0 &amp;&amp; groupimp &lt; 0)</a>
<a name="2039"><span class="lineNum">    2039 </span>            :                                 continue;</a>
<a name="2040"><span class="lineNum">    2040 </span>            : </a>
<a name="2041"><span class="lineNum">    2041 </span>            :                         env.dist = dist;</a>
<a name="2042"><span class="lineNum">    2042 </span>            :                         env.dst_nid = nid;</a>
<a name="2043"><span class="lineNum">    2043 </span>            :                         update_numa_stats(&amp;env, &amp;env.dst_stats, env.dst_nid, true);</a>
<a name="2044"><span class="lineNum">    2044 </span>            :                         task_numa_find_cpu(&amp;env, taskimp, groupimp);</a>
<a name="2045"><span class="lineNum">    2045 </span>            :                 }</a>
<a name="2046"><span class="lineNum">    2046 </span>            :         }</a>
<a name="2047"><span class="lineNum">    2047 </span>            : </a>
<a name="2048"><span class="lineNum">    2048 </span>            :         /*</a>
<a name="2049"><span class="lineNum">    2049 </span>            :          * If the task is part of a workload that spans multiple NUMA nodes,</a>
<a name="2050"><span class="lineNum">    2050 </span>            :          * and is migrating into one of the workload's active nodes, remember</a>
<a name="2051"><span class="lineNum">    2051 </span>            :          * this node as the task's preferred numa node, so the workload can</a>
<a name="2052"><span class="lineNum">    2052 </span>            :          * settle down.</a>
<a name="2053"><span class="lineNum">    2053 </span>            :          * A task that migrated to a second choice node will be better off</a>
<a name="2054"><span class="lineNum">    2054 </span>            :          * trying for a better one later. Do not set the preferred node here.</a>
<a name="2055"><span class="lineNum">    2055 </span>            :          */</a>
<a name="2056"><span class="lineNum">    2056 </span>            :         if (ng) {</a>
<a name="2057"><span class="lineNum">    2057 </span>            :                 if (env.best_cpu == -1)</a>
<a name="2058"><span class="lineNum">    2058 </span>            :                         nid = env.src_nid;</a>
<a name="2059"><span class="lineNum">    2059 </span>            :                 else</a>
<a name="2060"><span class="lineNum">    2060 </span>            :                         nid = cpu_to_node(env.best_cpu);</a>
<a name="2061"><span class="lineNum">    2061 </span>            : </a>
<a name="2062"><span class="lineNum">    2062 </span>            :                 if (nid != p-&gt;numa_preferred_nid)</a>
<a name="2063"><span class="lineNum">    2063 </span>            :                         sched_setnuma(p, nid);</a>
<a name="2064"><span class="lineNum">    2064 </span>            :         }</a>
<a name="2065"><span class="lineNum">    2065 </span>            : </a>
<a name="2066"><span class="lineNum">    2066 </span>            :         /* No better CPU than the current one was found. */</a>
<a name="2067"><span class="lineNum">    2067 </span>            :         if (env.best_cpu == -1) {</a>
<a name="2068"><span class="lineNum">    2068 </span>            :                 trace_sched_stick_numa(p, env.src_cpu, NULL, -1);</a>
<a name="2069"><span class="lineNum">    2069 </span>            :                 return -EAGAIN;</a>
<a name="2070"><span class="lineNum">    2070 </span>            :         }</a>
<a name="2071"><span class="lineNum">    2071 </span>            : </a>
<a name="2072"><span class="lineNum">    2072 </span>            :         best_rq = cpu_rq(env.best_cpu);</a>
<a name="2073"><span class="lineNum">    2073 </span>            :         if (env.best_task == NULL) {</a>
<a name="2074"><span class="lineNum">    2074 </span>            :                 ret = migrate_task_to(p, env.best_cpu);</a>
<a name="2075"><span class="lineNum">    2075 </span>            :                 WRITE_ONCE(best_rq-&gt;numa_migrate_on, 0);</a>
<a name="2076"><span class="lineNum">    2076 </span>            :                 if (ret != 0)</a>
<a name="2077"><span class="lineNum">    2077 </span>            :                         trace_sched_stick_numa(p, env.src_cpu, NULL, env.best_cpu);</a>
<a name="2078"><span class="lineNum">    2078 </span>            :                 return ret;</a>
<a name="2079"><span class="lineNum">    2079 </span>            :         }</a>
<a name="2080"><span class="lineNum">    2080 </span>            : </a>
<a name="2081"><span class="lineNum">    2081 </span>            :         ret = migrate_swap(p, env.best_task, env.best_cpu, env.src_cpu);</a>
<a name="2082"><span class="lineNum">    2082 </span>            :         WRITE_ONCE(best_rq-&gt;numa_migrate_on, 0);</a>
<a name="2083"><span class="lineNum">    2083 </span>            : </a>
<a name="2084"><span class="lineNum">    2084 </span>            :         if (ret != 0)</a>
<a name="2085"><span class="lineNum">    2085 </span>            :                 trace_sched_stick_numa(p, env.src_cpu, env.best_task, env.best_cpu);</a>
<a name="2086"><span class="lineNum">    2086 </span>            :         put_task_struct(env.best_task);</a>
<a name="2087"><span class="lineNum">    2087 </span>            :         return ret;</a>
<a name="2088"><span class="lineNum">    2088 </span>            : }</a>
<a name="2089"><span class="lineNum">    2089 </span>            : </a>
<a name="2090"><span class="lineNum">    2090 </span>            : /* Attempt to migrate a task to a CPU on the preferred node. */</a>
<a name="2091"><span class="lineNum">    2091 </span>            : static void numa_migrate_preferred(struct task_struct *p)</a>
<a name="2092"><span class="lineNum">    2092 </span>            : {</a>
<a name="2093"><span class="lineNum">    2093 </span>            :         unsigned long interval = HZ;</a>
<a name="2094"><span class="lineNum">    2094 </span>            : </a>
<a name="2095"><span class="lineNum">    2095 </span>            :         /* This task has no NUMA fault statistics yet */</a>
<a name="2096"><span class="lineNum">    2096 </span>            :         if (unlikely(p-&gt;numa_preferred_nid == NUMA_NO_NODE || !p-&gt;numa_faults))</a>
<a name="2097"><span class="lineNum">    2097 </span>            :                 return;</a>
<a name="2098"><span class="lineNum">    2098 </span>            : </a>
<a name="2099"><span class="lineNum">    2099 </span>            :         /* Periodically retry migrating the task to the preferred node */</a>
<a name="2100"><span class="lineNum">    2100 </span>            :         interval = min(interval, msecs_to_jiffies(p-&gt;numa_scan_period) / 16);</a>
<a name="2101"><span class="lineNum">    2101 </span>            :         p-&gt;numa_migrate_retry = jiffies + interval;</a>
<a name="2102"><span class="lineNum">    2102 </span>            : </a>
<a name="2103"><span class="lineNum">    2103 </span>            :         /* Success if task is already running on preferred CPU */</a>
<a name="2104"><span class="lineNum">    2104 </span>            :         if (task_node(p) == p-&gt;numa_preferred_nid)</a>
<a name="2105"><span class="lineNum">    2105 </span>            :                 return;</a>
<a name="2106"><span class="lineNum">    2106 </span>            : </a>
<a name="2107"><span class="lineNum">    2107 </span>            :         /* Otherwise, try migrate to a CPU on the preferred node */</a>
<a name="2108"><span class="lineNum">    2108 </span>            :         task_numa_migrate(p);</a>
<a name="2109"><span class="lineNum">    2109 </span>            : }</a>
<a name="2110"><span class="lineNum">    2110 </span>            : </a>
<a name="2111"><span class="lineNum">    2111 </span>            : /*</a>
<a name="2112"><span class="lineNum">    2112 </span>            :  * Find out how many nodes the workload is actively running on. Do this by</a>
<a name="2113"><span class="lineNum">    2113 </span>            :  * tracking the nodes from which NUMA hinting faults are triggered. This can</a>
<a name="2114"><span class="lineNum">    2114 </span>            :  * be different from the set of nodes where the workload's memory is currently</a>
<a name="2115"><span class="lineNum">    2115 </span>            :  * located.</a>
<a name="2116"><span class="lineNum">    2116 </span>            :  */</a>
<a name="2117"><span class="lineNum">    2117 </span>            : static void numa_group_count_active_nodes(struct numa_group *numa_group)</a>
<a name="2118"><span class="lineNum">    2118 </span>            : {</a>
<a name="2119"><span class="lineNum">    2119 </span>            :         unsigned long faults, max_faults = 0;</a>
<a name="2120"><span class="lineNum">    2120 </span>            :         int nid, active_nodes = 0;</a>
<a name="2121"><span class="lineNum">    2121 </span>            : </a>
<a name="2122"><span class="lineNum">    2122 </span>            :         for_each_node_state(nid, N_CPU) {</a>
<a name="2123"><span class="lineNum">    2123 </span>            :                 faults = group_faults_cpu(numa_group, nid);</a>
<a name="2124"><span class="lineNum">    2124 </span>            :                 if (faults &gt; max_faults)</a>
<a name="2125"><span class="lineNum">    2125 </span>            :                         max_faults = faults;</a>
<a name="2126"><span class="lineNum">    2126 </span>            :         }</a>
<a name="2127"><span class="lineNum">    2127 </span>            : </a>
<a name="2128"><span class="lineNum">    2128 </span>            :         for_each_node_state(nid, N_CPU) {</a>
<a name="2129"><span class="lineNum">    2129 </span>            :                 faults = group_faults_cpu(numa_group, nid);</a>
<a name="2130"><span class="lineNum">    2130 </span>            :                 if (faults * ACTIVE_NODE_FRACTION &gt; max_faults)</a>
<a name="2131"><span class="lineNum">    2131 </span>            :                         active_nodes++;</a>
<a name="2132"><span class="lineNum">    2132 </span>            :         }</a>
<a name="2133"><span class="lineNum">    2133 </span>            : </a>
<a name="2134"><span class="lineNum">    2134 </span>            :         numa_group-&gt;max_faults_cpu = max_faults;</a>
<a name="2135"><span class="lineNum">    2135 </span>            :         numa_group-&gt;active_nodes = active_nodes;</a>
<a name="2136"><span class="lineNum">    2136 </span>            : }</a>
<a name="2137"><span class="lineNum">    2137 </span>            : </a>
<a name="2138"><span class="lineNum">    2138 </span>            : /*</a>
<a name="2139"><span class="lineNum">    2139 </span>            :  * When adapting the scan rate, the period is divided into NUMA_PERIOD_SLOTS</a>
<a name="2140"><span class="lineNum">    2140 </span>            :  * increments. The more local the fault statistics are, the higher the scan</a>
<a name="2141"><span class="lineNum">    2141 </span>            :  * period will be for the next scan window. If local/(local+remote) ratio is</a>
<a name="2142"><span class="lineNum">    2142 </span>            :  * below NUMA_PERIOD_THRESHOLD (where range of ratio is 1..NUMA_PERIOD_SLOTS)</a>
<a name="2143"><span class="lineNum">    2143 </span>            :  * the scan period will decrease. Aim for 70% local accesses.</a>
<a name="2144"><span class="lineNum">    2144 </span>            :  */</a>
<a name="2145"><span class="lineNum">    2145 </span>            : #define NUMA_PERIOD_SLOTS 10</a>
<a name="2146"><span class="lineNum">    2146 </span>            : #define NUMA_PERIOD_THRESHOLD 7</a>
<a name="2147"><span class="lineNum">    2147 </span>            : </a>
<a name="2148"><span class="lineNum">    2148 </span>            : /*</a>
<a name="2149"><span class="lineNum">    2149 </span>            :  * Increase the scan period (slow down scanning) if the majority of</a>
<a name="2150"><span class="lineNum">    2150 </span>            :  * our memory is already on our local node, or if the majority of</a>
<a name="2151"><span class="lineNum">    2151 </span>            :  * the page accesses are shared with other processes.</a>
<a name="2152"><span class="lineNum">    2152 </span>            :  * Otherwise, decrease the scan period.</a>
<a name="2153"><span class="lineNum">    2153 </span>            :  */</a>
<a name="2154"><span class="lineNum">    2154 </span>            : static void update_task_scan_period(struct task_struct *p,</a>
<a name="2155"><span class="lineNum">    2155 </span>            :                         unsigned long shared, unsigned long private)</a>
<a name="2156"><span class="lineNum">    2156 </span>            : {</a>
<a name="2157"><span class="lineNum">    2157 </span>            :         unsigned int period_slot;</a>
<a name="2158"><span class="lineNum">    2158 </span>            :         int lr_ratio, ps_ratio;</a>
<a name="2159"><span class="lineNum">    2159 </span>            :         int diff;</a>
<a name="2160"><span class="lineNum">    2160 </span>            : </a>
<a name="2161"><span class="lineNum">    2161 </span>            :         unsigned long remote = p-&gt;numa_faults_locality[0];</a>
<a name="2162"><span class="lineNum">    2162 </span>            :         unsigned long local = p-&gt;numa_faults_locality[1];</a>
<a name="2163"><span class="lineNum">    2163 </span>            : </a>
<a name="2164"><span class="lineNum">    2164 </span>            :         /*</a>
<a name="2165"><span class="lineNum">    2165 </span>            :          * If there were no record hinting faults then either the task is</a>
<a name="2166"><span class="lineNum">    2166 </span>            :          * completely idle or all activity is in areas that are not of interest</a>
<a name="2167"><span class="lineNum">    2167 </span>            :          * to automatic numa balancing. Related to that, if there were failed</a>
<a name="2168"><span class="lineNum">    2168 </span>            :          * migration then it implies we are migrating too quickly or the local</a>
<a name="2169"><span class="lineNum">    2169 </span>            :          * node is overloaded. In either case, scan slower</a>
<a name="2170"><span class="lineNum">    2170 </span>            :          */</a>
<a name="2171"><span class="lineNum">    2171 </span>            :         if (local + shared == 0 || p-&gt;numa_faults_locality[2]) {</a>
<a name="2172"><span class="lineNum">    2172 </span>            :                 p-&gt;numa_scan_period = min(p-&gt;numa_scan_period_max,</a>
<a name="2173"><span class="lineNum">    2173 </span>            :                         p-&gt;numa_scan_period &lt;&lt; 1);</a>
<a name="2174"><span class="lineNum">    2174 </span>            : </a>
<a name="2175"><span class="lineNum">    2175 </span>            :                 p-&gt;mm-&gt;numa_next_scan = jiffies +</a>
<a name="2176"><span class="lineNum">    2176 </span>            :                         msecs_to_jiffies(p-&gt;numa_scan_period);</a>
<a name="2177"><span class="lineNum">    2177 </span>            : </a>
<a name="2178"><span class="lineNum">    2178 </span>            :                 return;</a>
<a name="2179"><span class="lineNum">    2179 </span>            :         }</a>
<a name="2180"><span class="lineNum">    2180 </span>            : </a>
<a name="2181"><span class="lineNum">    2181 </span>            :         /*</a>
<a name="2182"><span class="lineNum">    2182 </span>            :          * Prepare to scale scan period relative to the current period.</a>
<a name="2183"><span class="lineNum">    2183 </span>            :          *       == NUMA_PERIOD_THRESHOLD scan period stays the same</a>
<a name="2184"><span class="lineNum">    2184 </span>            :          *       &lt;  NUMA_PERIOD_THRESHOLD scan period decreases (scan faster)</a>
<a name="2185"><span class="lineNum">    2185 </span>            :          *       &gt;= NUMA_PERIOD_THRESHOLD scan period increases (scan slower)</a>
<a name="2186"><span class="lineNum">    2186 </span>            :          */</a>
<a name="2187"><span class="lineNum">    2187 </span>            :         period_slot = DIV_ROUND_UP(p-&gt;numa_scan_period, NUMA_PERIOD_SLOTS);</a>
<a name="2188"><span class="lineNum">    2188 </span>            :         lr_ratio = (local * NUMA_PERIOD_SLOTS) / (local + remote);</a>
<a name="2189"><span class="lineNum">    2189 </span>            :         ps_ratio = (private * NUMA_PERIOD_SLOTS) / (private + shared);</a>
<a name="2190"><span class="lineNum">    2190 </span>            : </a>
<a name="2191"><span class="lineNum">    2191 </span>            :         if (ps_ratio &gt;= NUMA_PERIOD_THRESHOLD) {</a>
<a name="2192"><span class="lineNum">    2192 </span>            :                 /*</a>
<a name="2193"><span class="lineNum">    2193 </span>            :                  * Most memory accesses are local. There is no need to</a>
<a name="2194"><span class="lineNum">    2194 </span>            :                  * do fast NUMA scanning, since memory is already local.</a>
<a name="2195"><span class="lineNum">    2195 </span>            :                  */</a>
<a name="2196"><span class="lineNum">    2196 </span>            :                 int slot = ps_ratio - NUMA_PERIOD_THRESHOLD;</a>
<a name="2197"><span class="lineNum">    2197 </span>            :                 if (!slot)</a>
<a name="2198"><span class="lineNum">    2198 </span>            :                         slot = 1;</a>
<a name="2199"><span class="lineNum">    2199 </span>            :                 diff = slot * period_slot;</a>
<a name="2200"><span class="lineNum">    2200 </span>            :         } else if (lr_ratio &gt;= NUMA_PERIOD_THRESHOLD) {</a>
<a name="2201"><span class="lineNum">    2201 </span>            :                 /*</a>
<a name="2202"><span class="lineNum">    2202 </span>            :                  * Most memory accesses are shared with other tasks.</a>
<a name="2203"><span class="lineNum">    2203 </span>            :                  * There is no point in continuing fast NUMA scanning,</a>
<a name="2204"><span class="lineNum">    2204 </span>            :                  * since other tasks may just move the memory elsewhere.</a>
<a name="2205"><span class="lineNum">    2205 </span>            :                  */</a>
<a name="2206"><span class="lineNum">    2206 </span>            :                 int slot = lr_ratio - NUMA_PERIOD_THRESHOLD;</a>
<a name="2207"><span class="lineNum">    2207 </span>            :                 if (!slot)</a>
<a name="2208"><span class="lineNum">    2208 </span>            :                         slot = 1;</a>
<a name="2209"><span class="lineNum">    2209 </span>            :                 diff = slot * period_slot;</a>
<a name="2210"><span class="lineNum">    2210 </span>            :         } else {</a>
<a name="2211"><span class="lineNum">    2211 </span>            :                 /*</a>
<a name="2212"><span class="lineNum">    2212 </span>            :                  * Private memory faults exceed (SLOTS-THRESHOLD)/SLOTS,</a>
<a name="2213"><span class="lineNum">    2213 </span>            :                  * yet they are not on the local NUMA node. Speed up</a>
<a name="2214"><span class="lineNum">    2214 </span>            :                  * NUMA scanning to get the memory moved over.</a>
<a name="2215"><span class="lineNum">    2215 </span>            :                  */</a>
<a name="2216"><span class="lineNum">    2216 </span>            :                 int ratio = max(lr_ratio, ps_ratio);</a>
<a name="2217"><span class="lineNum">    2217 </span>            :                 diff = -(NUMA_PERIOD_THRESHOLD - ratio) * period_slot;</a>
<a name="2218"><span class="lineNum">    2218 </span>            :         }</a>
<a name="2219"><span class="lineNum">    2219 </span>            : </a>
<a name="2220"><span class="lineNum">    2220 </span>            :         p-&gt;numa_scan_period = clamp(p-&gt;numa_scan_period + diff,</a>
<a name="2221"><span class="lineNum">    2221 </span>            :                         task_scan_min(p), task_scan_max(p));</a>
<a name="2222"><span class="lineNum">    2222 </span>            :         memset(p-&gt;numa_faults_locality, 0, sizeof(p-&gt;numa_faults_locality));</a>
<a name="2223"><span class="lineNum">    2223 </span>            : }</a>
<a name="2224"><span class="lineNum">    2224 </span>            : </a>
<a name="2225"><span class="lineNum">    2225 </span>            : /*</a>
<a name="2226"><span class="lineNum">    2226 </span>            :  * Get the fraction of time the task has been running since the last</a>
<a name="2227"><span class="lineNum">    2227 </span>            :  * NUMA placement cycle. The scheduler keeps similar statistics, but</a>
<a name="2228"><span class="lineNum">    2228 </span>            :  * decays those on a 32ms period, which is orders of magnitude off</a>
<a name="2229"><span class="lineNum">    2229 </span>            :  * from the dozens-of-seconds NUMA balancing period. Use the scheduler</a>
<a name="2230"><span class="lineNum">    2230 </span>            :  * stats only if the task is so new there are no NUMA statistics yet.</a>
<a name="2231"><span class="lineNum">    2231 </span>            :  */</a>
<a name="2232"><span class="lineNum">    2232 </span>            : static u64 numa_get_avg_runtime(struct task_struct *p, u64 *period)</a>
<a name="2233"><span class="lineNum">    2233 </span>            : {</a>
<a name="2234"><span class="lineNum">    2234 </span>            :         u64 runtime, delta, now;</a>
<a name="2235"><span class="lineNum">    2235 </span>            :         /* Use the start of this time slice to avoid calculations. */</a>
<a name="2236"><span class="lineNum">    2236 </span>            :         now = p-&gt;se.exec_start;</a>
<a name="2237"><span class="lineNum">    2237 </span>            :         runtime = p-&gt;se.sum_exec_runtime;</a>
<a name="2238"><span class="lineNum">    2238 </span>            : </a>
<a name="2239"><span class="lineNum">    2239 </span>            :         if (p-&gt;last_task_numa_placement) {</a>
<a name="2240"><span class="lineNum">    2240 </span>            :                 delta = runtime - p-&gt;last_sum_exec_runtime;</a>
<a name="2241"><span class="lineNum">    2241 </span>            :                 *period = now - p-&gt;last_task_numa_placement;</a>
<a name="2242"><span class="lineNum">    2242 </span>            : </a>
<a name="2243"><span class="lineNum">    2243 </span>            :                 /* Avoid time going backwards, prevent potential divide error: */</a>
<a name="2244"><span class="lineNum">    2244 </span>            :                 if (unlikely((s64)*period &lt; 0))</a>
<a name="2245"><span class="lineNum">    2245 </span>            :                         *period = 0;</a>
<a name="2246"><span class="lineNum">    2246 </span>            :         } else {</a>
<a name="2247"><span class="lineNum">    2247 </span>            :                 delta = p-&gt;se.avg.load_sum;</a>
<a name="2248"><span class="lineNum">    2248 </span>            :                 *period = LOAD_AVG_MAX;</a>
<a name="2249"><span class="lineNum">    2249 </span>            :         }</a>
<a name="2250"><span class="lineNum">    2250 </span>            : </a>
<a name="2251"><span class="lineNum">    2251 </span>            :         p-&gt;last_sum_exec_runtime = runtime;</a>
<a name="2252"><span class="lineNum">    2252 </span>            :         p-&gt;last_task_numa_placement = now;</a>
<a name="2253"><span class="lineNum">    2253 </span>            : </a>
<a name="2254"><span class="lineNum">    2254 </span>            :         return delta;</a>
<a name="2255"><span class="lineNum">    2255 </span>            : }</a>
<a name="2256"><span class="lineNum">    2256 </span>            : </a>
<a name="2257"><span class="lineNum">    2257 </span>            : /*</a>
<a name="2258"><span class="lineNum">    2258 </span>            :  * Determine the preferred nid for a task in a numa_group. This needs to</a>
<a name="2259"><span class="lineNum">    2259 </span>            :  * be done in a way that produces consistent results with group_weight,</a>
<a name="2260"><span class="lineNum">    2260 </span>            :  * otherwise workloads might not converge.</a>
<a name="2261"><span class="lineNum">    2261 </span>            :  */</a>
<a name="2262"><span class="lineNum">    2262 </span>            : static int preferred_group_nid(struct task_struct *p, int nid)</a>
<a name="2263"><span class="lineNum">    2263 </span>            : {</a>
<a name="2264"><span class="lineNum">    2264 </span>            :         nodemask_t nodes;</a>
<a name="2265"><span class="lineNum">    2265 </span>            :         int dist;</a>
<a name="2266"><span class="lineNum">    2266 </span>            : </a>
<a name="2267"><span class="lineNum">    2267 </span>            :         /* Direct connections between all NUMA nodes. */</a>
<a name="2268"><span class="lineNum">    2268 </span>            :         if (sched_numa_topology_type == NUMA_DIRECT)</a>
<a name="2269"><span class="lineNum">    2269 </span>            :                 return nid;</a>
<a name="2270"><span class="lineNum">    2270 </span>            : </a>
<a name="2271"><span class="lineNum">    2271 </span>            :         /*</a>
<a name="2272"><span class="lineNum">    2272 </span>            :          * On a system with glueless mesh NUMA topology, group_weight</a>
<a name="2273"><span class="lineNum">    2273 </span>            :          * scores nodes according to the number of NUMA hinting faults on</a>
<a name="2274"><span class="lineNum">    2274 </span>            :          * both the node itself, and on nearby nodes.</a>
<a name="2275"><span class="lineNum">    2275 </span>            :          */</a>
<a name="2276"><span class="lineNum">    2276 </span>            :         if (sched_numa_topology_type == NUMA_GLUELESS_MESH) {</a>
<a name="2277"><span class="lineNum">    2277 </span>            :                 unsigned long score, max_score = 0;</a>
<a name="2278"><span class="lineNum">    2278 </span>            :                 int node, max_node = nid;</a>
<a name="2279"><span class="lineNum">    2279 </span>            : </a>
<a name="2280"><span class="lineNum">    2280 </span>            :                 dist = sched_max_numa_distance;</a>
<a name="2281"><span class="lineNum">    2281 </span>            : </a>
<a name="2282"><span class="lineNum">    2282 </span>            :                 for_each_node_state(node, N_CPU) {</a>
<a name="2283"><span class="lineNum">    2283 </span>            :                         score = group_weight(p, node, dist);</a>
<a name="2284"><span class="lineNum">    2284 </span>            :                         if (score &gt; max_score) {</a>
<a name="2285"><span class="lineNum">    2285 </span>            :                                 max_score = score;</a>
<a name="2286"><span class="lineNum">    2286 </span>            :                                 max_node = node;</a>
<a name="2287"><span class="lineNum">    2287 </span>            :                         }</a>
<a name="2288"><span class="lineNum">    2288 </span>            :                 }</a>
<a name="2289"><span class="lineNum">    2289 </span>            :                 return max_node;</a>
<a name="2290"><span class="lineNum">    2290 </span>            :         }</a>
<a name="2291"><span class="lineNum">    2291 </span>            : </a>
<a name="2292"><span class="lineNum">    2292 </span>            :         /*</a>
<a name="2293"><span class="lineNum">    2293 </span>            :          * Finding the preferred nid in a system with NUMA backplane</a>
<a name="2294"><span class="lineNum">    2294 </span>            :          * interconnect topology is more involved. The goal is to locate</a>
<a name="2295"><span class="lineNum">    2295 </span>            :          * tasks from numa_groups near each other in the system, and</a>
<a name="2296"><span class="lineNum">    2296 </span>            :          * untangle workloads from different sides of the system. This requires</a>
<a name="2297"><span class="lineNum">    2297 </span>            :          * searching down the hierarchy of node groups, recursively searching</a>
<a name="2298"><span class="lineNum">    2298 </span>            :          * inside the highest scoring group of nodes. The nodemask tricks</a>
<a name="2299"><span class="lineNum">    2299 </span>            :          * keep the complexity of the search down.</a>
<a name="2300"><span class="lineNum">    2300 </span>            :          */</a>
<a name="2301"><span class="lineNum">    2301 </span>            :         nodes = node_states[N_CPU];</a>
<a name="2302"><span class="lineNum">    2302 </span>            :         for (dist = sched_max_numa_distance; dist &gt; LOCAL_DISTANCE; dist--) {</a>
<a name="2303"><span class="lineNum">    2303 </span>            :                 unsigned long max_faults = 0;</a>
<a name="2304"><span class="lineNum">    2304 </span>            :                 nodemask_t max_group = NODE_MASK_NONE;</a>
<a name="2305"><span class="lineNum">    2305 </span>            :                 int a, b;</a>
<a name="2306"><span class="lineNum">    2306 </span>            : </a>
<a name="2307"><span class="lineNum">    2307 </span>            :                 /* Are there nodes at this distance from each other? */</a>
<a name="2308"><span class="lineNum">    2308 </span>            :                 if (!find_numa_distance(dist))</a>
<a name="2309"><span class="lineNum">    2309 </span>            :                         continue;</a>
<a name="2310"><span class="lineNum">    2310 </span>            : </a>
<a name="2311"><span class="lineNum">    2311 </span>            :                 for_each_node_mask(a, nodes) {</a>
<a name="2312"><span class="lineNum">    2312 </span>            :                         unsigned long faults = 0;</a>
<a name="2313"><span class="lineNum">    2313 </span>            :                         nodemask_t this_group;</a>
<a name="2314"><span class="lineNum">    2314 </span>            :                         nodes_clear(this_group);</a>
<a name="2315"><span class="lineNum">    2315 </span>            : </a>
<a name="2316"><span class="lineNum">    2316 </span>            :                         /* Sum group's NUMA faults; includes a==b case. */</a>
<a name="2317"><span class="lineNum">    2317 </span>            :                         for_each_node_mask(b, nodes) {</a>
<a name="2318"><span class="lineNum">    2318 </span>            :                                 if (node_distance(a, b) &lt; dist) {</a>
<a name="2319"><span class="lineNum">    2319 </span>            :                                         faults += group_faults(p, b);</a>
<a name="2320"><span class="lineNum">    2320 </span>            :                                         node_set(b, this_group);</a>
<a name="2321"><span class="lineNum">    2321 </span>            :                                         node_clear(b, nodes);</a>
<a name="2322"><span class="lineNum">    2322 </span>            :                                 }</a>
<a name="2323"><span class="lineNum">    2323 </span>            :                         }</a>
<a name="2324"><span class="lineNum">    2324 </span>            : </a>
<a name="2325"><span class="lineNum">    2325 </span>            :                         /* Remember the top group. */</a>
<a name="2326"><span class="lineNum">    2326 </span>            :                         if (faults &gt; max_faults) {</a>
<a name="2327"><span class="lineNum">    2327 </span>            :                                 max_faults = faults;</a>
<a name="2328"><span class="lineNum">    2328 </span>            :                                 max_group = this_group;</a>
<a name="2329"><span class="lineNum">    2329 </span>            :                                 /*</a>
<a name="2330"><span class="lineNum">    2330 </span>            :                                  * subtle: at the smallest distance there is</a>
<a name="2331"><span class="lineNum">    2331 </span>            :                                  * just one node left in each &quot;group&quot;, the</a>
<a name="2332"><span class="lineNum">    2332 </span>            :                                  * winner is the preferred nid.</a>
<a name="2333"><span class="lineNum">    2333 </span>            :                                  */</a>
<a name="2334"><span class="lineNum">    2334 </span>            :                                 nid = a;</a>
<a name="2335"><span class="lineNum">    2335 </span>            :                         }</a>
<a name="2336"><span class="lineNum">    2336 </span>            :                 }</a>
<a name="2337"><span class="lineNum">    2337 </span>            :                 /* Next round, evaluate the nodes within max_group. */</a>
<a name="2338"><span class="lineNum">    2338 </span>            :                 if (!max_faults)</a>
<a name="2339"><span class="lineNum">    2339 </span>            :                         break;</a>
<a name="2340"><span class="lineNum">    2340 </span>            :                 nodes = max_group;</a>
<a name="2341"><span class="lineNum">    2341 </span>            :         }</a>
<a name="2342"><span class="lineNum">    2342 </span>            :         return nid;</a>
<a name="2343"><span class="lineNum">    2343 </span>            : }</a>
<a name="2344"><span class="lineNum">    2344 </span>            : </a>
<a name="2345"><span class="lineNum">    2345 </span>            : static void task_numa_placement(struct task_struct *p)</a>
<a name="2346"><span class="lineNum">    2346 </span>            : {</a>
<a name="2347"><span class="lineNum">    2347 </span>            :         int seq, nid, max_nid = NUMA_NO_NODE;</a>
<a name="2348"><span class="lineNum">    2348 </span>            :         unsigned long max_faults = 0;</a>
<a name="2349"><span class="lineNum">    2349 </span>            :         unsigned long fault_types[2] = { 0, 0 };</a>
<a name="2350"><span class="lineNum">    2350 </span>            :         unsigned long total_faults;</a>
<a name="2351"><span class="lineNum">    2351 </span>            :         u64 runtime, period;</a>
<a name="2352"><span class="lineNum">    2352 </span>            :         spinlock_t *group_lock = NULL;</a>
<a name="2353"><span class="lineNum">    2353 </span>            :         struct numa_group *ng;</a>
<a name="2354"><span class="lineNum">    2354 </span>            : </a>
<a name="2355"><span class="lineNum">    2355 </span>            :         /*</a>
<a name="2356"><span class="lineNum">    2356 </span>            :          * The p-&gt;mm-&gt;numa_scan_seq field gets updated without</a>
<a name="2357"><span class="lineNum">    2357 </span>            :          * exclusive access. Use READ_ONCE() here to ensure</a>
<a name="2358"><span class="lineNum">    2358 </span>            :          * that the field is read in a single access:</a>
<a name="2359"><span class="lineNum">    2359 </span>            :          */</a>
<a name="2360"><span class="lineNum">    2360 </span>            :         seq = READ_ONCE(p-&gt;mm-&gt;numa_scan_seq);</a>
<a name="2361"><span class="lineNum">    2361 </span>            :         if (p-&gt;numa_scan_seq == seq)</a>
<a name="2362"><span class="lineNum">    2362 </span>            :                 return;</a>
<a name="2363"><span class="lineNum">    2363 </span>            :         p-&gt;numa_scan_seq = seq;</a>
<a name="2364"><span class="lineNum">    2364 </span>            :         p-&gt;numa_scan_period_max = task_scan_max(p);</a>
<a name="2365"><span class="lineNum">    2365 </span>            : </a>
<a name="2366"><span class="lineNum">    2366 </span>            :         total_faults = p-&gt;numa_faults_locality[0] +</a>
<a name="2367"><span class="lineNum">    2367 </span>            :                        p-&gt;numa_faults_locality[1];</a>
<a name="2368"><span class="lineNum">    2368 </span>            :         runtime = numa_get_avg_runtime(p, &amp;period);</a>
<a name="2369"><span class="lineNum">    2369 </span>            : </a>
<a name="2370"><span class="lineNum">    2370 </span>            :         /* If the task is part of a group prevent parallel updates to group stats */</a>
<a name="2371"><span class="lineNum">    2371 </span>            :         ng = deref_curr_numa_group(p);</a>
<a name="2372"><span class="lineNum">    2372 </span>            :         if (ng) {</a>
<a name="2373"><span class="lineNum">    2373 </span>            :                 group_lock = &amp;ng-&gt;lock;</a>
<a name="2374"><span class="lineNum">    2374 </span>            :                 spin_lock_irq(group_lock);</a>
<a name="2375"><span class="lineNum">    2375 </span>            :         }</a>
<a name="2376"><span class="lineNum">    2376 </span>            : </a>
<a name="2377"><span class="lineNum">    2377 </span>            :         /* Find the node with the highest number of faults */</a>
<a name="2378"><span class="lineNum">    2378 </span>            :         for_each_online_node(nid) {</a>
<a name="2379"><span class="lineNum">    2379 </span>            :                 /* Keep track of the offsets in numa_faults array */</a>
<a name="2380"><span class="lineNum">    2380 </span>            :                 int mem_idx, membuf_idx, cpu_idx, cpubuf_idx;</a>
<a name="2381"><span class="lineNum">    2381 </span>            :                 unsigned long faults = 0, group_faults = 0;</a>
<a name="2382"><span class="lineNum">    2382 </span>            :                 int priv;</a>
<a name="2383"><span class="lineNum">    2383 </span>            : </a>
<a name="2384"><span class="lineNum">    2384 </span>            :                 for (priv = 0; priv &lt; NR_NUMA_HINT_FAULT_TYPES; priv++) {</a>
<a name="2385"><span class="lineNum">    2385 </span>            :                         long diff, f_diff, f_weight;</a>
<a name="2386"><span class="lineNum">    2386 </span>            : </a>
<a name="2387"><span class="lineNum">    2387 </span>            :                         mem_idx = task_faults_idx(NUMA_MEM, nid, priv);</a>
<a name="2388"><span class="lineNum">    2388 </span>            :                         membuf_idx = task_faults_idx(NUMA_MEMBUF, nid, priv);</a>
<a name="2389"><span class="lineNum">    2389 </span>            :                         cpu_idx = task_faults_idx(NUMA_CPU, nid, priv);</a>
<a name="2390"><span class="lineNum">    2390 </span>            :                         cpubuf_idx = task_faults_idx(NUMA_CPUBUF, nid, priv);</a>
<a name="2391"><span class="lineNum">    2391 </span>            : </a>
<a name="2392"><span class="lineNum">    2392 </span>            :                         /* Decay existing window, copy faults since last scan */</a>
<a name="2393"><span class="lineNum">    2393 </span>            :                         diff = p-&gt;numa_faults[membuf_idx] - p-&gt;numa_faults[mem_idx] / 2;</a>
<a name="2394"><span class="lineNum">    2394 </span>            :                         fault_types[priv] += p-&gt;numa_faults[membuf_idx];</a>
<a name="2395"><span class="lineNum">    2395 </span>            :                         p-&gt;numa_faults[membuf_idx] = 0;</a>
<a name="2396"><span class="lineNum">    2396 </span>            : </a>
<a name="2397"><span class="lineNum">    2397 </span>            :                         /*</a>
<a name="2398"><span class="lineNum">    2398 </span>            :                          * Normalize the faults_from, so all tasks in a group</a>
<a name="2399"><span class="lineNum">    2399 </span>            :                          * count according to CPU use, instead of by the raw</a>
<a name="2400"><span class="lineNum">    2400 </span>            :                          * number of faults. Tasks with little runtime have</a>
<a name="2401"><span class="lineNum">    2401 </span>            :                          * little over-all impact on throughput, and thus their</a>
<a name="2402"><span class="lineNum">    2402 </span>            :                          * faults are less important.</a>
<a name="2403"><span class="lineNum">    2403 </span>            :                          */</a>
<a name="2404"><span class="lineNum">    2404 </span>            :                         f_weight = div64_u64(runtime &lt;&lt; 16, period + 1);</a>
<a name="2405"><span class="lineNum">    2405 </span>            :                         f_weight = (f_weight * p-&gt;numa_faults[cpubuf_idx]) /</a>
<a name="2406"><span class="lineNum">    2406 </span>            :                                    (total_faults + 1);</a>
<a name="2407"><span class="lineNum">    2407 </span>            :                         f_diff = f_weight - p-&gt;numa_faults[cpu_idx] / 2;</a>
<a name="2408"><span class="lineNum">    2408 </span>            :                         p-&gt;numa_faults[cpubuf_idx] = 0;</a>
<a name="2409"><span class="lineNum">    2409 </span>            : </a>
<a name="2410"><span class="lineNum">    2410 </span>            :                         p-&gt;numa_faults[mem_idx] += diff;</a>
<a name="2411"><span class="lineNum">    2411 </span>            :                         p-&gt;numa_faults[cpu_idx] += f_diff;</a>
<a name="2412"><span class="lineNum">    2412 </span>            :                         faults += p-&gt;numa_faults[mem_idx];</a>
<a name="2413"><span class="lineNum">    2413 </span>            :                         p-&gt;total_numa_faults += diff;</a>
<a name="2414"><span class="lineNum">    2414 </span>            :                         if (ng) {</a>
<a name="2415"><span class="lineNum">    2415 </span>            :                                 /*</a>
<a name="2416"><span class="lineNum">    2416 </span>            :                                  * safe because we can only change our own group</a>
<a name="2417"><span class="lineNum">    2417 </span>            :                                  *</a>
<a name="2418"><span class="lineNum">    2418 </span>            :                                  * mem_idx represents the offset for a given</a>
<a name="2419"><span class="lineNum">    2419 </span>            :                                  * nid and priv in a specific region because it</a>
<a name="2420"><span class="lineNum">    2420 </span>            :                                  * is at the beginning of the numa_faults array.</a>
<a name="2421"><span class="lineNum">    2421 </span>            :                                  */</a>
<a name="2422"><span class="lineNum">    2422 </span>            :                                 ng-&gt;faults[mem_idx] += diff;</a>
<a name="2423"><span class="lineNum">    2423 </span>            :                                 ng-&gt;faults[cpu_idx] += f_diff;</a>
<a name="2424"><span class="lineNum">    2424 </span>            :                                 ng-&gt;total_faults += diff;</a>
<a name="2425"><span class="lineNum">    2425 </span>            :                                 group_faults += ng-&gt;faults[mem_idx];</a>
<a name="2426"><span class="lineNum">    2426 </span>            :                         }</a>
<a name="2427"><span class="lineNum">    2427 </span>            :                 }</a>
<a name="2428"><span class="lineNum">    2428 </span>            : </a>
<a name="2429"><span class="lineNum">    2429 </span>            :                 if (!ng) {</a>
<a name="2430"><span class="lineNum">    2430 </span>            :                         if (faults &gt; max_faults) {</a>
<a name="2431"><span class="lineNum">    2431 </span>            :                                 max_faults = faults;</a>
<a name="2432"><span class="lineNum">    2432 </span>            :                                 max_nid = nid;</a>
<a name="2433"><span class="lineNum">    2433 </span>            :                         }</a>
<a name="2434"><span class="lineNum">    2434 </span>            :                 } else if (group_faults &gt; max_faults) {</a>
<a name="2435"><span class="lineNum">    2435 </span>            :                         max_faults = group_faults;</a>
<a name="2436"><span class="lineNum">    2436 </span>            :                         max_nid = nid;</a>
<a name="2437"><span class="lineNum">    2437 </span>            :                 }</a>
<a name="2438"><span class="lineNum">    2438 </span>            :         }</a>
<a name="2439"><span class="lineNum">    2439 </span>            : </a>
<a name="2440"><span class="lineNum">    2440 </span>            :         /* Cannot migrate task to CPU-less node */</a>
<a name="2441"><span class="lineNum">    2441 </span>            :         if (max_nid != NUMA_NO_NODE &amp;&amp; !node_state(max_nid, N_CPU)) {</a>
<a name="2442"><span class="lineNum">    2442 </span>            :                 int near_nid = max_nid;</a>
<a name="2443"><span class="lineNum">    2443 </span>            :                 int distance, near_distance = INT_MAX;</a>
<a name="2444"><span class="lineNum">    2444 </span>            : </a>
<a name="2445"><span class="lineNum">    2445 </span>            :                 for_each_node_state(nid, N_CPU) {</a>
<a name="2446"><span class="lineNum">    2446 </span>            :                         distance = node_distance(max_nid, nid);</a>
<a name="2447"><span class="lineNum">    2447 </span>            :                         if (distance &lt; near_distance) {</a>
<a name="2448"><span class="lineNum">    2448 </span>            :                                 near_nid = nid;</a>
<a name="2449"><span class="lineNum">    2449 </span>            :                                 near_distance = distance;</a>
<a name="2450"><span class="lineNum">    2450 </span>            :                         }</a>
<a name="2451"><span class="lineNum">    2451 </span>            :                 }</a>
<a name="2452"><span class="lineNum">    2452 </span>            :                 max_nid = near_nid;</a>
<a name="2453"><span class="lineNum">    2453 </span>            :         }</a>
<a name="2454"><span class="lineNum">    2454 </span>            : </a>
<a name="2455"><span class="lineNum">    2455 </span>            :         if (ng) {</a>
<a name="2456"><span class="lineNum">    2456 </span>            :                 numa_group_count_active_nodes(ng);</a>
<a name="2457"><span class="lineNum">    2457 </span>            :                 spin_unlock_irq(group_lock);</a>
<a name="2458"><span class="lineNum">    2458 </span>            :                 max_nid = preferred_group_nid(p, max_nid);</a>
<a name="2459"><span class="lineNum">    2459 </span>            :         }</a>
<a name="2460"><span class="lineNum">    2460 </span>            : </a>
<a name="2461"><span class="lineNum">    2461 </span>            :         if (max_faults) {</a>
<a name="2462"><span class="lineNum">    2462 </span>            :                 /* Set the new preferred node */</a>
<a name="2463"><span class="lineNum">    2463 </span>            :                 if (max_nid != p-&gt;numa_preferred_nid)</a>
<a name="2464"><span class="lineNum">    2464 </span>            :                         sched_setnuma(p, max_nid);</a>
<a name="2465"><span class="lineNum">    2465 </span>            :         }</a>
<a name="2466"><span class="lineNum">    2466 </span>            : </a>
<a name="2467"><span class="lineNum">    2467 </span>            :         update_task_scan_period(p, fault_types[0], fault_types[1]);</a>
<a name="2468"><span class="lineNum">    2468 </span>            : }</a>
<a name="2469"><span class="lineNum">    2469 </span>            : </a>
<a name="2470"><span class="lineNum">    2470 </span>            : static inline int get_numa_group(struct numa_group *grp)</a>
<a name="2471"><span class="lineNum">    2471 </span>            : {</a>
<a name="2472"><span class="lineNum">    2472 </span>            :         return refcount_inc_not_zero(&amp;grp-&gt;refcount);</a>
<a name="2473"><span class="lineNum">    2473 </span>            : }</a>
<a name="2474"><span class="lineNum">    2474 </span>            : </a>
<a name="2475"><span class="lineNum">    2475 </span>            : static inline void put_numa_group(struct numa_group *grp)</a>
<a name="2476"><span class="lineNum">    2476 </span>            : {</a>
<a name="2477"><span class="lineNum">    2477 </span>            :         if (refcount_dec_and_test(&amp;grp-&gt;refcount))</a>
<a name="2478"><span class="lineNum">    2478 </span>            :                 kfree_rcu(grp, rcu);</a>
<a name="2479"><span class="lineNum">    2479 </span>            : }</a>
<a name="2480"><span class="lineNum">    2480 </span>            : </a>
<a name="2481"><span class="lineNum">    2481 </span>            : static void task_numa_group(struct task_struct *p, int cpupid, int flags,</a>
<a name="2482"><span class="lineNum">    2482 </span>            :                         int *priv)</a>
<a name="2483"><span class="lineNum">    2483 </span>            : {</a>
<a name="2484"><span class="lineNum">    2484 </span>            :         struct numa_group *grp, *my_grp;</a>
<a name="2485"><span class="lineNum">    2485 </span>            :         struct task_struct *tsk;</a>
<a name="2486"><span class="lineNum">    2486 </span>            :         bool join = false;</a>
<a name="2487"><span class="lineNum">    2487 </span>            :         int cpu = cpupid_to_cpu(cpupid);</a>
<a name="2488"><span class="lineNum">    2488 </span>            :         int i;</a>
<a name="2489"><span class="lineNum">    2489 </span>            : </a>
<a name="2490"><span class="lineNum">    2490 </span>            :         if (unlikely(!deref_curr_numa_group(p))) {</a>
<a name="2491"><span class="lineNum">    2491 </span>            :                 unsigned int size = sizeof(struct numa_group) +</a>
<a name="2492"><span class="lineNum">    2492 </span>            :                                     NR_NUMA_HINT_FAULT_STATS *</a>
<a name="2493"><span class="lineNum">    2493 </span>            :                                     nr_node_ids * sizeof(unsigned long);</a>
<a name="2494"><span class="lineNum">    2494 </span>            : </a>
<a name="2495"><span class="lineNum">    2495 </span>            :                 grp = kzalloc(size, GFP_KERNEL | __GFP_NOWARN);</a>
<a name="2496"><span class="lineNum">    2496 </span>            :                 if (!grp)</a>
<a name="2497"><span class="lineNum">    2497 </span>            :                         return;</a>
<a name="2498"><span class="lineNum">    2498 </span>            : </a>
<a name="2499"><span class="lineNum">    2499 </span>            :                 refcount_set(&amp;grp-&gt;refcount, 1);</a>
<a name="2500"><span class="lineNum">    2500 </span>            :                 grp-&gt;active_nodes = 1;</a>
<a name="2501"><span class="lineNum">    2501 </span>            :                 grp-&gt;max_faults_cpu = 0;</a>
<a name="2502"><span class="lineNum">    2502 </span>            :                 spin_lock_init(&amp;grp-&gt;lock);</a>
<a name="2503"><span class="lineNum">    2503 </span>            :                 grp-&gt;gid = p-&gt;pid;</a>
<a name="2504"><span class="lineNum">    2504 </span>            : </a>
<a name="2505"><span class="lineNum">    2505 </span>            :                 for (i = 0; i &lt; NR_NUMA_HINT_FAULT_STATS * nr_node_ids; i++)</a>
<a name="2506"><span class="lineNum">    2506 </span>            :                         grp-&gt;faults[i] = p-&gt;numa_faults[i];</a>
<a name="2507"><span class="lineNum">    2507 </span>            : </a>
<a name="2508"><span class="lineNum">    2508 </span>            :                 grp-&gt;total_faults = p-&gt;total_numa_faults;</a>
<a name="2509"><span class="lineNum">    2509 </span>            : </a>
<a name="2510"><span class="lineNum">    2510 </span>            :                 grp-&gt;nr_tasks++;</a>
<a name="2511"><span class="lineNum">    2511 </span>            :                 rcu_assign_pointer(p-&gt;numa_group, grp);</a>
<a name="2512"><span class="lineNum">    2512 </span>            :         }</a>
<a name="2513"><span class="lineNum">    2513 </span>            : </a>
<a name="2514"><span class="lineNum">    2514 </span>            :         rcu_read_lock();</a>
<a name="2515"><span class="lineNum">    2515 </span>            :         tsk = READ_ONCE(cpu_rq(cpu)-&gt;curr);</a>
<a name="2516"><span class="lineNum">    2516 </span>            : </a>
<a name="2517"><span class="lineNum">    2517 </span>            :         if (!cpupid_match_pid(tsk, cpupid))</a>
<a name="2518"><span class="lineNum">    2518 </span>            :                 goto no_join;</a>
<a name="2519"><span class="lineNum">    2519 </span>            : </a>
<a name="2520"><span class="lineNum">    2520 </span>            :         grp = rcu_dereference(tsk-&gt;numa_group);</a>
<a name="2521"><span class="lineNum">    2521 </span>            :         if (!grp)</a>
<a name="2522"><span class="lineNum">    2522 </span>            :                 goto no_join;</a>
<a name="2523"><span class="lineNum">    2523 </span>            : </a>
<a name="2524"><span class="lineNum">    2524 </span>            :         my_grp = deref_curr_numa_group(p);</a>
<a name="2525"><span class="lineNum">    2525 </span>            :         if (grp == my_grp)</a>
<a name="2526"><span class="lineNum">    2526 </span>            :                 goto no_join;</a>
<a name="2527"><span class="lineNum">    2527 </span>            : </a>
<a name="2528"><span class="lineNum">    2528 </span>            :         /*</a>
<a name="2529"><span class="lineNum">    2529 </span>            :          * Only join the other group if its bigger; if we're the bigger group,</a>
<a name="2530"><span class="lineNum">    2530 </span>            :          * the other task will join us.</a>
<a name="2531"><span class="lineNum">    2531 </span>            :          */</a>
<a name="2532"><span class="lineNum">    2532 </span>            :         if (my_grp-&gt;nr_tasks &gt; grp-&gt;nr_tasks)</a>
<a name="2533"><span class="lineNum">    2533 </span>            :                 goto no_join;</a>
<a name="2534"><span class="lineNum">    2534 </span>            : </a>
<a name="2535"><span class="lineNum">    2535 </span>            :         /*</a>
<a name="2536"><span class="lineNum">    2536 </span>            :          * Tie-break on the grp address.</a>
<a name="2537"><span class="lineNum">    2537 </span>            :          */</a>
<a name="2538"><span class="lineNum">    2538 </span>            :         if (my_grp-&gt;nr_tasks == grp-&gt;nr_tasks &amp;&amp; my_grp &gt; grp)</a>
<a name="2539"><span class="lineNum">    2539 </span>            :                 goto no_join;</a>
<a name="2540"><span class="lineNum">    2540 </span>            : </a>
<a name="2541"><span class="lineNum">    2541 </span>            :         /* Always join threads in the same process. */</a>
<a name="2542"><span class="lineNum">    2542 </span>            :         if (tsk-&gt;mm == current-&gt;mm)</a>
<a name="2543"><span class="lineNum">    2543 </span>            :                 join = true;</a>
<a name="2544"><span class="lineNum">    2544 </span>            : </a>
<a name="2545"><span class="lineNum">    2545 </span>            :         /* Simple filter to avoid false positives due to PID collisions */</a>
<a name="2546"><span class="lineNum">    2546 </span>            :         if (flags &amp; TNF_SHARED)</a>
<a name="2547"><span class="lineNum">    2547 </span>            :                 join = true;</a>
<a name="2548"><span class="lineNum">    2548 </span>            : </a>
<a name="2549"><span class="lineNum">    2549 </span>            :         /* Update priv based on whether false sharing was detected */</a>
<a name="2550"><span class="lineNum">    2550 </span>            :         *priv = !join;</a>
<a name="2551"><span class="lineNum">    2551 </span>            : </a>
<a name="2552"><span class="lineNum">    2552 </span>            :         if (join &amp;&amp; !get_numa_group(grp))</a>
<a name="2553"><span class="lineNum">    2553 </span>            :                 goto no_join;</a>
<a name="2554"><span class="lineNum">    2554 </span>            : </a>
<a name="2555"><span class="lineNum">    2555 </span>            :         rcu_read_unlock();</a>
<a name="2556"><span class="lineNum">    2556 </span>            : </a>
<a name="2557"><span class="lineNum">    2557 </span>            :         if (!join)</a>
<a name="2558"><span class="lineNum">    2558 </span>            :                 return;</a>
<a name="2559"><span class="lineNum">    2559 </span>            : </a>
<a name="2560"><span class="lineNum">    2560 </span>            :         BUG_ON(irqs_disabled());</a>
<a name="2561"><span class="lineNum">    2561 </span>            :         double_lock_irq(&amp;my_grp-&gt;lock, &amp;grp-&gt;lock);</a>
<a name="2562"><span class="lineNum">    2562 </span>            : </a>
<a name="2563"><span class="lineNum">    2563 </span>            :         for (i = 0; i &lt; NR_NUMA_HINT_FAULT_STATS * nr_node_ids; i++) {</a>
<a name="2564"><span class="lineNum">    2564 </span>            :                 my_grp-&gt;faults[i] -= p-&gt;numa_faults[i];</a>
<a name="2565"><span class="lineNum">    2565 </span>            :                 grp-&gt;faults[i] += p-&gt;numa_faults[i];</a>
<a name="2566"><span class="lineNum">    2566 </span>            :         }</a>
<a name="2567"><span class="lineNum">    2567 </span>            :         my_grp-&gt;total_faults -= p-&gt;total_numa_faults;</a>
<a name="2568"><span class="lineNum">    2568 </span>            :         grp-&gt;total_faults += p-&gt;total_numa_faults;</a>
<a name="2569"><span class="lineNum">    2569 </span>            : </a>
<a name="2570"><span class="lineNum">    2570 </span>            :         my_grp-&gt;nr_tasks--;</a>
<a name="2571"><span class="lineNum">    2571 </span>            :         grp-&gt;nr_tasks++;</a>
<a name="2572"><span class="lineNum">    2572 </span>            : </a>
<a name="2573"><span class="lineNum">    2573 </span>            :         spin_unlock(&amp;my_grp-&gt;lock);</a>
<a name="2574"><span class="lineNum">    2574 </span>            :         spin_unlock_irq(&amp;grp-&gt;lock);</a>
<a name="2575"><span class="lineNum">    2575 </span>            : </a>
<a name="2576"><span class="lineNum">    2576 </span>            :         rcu_assign_pointer(p-&gt;numa_group, grp);</a>
<a name="2577"><span class="lineNum">    2577 </span>            : </a>
<a name="2578"><span class="lineNum">    2578 </span>            :         put_numa_group(my_grp);</a>
<a name="2579"><span class="lineNum">    2579 </span>            :         return;</a>
<a name="2580"><span class="lineNum">    2580 </span>            : </a>
<a name="2581"><span class="lineNum">    2581 </span>            : no_join:</a>
<a name="2582"><span class="lineNum">    2582 </span>            :         rcu_read_unlock();</a>
<a name="2583"><span class="lineNum">    2583 </span>            :         return;</a>
<a name="2584"><span class="lineNum">    2584 </span>            : }</a>
<a name="2585"><span class="lineNum">    2585 </span>            : </a>
<a name="2586"><span class="lineNum">    2586 </span>            : /*</a>
<a name="2587"><span class="lineNum">    2587 </span>            :  * Get rid of NUMA statistics associated with a task (either current or dead).</a>
<a name="2588"><span class="lineNum">    2588 </span>            :  * If @final is set, the task is dead and has reached refcount zero, so we can</a>
<a name="2589"><span class="lineNum">    2589 </span>            :  * safely free all relevant data structures. Otherwise, there might be</a>
<a name="2590"><span class="lineNum">    2590 </span>            :  * concurrent reads from places like load balancing and procfs, and we should</a>
<a name="2591"><span class="lineNum">    2591 </span>            :  * reset the data back to default state without freeing -&gt;numa_faults.</a>
<a name="2592"><span class="lineNum">    2592 </span>            :  */</a>
<a name="2593"><span class="lineNum">    2593 </span>            : void task_numa_free(struct task_struct *p, bool final)</a>
<a name="2594"><span class="lineNum">    2594 </span>            : {</a>
<a name="2595"><span class="lineNum">    2595 </span>            :         /* safe: p either is current or is being freed by current */</a>
<a name="2596"><span class="lineNum">    2596 </span>            :         struct numa_group *grp = rcu_dereference_raw(p-&gt;numa_group);</a>
<a name="2597"><span class="lineNum">    2597 </span>            :         unsigned long *numa_faults = p-&gt;numa_faults;</a>
<a name="2598"><span class="lineNum">    2598 </span>            :         unsigned long flags;</a>
<a name="2599"><span class="lineNum">    2599 </span>            :         int i;</a>
<a name="2600"><span class="lineNum">    2600 </span>            : </a>
<a name="2601"><span class="lineNum">    2601 </span>            :         if (!numa_faults)</a>
<a name="2602"><span class="lineNum">    2602 </span>            :                 return;</a>
<a name="2603"><span class="lineNum">    2603 </span>            : </a>
<a name="2604"><span class="lineNum">    2604 </span>            :         if (grp) {</a>
<a name="2605"><span class="lineNum">    2605 </span>            :                 spin_lock_irqsave(&amp;grp-&gt;lock, flags);</a>
<a name="2606"><span class="lineNum">    2606 </span>            :                 for (i = 0; i &lt; NR_NUMA_HINT_FAULT_STATS * nr_node_ids; i++)</a>
<a name="2607"><span class="lineNum">    2607 </span>            :                         grp-&gt;faults[i] -= p-&gt;numa_faults[i];</a>
<a name="2608"><span class="lineNum">    2608 </span>            :                 grp-&gt;total_faults -= p-&gt;total_numa_faults;</a>
<a name="2609"><span class="lineNum">    2609 </span>            : </a>
<a name="2610"><span class="lineNum">    2610 </span>            :                 grp-&gt;nr_tasks--;</a>
<a name="2611"><span class="lineNum">    2611 </span>            :                 spin_unlock_irqrestore(&amp;grp-&gt;lock, flags);</a>
<a name="2612"><span class="lineNum">    2612 </span>            :                 RCU_INIT_POINTER(p-&gt;numa_group, NULL);</a>
<a name="2613"><span class="lineNum">    2613 </span>            :                 put_numa_group(grp);</a>
<a name="2614"><span class="lineNum">    2614 </span>            :         }</a>
<a name="2615"><span class="lineNum">    2615 </span>            : </a>
<a name="2616"><span class="lineNum">    2616 </span>            :         if (final) {</a>
<a name="2617"><span class="lineNum">    2617 </span>            :                 p-&gt;numa_faults = NULL;</a>
<a name="2618"><span class="lineNum">    2618 </span>            :                 kfree(numa_faults);</a>
<a name="2619"><span class="lineNum">    2619 </span>            :         } else {</a>
<a name="2620"><span class="lineNum">    2620 </span>            :                 p-&gt;total_numa_faults = 0;</a>
<a name="2621"><span class="lineNum">    2621 </span>            :                 for (i = 0; i &lt; NR_NUMA_HINT_FAULT_STATS * nr_node_ids; i++)</a>
<a name="2622"><span class="lineNum">    2622 </span>            :                         numa_faults[i] = 0;</a>
<a name="2623"><span class="lineNum">    2623 </span>            :         }</a>
<a name="2624"><span class="lineNum">    2624 </span>            : }</a>
<a name="2625"><span class="lineNum">    2625 </span>            : </a>
<a name="2626"><span class="lineNum">    2626 </span>            : /*</a>
<a name="2627"><span class="lineNum">    2627 </span>            :  * Got a PROT_NONE fault for a page on @node.</a>
<a name="2628"><span class="lineNum">    2628 </span>            :  */</a>
<a name="2629"><span class="lineNum">    2629 </span>            : void task_numa_fault(int last_cpupid, int mem_node, int pages, int flags)</a>
<a name="2630"><span class="lineNum">    2630 </span>            : {</a>
<a name="2631"><span class="lineNum">    2631 </span>            :         struct task_struct *p = current;</a>
<a name="2632"><span class="lineNum">    2632 </span>            :         bool migrated = flags &amp; TNF_MIGRATED;</a>
<a name="2633"><span class="lineNum">    2633 </span>            :         int cpu_node = task_node(current);</a>
<a name="2634"><span class="lineNum">    2634 </span>            :         int local = !!(flags &amp; TNF_FAULT_LOCAL);</a>
<a name="2635"><span class="lineNum">    2635 </span>            :         struct numa_group *ng;</a>
<a name="2636"><span class="lineNum">    2636 </span>            :         int priv;</a>
<a name="2637"><span class="lineNum">    2637 </span>            : </a>
<a name="2638"><span class="lineNum">    2638 </span>            :         if (!static_branch_likely(&amp;sched_numa_balancing))</a>
<a name="2639"><span class="lineNum">    2639 </span>            :                 return;</a>
<a name="2640"><span class="lineNum">    2640 </span>            : </a>
<a name="2641"><span class="lineNum">    2641 </span>            :         /* for example, ksmd faulting in a user's mm */</a>
<a name="2642"><span class="lineNum">    2642 </span>            :         if (!p-&gt;mm)</a>
<a name="2643"><span class="lineNum">    2643 </span>            :                 return;</a>
<a name="2644"><span class="lineNum">    2644 </span>            : </a>
<a name="2645"><span class="lineNum">    2645 </span>            :         /* Allocate buffer to track faults on a per-node basis */</a>
<a name="2646"><span class="lineNum">    2646 </span>            :         if (unlikely(!p-&gt;numa_faults)) {</a>
<a name="2647"><span class="lineNum">    2647 </span>            :                 int size = sizeof(*p-&gt;numa_faults) *</a>
<a name="2648"><span class="lineNum">    2648 </span>            :                            NR_NUMA_HINT_FAULT_BUCKETS * nr_node_ids;</a>
<a name="2649"><span class="lineNum">    2649 </span>            : </a>
<a name="2650"><span class="lineNum">    2650 </span>            :                 p-&gt;numa_faults = kzalloc(size, GFP_KERNEL|__GFP_NOWARN);</a>
<a name="2651"><span class="lineNum">    2651 </span>            :                 if (!p-&gt;numa_faults)</a>
<a name="2652"><span class="lineNum">    2652 </span>            :                         return;</a>
<a name="2653"><span class="lineNum">    2653 </span>            : </a>
<a name="2654"><span class="lineNum">    2654 </span>            :                 p-&gt;total_numa_faults = 0;</a>
<a name="2655"><span class="lineNum">    2655 </span>            :                 memset(p-&gt;numa_faults_locality, 0, sizeof(p-&gt;numa_faults_locality));</a>
<a name="2656"><span class="lineNum">    2656 </span>            :         }</a>
<a name="2657"><span class="lineNum">    2657 </span>            : </a>
<a name="2658"><span class="lineNum">    2658 </span>            :         /*</a>
<a name="2659"><span class="lineNum">    2659 </span>            :          * First accesses are treated as private, otherwise consider accesses</a>
<a name="2660"><span class="lineNum">    2660 </span>            :          * to be private if the accessing pid has not changed</a>
<a name="2661"><span class="lineNum">    2661 </span>            :          */</a>
<a name="2662"><span class="lineNum">    2662 </span>            :         if (unlikely(last_cpupid == (-1 &amp; LAST_CPUPID_MASK))) {</a>
<a name="2663"><span class="lineNum">    2663 </span>            :                 priv = 1;</a>
<a name="2664"><span class="lineNum">    2664 </span>            :         } else {</a>
<a name="2665"><span class="lineNum">    2665 </span>            :                 priv = cpupid_match_pid(p, last_cpupid);</a>
<a name="2666"><span class="lineNum">    2666 </span>            :                 if (!priv &amp;&amp; !(flags &amp; TNF_NO_GROUP))</a>
<a name="2667"><span class="lineNum">    2667 </span>            :                         task_numa_group(p, last_cpupid, flags, &amp;priv);</a>
<a name="2668"><span class="lineNum">    2668 </span>            :         }</a>
<a name="2669"><span class="lineNum">    2669 </span>            : </a>
<a name="2670"><span class="lineNum">    2670 </span>            :         /*</a>
<a name="2671"><span class="lineNum">    2671 </span>            :          * If a workload spans multiple NUMA nodes, a shared fault that</a>
<a name="2672"><span class="lineNum">    2672 </span>            :          * occurs wholly within the set of nodes that the workload is</a>
<a name="2673"><span class="lineNum">    2673 </span>            :          * actively using should be counted as local. This allows the</a>
<a name="2674"><span class="lineNum">    2674 </span>            :          * scan rate to slow down when a workload has settled down.</a>
<a name="2675"><span class="lineNum">    2675 </span>            :          */</a>
<a name="2676"><span class="lineNum">    2676 </span>            :         ng = deref_curr_numa_group(p);</a>
<a name="2677"><span class="lineNum">    2677 </span>            :         if (!priv &amp;&amp; !local &amp;&amp; ng &amp;&amp; ng-&gt;active_nodes &gt; 1 &amp;&amp;</a>
<a name="2678"><span class="lineNum">    2678 </span>            :                                 numa_is_active_node(cpu_node, ng) &amp;&amp;</a>
<a name="2679"><span class="lineNum">    2679 </span>            :                                 numa_is_active_node(mem_node, ng))</a>
<a name="2680"><span class="lineNum">    2680 </span>            :                 local = 1;</a>
<a name="2681"><span class="lineNum">    2681 </span>            : </a>
<a name="2682"><span class="lineNum">    2682 </span>            :         /*</a>
<a name="2683"><span class="lineNum">    2683 </span>            :          * Retry to migrate task to preferred node periodically, in case it</a>
<a name="2684"><span class="lineNum">    2684 </span>            :          * previously failed, or the scheduler moved us.</a>
<a name="2685"><span class="lineNum">    2685 </span>            :          */</a>
<a name="2686"><span class="lineNum">    2686 </span>            :         if (time_after(jiffies, p-&gt;numa_migrate_retry)) {</a>
<a name="2687"><span class="lineNum">    2687 </span>            :                 task_numa_placement(p);</a>
<a name="2688"><span class="lineNum">    2688 </span>            :                 numa_migrate_preferred(p);</a>
<a name="2689"><span class="lineNum">    2689 </span>            :         }</a>
<a name="2690"><span class="lineNum">    2690 </span>            : </a>
<a name="2691"><span class="lineNum">    2691 </span>            :         if (migrated)</a>
<a name="2692"><span class="lineNum">    2692 </span>            :                 p-&gt;numa_pages_migrated += pages;</a>
<a name="2693"><span class="lineNum">    2693 </span>            :         if (flags &amp; TNF_MIGRATE_FAIL)</a>
<a name="2694"><span class="lineNum">    2694 </span>            :                 p-&gt;numa_faults_locality[2] += pages;</a>
<a name="2695"><span class="lineNum">    2695 </span>            : </a>
<a name="2696"><span class="lineNum">    2696 </span>            :         p-&gt;numa_faults[task_faults_idx(NUMA_MEMBUF, mem_node, priv)] += pages;</a>
<a name="2697"><span class="lineNum">    2697 </span>            :         p-&gt;numa_faults[task_faults_idx(NUMA_CPUBUF, cpu_node, priv)] += pages;</a>
<a name="2698"><span class="lineNum">    2698 </span>            :         p-&gt;numa_faults_locality[local] += pages;</a>
<a name="2699"><span class="lineNum">    2699 </span>            : }</a>
<a name="2700"><span class="lineNum">    2700 </span>            : </a>
<a name="2701"><span class="lineNum">    2701 </span>            : static void reset_ptenuma_scan(struct task_struct *p)</a>
<a name="2702"><span class="lineNum">    2702 </span>            : {</a>
<a name="2703"><span class="lineNum">    2703 </span>            :         /*</a>
<a name="2704"><span class="lineNum">    2704 </span>            :          * We only did a read acquisition of the mmap sem, so</a>
<a name="2705"><span class="lineNum">    2705 </span>            :          * p-&gt;mm-&gt;numa_scan_seq is written to without exclusive access</a>
<a name="2706"><span class="lineNum">    2706 </span>            :          * and the update is not guaranteed to be atomic. That's not</a>
<a name="2707"><span class="lineNum">    2707 </span>            :          * much of an issue though, since this is just used for</a>
<a name="2708"><span class="lineNum">    2708 </span>            :          * statistical sampling. Use READ_ONCE/WRITE_ONCE, which are not</a>
<a name="2709"><span class="lineNum">    2709 </span>            :          * expensive, to avoid any form of compiler optimizations:</a>
<a name="2710"><span class="lineNum">    2710 </span>            :          */</a>
<a name="2711"><span class="lineNum">    2711 </span>            :         WRITE_ONCE(p-&gt;mm-&gt;numa_scan_seq, READ_ONCE(p-&gt;mm-&gt;numa_scan_seq) + 1);</a>
<a name="2712"><span class="lineNum">    2712 </span>            :         p-&gt;mm-&gt;numa_scan_offset = 0;</a>
<a name="2713"><span class="lineNum">    2713 </span>            : }</a>
<a name="2714"><span class="lineNum">    2714 </span>            : </a>
<a name="2715"><span class="lineNum">    2715 </span>            : /*</a>
<a name="2716"><span class="lineNum">    2716 </span>            :  * The expensive part of numa migration is done from task_work context.</a>
<a name="2717"><span class="lineNum">    2717 </span>            :  * Triggered from task_tick_numa().</a>
<a name="2718"><span class="lineNum">    2718 </span>            :  */</a>
<a name="2719"><span class="lineNum">    2719 </span>            : static void task_numa_work(struct callback_head *work)</a>
<a name="2720"><span class="lineNum">    2720 </span>            : {</a>
<a name="2721"><span class="lineNum">    2721 </span>            :         unsigned long migrate, next_scan, now = jiffies;</a>
<a name="2722"><span class="lineNum">    2722 </span>            :         struct task_struct *p = current;</a>
<a name="2723"><span class="lineNum">    2723 </span>            :         struct mm_struct *mm = p-&gt;mm;</a>
<a name="2724"><span class="lineNum">    2724 </span>            :         u64 runtime = p-&gt;se.sum_exec_runtime;</a>
<a name="2725"><span class="lineNum">    2725 </span>            :         struct vm_area_struct *vma;</a>
<a name="2726"><span class="lineNum">    2726 </span>            :         unsigned long start, end;</a>
<a name="2727"><span class="lineNum">    2727 </span>            :         unsigned long nr_pte_updates = 0;</a>
<a name="2728"><span class="lineNum">    2728 </span>            :         long pages, virtpages;</a>
<a name="2729"><span class="lineNum">    2729 </span>            : </a>
<a name="2730"><span class="lineNum">    2730 </span>            :         SCHED_WARN_ON(p != container_of(work, struct task_struct, numa_work));</a>
<a name="2731"><span class="lineNum">    2731 </span>            : </a>
<a name="2732"><span class="lineNum">    2732 </span>            :         work-&gt;next = work;</a>
<a name="2733"><span class="lineNum">    2733 </span>            :         /*</a>
<a name="2734"><span class="lineNum">    2734 </span>            :          * Who cares about NUMA placement when they're dying.</a>
<a name="2735"><span class="lineNum">    2735 </span>            :          *</a>
<a name="2736"><span class="lineNum">    2736 </span>            :          * NOTE: make sure not to dereference p-&gt;mm before this check,</a>
<a name="2737"><span class="lineNum">    2737 </span>            :          * exit_task_work() happens _after_ exit_mm() so we could be called</a>
<a name="2738"><span class="lineNum">    2738 </span>            :          * without p-&gt;mm even though we still had it when we enqueued this</a>
<a name="2739"><span class="lineNum">    2739 </span>            :          * work.</a>
<a name="2740"><span class="lineNum">    2740 </span>            :          */</a>
<a name="2741"><span class="lineNum">    2741 </span>            :         if (p-&gt;flags &amp; PF_EXITING)</a>
<a name="2742"><span class="lineNum">    2742 </span>            :                 return;</a>
<a name="2743"><span class="lineNum">    2743 </span>            : </a>
<a name="2744"><span class="lineNum">    2744 </span>            :         if (!mm-&gt;numa_next_scan) {</a>
<a name="2745"><span class="lineNum">    2745 </span>            :                 mm-&gt;numa_next_scan = now +</a>
<a name="2746"><span class="lineNum">    2746 </span>            :                         msecs_to_jiffies(sysctl_numa_balancing_scan_delay);</a>
<a name="2747"><span class="lineNum">    2747 </span>            :         }</a>
<a name="2748"><span class="lineNum">    2748 </span>            : </a>
<a name="2749"><span class="lineNum">    2749 </span>            :         /*</a>
<a name="2750"><span class="lineNum">    2750 </span>            :          * Enforce maximal scan/migration frequency..</a>
<a name="2751"><span class="lineNum">    2751 </span>            :          */</a>
<a name="2752"><span class="lineNum">    2752 </span>            :         migrate = mm-&gt;numa_next_scan;</a>
<a name="2753"><span class="lineNum">    2753 </span>            :         if (time_before(now, migrate))</a>
<a name="2754"><span class="lineNum">    2754 </span>            :                 return;</a>
<a name="2755"><span class="lineNum">    2755 </span>            : </a>
<a name="2756"><span class="lineNum">    2756 </span>            :         if (p-&gt;numa_scan_period == 0) {</a>
<a name="2757"><span class="lineNum">    2757 </span>            :                 p-&gt;numa_scan_period_max = task_scan_max(p);</a>
<a name="2758"><span class="lineNum">    2758 </span>            :                 p-&gt;numa_scan_period = task_scan_start(p);</a>
<a name="2759"><span class="lineNum">    2759 </span>            :         }</a>
<a name="2760"><span class="lineNum">    2760 </span>            : </a>
<a name="2761"><span class="lineNum">    2761 </span>            :         next_scan = now + msecs_to_jiffies(p-&gt;numa_scan_period);</a>
<a name="2762"><span class="lineNum">    2762 </span>            :         if (cmpxchg(&amp;mm-&gt;numa_next_scan, migrate, next_scan) != migrate)</a>
<a name="2763"><span class="lineNum">    2763 </span>            :                 return;</a>
<a name="2764"><span class="lineNum">    2764 </span>            : </a>
<a name="2765"><span class="lineNum">    2765 </span>            :         /*</a>
<a name="2766"><span class="lineNum">    2766 </span>            :          * Delay this task enough that another task of this mm will likely win</a>
<a name="2767"><span class="lineNum">    2767 </span>            :          * the next time around.</a>
<a name="2768"><span class="lineNum">    2768 </span>            :          */</a>
<a name="2769"><span class="lineNum">    2769 </span>            :         p-&gt;node_stamp += 2 * TICK_NSEC;</a>
<a name="2770"><span class="lineNum">    2770 </span>            : </a>
<a name="2771"><span class="lineNum">    2771 </span>            :         start = mm-&gt;numa_scan_offset;</a>
<a name="2772"><span class="lineNum">    2772 </span>            :         pages = sysctl_numa_balancing_scan_size;</a>
<a name="2773"><span class="lineNum">    2773 </span>            :         pages &lt;&lt;= 20 - PAGE_SHIFT; /* MB in pages */</a>
<a name="2774"><span class="lineNum">    2774 </span>            :         virtpages = pages * 8;     /* Scan up to this much virtual space */</a>
<a name="2775"><span class="lineNum">    2775 </span>            :         if (!pages)</a>
<a name="2776"><span class="lineNum">    2776 </span>            :                 return;</a>
<a name="2777"><span class="lineNum">    2777 </span>            : </a>
<a name="2778"><span class="lineNum">    2778 </span>            : </a>
<a name="2779"><span class="lineNum">    2779 </span>            :         if (!mmap_read_trylock(mm))</a>
<a name="2780"><span class="lineNum">    2780 </span>            :                 return;</a>
<a name="2781"><span class="lineNum">    2781 </span>            :         vma = find_vma(mm, start);</a>
<a name="2782"><span class="lineNum">    2782 </span>            :         if (!vma) {</a>
<a name="2783"><span class="lineNum">    2783 </span>            :                 reset_ptenuma_scan(p);</a>
<a name="2784"><span class="lineNum">    2784 </span>            :                 start = 0;</a>
<a name="2785"><span class="lineNum">    2785 </span>            :                 vma = mm-&gt;mmap;</a>
<a name="2786"><span class="lineNum">    2786 </span>            :         }</a>
<a name="2787"><span class="lineNum">    2787 </span>            :         for (; vma; vma = vma-&gt;vm_next) {</a>
<a name="2788"><span class="lineNum">    2788 </span>            :                 if (!vma_migratable(vma) || !vma_policy_mof(vma) ||</a>
<a name="2789"><span class="lineNum">    2789 </span>            :                         is_vm_hugetlb_page(vma) || (vma-&gt;vm_flags &amp; VM_MIXEDMAP)) {</a>
<a name="2790"><span class="lineNum">    2790 </span>            :                         continue;</a>
<a name="2791"><span class="lineNum">    2791 </span>            :                 }</a>
<a name="2792"><span class="lineNum">    2792 </span>            : </a>
<a name="2793"><span class="lineNum">    2793 </span>            :                 /*</a>
<a name="2794"><span class="lineNum">    2794 </span>            :                  * Shared library pages mapped by multiple processes are not</a>
<a name="2795"><span class="lineNum">    2795 </span>            :                  * migrated as it is expected they are cache replicated. Avoid</a>
<a name="2796"><span class="lineNum">    2796 </span>            :                  * hinting faults in read-only file-backed mappings or the vdso</a>
<a name="2797"><span class="lineNum">    2797 </span>            :                  * as migrating the pages will be of marginal benefit.</a>
<a name="2798"><span class="lineNum">    2798 </span>            :                  */</a>
<a name="2799"><span class="lineNum">    2799 </span>            :                 if (!vma-&gt;vm_mm ||</a>
<a name="2800"><span class="lineNum">    2800 </span>            :                     (vma-&gt;vm_file &amp;&amp; (vma-&gt;vm_flags &amp; (VM_READ|VM_WRITE)) == (VM_READ)))</a>
<a name="2801"><span class="lineNum">    2801 </span>            :                         continue;</a>
<a name="2802"><span class="lineNum">    2802 </span>            : </a>
<a name="2803"><span class="lineNum">    2803 </span>            :                 /*</a>
<a name="2804"><span class="lineNum">    2804 </span>            :                  * Skip inaccessible VMAs to avoid any confusion between</a>
<a name="2805"><span class="lineNum">    2805 </span>            :                  * PROT_NONE and NUMA hinting ptes</a>
<a name="2806"><span class="lineNum">    2806 </span>            :                  */</a>
<a name="2807"><span class="lineNum">    2807 </span>            :                 if (!vma_is_accessible(vma))</a>
<a name="2808"><span class="lineNum">    2808 </span>            :                         continue;</a>
<a name="2809"><span class="lineNum">    2809 </span>            : </a>
<a name="2810"><span class="lineNum">    2810 </span>            :                 do {</a>
<a name="2811"><span class="lineNum">    2811 </span>            :                         start = max(start, vma-&gt;vm_start);</a>
<a name="2812"><span class="lineNum">    2812 </span>            :                         end = ALIGN(start + (pages &lt;&lt; PAGE_SHIFT), HPAGE_SIZE);</a>
<a name="2813"><span class="lineNum">    2813 </span>            :                         end = min(end, vma-&gt;vm_end);</a>
<a name="2814"><span class="lineNum">    2814 </span>            :                         nr_pte_updates = change_prot_numa(vma, start, end);</a>
<a name="2815"><span class="lineNum">    2815 </span>            : </a>
<a name="2816"><span class="lineNum">    2816 </span>            :                         /*</a>
<a name="2817"><span class="lineNum">    2817 </span>            :                          * Try to scan sysctl_numa_balancing_size worth of</a>
<a name="2818"><span class="lineNum">    2818 </span>            :                          * hpages that have at least one present PTE that</a>
<a name="2819"><span class="lineNum">    2819 </span>            :                          * is not already pte-numa. If the VMA contains</a>
<a name="2820"><span class="lineNum">    2820 </span>            :                          * areas that are unused or already full of prot_numa</a>
<a name="2821"><span class="lineNum">    2821 </span>            :                          * PTEs, scan up to virtpages, to skip through those</a>
<a name="2822"><span class="lineNum">    2822 </span>            :                          * areas faster.</a>
<a name="2823"><span class="lineNum">    2823 </span>            :                          */</a>
<a name="2824"><span class="lineNum">    2824 </span>            :                         if (nr_pte_updates)</a>
<a name="2825"><span class="lineNum">    2825 </span>            :                                 pages -= (end - start) &gt;&gt; PAGE_SHIFT;</a>
<a name="2826"><span class="lineNum">    2826 </span>            :                         virtpages -= (end - start) &gt;&gt; PAGE_SHIFT;</a>
<a name="2827"><span class="lineNum">    2827 </span>            : </a>
<a name="2828"><span class="lineNum">    2828 </span>            :                         start = end;</a>
<a name="2829"><span class="lineNum">    2829 </span>            :                         if (pages &lt;= 0 || virtpages &lt;= 0)</a>
<a name="2830"><span class="lineNum">    2830 </span>            :                                 goto out;</a>
<a name="2831"><span class="lineNum">    2831 </span>            : </a>
<a name="2832"><span class="lineNum">    2832 </span>            :                         cond_resched();</a>
<a name="2833"><span class="lineNum">    2833 </span>            :                 } while (end != vma-&gt;vm_end);</a>
<a name="2834"><span class="lineNum">    2834 </span>            :         }</a>
<a name="2835"><span class="lineNum">    2835 </span>            : </a>
<a name="2836"><span class="lineNum">    2836 </span>            : out:</a>
<a name="2837"><span class="lineNum">    2837 </span>            :         /*</a>
<a name="2838"><span class="lineNum">    2838 </span>            :          * It is possible to reach the end of the VMA list but the last few</a>
<a name="2839"><span class="lineNum">    2839 </span>            :          * VMAs are not guaranteed to the vma_migratable. If they are not, we</a>
<a name="2840"><span class="lineNum">    2840 </span>            :          * would find the !migratable VMA on the next scan but not reset the</a>
<a name="2841"><span class="lineNum">    2841 </span>            :          * scanner to the start so check it now.</a>
<a name="2842"><span class="lineNum">    2842 </span>            :          */</a>
<a name="2843"><span class="lineNum">    2843 </span>            :         if (vma)</a>
<a name="2844"><span class="lineNum">    2844 </span>            :                 mm-&gt;numa_scan_offset = start;</a>
<a name="2845"><span class="lineNum">    2845 </span>            :         else</a>
<a name="2846"><span class="lineNum">    2846 </span>            :                 reset_ptenuma_scan(p);</a>
<a name="2847"><span class="lineNum">    2847 </span>            :         mmap_read_unlock(mm);</a>
<a name="2848"><span class="lineNum">    2848 </span>            : </a>
<a name="2849"><span class="lineNum">    2849 </span>            :         /*</a>
<a name="2850"><span class="lineNum">    2850 </span>            :          * Make sure tasks use at least 32x as much time to run other code</a>
<a name="2851"><span class="lineNum">    2851 </span>            :          * than they used here, to limit NUMA PTE scanning overhead to 3% max.</a>
<a name="2852"><span class="lineNum">    2852 </span>            :          * Usually update_task_scan_period slows down scanning enough; on an</a>
<a name="2853"><span class="lineNum">    2853 </span>            :          * overloaded system we need to limit overhead on a per task basis.</a>
<a name="2854"><span class="lineNum">    2854 </span>            :          */</a>
<a name="2855"><span class="lineNum">    2855 </span>            :         if (unlikely(p-&gt;se.sum_exec_runtime != runtime)) {</a>
<a name="2856"><span class="lineNum">    2856 </span>            :                 u64 diff = p-&gt;se.sum_exec_runtime - runtime;</a>
<a name="2857"><span class="lineNum">    2857 </span>            :                 p-&gt;node_stamp += 32 * diff;</a>
<a name="2858"><span class="lineNum">    2858 </span>            :         }</a>
<a name="2859"><span class="lineNum">    2859 </span>            : }</a>
<a name="2860"><span class="lineNum">    2860 </span>            : </a>
<a name="2861"><span class="lineNum">    2861 </span>            : void init_numa_balancing(unsigned long clone_flags, struct task_struct *p)</a>
<a name="2862"><span class="lineNum">    2862 </span>            : {</a>
<a name="2863"><span class="lineNum">    2863 </span>            :         int mm_users = 0;</a>
<a name="2864"><span class="lineNum">    2864 </span>            :         struct mm_struct *mm = p-&gt;mm;</a>
<a name="2865"><span class="lineNum">    2865 </span>            : </a>
<a name="2866"><span class="lineNum">    2866 </span>            :         if (mm) {</a>
<a name="2867"><span class="lineNum">    2867 </span>            :                 mm_users = atomic_read(&amp;mm-&gt;mm_users);</a>
<a name="2868"><span class="lineNum">    2868 </span>            :                 if (mm_users == 1) {</a>
<a name="2869"><span class="lineNum">    2869 </span>            :                         mm-&gt;numa_next_scan = jiffies + msecs_to_jiffies(sysctl_numa_balancing_scan_delay);</a>
<a name="2870"><span class="lineNum">    2870 </span>            :                         mm-&gt;numa_scan_seq = 0;</a>
<a name="2871"><span class="lineNum">    2871 </span>            :                 }</a>
<a name="2872"><span class="lineNum">    2872 </span>            :         }</a>
<a name="2873"><span class="lineNum">    2873 </span>            :         p-&gt;node_stamp                        = 0;</a>
<a name="2874"><span class="lineNum">    2874 </span>            :         p-&gt;numa_scan_seq             = mm ? mm-&gt;numa_scan_seq : 0;</a>
<a name="2875"><span class="lineNum">    2875 </span>            :         p-&gt;numa_scan_period          = sysctl_numa_balancing_scan_delay;</a>
<a name="2876"><span class="lineNum">    2876 </span>            :         /* Protect against double add, see task_tick_numa and task_numa_work */</a>
<a name="2877"><span class="lineNum">    2877 </span>            :         p-&gt;numa_work.next            = &amp;p-&gt;numa_work;</a>
<a name="2878"><span class="lineNum">    2878 </span>            :         p-&gt;numa_faults                       = NULL;</a>
<a name="2879"><span class="lineNum">    2879 </span>            :         p-&gt;numa_pages_migrated               = 0;</a>
<a name="2880"><span class="lineNum">    2880 </span>            :         p-&gt;total_numa_faults         = 0;</a>
<a name="2881"><span class="lineNum">    2881 </span>            :         RCU_INIT_POINTER(p-&gt;numa_group, NULL);</a>
<a name="2882"><span class="lineNum">    2882 </span>            :         p-&gt;last_task_numa_placement  = 0;</a>
<a name="2883"><span class="lineNum">    2883 </span>            :         p-&gt;last_sum_exec_runtime     = 0;</a>
<a name="2884"><span class="lineNum">    2884 </span>            : </a>
<a name="2885"><span class="lineNum">    2885 </span>            :         init_task_work(&amp;p-&gt;numa_work, task_numa_work);</a>
<a name="2886"><span class="lineNum">    2886 </span>            : </a>
<a name="2887"><span class="lineNum">    2887 </span>            :         /* New address space, reset the preferred nid */</a>
<a name="2888"><span class="lineNum">    2888 </span>            :         if (!(clone_flags &amp; CLONE_VM)) {</a>
<a name="2889"><span class="lineNum">    2889 </span>            :                 p-&gt;numa_preferred_nid = NUMA_NO_NODE;</a>
<a name="2890"><span class="lineNum">    2890 </span>            :                 return;</a>
<a name="2891"><span class="lineNum">    2891 </span>            :         }</a>
<a name="2892"><span class="lineNum">    2892 </span>            : </a>
<a name="2893"><span class="lineNum">    2893 </span>            :         /*</a>
<a name="2894"><span class="lineNum">    2894 </span>            :          * New thread, keep existing numa_preferred_nid which should be copied</a>
<a name="2895"><span class="lineNum">    2895 </span>            :          * already by arch_dup_task_struct but stagger when scans start.</a>
<a name="2896"><span class="lineNum">    2896 </span>            :          */</a>
<a name="2897"><span class="lineNum">    2897 </span>            :         if (mm) {</a>
<a name="2898"><span class="lineNum">    2898 </span>            :                 unsigned int delay;</a>
<a name="2899"><span class="lineNum">    2899 </span>            : </a>
<a name="2900"><span class="lineNum">    2900 </span>            :                 delay = min_t(unsigned int, task_scan_max(current),</a>
<a name="2901"><span class="lineNum">    2901 </span>            :                         current-&gt;numa_scan_period * mm_users * NSEC_PER_MSEC);</a>
<a name="2902"><span class="lineNum">    2902 </span>            :                 delay += 2 * TICK_NSEC;</a>
<a name="2903"><span class="lineNum">    2903 </span>            :                 p-&gt;node_stamp = delay;</a>
<a name="2904"><span class="lineNum">    2904 </span>            :         }</a>
<a name="2905"><span class="lineNum">    2905 </span>            : }</a>
<a name="2906"><span class="lineNum">    2906 </span>            : </a>
<a name="2907"><span class="lineNum">    2907 </span>            : /*</a>
<a name="2908"><span class="lineNum">    2908 </span>            :  * Drive the periodic memory faults..</a>
<a name="2909"><span class="lineNum">    2909 </span>            :  */</a>
<a name="2910"><span class="lineNum">    2910 </span>            : static void task_tick_numa(struct rq *rq, struct task_struct *curr)</a>
<a name="2911"><span class="lineNum">    2911 </span>            : {</a>
<a name="2912"><span class="lineNum">    2912 </span>            :         struct callback_head *work = &amp;curr-&gt;numa_work;</a>
<a name="2913"><span class="lineNum">    2913 </span>            :         u64 period, now;</a>
<a name="2914"><span class="lineNum">    2914 </span>            : </a>
<a name="2915"><span class="lineNum">    2915 </span>            :         /*</a>
<a name="2916"><span class="lineNum">    2916 </span>            :          * We don't care about NUMA placement if we don't have memory.</a>
<a name="2917"><span class="lineNum">    2917 </span>            :          */</a>
<a name="2918"><span class="lineNum">    2918 </span>            :         if ((curr-&gt;flags &amp; (PF_EXITING | PF_KTHREAD)) || work-&gt;next != work)</a>
<a name="2919"><span class="lineNum">    2919 </span>            :                 return;</a>
<a name="2920"><span class="lineNum">    2920 </span>            : </a>
<a name="2921"><span class="lineNum">    2921 </span>            :         /*</a>
<a name="2922"><span class="lineNum">    2922 </span>            :          * Using runtime rather than walltime has the dual advantage that</a>
<a name="2923"><span class="lineNum">    2923 </span>            :          * we (mostly) drive the selection from busy threads and that the</a>
<a name="2924"><span class="lineNum">    2924 </span>            :          * task needs to have done some actual work before we bother with</a>
<a name="2925"><span class="lineNum">    2925 </span>            :          * NUMA placement.</a>
<a name="2926"><span class="lineNum">    2926 </span>            :          */</a>
<a name="2927"><span class="lineNum">    2927 </span>            :         now = curr-&gt;se.sum_exec_runtime;</a>
<a name="2928"><span class="lineNum">    2928 </span>            :         period = (u64)curr-&gt;numa_scan_period * NSEC_PER_MSEC;</a>
<a name="2929"><span class="lineNum">    2929 </span>            : </a>
<a name="2930"><span class="lineNum">    2930 </span>            :         if (now &gt; curr-&gt;node_stamp + period) {</a>
<a name="2931"><span class="lineNum">    2931 </span>            :                 if (!curr-&gt;node_stamp)</a>
<a name="2932"><span class="lineNum">    2932 </span>            :                         curr-&gt;numa_scan_period = task_scan_start(curr);</a>
<a name="2933"><span class="lineNum">    2933 </span>            :                 curr-&gt;node_stamp += period;</a>
<a name="2934"><span class="lineNum">    2934 </span>            : </a>
<a name="2935"><span class="lineNum">    2935 </span>            :                 if (!time_before(jiffies, curr-&gt;mm-&gt;numa_next_scan))</a>
<a name="2936"><span class="lineNum">    2936 </span>            :                         task_work_add(curr, work, TWA_RESUME);</a>
<a name="2937"><span class="lineNum">    2937 </span>            :         }</a>
<a name="2938"><span class="lineNum">    2938 </span>            : }</a>
<a name="2939"><span class="lineNum">    2939 </span>            : </a>
<a name="2940"><span class="lineNum">    2940 </span>            : static void update_scan_period(struct task_struct *p, int new_cpu)</a>
<a name="2941"><span class="lineNum">    2941 </span>            : {</a>
<a name="2942"><span class="lineNum">    2942 </span>            :         int src_nid = cpu_to_node(task_cpu(p));</a>
<a name="2943"><span class="lineNum">    2943 </span>            :         int dst_nid = cpu_to_node(new_cpu);</a>
<a name="2944"><span class="lineNum">    2944 </span>            : </a>
<a name="2945"><span class="lineNum">    2945 </span>            :         if (!static_branch_likely(&amp;sched_numa_balancing))</a>
<a name="2946"><span class="lineNum">    2946 </span>            :                 return;</a>
<a name="2947"><span class="lineNum">    2947 </span>            : </a>
<a name="2948"><span class="lineNum">    2948 </span>            :         if (!p-&gt;mm || !p-&gt;numa_faults || (p-&gt;flags &amp; PF_EXITING))</a>
<a name="2949"><span class="lineNum">    2949 </span>            :                 return;</a>
<a name="2950"><span class="lineNum">    2950 </span>            : </a>
<a name="2951"><span class="lineNum">    2951 </span>            :         if (src_nid == dst_nid)</a>
<a name="2952"><span class="lineNum">    2952 </span>            :                 return;</a>
<a name="2953"><span class="lineNum">    2953 </span>            : </a>
<a name="2954"><span class="lineNum">    2954 </span>            :         /*</a>
<a name="2955"><span class="lineNum">    2955 </span>            :          * Allow resets if faults have been trapped before one scan</a>
<a name="2956"><span class="lineNum">    2956 </span>            :          * has completed. This is most likely due to a new task that</a>
<a name="2957"><span class="lineNum">    2957 </span>            :          * is pulled cross-node due to wakeups or load balancing.</a>
<a name="2958"><span class="lineNum">    2958 </span>            :          */</a>
<a name="2959"><span class="lineNum">    2959 </span>            :         if (p-&gt;numa_scan_seq) {</a>
<a name="2960"><span class="lineNum">    2960 </span>            :                 /*</a>
<a name="2961"><span class="lineNum">    2961 </span>            :                  * Avoid scan adjustments if moving to the preferred</a>
<a name="2962"><span class="lineNum">    2962 </span>            :                  * node or if the task was not previously running on</a>
<a name="2963"><span class="lineNum">    2963 </span>            :                  * the preferred node.</a>
<a name="2964"><span class="lineNum">    2964 </span>            :                  */</a>
<a name="2965"><span class="lineNum">    2965 </span>            :                 if (dst_nid == p-&gt;numa_preferred_nid ||</a>
<a name="2966"><span class="lineNum">    2966 </span>            :                     (p-&gt;numa_preferred_nid != NUMA_NO_NODE &amp;&amp;</a>
<a name="2967"><span class="lineNum">    2967 </span>            :                         src_nid != p-&gt;numa_preferred_nid))</a>
<a name="2968"><span class="lineNum">    2968 </span>            :                         return;</a>
<a name="2969"><span class="lineNum">    2969 </span>            :         }</a>
<a name="2970"><span class="lineNum">    2970 </span>            : </a>
<a name="2971"><span class="lineNum">    2971 </span>            :         p-&gt;numa_scan_period = task_scan_start(p);</a>
<a name="2972"><span class="lineNum">    2972 </span>            : }</a>
<a name="2973"><span class="lineNum">    2973 </span>            : </a>
<a name="2974"><span class="lineNum">    2974 </span>            : #else</a>
<a name="2975"><span class="lineNum">    2975 </span>            : static void task_tick_numa(struct rq *rq, struct task_struct *curr)</a>
<a name="2976"><span class="lineNum">    2976 </span>            : {</a>
<a name="2977"><span class="lineNum">    2977 </span>            : }</a>
<a name="2978"><span class="lineNum">    2978 </span>            : </a>
<a name="2979"><span class="lineNum">    2979 </span>            : static inline void account_numa_enqueue(struct rq *rq, struct task_struct *p)</a>
<a name="2980"><span class="lineNum">    2980 </span>            : {</a>
<a name="2981"><span class="lineNum">    2981 </span>            : }</a>
<a name="2982"><span class="lineNum">    2982 </span>            : </a>
<a name="2983"><span class="lineNum">    2983 </span>            : static inline void account_numa_dequeue(struct rq *rq, struct task_struct *p)</a>
<a name="2984"><span class="lineNum">    2984 </span>            : {</a>
<a name="2985"><span class="lineNum">    2985 </span>            : }</a>
<a name="2986"><span class="lineNum">    2986 </span>            : </a>
<a name="2987"><span class="lineNum">    2987 </span>            : static inline void update_scan_period(struct task_struct *p, int new_cpu)</a>
<a name="2988"><span class="lineNum">    2988 </span>            : {</a>
<a name="2989"><span class="lineNum">    2989 </span>            : }</a>
<a name="2990"><span class="lineNum">    2990 </span>            : </a>
<a name="2991"><span class="lineNum">    2991 </span>            : #endif /* CONFIG_NUMA_BALANCING */</a>
<a name="2992"><span class="lineNum">    2992 </span>            : </a>
<a name="2993"><span class="lineNum">    2993 </span>            : static void</a>
<a name="2994"><span class="lineNum">    2994 </span>            : account_entity_enqueue(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="2995"><span class="lineNum">    2995 </span>            : {</a>
<a name="2996"><span class="lineNum">    2996 </span><span class="lineCov">       1236 :         update_load_add(&amp;cfs_rq-&gt;load, se-&gt;load.weight);</span></a>
<a name="2997"><span class="lineNum">    2997 </span>            : #ifdef CONFIG_SMP</a>
<a name="2998"><span class="lineNum">    2998 </span>            :         if (entity_is_task(se)) {</a>
<a name="2999"><span class="lineNum">    2999 </span>            :                 struct rq *rq = rq_of(cfs_rq);</a>
<a name="3000"><span class="lineNum">    3000 </span>            : </a>
<a name="3001"><span class="lineNum">    3001 </span>            :                 account_numa_enqueue(rq, task_of(se));</a>
<a name="3002"><span class="lineNum">    3002 </span>            :                 list_add(&amp;se-&gt;group_node, &amp;rq-&gt;cfs_tasks);</a>
<a name="3003"><span class="lineNum">    3003 </span>            :         }</a>
<a name="3004"><span class="lineNum">    3004 </span>            : #endif</a>
<a name="3005"><span class="lineNum">    3005 </span><span class="lineCov">        618 :         cfs_rq-&gt;nr_running++;</span></a>
<a name="3006"><span class="lineNum">    3006 </span><span class="lineCov">        618 :         if (se_is_idle(se))</span></a>
<a name="3007"><span class="lineNum">    3007 </span>            :                 cfs_rq-&gt;idle_nr_running++;</a>
<a name="3008"><span class="lineNum">    3008 </span>            : }</a>
<a name="3009"><span class="lineNum">    3009 </span>            : </a>
<a name="3010"><span class="lineNum">    3010 </span>            : static void</a>
<a name="3011"><span class="lineNum">    3011 </span>            : account_entity_dequeue(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="3012"><span class="lineNum">    3012 </span>            : {</a>
<a name="3013"><span class="lineNum">    3013 </span><span class="lineCov">       1232 :         update_load_sub(&amp;cfs_rq-&gt;load, se-&gt;load.weight);</span></a>
<a name="3014"><span class="lineNum">    3014 </span>            : #ifdef CONFIG_SMP</a>
<a name="3015"><span class="lineNum">    3015 </span>            :         if (entity_is_task(se)) {</a>
<a name="3016"><span class="lineNum">    3016 </span>            :                 account_numa_dequeue(rq_of(cfs_rq), task_of(se));</a>
<a name="3017"><span class="lineNum">    3017 </span>            :                 list_del_init(&amp;se-&gt;group_node);</a>
<a name="3018"><span class="lineNum">    3018 </span>            :         }</a>
<a name="3019"><span class="lineNum">    3019 </span>            : #endif</a>
<a name="3020"><span class="lineNum">    3020 </span><span class="lineCov">        616 :         cfs_rq-&gt;nr_running--;</span></a>
<a name="3021"><span class="lineNum">    3021 </span><span class="lineCov">        616 :         if (se_is_idle(se))</span></a>
<a name="3022"><span class="lineNum">    3022 </span>            :                 cfs_rq-&gt;idle_nr_running--;</a>
<a name="3023"><span class="lineNum">    3023 </span>            : }</a>
<a name="3024"><span class="lineNum">    3024 </span>            : </a>
<a name="3025"><span class="lineNum">    3025 </span>            : /*</a>
<a name="3026"><span class="lineNum">    3026 </span>            :  * Signed add and clamp on underflow.</a>
<a name="3027"><span class="lineNum">    3027 </span>            :  *</a>
<a name="3028"><span class="lineNum">    3028 </span>            :  * Explicitly do a load-store to ensure the intermediate value never hits</a>
<a name="3029"><span class="lineNum">    3029 </span>            :  * memory. This allows lockless observations without ever seeing the negative</a>
<a name="3030"><span class="lineNum">    3030 </span>            :  * values.</a>
<a name="3031"><span class="lineNum">    3031 </span>            :  */</a>
<a name="3032"><span class="lineNum">    3032 </span>            : #define add_positive(_ptr, _val) do {                           \</a>
<a name="3033"><span class="lineNum">    3033 </span>            :         typeof(_ptr) ptr = (_ptr);                              \</a>
<a name="3034"><span class="lineNum">    3034 </span>            :         typeof(_val) val = (_val);                              \</a>
<a name="3035"><span class="lineNum">    3035 </span>            :         typeof(*ptr) res, var = READ_ONCE(*ptr);                \</a>
<a name="3036"><span class="lineNum">    3036 </span>            :                                                                 \</a>
<a name="3037"><span class="lineNum">    3037 </span>            :         res = var + val;                                        \</a>
<a name="3038"><span class="lineNum">    3038 </span>            :                                                                 \</a>
<a name="3039"><span class="lineNum">    3039 </span>            :         if (val &lt; 0 &amp;&amp; res &gt; var)                               \</a>
<a name="3040"><span class="lineNum">    3040 </span>            :                 res = 0;                                        \</a>
<a name="3041"><span class="lineNum">    3041 </span>            :                                                                 \</a>
<a name="3042"><span class="lineNum">    3042 </span>            :         WRITE_ONCE(*ptr, res);                                  \</a>
<a name="3043"><span class="lineNum">    3043 </span>            : } while (0)</a>
<a name="3044"><span class="lineNum">    3044 </span>            : </a>
<a name="3045"><span class="lineNum">    3045 </span>            : /*</a>
<a name="3046"><span class="lineNum">    3046 </span>            :  * Unsigned subtract and clamp on underflow.</a>
<a name="3047"><span class="lineNum">    3047 </span>            :  *</a>
<a name="3048"><span class="lineNum">    3048 </span>            :  * Explicitly do a load-store to ensure the intermediate value never hits</a>
<a name="3049"><span class="lineNum">    3049 </span>            :  * memory. This allows lockless observations without ever seeing the negative</a>
<a name="3050"><span class="lineNum">    3050 </span>            :  * values.</a>
<a name="3051"><span class="lineNum">    3051 </span>            :  */</a>
<a name="3052"><span class="lineNum">    3052 </span>            : #define sub_positive(_ptr, _val) do {                           \</a>
<a name="3053"><span class="lineNum">    3053 </span>            :         typeof(_ptr) ptr = (_ptr);                              \</a>
<a name="3054"><span class="lineNum">    3054 </span>            :         typeof(*ptr) val = (_val);                              \</a>
<a name="3055"><span class="lineNum">    3055 </span>            :         typeof(*ptr) res, var = READ_ONCE(*ptr);                \</a>
<a name="3056"><span class="lineNum">    3056 </span>            :         res = var - val;                                        \</a>
<a name="3057"><span class="lineNum">    3057 </span>            :         if (res &gt; var)                                               \</a>
<a name="3058"><span class="lineNum">    3058 </span>            :                 res = 0;                                        \</a>
<a name="3059"><span class="lineNum">    3059 </span>            :         WRITE_ONCE(*ptr, res);                                  \</a>
<a name="3060"><span class="lineNum">    3060 </span>            : } while (0)</a>
<a name="3061"><span class="lineNum">    3061 </span>            : </a>
<a name="3062"><span class="lineNum">    3062 </span>            : /*</a>
<a name="3063"><span class="lineNum">    3063 </span>            :  * Remove and clamp on negative, from a local variable.</a>
<a name="3064"><span class="lineNum">    3064 </span>            :  *</a>
<a name="3065"><span class="lineNum">    3065 </span>            :  * A variant of sub_positive(), which does not use explicit load-store</a>
<a name="3066"><span class="lineNum">    3066 </span>            :  * and is thus optimized for local variable updates.</a>
<a name="3067"><span class="lineNum">    3067 </span>            :  */</a>
<a name="3068"><span class="lineNum">    3068 </span>            : #define lsub_positive(_ptr, _val) do {                          \</a>
<a name="3069"><span class="lineNum">    3069 </span>            :         typeof(_ptr) ptr = (_ptr);                              \</a>
<a name="3070"><span class="lineNum">    3070 </span>            :         *ptr -= min_t(typeof(*ptr), *ptr, _val);                \</a>
<a name="3071"><span class="lineNum">    3071 </span>            : } while (0)</a>
<a name="3072"><span class="lineNum">    3072 </span>            : </a>
<a name="3073"><span class="lineNum">    3073 </span>            : #ifdef CONFIG_SMP</a>
<a name="3074"><span class="lineNum">    3074 </span>            : static inline void</a>
<a name="3075"><span class="lineNum">    3075 </span>            : enqueue_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="3076"><span class="lineNum">    3076 </span>            : {</a>
<a name="3077"><span class="lineNum">    3077 </span>            :         cfs_rq-&gt;avg.load_avg += se-&gt;avg.load_avg;</a>
<a name="3078"><span class="lineNum">    3078 </span>            :         cfs_rq-&gt;avg.load_sum += se_weight(se) * se-&gt;avg.load_sum;</a>
<a name="3079"><span class="lineNum">    3079 </span>            : }</a>
<a name="3080"><span class="lineNum">    3080 </span>            : </a>
<a name="3081"><span class="lineNum">    3081 </span>            : static inline void</a>
<a name="3082"><span class="lineNum">    3082 </span>            : dequeue_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="3083"><span class="lineNum">    3083 </span>            : {</a>
<a name="3084"><span class="lineNum">    3084 </span>            :         sub_positive(&amp;cfs_rq-&gt;avg.load_avg, se-&gt;avg.load_avg);</a>
<a name="3085"><span class="lineNum">    3085 </span>            :         sub_positive(&amp;cfs_rq-&gt;avg.load_sum, se_weight(se) * se-&gt;avg.load_sum);</a>
<a name="3086"><span class="lineNum">    3086 </span>            :         /* See update_cfs_rq_load_avg() */</a>
<a name="3087"><span class="lineNum">    3087 </span>            :         cfs_rq-&gt;avg.load_sum = max_t(u32, cfs_rq-&gt;avg.load_sum,</a>
<a name="3088"><span class="lineNum">    3088 </span>            :                                           cfs_rq-&gt;avg.load_avg * PELT_MIN_DIVIDER);</a>
<a name="3089"><span class="lineNum">    3089 </span>            : }</a>
<a name="3090"><span class="lineNum">    3090 </span>            : #else</a>
<a name="3091"><span class="lineNum">    3091 </span>            : static inline void</a>
<a name="3092"><span class="lineNum">    3092 </span>            : enqueue_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) { }</a>
<a name="3093"><span class="lineNum">    3093 </span>            : static inline void</a>
<a name="3094"><span class="lineNum">    3094 </span>            : dequeue_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) { }</a>
<a name="3095"><span class="lineNum">    3095 </span>            : #endif</a>
<a name="3096"><span class="lineNum">    3096 </span>            : </a>
<a name="3097"><span class="lineNum">    3097 </span><span class="lineCov">          4 : static void reweight_entity(struct cfs_rq *cfs_rq, struct sched_entity *se,</span></a>
<a name="3098"><span class="lineNum">    3098 </span>            :                             unsigned long weight)</a>
<a name="3099"><span class="lineNum">    3099 </span>            : {</a>
<a name="3100"><span class="lineNum">    3100 </span><span class="lineCov">          4 :         if (se-&gt;on_rq) {</span></a>
<a name="3101"><span class="lineNum">    3101 </span>            :                 /* commit outstanding execution time */</a>
<a name="3102"><span class="lineNum">    3102 </span><span class="lineNoCov">          0 :                 if (cfs_rq-&gt;curr == se)</span></a>
<a name="3103"><span class="lineNum">    3103 </span><span class="lineNoCov">          0 :                         update_curr(cfs_rq);</span></a>
<a name="3104"><span class="lineNum">    3104 </span><span class="lineNoCov">          0 :                 update_load_sub(&amp;cfs_rq-&gt;load, se-&gt;load.weight);</span></a>
<a name="3105"><span class="lineNum">    3105 </span>            :         }</a>
<a name="3106"><span class="lineNum">    3106 </span><span class="lineCov">          4 :         dequeue_load_avg(cfs_rq, se);</span></a>
<a name="3107"><span class="lineNum">    3107 </span>            : </a>
<a name="3108"><span class="lineNum">    3108 </span><span class="lineCov">          8 :         update_load_set(&amp;se-&gt;load, weight);</span></a>
<a name="3109"><span class="lineNum">    3109 </span>            : </a>
<a name="3110"><span class="lineNum">    3110 </span>            : #ifdef CONFIG_SMP</a>
<a name="3111"><span class="lineNum">    3111 </span>            :         do {</a>
<a name="3112"><span class="lineNum">    3112 </span>            :                 u32 divider = get_pelt_divider(&amp;se-&gt;avg);</a>
<a name="3113"><span class="lineNum">    3113 </span>            : </a>
<a name="3114"><span class="lineNum">    3114 </span>            :                 se-&gt;avg.load_avg = div_u64(se_weight(se) * se-&gt;avg.load_sum, divider);</a>
<a name="3115"><span class="lineNum">    3115 </span>            :         } while (0);</a>
<a name="3116"><span class="lineNum">    3116 </span>            : #endif</a>
<a name="3117"><span class="lineNum">    3117 </span>            : </a>
<a name="3118"><span class="lineNum">    3118 </span><span class="lineCov">          4 :         enqueue_load_avg(cfs_rq, se);</span></a>
<a name="3119"><span class="lineNum">    3119 </span><span class="lineCov">          4 :         if (se-&gt;on_rq)</span></a>
<a name="3120"><span class="lineNum">    3120 </span><span class="lineNoCov">          0 :                 update_load_add(&amp;cfs_rq-&gt;load, se-&gt;load.weight);</span></a>
<a name="3121"><span class="lineNum">    3121 </span>            : </a>
<a name="3122"><span class="lineNum">    3122 </span><span class="lineCov">          4 : }</span></a>
<a name="3123"><span class="lineNum">    3123 </span>            : </a>
<a name="3124"><span class="lineNum">    3124 </span><span class="lineCov">          4 : void reweight_task(struct task_struct *p, int prio)</span></a>
<a name="3125"><span class="lineNum">    3125 </span>            : {</a>
<a name="3126"><span class="lineNum">    3126 </span><span class="lineCov">          4 :         struct sched_entity *se = &amp;p-&gt;se;</span></a>
<a name="3127"><span class="lineNum">    3127 </span><span class="lineCov">          8 :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="3128"><span class="lineNum">    3128 </span><span class="lineCov">          4 :         struct load_weight *load = &amp;se-&gt;load;</span></a>
<a name="3129"><span class="lineNum">    3129 </span><span class="lineCov">          4 :         unsigned long weight = scale_load(sched_prio_to_weight[prio]);</span></a>
<a name="3130"><span class="lineNum">    3130 </span>            : </a>
<a name="3131"><span class="lineNum">    3131 </span><span class="lineCov">          4 :         reweight_entity(cfs_rq, se, weight);</span></a>
<a name="3132"><span class="lineNum">    3132 </span><span class="lineCov">          4 :         load-&gt;inv_weight = sched_prio_to_wmult[prio];</span></a>
<a name="3133"><span class="lineNum">    3133 </span><span class="lineCov">          4 : }</span></a>
<a name="3134"><span class="lineNum">    3134 </span>            : </a>
<a name="3135"><span class="lineNum">    3135 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="3136"><span class="lineNum">    3136 </span>            : #ifdef CONFIG_SMP</a>
<a name="3137"><span class="lineNum">    3137 </span>            : /*</a>
<a name="3138"><span class="lineNum">    3138 </span>            :  * All this does is approximate the hierarchical proportion which includes that</a>
<a name="3139"><span class="lineNum">    3139 </span>            :  * global sum we all love to hate.</a>
<a name="3140"><span class="lineNum">    3140 </span>            :  *</a>
<a name="3141"><span class="lineNum">    3141 </span>            :  * That is, the weight of a group entity, is the proportional share of the</a>
<a name="3142"><span class="lineNum">    3142 </span>            :  * group weight based on the group runqueue weights. That is:</a>
<a name="3143"><span class="lineNum">    3143 </span>            :  *</a>
<a name="3144"><span class="lineNum">    3144 </span>            :  *                     tg-&gt;weight * grq-&gt;load.weight</a>
<a name="3145"><span class="lineNum">    3145 </span>            :  *   ge-&gt;load.weight = -----------------------------               (1)</a>
<a name="3146"><span class="lineNum">    3146 </span>            :  *                       \Sum grq-&gt;load.weight</a>
<a name="3147"><span class="lineNum">    3147 </span>            :  *</a>
<a name="3148"><span class="lineNum">    3148 </span>            :  * Now, because computing that sum is prohibitively expensive to compute (been</a>
<a name="3149"><span class="lineNum">    3149 </span>            :  * there, done that) we approximate it with this average stuff. The average</a>
<a name="3150"><span class="lineNum">    3150 </span>            :  * moves slower and therefore the approximation is cheaper and more stable.</a>
<a name="3151"><span class="lineNum">    3151 </span>            :  *</a>
<a name="3152"><span class="lineNum">    3152 </span>            :  * So instead of the above, we substitute:</a>
<a name="3153"><span class="lineNum">    3153 </span>            :  *</a>
<a name="3154"><span class="lineNum">    3154 </span>            :  *   grq-&gt;load.weight -&gt; grq-&gt;avg.load_avg                         (2)</a>
<a name="3155"><span class="lineNum">    3155 </span>            :  *</a>
<a name="3156"><span class="lineNum">    3156 </span>            :  * which yields the following:</a>
<a name="3157"><span class="lineNum">    3157 </span>            :  *</a>
<a name="3158"><span class="lineNum">    3158 </span>            :  *                     tg-&gt;weight * grq-&gt;avg.load_avg</a>
<a name="3159"><span class="lineNum">    3159 </span>            :  *   ge-&gt;load.weight = ------------------------------              (3)</a>
<a name="3160"><span class="lineNum">    3160 </span>            :  *                             tg-&gt;load_avg</a>
<a name="3161"><span class="lineNum">    3161 </span>            :  *</a>
<a name="3162"><span class="lineNum">    3162 </span>            :  * Where: tg-&gt;load_avg ~= \Sum grq-&gt;avg.load_avg</a>
<a name="3163"><span class="lineNum">    3163 </span>            :  *</a>
<a name="3164"><span class="lineNum">    3164 </span>            :  * That is shares_avg, and it is right (given the approximation (2)).</a>
<a name="3165"><span class="lineNum">    3165 </span>            :  *</a>
<a name="3166"><span class="lineNum">    3166 </span>            :  * The problem with it is that because the average is slow -- it was designed</a>
<a name="3167"><span class="lineNum">    3167 </span>            :  * to be exactly that of course -- this leads to transients in boundary</a>
<a name="3168"><span class="lineNum">    3168 </span>            :  * conditions. In specific, the case where the group was idle and we start the</a>
<a name="3169"><span class="lineNum">    3169 </span>            :  * one task. It takes time for our CPU's grq-&gt;avg.load_avg to build up,</a>
<a name="3170"><span class="lineNum">    3170 </span>            :  * yielding bad latency etc..</a>
<a name="3171"><span class="lineNum">    3171 </span>            :  *</a>
<a name="3172"><span class="lineNum">    3172 </span>            :  * Now, in that special case (1) reduces to:</a>
<a name="3173"><span class="lineNum">    3173 </span>            :  *</a>
<a name="3174"><span class="lineNum">    3174 </span>            :  *                     tg-&gt;weight * grq-&gt;load.weight</a>
<a name="3175"><span class="lineNum">    3175 </span>            :  *   ge-&gt;load.weight = ----------------------------- = tg-&gt;weight   (4)</a>
<a name="3176"><span class="lineNum">    3176 </span>            :  *                         grp-&gt;load.weight</a>
<a name="3177"><span class="lineNum">    3177 </span>            :  *</a>
<a name="3178"><span class="lineNum">    3178 </span>            :  * That is, the sum collapses because all other CPUs are idle; the UP scenario.</a>
<a name="3179"><span class="lineNum">    3179 </span>            :  *</a>
<a name="3180"><span class="lineNum">    3180 </span>            :  * So what we do is modify our approximation (3) to approach (4) in the (near)</a>
<a name="3181"><span class="lineNum">    3181 </span>            :  * UP case, like:</a>
<a name="3182"><span class="lineNum">    3182 </span>            :  *</a>
<a name="3183"><span class="lineNum">    3183 </span>            :  *   ge-&gt;load.weight =</a>
<a name="3184"><span class="lineNum">    3184 </span>            :  *</a>
<a name="3185"><span class="lineNum">    3185 </span>            :  *              tg-&gt;weight * grq-&gt;load.weight</a>
<a name="3186"><span class="lineNum">    3186 </span>            :  *     ---------------------------------------------------         (5)</a>
<a name="3187"><span class="lineNum">    3187 </span>            :  *     tg-&gt;load_avg - grq-&gt;avg.load_avg + grq-&gt;load.weight</a>
<a name="3188"><span class="lineNum">    3188 </span>            :  *</a>
<a name="3189"><span class="lineNum">    3189 </span>            :  * But because grq-&gt;load.weight can drop to 0, resulting in a divide by zero,</a>
<a name="3190"><span class="lineNum">    3190 </span>            :  * we need to use grq-&gt;avg.load_avg as its lower bound, which then gives:</a>
<a name="3191"><span class="lineNum">    3191 </span>            :  *</a>
<a name="3192"><span class="lineNum">    3192 </span>            :  *</a>
<a name="3193"><span class="lineNum">    3193 </span>            :  *                     tg-&gt;weight * grq-&gt;load.weight</a>
<a name="3194"><span class="lineNum">    3194 </span>            :  *   ge-&gt;load.weight = -----------------------------            (6)</a>
<a name="3195"><span class="lineNum">    3195 </span>            :  *                             tg_load_avg'</a>
<a name="3196"><span class="lineNum">    3196 </span>            :  *</a>
<a name="3197"><span class="lineNum">    3197 </span>            :  * Where:</a>
<a name="3198"><span class="lineNum">    3198 </span>            :  *</a>
<a name="3199"><span class="lineNum">    3199 </span>            :  *   tg_load_avg' = tg-&gt;load_avg - grq-&gt;avg.load_avg +</a>
<a name="3200"><span class="lineNum">    3200 </span>            :  *                  max(grq-&gt;load.weight, grq-&gt;avg.load_avg)</a>
<a name="3201"><span class="lineNum">    3201 </span>            :  *</a>
<a name="3202"><span class="lineNum">    3202 </span>            :  * And that is shares_weight and is icky. In the (near) UP case it approaches</a>
<a name="3203"><span class="lineNum">    3203 </span>            :  * (4) while in the normal case it approaches (3). It consistently</a>
<a name="3204"><span class="lineNum">    3204 </span>            :  * overestimates the ge-&gt;load.weight and therefore:</a>
<a name="3205"><span class="lineNum">    3205 </span>            :  *</a>
<a name="3206"><span class="lineNum">    3206 </span>            :  *   \Sum ge-&gt;load.weight &gt;= tg-&gt;weight</a>
<a name="3207"><span class="lineNum">    3207 </span>            :  *</a>
<a name="3208"><span class="lineNum">    3208 </span>            :  * hence icky!</a>
<a name="3209"><span class="lineNum">    3209 </span>            :  */</a>
<a name="3210"><span class="lineNum">    3210 </span>            : static long calc_group_shares(struct cfs_rq *cfs_rq)</a>
<a name="3211"><span class="lineNum">    3211 </span>            : {</a>
<a name="3212"><span class="lineNum">    3212 </span>            :         long tg_weight, tg_shares, load, shares;</a>
<a name="3213"><span class="lineNum">    3213 </span>            :         struct task_group *tg = cfs_rq-&gt;tg;</a>
<a name="3214"><span class="lineNum">    3214 </span>            : </a>
<a name="3215"><span class="lineNum">    3215 </span>            :         tg_shares = READ_ONCE(tg-&gt;shares);</a>
<a name="3216"><span class="lineNum">    3216 </span>            : </a>
<a name="3217"><span class="lineNum">    3217 </span>            :         load = max(scale_load_down(cfs_rq-&gt;load.weight), cfs_rq-&gt;avg.load_avg);</a>
<a name="3218"><span class="lineNum">    3218 </span>            : </a>
<a name="3219"><span class="lineNum">    3219 </span>            :         tg_weight = atomic_long_read(&amp;tg-&gt;load_avg);</a>
<a name="3220"><span class="lineNum">    3220 </span>            : </a>
<a name="3221"><span class="lineNum">    3221 </span>            :         /* Ensure tg_weight &gt;= load */</a>
<a name="3222"><span class="lineNum">    3222 </span>            :         tg_weight -= cfs_rq-&gt;tg_load_avg_contrib;</a>
<a name="3223"><span class="lineNum">    3223 </span>            :         tg_weight += load;</a>
<a name="3224"><span class="lineNum">    3224 </span>            : </a>
<a name="3225"><span class="lineNum">    3225 </span>            :         shares = (tg_shares * load);</a>
<a name="3226"><span class="lineNum">    3226 </span>            :         if (tg_weight)</a>
<a name="3227"><span class="lineNum">    3227 </span>            :                 shares /= tg_weight;</a>
<a name="3228"><span class="lineNum">    3228 </span>            : </a>
<a name="3229"><span class="lineNum">    3229 </span>            :         /*</a>
<a name="3230"><span class="lineNum">    3230 </span>            :          * MIN_SHARES has to be unscaled here to support per-CPU partitioning</a>
<a name="3231"><span class="lineNum">    3231 </span>            :          * of a group with small tg-&gt;shares value. It is a floor value which is</a>
<a name="3232"><span class="lineNum">    3232 </span>            :          * assigned as a minimum load.weight to the sched_entity representing</a>
<a name="3233"><span class="lineNum">    3233 </span>            :          * the group on a CPU.</a>
<a name="3234"><span class="lineNum">    3234 </span>            :          *</a>
<a name="3235"><span class="lineNum">    3235 </span>            :          * E.g. on 64-bit for a group with tg-&gt;shares of scale_load(15)=15*1024</a>
<a name="3236"><span class="lineNum">    3236 </span>            :          * on an 8-core system with 8 tasks each runnable on one CPU shares has</a>
<a name="3237"><span class="lineNum">    3237 </span>            :          * to be 15*1024*1/8=1920 instead of scale_load(MIN_SHARES)=2*1024. In</a>
<a name="3238"><span class="lineNum">    3238 </span>            :          * case no task is runnable on a CPU MIN_SHARES=2 should be returned</a>
<a name="3239"><span class="lineNum">    3239 </span>            :          * instead of 0.</a>
<a name="3240"><span class="lineNum">    3240 </span>            :          */</a>
<a name="3241"><span class="lineNum">    3241 </span>            :         return clamp_t(long, shares, MIN_SHARES, tg_shares);</a>
<a name="3242"><span class="lineNum">    3242 </span>            : }</a>
<a name="3243"><span class="lineNum">    3243 </span>            : #endif /* CONFIG_SMP */</a>
<a name="3244"><span class="lineNum">    3244 </span>            : </a>
<a name="3245"><span class="lineNum">    3245 </span>            : static inline int throttled_hierarchy(struct cfs_rq *cfs_rq);</a>
<a name="3246"><span class="lineNum">    3246 </span>            : </a>
<a name="3247"><span class="lineNum">    3247 </span>            : /*</a>
<a name="3248"><span class="lineNum">    3248 </span>            :  * Recomputes the group entity based on the current state of its group</a>
<a name="3249"><span class="lineNum">    3249 </span>            :  * runqueue.</a>
<a name="3250"><span class="lineNum">    3250 </span>            :  */</a>
<a name="3251"><span class="lineNum">    3251 </span>            : static void update_cfs_group(struct sched_entity *se)</a>
<a name="3252"><span class="lineNum">    3252 </span>            : {</a>
<a name="3253"><span class="lineNum">    3253 </span>            :         struct cfs_rq *gcfs_rq = group_cfs_rq(se);</a>
<a name="3254"><span class="lineNum">    3254 </span>            :         long shares;</a>
<a name="3255"><span class="lineNum">    3255 </span>            : </a>
<a name="3256"><span class="lineNum">    3256 </span>            :         if (!gcfs_rq)</a>
<a name="3257"><span class="lineNum">    3257 </span>            :                 return;</a>
<a name="3258"><span class="lineNum">    3258 </span>            : </a>
<a name="3259"><span class="lineNum">    3259 </span>            :         if (throttled_hierarchy(gcfs_rq))</a>
<a name="3260"><span class="lineNum">    3260 </span>            :                 return;</a>
<a name="3261"><span class="lineNum">    3261 </span>            : </a>
<a name="3262"><span class="lineNum">    3262 </span>            : #ifndef CONFIG_SMP</a>
<a name="3263"><span class="lineNum">    3263 </span>            :         shares = READ_ONCE(gcfs_rq-&gt;tg-&gt;shares);</a>
<a name="3264"><span class="lineNum">    3264 </span>            : </a>
<a name="3265"><span class="lineNum">    3265 </span>            :         if (likely(se-&gt;load.weight == shares))</a>
<a name="3266"><span class="lineNum">    3266 </span>            :                 return;</a>
<a name="3267"><span class="lineNum">    3267 </span>            : #else</a>
<a name="3268"><span class="lineNum">    3268 </span>            :         shares   = calc_group_shares(gcfs_rq);</a>
<a name="3269"><span class="lineNum">    3269 </span>            : #endif</a>
<a name="3270"><span class="lineNum">    3270 </span>            : </a>
<a name="3271"><span class="lineNum">    3271 </span>            :         reweight_entity(cfs_rq_of(se), se, shares);</a>
<a name="3272"><span class="lineNum">    3272 </span>            : }</a>
<a name="3273"><span class="lineNum">    3273 </span>            : </a>
<a name="3274"><span class="lineNum">    3274 </span>            : #else /* CONFIG_FAIR_GROUP_SCHED */</a>
<a name="3275"><span class="lineNum">    3275 </span>            : static inline void update_cfs_group(struct sched_entity *se)</a>
<a name="3276"><span class="lineNum">    3276 </span>            : {</a>
<a name="3277"><span class="lineNum">    3277 </span>            : }</a>
<a name="3278"><span class="lineNum">    3278 </span>            : #endif /* CONFIG_FAIR_GROUP_SCHED */</a>
<a name="3279"><span class="lineNum">    3279 </span>            : </a>
<a name="3280"><span class="lineNum">    3280 </span>            : static inline void cfs_rq_util_change(struct cfs_rq *cfs_rq, int flags)</a>
<a name="3281"><span class="lineNum">    3281 </span>            : {</a>
<a name="3282"><span class="lineNum">    3282 </span><span class="lineCov">       1236 :         struct rq *rq = rq_of(cfs_rq);</span></a>
<a name="3283"><span class="lineNum">    3283 </span>            : </a>
<a name="3284"><span class="lineNum">    3284 </span>            :         if (&amp;rq-&gt;cfs == cfs_rq) {</a>
<a name="3285"><span class="lineNum">    3285 </span>            :                 /*</a>
<a name="3286"><span class="lineNum">    3286 </span>            :                  * There are a few boundary cases this might miss but it should</a>
<a name="3287"><span class="lineNum">    3287 </span>            :                  * get called often enough that that should (hopefully) not be</a>
<a name="3288"><span class="lineNum">    3288 </span>            :                  * a real problem.</a>
<a name="3289"><span class="lineNum">    3289 </span>            :                  *</a>
<a name="3290"><span class="lineNum">    3290 </span>            :                  * It will not get called when we go idle, because the idle</a>
<a name="3291"><span class="lineNum">    3291 </span>            :                  * thread is a different class (!fair), nor will the utilization</a>
<a name="3292"><span class="lineNum">    3292 </span>            :                  * number include things like RT tasks.</a>
<a name="3293"><span class="lineNum">    3293 </span>            :                  *</a>
<a name="3294"><span class="lineNum">    3294 </span>            :                  * As is, the util number is not freq-invariant (we'd have to</a>
<a name="3295"><span class="lineNum">    3295 </span>            :                  * implement arch_scale_freq_capacity() for that).</a>
<a name="3296"><span class="lineNum">    3296 </span>            :                  *</a>
<a name="3297"><span class="lineNum">    3297 </span>            :                  * See cpu_util_cfs().</a>
<a name="3298"><span class="lineNum">    3298 </span>            :                  */</a>
<a name="3299"><span class="lineNum">    3299 </span>            :                 cpufreq_update_util(rq, flags);</a>
<a name="3300"><span class="lineNum">    3300 </span>            :         }</a>
<a name="3301"><span class="lineNum">    3301 </span>            : }</a>
<a name="3302"><span class="lineNum">    3302 </span>            : </a>
<a name="3303"><span class="lineNum">    3303 </span>            : #ifdef CONFIG_SMP</a>
<a name="3304"><span class="lineNum">    3304 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="3305"><span class="lineNum">    3305 </span>            : /*</a>
<a name="3306"><span class="lineNum">    3306 </span>            :  * Because list_add_leaf_cfs_rq always places a child cfs_rq on the list</a>
<a name="3307"><span class="lineNum">    3307 </span>            :  * immediately before a parent cfs_rq, and cfs_rqs are removed from the list</a>
<a name="3308"><span class="lineNum">    3308 </span>            :  * bottom-up, we only have to test whether the cfs_rq before us on the list</a>
<a name="3309"><span class="lineNum">    3309 </span>            :  * is our child.</a>
<a name="3310"><span class="lineNum">    3310 </span>            :  * If cfs_rq is not on the list, test whether a child needs its to be added to</a>
<a name="3311"><span class="lineNum">    3311 </span>            :  * connect a branch to the tree  * (see list_add_leaf_cfs_rq() for details).</a>
<a name="3312"><span class="lineNum">    3312 </span>            :  */</a>
<a name="3313"><span class="lineNum">    3313 </span>            : static inline bool child_cfs_rq_on_list(struct cfs_rq *cfs_rq)</a>
<a name="3314"><span class="lineNum">    3314 </span>            : {</a>
<a name="3315"><span class="lineNum">    3315 </span>            :         struct cfs_rq *prev_cfs_rq;</a>
<a name="3316"><span class="lineNum">    3316 </span>            :         struct list_head *prev;</a>
<a name="3317"><span class="lineNum">    3317 </span>            : </a>
<a name="3318"><span class="lineNum">    3318 </span>            :         if (cfs_rq-&gt;on_list) {</a>
<a name="3319"><span class="lineNum">    3319 </span>            :                 prev = cfs_rq-&gt;leaf_cfs_rq_list.prev;</a>
<a name="3320"><span class="lineNum">    3320 </span>            :         } else {</a>
<a name="3321"><span class="lineNum">    3321 </span>            :                 struct rq *rq = rq_of(cfs_rq);</a>
<a name="3322"><span class="lineNum">    3322 </span>            : </a>
<a name="3323"><span class="lineNum">    3323 </span>            :                 prev = rq-&gt;tmp_alone_branch;</a>
<a name="3324"><span class="lineNum">    3324 </span>            :         }</a>
<a name="3325"><span class="lineNum">    3325 </span>            : </a>
<a name="3326"><span class="lineNum">    3326 </span>            :         prev_cfs_rq = container_of(prev, struct cfs_rq, leaf_cfs_rq_list);</a>
<a name="3327"><span class="lineNum">    3327 </span>            : </a>
<a name="3328"><span class="lineNum">    3328 </span>            :         return (prev_cfs_rq-&gt;tg-&gt;parent == cfs_rq-&gt;tg);</a>
<a name="3329"><span class="lineNum">    3329 </span>            : }</a>
<a name="3330"><span class="lineNum">    3330 </span>            : </a>
<a name="3331"><span class="lineNum">    3331 </span>            : static inline bool cfs_rq_is_decayed(struct cfs_rq *cfs_rq)</a>
<a name="3332"><span class="lineNum">    3332 </span>            : {</a>
<a name="3333"><span class="lineNum">    3333 </span>            :         if (cfs_rq-&gt;load.weight)</a>
<a name="3334"><span class="lineNum">    3334 </span>            :                 return false;</a>
<a name="3335"><span class="lineNum">    3335 </span>            : </a>
<a name="3336"><span class="lineNum">    3336 </span>            :         if (cfs_rq-&gt;avg.load_sum)</a>
<a name="3337"><span class="lineNum">    3337 </span>            :                 return false;</a>
<a name="3338"><span class="lineNum">    3338 </span>            : </a>
<a name="3339"><span class="lineNum">    3339 </span>            :         if (cfs_rq-&gt;avg.util_sum)</a>
<a name="3340"><span class="lineNum">    3340 </span>            :                 return false;</a>
<a name="3341"><span class="lineNum">    3341 </span>            : </a>
<a name="3342"><span class="lineNum">    3342 </span>            :         if (cfs_rq-&gt;avg.runnable_sum)</a>
<a name="3343"><span class="lineNum">    3343 </span>            :                 return false;</a>
<a name="3344"><span class="lineNum">    3344 </span>            : </a>
<a name="3345"><span class="lineNum">    3345 </span>            :         if (child_cfs_rq_on_list(cfs_rq))</a>
<a name="3346"><span class="lineNum">    3346 </span>            :                 return false;</a>
<a name="3347"><span class="lineNum">    3347 </span>            : </a>
<a name="3348"><span class="lineNum">    3348 </span>            :         /*</a>
<a name="3349"><span class="lineNum">    3349 </span>            :          * _avg must be null when _sum are null because _avg = _sum / divider</a>
<a name="3350"><span class="lineNum">    3350 </span>            :          * Make sure that rounding and/or propagation of PELT values never</a>
<a name="3351"><span class="lineNum">    3351 </span>            :          * break this.</a>
<a name="3352"><span class="lineNum">    3352 </span>            :          */</a>
<a name="3353"><span class="lineNum">    3353 </span>            :         SCHED_WARN_ON(cfs_rq-&gt;avg.load_avg ||</a>
<a name="3354"><span class="lineNum">    3354 </span>            :                       cfs_rq-&gt;avg.util_avg ||</a>
<a name="3355"><span class="lineNum">    3355 </span>            :                       cfs_rq-&gt;avg.runnable_avg);</a>
<a name="3356"><span class="lineNum">    3356 </span>            : </a>
<a name="3357"><span class="lineNum">    3357 </span>            :         return true;</a>
<a name="3358"><span class="lineNum">    3358 </span>            : }</a>
<a name="3359"><span class="lineNum">    3359 </span>            : </a>
<a name="3360"><span class="lineNum">    3360 </span>            : /**</a>
<a name="3361"><span class="lineNum">    3361 </span>            :  * update_tg_load_avg - update the tg's load avg</a>
<a name="3362"><span class="lineNum">    3362 </span>            :  * @cfs_rq: the cfs_rq whose avg changed</a>
<a name="3363"><span class="lineNum">    3363 </span>            :  *</a>
<a name="3364"><span class="lineNum">    3364 </span>            :  * This function 'ensures': tg-&gt;load_avg := \Sum tg-&gt;cfs_rq[]-&gt;avg.load.</a>
<a name="3365"><span class="lineNum">    3365 </span>            :  * However, because tg-&gt;load_avg is a global value there are performance</a>
<a name="3366"><span class="lineNum">    3366 </span>            :  * considerations.</a>
<a name="3367"><span class="lineNum">    3367 </span>            :  *</a>
<a name="3368"><span class="lineNum">    3368 </span>            :  * In order to avoid having to look at the other cfs_rq's, we use a</a>
<a name="3369"><span class="lineNum">    3369 </span>            :  * differential update where we store the last value we propagated. This in</a>
<a name="3370"><span class="lineNum">    3370 </span>            :  * turn allows skipping updates if the differential is 'small'.</a>
<a name="3371"><span class="lineNum">    3371 </span>            :  *</a>
<a name="3372"><span class="lineNum">    3372 </span>            :  * Updating tg's load_avg is necessary before update_cfs_share().</a>
<a name="3373"><span class="lineNum">    3373 </span>            :  */</a>
<a name="3374"><span class="lineNum">    3374 </span>            : static inline void update_tg_load_avg(struct cfs_rq *cfs_rq)</a>
<a name="3375"><span class="lineNum">    3375 </span>            : {</a>
<a name="3376"><span class="lineNum">    3376 </span>            :         long delta = cfs_rq-&gt;avg.load_avg - cfs_rq-&gt;tg_load_avg_contrib;</a>
<a name="3377"><span class="lineNum">    3377 </span>            : </a>
<a name="3378"><span class="lineNum">    3378 </span>            :         /*</a>
<a name="3379"><span class="lineNum">    3379 </span>            :          * No need to update load_avg for root_task_group as it is not used.</a>
<a name="3380"><span class="lineNum">    3380 </span>            :          */</a>
<a name="3381"><span class="lineNum">    3381 </span>            :         if (cfs_rq-&gt;tg == &amp;root_task_group)</a>
<a name="3382"><span class="lineNum">    3382 </span>            :                 return;</a>
<a name="3383"><span class="lineNum">    3383 </span>            : </a>
<a name="3384"><span class="lineNum">    3384 </span>            :         if (abs(delta) &gt; cfs_rq-&gt;tg_load_avg_contrib / 64) {</a>
<a name="3385"><span class="lineNum">    3385 </span>            :                 atomic_long_add(delta, &amp;cfs_rq-&gt;tg-&gt;load_avg);</a>
<a name="3386"><span class="lineNum">    3386 </span>            :                 cfs_rq-&gt;tg_load_avg_contrib = cfs_rq-&gt;avg.load_avg;</a>
<a name="3387"><span class="lineNum">    3387 </span>            :         }</a>
<a name="3388"><span class="lineNum">    3388 </span>            : }</a>
<a name="3389"><span class="lineNum">    3389 </span>            : </a>
<a name="3390"><span class="lineNum">    3390 </span>            : /*</a>
<a name="3391"><span class="lineNum">    3391 </span>            :  * Called within set_task_rq() right before setting a task's CPU. The</a>
<a name="3392"><span class="lineNum">    3392 </span>            :  * caller only guarantees p-&gt;pi_lock is held; no other assumptions,</a>
<a name="3393"><span class="lineNum">    3393 </span>            :  * including the state of rq-&gt;lock, should be made.</a>
<a name="3394"><span class="lineNum">    3394 </span>            :  */</a>
<a name="3395"><span class="lineNum">    3395 </span>            : void set_task_rq_fair(struct sched_entity *se,</a>
<a name="3396"><span class="lineNum">    3396 </span>            :                       struct cfs_rq *prev, struct cfs_rq *next)</a>
<a name="3397"><span class="lineNum">    3397 </span>            : {</a>
<a name="3398"><span class="lineNum">    3398 </span>            :         u64 p_last_update_time;</a>
<a name="3399"><span class="lineNum">    3399 </span>            :         u64 n_last_update_time;</a>
<a name="3400"><span class="lineNum">    3400 </span>            : </a>
<a name="3401"><span class="lineNum">    3401 </span>            :         if (!sched_feat(ATTACH_AGE_LOAD))</a>
<a name="3402"><span class="lineNum">    3402 </span>            :                 return;</a>
<a name="3403"><span class="lineNum">    3403 </span>            : </a>
<a name="3404"><span class="lineNum">    3404 </span>            :         /*</a>
<a name="3405"><span class="lineNum">    3405 </span>            :          * We are supposed to update the task to &quot;current&quot; time, then its up to</a>
<a name="3406"><span class="lineNum">    3406 </span>            :          * date and ready to go to new CPU/cfs_rq. But we have difficulty in</a>
<a name="3407"><span class="lineNum">    3407 </span>            :          * getting what current time is, so simply throw away the out-of-date</a>
<a name="3408"><span class="lineNum">    3408 </span>            :          * time. This will result in the wakee task is less decayed, but giving</a>
<a name="3409"><span class="lineNum">    3409 </span>            :          * the wakee more load sounds not bad.</a>
<a name="3410"><span class="lineNum">    3410 </span>            :          */</a>
<a name="3411"><span class="lineNum">    3411 </span>            :         if (!(se-&gt;avg.last_update_time &amp;&amp; prev))</a>
<a name="3412"><span class="lineNum">    3412 </span>            :                 return;</a>
<a name="3413"><span class="lineNum">    3413 </span>            : </a>
<a name="3414"><span class="lineNum">    3414 </span>            : #ifndef CONFIG_64BIT</a>
<a name="3415"><span class="lineNum">    3415 </span>            :         {</a>
<a name="3416"><span class="lineNum">    3416 </span>            :                 u64 p_last_update_time_copy;</a>
<a name="3417"><span class="lineNum">    3417 </span>            :                 u64 n_last_update_time_copy;</a>
<a name="3418"><span class="lineNum">    3418 </span>            : </a>
<a name="3419"><span class="lineNum">    3419 </span>            :                 do {</a>
<a name="3420"><span class="lineNum">    3420 </span>            :                         p_last_update_time_copy = prev-&gt;load_last_update_time_copy;</a>
<a name="3421"><span class="lineNum">    3421 </span>            :                         n_last_update_time_copy = next-&gt;load_last_update_time_copy;</a>
<a name="3422"><span class="lineNum">    3422 </span>            : </a>
<a name="3423"><span class="lineNum">    3423 </span>            :                         smp_rmb();</a>
<a name="3424"><span class="lineNum">    3424 </span>            : </a>
<a name="3425"><span class="lineNum">    3425 </span>            :                         p_last_update_time = prev-&gt;avg.last_update_time;</a>
<a name="3426"><span class="lineNum">    3426 </span>            :                         n_last_update_time = next-&gt;avg.last_update_time;</a>
<a name="3427"><span class="lineNum">    3427 </span>            : </a>
<a name="3428"><span class="lineNum">    3428 </span>            :                 } while (p_last_update_time != p_last_update_time_copy ||</a>
<a name="3429"><span class="lineNum">    3429 </span>            :                          n_last_update_time != n_last_update_time_copy);</a>
<a name="3430"><span class="lineNum">    3430 </span>            :         }</a>
<a name="3431"><span class="lineNum">    3431 </span>            : #else</a>
<a name="3432"><span class="lineNum">    3432 </span>            :         p_last_update_time = prev-&gt;avg.last_update_time;</a>
<a name="3433"><span class="lineNum">    3433 </span>            :         n_last_update_time = next-&gt;avg.last_update_time;</a>
<a name="3434"><span class="lineNum">    3434 </span>            : #endif</a>
<a name="3435"><span class="lineNum">    3435 </span>            :         __update_load_avg_blocked_se(p_last_update_time, se);</a>
<a name="3436"><span class="lineNum">    3436 </span>            :         se-&gt;avg.last_update_time = n_last_update_time;</a>
<a name="3437"><span class="lineNum">    3437 </span>            : }</a>
<a name="3438"><span class="lineNum">    3438 </span>            : </a>
<a name="3439"><span class="lineNum">    3439 </span>            : /*</a>
<a name="3440"><span class="lineNum">    3440 </span>            :  * When on migration a sched_entity joins/leaves the PELT hierarchy, we need to</a>
<a name="3441"><span class="lineNum">    3441 </span>            :  * propagate its contribution. The key to this propagation is the invariant</a>
<a name="3442"><span class="lineNum">    3442 </span>            :  * that for each group:</a>
<a name="3443"><span class="lineNum">    3443 </span>            :  *</a>
<a name="3444"><span class="lineNum">    3444 </span>            :  *   ge-&gt;avg == grq-&gt;avg                                          (1)</a>
<a name="3445"><span class="lineNum">    3445 </span>            :  *</a>
<a name="3446"><span class="lineNum">    3446 </span>            :  * _IFF_ we look at the pure running and runnable sums. Because they</a>
<a name="3447"><span class="lineNum">    3447 </span>            :  * represent the very same entity, just at different points in the hierarchy.</a>
<a name="3448"><span class="lineNum">    3448 </span>            :  *</a>
<a name="3449"><span class="lineNum">    3449 </span>            :  * Per the above update_tg_cfs_util() and update_tg_cfs_runnable() are trivial</a>
<a name="3450"><span class="lineNum">    3450 </span>            :  * and simply copies the running/runnable sum over (but still wrong, because</a>
<a name="3451"><span class="lineNum">    3451 </span>            :  * the group entity and group rq do not have their PELT windows aligned).</a>
<a name="3452"><span class="lineNum">    3452 </span>            :  *</a>
<a name="3453"><span class="lineNum">    3453 </span>            :  * However, update_tg_cfs_load() is more complex. So we have:</a>
<a name="3454"><span class="lineNum">    3454 </span>            :  *</a>
<a name="3455"><span class="lineNum">    3455 </span>            :  *   ge-&gt;avg.load_avg = ge-&gt;load.weight * ge-&gt;avg.runnable_avg         (2)</a>
<a name="3456"><span class="lineNum">    3456 </span>            :  *</a>
<a name="3457"><span class="lineNum">    3457 </span>            :  * And since, like util, the runnable part should be directly transferable,</a>
<a name="3458"><span class="lineNum">    3458 </span>            :  * the following would _appear_ to be the straight forward approach:</a>
<a name="3459"><span class="lineNum">    3459 </span>            :  *</a>
<a name="3460"><span class="lineNum">    3460 </span>            :  *   grq-&gt;avg.load_avg = grq-&gt;load.weight * grq-&gt;avg.runnable_avg      (3)</a>
<a name="3461"><span class="lineNum">    3461 </span>            :  *</a>
<a name="3462"><span class="lineNum">    3462 </span>            :  * And per (1) we have:</a>
<a name="3463"><span class="lineNum">    3463 </span>            :  *</a>
<a name="3464"><span class="lineNum">    3464 </span>            :  *   ge-&gt;avg.runnable_avg == grq-&gt;avg.runnable_avg</a>
<a name="3465"><span class="lineNum">    3465 </span>            :  *</a>
<a name="3466"><span class="lineNum">    3466 </span>            :  * Which gives:</a>
<a name="3467"><span class="lineNum">    3467 </span>            :  *</a>
<a name="3468"><span class="lineNum">    3468 </span>            :  *                      ge-&gt;load.weight * grq-&gt;avg.load_avg</a>
<a name="3469"><span class="lineNum">    3469 </span>            :  *   ge-&gt;avg.load_avg = -----------------------------------          (4)</a>
<a name="3470"><span class="lineNum">    3470 </span>            :  *                               grq-&gt;load.weight</a>
<a name="3471"><span class="lineNum">    3471 </span>            :  *</a>
<a name="3472"><span class="lineNum">    3472 </span>            :  * Except that is wrong!</a>
<a name="3473"><span class="lineNum">    3473 </span>            :  *</a>
<a name="3474"><span class="lineNum">    3474 </span>            :  * Because while for entities historical weight is not important and we</a>
<a name="3475"><span class="lineNum">    3475 </span>            :  * really only care about our future and therefore can consider a pure</a>
<a name="3476"><span class="lineNum">    3476 </span>            :  * runnable sum, runqueues can NOT do this.</a>
<a name="3477"><span class="lineNum">    3477 </span>            :  *</a>
<a name="3478"><span class="lineNum">    3478 </span>            :  * We specifically want runqueues to have a load_avg that includes</a>
<a name="3479"><span class="lineNum">    3479 </span>            :  * historical weights. Those represent the blocked load, the load we expect</a>
<a name="3480"><span class="lineNum">    3480 </span>            :  * to (shortly) return to us. This only works by keeping the weights as</a>
<a name="3481"><span class="lineNum">    3481 </span>            :  * integral part of the sum. We therefore cannot decompose as per (3).</a>
<a name="3482"><span class="lineNum">    3482 </span>            :  *</a>
<a name="3483"><span class="lineNum">    3483 </span>            :  * Another reason this doesn't work is that runnable isn't a 0-sum entity.</a>
<a name="3484"><span class="lineNum">    3484 </span>            :  * Imagine a rq with 2 tasks that each are runnable 2/3 of the time. Then the</a>
<a name="3485"><span class="lineNum">    3485 </span>            :  * rq itself is runnable anywhere between 2/3 and 1 depending on how the</a>
<a name="3486"><span class="lineNum">    3486 </span>            :  * runnable section of these tasks overlap (or not). If they were to perfectly</a>
<a name="3487"><span class="lineNum">    3487 </span>            :  * align the rq as a whole would be runnable 2/3 of the time. If however we</a>
<a name="3488"><span class="lineNum">    3488 </span>            :  * always have at least 1 runnable task, the rq as a whole is always runnable.</a>
<a name="3489"><span class="lineNum">    3489 </span>            :  *</a>
<a name="3490"><span class="lineNum">    3490 </span>            :  * So we'll have to approximate.. :/</a>
<a name="3491"><span class="lineNum">    3491 </span>            :  *</a>
<a name="3492"><span class="lineNum">    3492 </span>            :  * Given the constraint:</a>
<a name="3493"><span class="lineNum">    3493 </span>            :  *</a>
<a name="3494"><span class="lineNum">    3494 </span>            :  *   ge-&gt;avg.running_sum &lt;= ge-&gt;avg.runnable_sum &lt;= LOAD_AVG_MAX</a>
<a name="3495"><span class="lineNum">    3495 </span>            :  *</a>
<a name="3496"><span class="lineNum">    3496 </span>            :  * We can construct a rule that adds runnable to a rq by assuming minimal</a>
<a name="3497"><span class="lineNum">    3497 </span>            :  * overlap.</a>
<a name="3498"><span class="lineNum">    3498 </span>            :  *</a>
<a name="3499"><span class="lineNum">    3499 </span>            :  * On removal, we'll assume each task is equally runnable; which yields:</a>
<a name="3500"><span class="lineNum">    3500 </span>            :  *</a>
<a name="3501"><span class="lineNum">    3501 </span>            :  *   grq-&gt;avg.runnable_sum = grq-&gt;avg.load_sum / grq-&gt;load.weight</a>
<a name="3502"><span class="lineNum">    3502 </span>            :  *</a>
<a name="3503"><span class="lineNum">    3503 </span>            :  * XXX: only do this for the part of runnable &gt; running ?</a>
<a name="3504"><span class="lineNum">    3504 </span>            :  *</a>
<a name="3505"><span class="lineNum">    3505 </span>            :  */</a>
<a name="3506"><span class="lineNum">    3506 </span>            : static inline void</a>
<a name="3507"><span class="lineNum">    3507 </span>            : update_tg_cfs_util(struct cfs_rq *cfs_rq, struct sched_entity *se, struct cfs_rq *gcfs_rq)</a>
<a name="3508"><span class="lineNum">    3508 </span>            : {</a>
<a name="3509"><span class="lineNum">    3509 </span>            :         long delta_sum, delta_avg = gcfs_rq-&gt;avg.util_avg - se-&gt;avg.util_avg;</a>
<a name="3510"><span class="lineNum">    3510 </span>            :         u32 new_sum, divider;</a>
<a name="3511"><span class="lineNum">    3511 </span>            : </a>
<a name="3512"><span class="lineNum">    3512 </span>            :         /* Nothing to update */</a>
<a name="3513"><span class="lineNum">    3513 </span>            :         if (!delta_avg)</a>
<a name="3514"><span class="lineNum">    3514 </span>            :                 return;</a>
<a name="3515"><span class="lineNum">    3515 </span>            : </a>
<a name="3516"><span class="lineNum">    3516 </span>            :         /*</a>
<a name="3517"><span class="lineNum">    3517 </span>            :          * cfs_rq-&gt;avg.period_contrib can be used for both cfs_rq and se.</a>
<a name="3518"><span class="lineNum">    3518 </span>            :          * See ___update_load_avg() for details.</a>
<a name="3519"><span class="lineNum">    3519 </span>            :          */</a>
<a name="3520"><span class="lineNum">    3520 </span>            :         divider = get_pelt_divider(&amp;cfs_rq-&gt;avg);</a>
<a name="3521"><span class="lineNum">    3521 </span>            : </a>
<a name="3522"><span class="lineNum">    3522 </span>            : </a>
<a name="3523"><span class="lineNum">    3523 </span>            :         /* Set new sched_entity's utilization */</a>
<a name="3524"><span class="lineNum">    3524 </span>            :         se-&gt;avg.util_avg = gcfs_rq-&gt;avg.util_avg;</a>
<a name="3525"><span class="lineNum">    3525 </span>            :         new_sum = se-&gt;avg.util_avg * divider;</a>
<a name="3526"><span class="lineNum">    3526 </span>            :         delta_sum = (long)new_sum - (long)se-&gt;avg.util_sum;</a>
<a name="3527"><span class="lineNum">    3527 </span>            :         se-&gt;avg.util_sum = new_sum;</a>
<a name="3528"><span class="lineNum">    3528 </span>            : </a>
<a name="3529"><span class="lineNum">    3529 </span>            :         /* Update parent cfs_rq utilization */</a>
<a name="3530"><span class="lineNum">    3530 </span>            :         add_positive(&amp;cfs_rq-&gt;avg.util_avg, delta_avg);</a>
<a name="3531"><span class="lineNum">    3531 </span>            :         add_positive(&amp;cfs_rq-&gt;avg.util_sum, delta_sum);</a>
<a name="3532"><span class="lineNum">    3532 </span>            : </a>
<a name="3533"><span class="lineNum">    3533 </span>            :         /* See update_cfs_rq_load_avg() */</a>
<a name="3534"><span class="lineNum">    3534 </span>            :         cfs_rq-&gt;avg.util_sum = max_t(u32, cfs_rq-&gt;avg.util_sum,</a>
<a name="3535"><span class="lineNum">    3535 </span>            :                                           cfs_rq-&gt;avg.util_avg * PELT_MIN_DIVIDER);</a>
<a name="3536"><span class="lineNum">    3536 </span>            : }</a>
<a name="3537"><span class="lineNum">    3537 </span>            : </a>
<a name="3538"><span class="lineNum">    3538 </span>            : static inline void</a>
<a name="3539"><span class="lineNum">    3539 </span>            : update_tg_cfs_runnable(struct cfs_rq *cfs_rq, struct sched_entity *se, struct cfs_rq *gcfs_rq)</a>
<a name="3540"><span class="lineNum">    3540 </span>            : {</a>
<a name="3541"><span class="lineNum">    3541 </span>            :         long delta_sum, delta_avg = gcfs_rq-&gt;avg.runnable_avg - se-&gt;avg.runnable_avg;</a>
<a name="3542"><span class="lineNum">    3542 </span>            :         u32 new_sum, divider;</a>
<a name="3543"><span class="lineNum">    3543 </span>            : </a>
<a name="3544"><span class="lineNum">    3544 </span>            :         /* Nothing to update */</a>
<a name="3545"><span class="lineNum">    3545 </span>            :         if (!delta_avg)</a>
<a name="3546"><span class="lineNum">    3546 </span>            :                 return;</a>
<a name="3547"><span class="lineNum">    3547 </span>            : </a>
<a name="3548"><span class="lineNum">    3548 </span>            :         /*</a>
<a name="3549"><span class="lineNum">    3549 </span>            :          * cfs_rq-&gt;avg.period_contrib can be used for both cfs_rq and se.</a>
<a name="3550"><span class="lineNum">    3550 </span>            :          * See ___update_load_avg() for details.</a>
<a name="3551"><span class="lineNum">    3551 </span>            :          */</a>
<a name="3552"><span class="lineNum">    3552 </span>            :         divider = get_pelt_divider(&amp;cfs_rq-&gt;avg);</a>
<a name="3553"><span class="lineNum">    3553 </span>            : </a>
<a name="3554"><span class="lineNum">    3554 </span>            :         /* Set new sched_entity's runnable */</a>
<a name="3555"><span class="lineNum">    3555 </span>            :         se-&gt;avg.runnable_avg = gcfs_rq-&gt;avg.runnable_avg;</a>
<a name="3556"><span class="lineNum">    3556 </span>            :         new_sum = se-&gt;avg.runnable_avg * divider;</a>
<a name="3557"><span class="lineNum">    3557 </span>            :         delta_sum = (long)new_sum - (long)se-&gt;avg.runnable_sum;</a>
<a name="3558"><span class="lineNum">    3558 </span>            :         se-&gt;avg.runnable_sum = new_sum;</a>
<a name="3559"><span class="lineNum">    3559 </span>            : </a>
<a name="3560"><span class="lineNum">    3560 </span>            :         /* Update parent cfs_rq runnable */</a>
<a name="3561"><span class="lineNum">    3561 </span>            :         add_positive(&amp;cfs_rq-&gt;avg.runnable_avg, delta_avg);</a>
<a name="3562"><span class="lineNum">    3562 </span>            :         add_positive(&amp;cfs_rq-&gt;avg.runnable_sum, delta_sum);</a>
<a name="3563"><span class="lineNum">    3563 </span>            :         /* See update_cfs_rq_load_avg() */</a>
<a name="3564"><span class="lineNum">    3564 </span>            :         cfs_rq-&gt;avg.runnable_sum = max_t(u32, cfs_rq-&gt;avg.runnable_sum,</a>
<a name="3565"><span class="lineNum">    3565 </span>            :                                               cfs_rq-&gt;avg.runnable_avg * PELT_MIN_DIVIDER);</a>
<a name="3566"><span class="lineNum">    3566 </span>            : }</a>
<a name="3567"><span class="lineNum">    3567 </span>            : </a>
<a name="3568"><span class="lineNum">    3568 </span>            : static inline void</a>
<a name="3569"><span class="lineNum">    3569 </span>            : update_tg_cfs_load(struct cfs_rq *cfs_rq, struct sched_entity *se, struct cfs_rq *gcfs_rq)</a>
<a name="3570"><span class="lineNum">    3570 </span>            : {</a>
<a name="3571"><span class="lineNum">    3571 </span>            :         long delta_avg, running_sum, runnable_sum = gcfs_rq-&gt;prop_runnable_sum;</a>
<a name="3572"><span class="lineNum">    3572 </span>            :         unsigned long load_avg;</a>
<a name="3573"><span class="lineNum">    3573 </span>            :         u64 load_sum = 0;</a>
<a name="3574"><span class="lineNum">    3574 </span>            :         s64 delta_sum;</a>
<a name="3575"><span class="lineNum">    3575 </span>            :         u32 divider;</a>
<a name="3576"><span class="lineNum">    3576 </span>            : </a>
<a name="3577"><span class="lineNum">    3577 </span>            :         if (!runnable_sum)</a>
<a name="3578"><span class="lineNum">    3578 </span>            :                 return;</a>
<a name="3579"><span class="lineNum">    3579 </span>            : </a>
<a name="3580"><span class="lineNum">    3580 </span>            :         gcfs_rq-&gt;prop_runnable_sum = 0;</a>
<a name="3581"><span class="lineNum">    3581 </span>            : </a>
<a name="3582"><span class="lineNum">    3582 </span>            :         /*</a>
<a name="3583"><span class="lineNum">    3583 </span>            :          * cfs_rq-&gt;avg.period_contrib can be used for both cfs_rq and se.</a>
<a name="3584"><span class="lineNum">    3584 </span>            :          * See ___update_load_avg() for details.</a>
<a name="3585"><span class="lineNum">    3585 </span>            :          */</a>
<a name="3586"><span class="lineNum">    3586 </span>            :         divider = get_pelt_divider(&amp;cfs_rq-&gt;avg);</a>
<a name="3587"><span class="lineNum">    3587 </span>            : </a>
<a name="3588"><span class="lineNum">    3588 </span>            :         if (runnable_sum &gt;= 0) {</a>
<a name="3589"><span class="lineNum">    3589 </span>            :                 /*</a>
<a name="3590"><span class="lineNum">    3590 </span>            :                  * Add runnable; clip at LOAD_AVG_MAX. Reflects that until</a>
<a name="3591"><span class="lineNum">    3591 </span>            :                  * the CPU is saturated running == runnable.</a>
<a name="3592"><span class="lineNum">    3592 </span>            :                  */</a>
<a name="3593"><span class="lineNum">    3593 </span>            :                 runnable_sum += se-&gt;avg.load_sum;</a>
<a name="3594"><span class="lineNum">    3594 </span>            :                 runnable_sum = min_t(long, runnable_sum, divider);</a>
<a name="3595"><span class="lineNum">    3595 </span>            :         } else {</a>
<a name="3596"><span class="lineNum">    3596 </span>            :                 /*</a>
<a name="3597"><span class="lineNum">    3597 </span>            :                  * Estimate the new unweighted runnable_sum of the gcfs_rq by</a>
<a name="3598"><span class="lineNum">    3598 </span>            :                  * assuming all tasks are equally runnable.</a>
<a name="3599"><span class="lineNum">    3599 </span>            :                  */</a>
<a name="3600"><span class="lineNum">    3600 </span>            :                 if (scale_load_down(gcfs_rq-&gt;load.weight)) {</a>
<a name="3601"><span class="lineNum">    3601 </span>            :                         load_sum = div_u64(gcfs_rq-&gt;avg.load_sum,</a>
<a name="3602"><span class="lineNum">    3602 </span>            :                                 scale_load_down(gcfs_rq-&gt;load.weight));</a>
<a name="3603"><span class="lineNum">    3603 </span>            :                 }</a>
<a name="3604"><span class="lineNum">    3604 </span>            : </a>
<a name="3605"><span class="lineNum">    3605 </span>            :                 /* But make sure to not inflate se's runnable */</a>
<a name="3606"><span class="lineNum">    3606 </span>            :                 runnable_sum = min(se-&gt;avg.load_sum, load_sum);</a>
<a name="3607"><span class="lineNum">    3607 </span>            :         }</a>
<a name="3608"><span class="lineNum">    3608 </span>            : </a>
<a name="3609"><span class="lineNum">    3609 </span>            :         /*</a>
<a name="3610"><span class="lineNum">    3610 </span>            :          * runnable_sum can't be lower than running_sum</a>
<a name="3611"><span class="lineNum">    3611 </span>            :          * Rescale running sum to be in the same range as runnable sum</a>
<a name="3612"><span class="lineNum">    3612 </span>            :          * running_sum is in [0 : LOAD_AVG_MAX &lt;&lt;  SCHED_CAPACITY_SHIFT]</a>
<a name="3613"><span class="lineNum">    3613 </span>            :          * runnable_sum is in [0 : LOAD_AVG_MAX]</a>
<a name="3614"><span class="lineNum">    3614 </span>            :          */</a>
<a name="3615"><span class="lineNum">    3615 </span>            :         running_sum = se-&gt;avg.util_sum &gt;&gt; SCHED_CAPACITY_SHIFT;</a>
<a name="3616"><span class="lineNum">    3616 </span>            :         runnable_sum = max(runnable_sum, running_sum);</a>
<a name="3617"><span class="lineNum">    3617 </span>            : </a>
<a name="3618"><span class="lineNum">    3618 </span>            :         load_sum = se_weight(se) * runnable_sum;</a>
<a name="3619"><span class="lineNum">    3619 </span>            :         load_avg = div_u64(load_sum, divider);</a>
<a name="3620"><span class="lineNum">    3620 </span>            : </a>
<a name="3621"><span class="lineNum">    3621 </span>            :         delta_avg = load_avg - se-&gt;avg.load_avg;</a>
<a name="3622"><span class="lineNum">    3622 </span>            :         if (!delta_avg)</a>
<a name="3623"><span class="lineNum">    3623 </span>            :                 return;</a>
<a name="3624"><span class="lineNum">    3624 </span>            : </a>
<a name="3625"><span class="lineNum">    3625 </span>            :         delta_sum = load_sum - (s64)se_weight(se) * se-&gt;avg.load_sum;</a>
<a name="3626"><span class="lineNum">    3626 </span>            : </a>
<a name="3627"><span class="lineNum">    3627 </span>            :         se-&gt;avg.load_sum = runnable_sum;</a>
<a name="3628"><span class="lineNum">    3628 </span>            :         se-&gt;avg.load_avg = load_avg;</a>
<a name="3629"><span class="lineNum">    3629 </span>            :         add_positive(&amp;cfs_rq-&gt;avg.load_avg, delta_avg);</a>
<a name="3630"><span class="lineNum">    3630 </span>            :         add_positive(&amp;cfs_rq-&gt;avg.load_sum, delta_sum);</a>
<a name="3631"><span class="lineNum">    3631 </span>            :         /* See update_cfs_rq_load_avg() */</a>
<a name="3632"><span class="lineNum">    3632 </span>            :         cfs_rq-&gt;avg.load_sum = max_t(u32, cfs_rq-&gt;avg.load_sum,</a>
<a name="3633"><span class="lineNum">    3633 </span>            :                                           cfs_rq-&gt;avg.load_avg * PELT_MIN_DIVIDER);</a>
<a name="3634"><span class="lineNum">    3634 </span>            : }</a>
<a name="3635"><span class="lineNum">    3635 </span>            : </a>
<a name="3636"><span class="lineNum">    3636 </span>            : static inline void add_tg_cfs_propagate(struct cfs_rq *cfs_rq, long runnable_sum)</a>
<a name="3637"><span class="lineNum">    3637 </span>            : {</a>
<a name="3638"><span class="lineNum">    3638 </span>            :         cfs_rq-&gt;propagate = 1;</a>
<a name="3639"><span class="lineNum">    3639 </span>            :         cfs_rq-&gt;prop_runnable_sum += runnable_sum;</a>
<a name="3640"><span class="lineNum">    3640 </span>            : }</a>
<a name="3641"><span class="lineNum">    3641 </span>            : </a>
<a name="3642"><span class="lineNum">    3642 </span>            : /* Update task and its cfs_rq load average */</a>
<a name="3643"><span class="lineNum">    3643 </span>            : static inline int propagate_entity_load_avg(struct sched_entity *se)</a>
<a name="3644"><span class="lineNum">    3644 </span>            : {</a>
<a name="3645"><span class="lineNum">    3645 </span>            :         struct cfs_rq *cfs_rq, *gcfs_rq;</a>
<a name="3646"><span class="lineNum">    3646 </span>            : </a>
<a name="3647"><span class="lineNum">    3647 </span>            :         if (entity_is_task(se))</a>
<a name="3648"><span class="lineNum">    3648 </span>            :                 return 0;</a>
<a name="3649"><span class="lineNum">    3649 </span>            : </a>
<a name="3650"><span class="lineNum">    3650 </span>            :         gcfs_rq = group_cfs_rq(se);</a>
<a name="3651"><span class="lineNum">    3651 </span>            :         if (!gcfs_rq-&gt;propagate)</a>
<a name="3652"><span class="lineNum">    3652 </span>            :                 return 0;</a>
<a name="3653"><span class="lineNum">    3653 </span>            : </a>
<a name="3654"><span class="lineNum">    3654 </span>            :         gcfs_rq-&gt;propagate = 0;</a>
<a name="3655"><span class="lineNum">    3655 </span>            : </a>
<a name="3656"><span class="lineNum">    3656 </span>            :         cfs_rq = cfs_rq_of(se);</a>
<a name="3657"><span class="lineNum">    3657 </span>            : </a>
<a name="3658"><span class="lineNum">    3658 </span>            :         add_tg_cfs_propagate(cfs_rq, gcfs_rq-&gt;prop_runnable_sum);</a>
<a name="3659"><span class="lineNum">    3659 </span>            : </a>
<a name="3660"><span class="lineNum">    3660 </span>            :         update_tg_cfs_util(cfs_rq, se, gcfs_rq);</a>
<a name="3661"><span class="lineNum">    3661 </span>            :         update_tg_cfs_runnable(cfs_rq, se, gcfs_rq);</a>
<a name="3662"><span class="lineNum">    3662 </span>            :         update_tg_cfs_load(cfs_rq, se, gcfs_rq);</a>
<a name="3663"><span class="lineNum">    3663 </span>            : </a>
<a name="3664"><span class="lineNum">    3664 </span>            :         trace_pelt_cfs_tp(cfs_rq);</a>
<a name="3665"><span class="lineNum">    3665 </span>            :         trace_pelt_se_tp(se);</a>
<a name="3666"><span class="lineNum">    3666 </span>            : </a>
<a name="3667"><span class="lineNum">    3667 </span>            :         return 1;</a>
<a name="3668"><span class="lineNum">    3668 </span>            : }</a>
<a name="3669"><span class="lineNum">    3669 </span>            : </a>
<a name="3670"><span class="lineNum">    3670 </span>            : /*</a>
<a name="3671"><span class="lineNum">    3671 </span>            :  * Check if we need to update the load and the utilization of a blocked</a>
<a name="3672"><span class="lineNum">    3672 </span>            :  * group_entity:</a>
<a name="3673"><span class="lineNum">    3673 </span>            :  */</a>
<a name="3674"><span class="lineNum">    3674 </span>            : static inline bool skip_blocked_update(struct sched_entity *se)</a>
<a name="3675"><span class="lineNum">    3675 </span>            : {</a>
<a name="3676"><span class="lineNum">    3676 </span>            :         struct cfs_rq *gcfs_rq = group_cfs_rq(se);</a>
<a name="3677"><span class="lineNum">    3677 </span>            : </a>
<a name="3678"><span class="lineNum">    3678 </span>            :         /*</a>
<a name="3679"><span class="lineNum">    3679 </span>            :          * If sched_entity still have not zero load or utilization, we have to</a>
<a name="3680"><span class="lineNum">    3680 </span>            :          * decay it:</a>
<a name="3681"><span class="lineNum">    3681 </span>            :          */</a>
<a name="3682"><span class="lineNum">    3682 </span>            :         if (se-&gt;avg.load_avg || se-&gt;avg.util_avg)</a>
<a name="3683"><span class="lineNum">    3683 </span>            :                 return false;</a>
<a name="3684"><span class="lineNum">    3684 </span>            : </a>
<a name="3685"><span class="lineNum">    3685 </span>            :         /*</a>
<a name="3686"><span class="lineNum">    3686 </span>            :          * If there is a pending propagation, we have to update the load and</a>
<a name="3687"><span class="lineNum">    3687 </span>            :          * the utilization of the sched_entity:</a>
<a name="3688"><span class="lineNum">    3688 </span>            :          */</a>
<a name="3689"><span class="lineNum">    3689 </span>            :         if (gcfs_rq-&gt;propagate)</a>
<a name="3690"><span class="lineNum">    3690 </span>            :                 return false;</a>
<a name="3691"><span class="lineNum">    3691 </span>            : </a>
<a name="3692"><span class="lineNum">    3692 </span>            :         /*</a>
<a name="3693"><span class="lineNum">    3693 </span>            :          * Otherwise, the load and the utilization of the sched_entity is</a>
<a name="3694"><span class="lineNum">    3694 </span>            :          * already zero and there is no pending propagation, so it will be a</a>
<a name="3695"><span class="lineNum">    3695 </span>            :          * waste of time to try to decay it:</a>
<a name="3696"><span class="lineNum">    3696 </span>            :          */</a>
<a name="3697"><span class="lineNum">    3697 </span>            :         return true;</a>
<a name="3698"><span class="lineNum">    3698 </span>            : }</a>
<a name="3699"><span class="lineNum">    3699 </span>            : </a>
<a name="3700"><span class="lineNum">    3700 </span>            : #else /* CONFIG_FAIR_GROUP_SCHED */</a>
<a name="3701"><span class="lineNum">    3701 </span>            : </a>
<a name="3702"><span class="lineNum">    3702 </span>            : static inline void update_tg_load_avg(struct cfs_rq *cfs_rq) {}</a>
<a name="3703"><span class="lineNum">    3703 </span>            : </a>
<a name="3704"><span class="lineNum">    3704 </span>            : static inline int propagate_entity_load_avg(struct sched_entity *se)</a>
<a name="3705"><span class="lineNum">    3705 </span>            : {</a>
<a name="3706"><span class="lineNum">    3706 </span>            :         return 0;</a>
<a name="3707"><span class="lineNum">    3707 </span>            : }</a>
<a name="3708"><span class="lineNum">    3708 </span>            : </a>
<a name="3709"><span class="lineNum">    3709 </span>            : static inline void add_tg_cfs_propagate(struct cfs_rq *cfs_rq, long runnable_sum) {}</a>
<a name="3710"><span class="lineNum">    3710 </span>            : </a>
<a name="3711"><span class="lineNum">    3711 </span>            : #endif /* CONFIG_FAIR_GROUP_SCHED */</a>
<a name="3712"><span class="lineNum">    3712 </span>            : </a>
<a name="3713"><span class="lineNum">    3713 </span>            : /**</a>
<a name="3714"><span class="lineNum">    3714 </span>            :  * update_cfs_rq_load_avg - update the cfs_rq's load/util averages</a>
<a name="3715"><span class="lineNum">    3715 </span>            :  * @now: current time, as per cfs_rq_clock_pelt()</a>
<a name="3716"><span class="lineNum">    3716 </span>            :  * @cfs_rq: cfs_rq to update</a>
<a name="3717"><span class="lineNum">    3717 </span>            :  *</a>
<a name="3718"><span class="lineNum">    3718 </span>            :  * The cfs_rq avg is the direct sum of all its entities (blocked and runnable)</a>
<a name="3719"><span class="lineNum">    3719 </span>            :  * avg. The immediate corollary is that all (fair) tasks must be attached, see</a>
<a name="3720"><span class="lineNum">    3720 </span>            :  * post_init_entity_util_avg().</a>
<a name="3721"><span class="lineNum">    3721 </span>            :  *</a>
<a name="3722"><span class="lineNum">    3722 </span>            :  * cfs_rq-&gt;avg is used for task_h_load() and update_cfs_share() for example.</a>
<a name="3723"><span class="lineNum">    3723 </span>            :  *</a>
<a name="3724"><span class="lineNum">    3724 </span>            :  * Return: true if the load decayed or we removed load.</a>
<a name="3725"><span class="lineNum">    3725 </span>            :  *</a>
<a name="3726"><span class="lineNum">    3726 </span>            :  * Since both these conditions indicate a changed cfs_rq-&gt;avg.load we should</a>
<a name="3727"><span class="lineNum">    3727 </span>            :  * call update_tg_load_avg() when this function returns true.</a>
<a name="3728"><span class="lineNum">    3728 </span>            :  */</a>
<a name="3729"><span class="lineNum">    3729 </span>            : static inline int</a>
<a name="3730"><span class="lineNum">    3730 </span>            : update_cfs_rq_load_avg(u64 now, struct cfs_rq *cfs_rq)</a>
<a name="3731"><span class="lineNum">    3731 </span>            : {</a>
<a name="3732"><span class="lineNum">    3732 </span>            :         unsigned long removed_load = 0, removed_util = 0, removed_runnable = 0;</a>
<a name="3733"><span class="lineNum">    3733 </span>            :         struct sched_avg *sa = &amp;cfs_rq-&gt;avg;</a>
<a name="3734"><span class="lineNum">    3734 </span>            :         int decayed = 0;</a>
<a name="3735"><span class="lineNum">    3735 </span>            : </a>
<a name="3736"><span class="lineNum">    3736 </span>            :         if (cfs_rq-&gt;removed.nr) {</a>
<a name="3737"><span class="lineNum">    3737 </span>            :                 unsigned long r;</a>
<a name="3738"><span class="lineNum">    3738 </span>            :                 u32 divider = get_pelt_divider(&amp;cfs_rq-&gt;avg);</a>
<a name="3739"><span class="lineNum">    3739 </span>            : </a>
<a name="3740"><span class="lineNum">    3740 </span>            :                 raw_spin_lock(&amp;cfs_rq-&gt;removed.lock);</a>
<a name="3741"><span class="lineNum">    3741 </span>            :                 swap(cfs_rq-&gt;removed.util_avg, removed_util);</a>
<a name="3742"><span class="lineNum">    3742 </span>            :                 swap(cfs_rq-&gt;removed.load_avg, removed_load);</a>
<a name="3743"><span class="lineNum">    3743 </span>            :                 swap(cfs_rq-&gt;removed.runnable_avg, removed_runnable);</a>
<a name="3744"><span class="lineNum">    3744 </span>            :                 cfs_rq-&gt;removed.nr = 0;</a>
<a name="3745"><span class="lineNum">    3745 </span>            :                 raw_spin_unlock(&amp;cfs_rq-&gt;removed.lock);</a>
<a name="3746"><span class="lineNum">    3746 </span>            : </a>
<a name="3747"><span class="lineNum">    3747 </span>            :                 r = removed_load;</a>
<a name="3748"><span class="lineNum">    3748 </span>            :                 sub_positive(&amp;sa-&gt;load_avg, r);</a>
<a name="3749"><span class="lineNum">    3749 </span>            :                 sub_positive(&amp;sa-&gt;load_sum, r * divider);</a>
<a name="3750"><span class="lineNum">    3750 </span>            :                 /* See sa-&gt;util_sum below */</a>
<a name="3751"><span class="lineNum">    3751 </span>            :                 sa-&gt;load_sum = max_t(u32, sa-&gt;load_sum, sa-&gt;load_avg * PELT_MIN_DIVIDER);</a>
<a name="3752"><span class="lineNum">    3752 </span>            : </a>
<a name="3753"><span class="lineNum">    3753 </span>            :                 r = removed_util;</a>
<a name="3754"><span class="lineNum">    3754 </span>            :                 sub_positive(&amp;sa-&gt;util_avg, r);</a>
<a name="3755"><span class="lineNum">    3755 </span>            :                 sub_positive(&amp;sa-&gt;util_sum, r * divider);</a>
<a name="3756"><span class="lineNum">    3756 </span>            :                 /*</a>
<a name="3757"><span class="lineNum">    3757 </span>            :                  * Because of rounding, se-&gt;util_sum might ends up being +1 more than</a>
<a name="3758"><span class="lineNum">    3758 </span>            :                  * cfs-&gt;util_sum. Although this is not a problem by itself, detaching</a>
<a name="3759"><span class="lineNum">    3759 </span>            :                  * a lot of tasks with the rounding problem between 2 updates of</a>
<a name="3760"><span class="lineNum">    3760 </span>            :                  * util_avg (~1ms) can make cfs-&gt;util_sum becoming null whereas</a>
<a name="3761"><span class="lineNum">    3761 </span>            :                  * cfs_util_avg is not.</a>
<a name="3762"><span class="lineNum">    3762 </span>            :                  * Check that util_sum is still above its lower bound for the new</a>
<a name="3763"><span class="lineNum">    3763 </span>            :                  * util_avg. Given that period_contrib might have moved since the last</a>
<a name="3764"><span class="lineNum">    3764 </span>            :                  * sync, we are only sure that util_sum must be above or equal to</a>
<a name="3765"><span class="lineNum">    3765 </span>            :                  *    util_avg * minimum possible divider</a>
<a name="3766"><span class="lineNum">    3766 </span>            :                  */</a>
<a name="3767"><span class="lineNum">    3767 </span>            :                 sa-&gt;util_sum = max_t(u32, sa-&gt;util_sum, sa-&gt;util_avg * PELT_MIN_DIVIDER);</a>
<a name="3768"><span class="lineNum">    3768 </span>            : </a>
<a name="3769"><span class="lineNum">    3769 </span>            :                 r = removed_runnable;</a>
<a name="3770"><span class="lineNum">    3770 </span>            :                 sub_positive(&amp;sa-&gt;runnable_avg, r);</a>
<a name="3771"><span class="lineNum">    3771 </span>            :                 sub_positive(&amp;sa-&gt;runnable_sum, r * divider);</a>
<a name="3772"><span class="lineNum">    3772 </span>            :                 /* See sa-&gt;util_sum above */</a>
<a name="3773"><span class="lineNum">    3773 </span>            :                 sa-&gt;runnable_sum = max_t(u32, sa-&gt;runnable_sum,</a>
<a name="3774"><span class="lineNum">    3774 </span>            :                                               sa-&gt;runnable_avg * PELT_MIN_DIVIDER);</a>
<a name="3775"><span class="lineNum">    3775 </span>            : </a>
<a name="3776"><span class="lineNum">    3776 </span>            :                 /*</a>
<a name="3777"><span class="lineNum">    3777 </span>            :                  * removed_runnable is the unweighted version of removed_load so we</a>
<a name="3778"><span class="lineNum">    3778 </span>            :                  * can use it to estimate removed_load_sum.</a>
<a name="3779"><span class="lineNum">    3779 </span>            :                  */</a>
<a name="3780"><span class="lineNum">    3780 </span>            :                 add_tg_cfs_propagate(cfs_rq,</a>
<a name="3781"><span class="lineNum">    3781 </span>            :                         -(long)(removed_runnable * divider) &gt;&gt; SCHED_CAPACITY_SHIFT);</a>
<a name="3782"><span class="lineNum">    3782 </span>            : </a>
<a name="3783"><span class="lineNum">    3783 </span>            :                 decayed = 1;</a>
<a name="3784"><span class="lineNum">    3784 </span>            :         }</a>
<a name="3785"><span class="lineNum">    3785 </span>            : </a>
<a name="3786"><span class="lineNum">    3786 </span>            :         decayed |= __update_load_avg_cfs_rq(now, cfs_rq);</a>
<a name="3787"><span class="lineNum">    3787 </span>            : </a>
<a name="3788"><span class="lineNum">    3788 </span>            : #ifndef CONFIG_64BIT</a>
<a name="3789"><span class="lineNum">    3789 </span>            :         smp_wmb();</a>
<a name="3790"><span class="lineNum">    3790 </span>            :         cfs_rq-&gt;load_last_update_time_copy = sa-&gt;last_update_time;</a>
<a name="3791"><span class="lineNum">    3791 </span>            : #endif</a>
<a name="3792"><span class="lineNum">    3792 </span>            : </a>
<a name="3793"><span class="lineNum">    3793 </span>            :         return decayed;</a>
<a name="3794"><span class="lineNum">    3794 </span>            : }</a>
<a name="3795"><span class="lineNum">    3795 </span>            : </a>
<a name="3796"><span class="lineNum">    3796 </span>            : /**</a>
<a name="3797"><span class="lineNum">    3797 </span>            :  * attach_entity_load_avg - attach this entity to its cfs_rq load avg</a>
<a name="3798"><span class="lineNum">    3798 </span>            :  * @cfs_rq: cfs_rq to attach to</a>
<a name="3799"><span class="lineNum">    3799 </span>            :  * @se: sched_entity to attach</a>
<a name="3800"><span class="lineNum">    3800 </span>            :  *</a>
<a name="3801"><span class="lineNum">    3801 </span>            :  * Must call update_cfs_rq_load_avg() before this, since we rely on</a>
<a name="3802"><span class="lineNum">    3802 </span>            :  * cfs_rq-&gt;avg.last_update_time being current.</a>
<a name="3803"><span class="lineNum">    3803 </span>            :  */</a>
<a name="3804"><span class="lineNum">    3804 </span>            : static void attach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="3805"><span class="lineNum">    3805 </span>            : {</a>
<a name="3806"><span class="lineNum">    3806 </span>            :         /*</a>
<a name="3807"><span class="lineNum">    3807 </span>            :          * cfs_rq-&gt;avg.period_contrib can be used for both cfs_rq and se.</a>
<a name="3808"><span class="lineNum">    3808 </span>            :          * See ___update_load_avg() for details.</a>
<a name="3809"><span class="lineNum">    3809 </span>            :          */</a>
<a name="3810"><span class="lineNum">    3810 </span>            :         u32 divider = get_pelt_divider(&amp;cfs_rq-&gt;avg);</a>
<a name="3811"><span class="lineNum">    3811 </span>            : </a>
<a name="3812"><span class="lineNum">    3812 </span>            :         /*</a>
<a name="3813"><span class="lineNum">    3813 </span>            :          * When we attach the @se to the @cfs_rq, we must align the decay</a>
<a name="3814"><span class="lineNum">    3814 </span>            :          * window because without that, really weird and wonderful things can</a>
<a name="3815"><span class="lineNum">    3815 </span>            :          * happen.</a>
<a name="3816"><span class="lineNum">    3816 </span>            :          *</a>
<a name="3817"><span class="lineNum">    3817 </span>            :          * XXX illustrate</a>
<a name="3818"><span class="lineNum">    3818 </span>            :          */</a>
<a name="3819"><span class="lineNum">    3819 </span>            :         se-&gt;avg.last_update_time = cfs_rq-&gt;avg.last_update_time;</a>
<a name="3820"><span class="lineNum">    3820 </span>            :         se-&gt;avg.period_contrib = cfs_rq-&gt;avg.period_contrib;</a>
<a name="3821"><span class="lineNum">    3821 </span>            : </a>
<a name="3822"><span class="lineNum">    3822 </span>            :         /*</a>
<a name="3823"><span class="lineNum">    3823 </span>            :          * Hell(o) Nasty stuff.. we need to recompute _sum based on the new</a>
<a name="3824"><span class="lineNum">    3824 </span>            :          * period_contrib. This isn't strictly correct, but since we're</a>
<a name="3825"><span class="lineNum">    3825 </span>            :          * entirely outside of the PELT hierarchy, nobody cares if we truncate</a>
<a name="3826"><span class="lineNum">    3826 </span>            :          * _sum a little.</a>
<a name="3827"><span class="lineNum">    3827 </span>            :          */</a>
<a name="3828"><span class="lineNum">    3828 </span>            :         se-&gt;avg.util_sum = se-&gt;avg.util_avg * divider;</a>
<a name="3829"><span class="lineNum">    3829 </span>            : </a>
<a name="3830"><span class="lineNum">    3830 </span>            :         se-&gt;avg.runnable_sum = se-&gt;avg.runnable_avg * divider;</a>
<a name="3831"><span class="lineNum">    3831 </span>            : </a>
<a name="3832"><span class="lineNum">    3832 </span>            :         se-&gt;avg.load_sum = se-&gt;avg.load_avg * divider;</a>
<a name="3833"><span class="lineNum">    3833 </span>            :         if (se_weight(se) &lt; se-&gt;avg.load_sum)</a>
<a name="3834"><span class="lineNum">    3834 </span>            :                 se-&gt;avg.load_sum = div_u64(se-&gt;avg.load_sum, se_weight(se));</a>
<a name="3835"><span class="lineNum">    3835 </span>            :         else</a>
<a name="3836"><span class="lineNum">    3836 </span>            :                 se-&gt;avg.load_sum = 1;</a>
<a name="3837"><span class="lineNum">    3837 </span>            : </a>
<a name="3838"><span class="lineNum">    3838 </span>            :         enqueue_load_avg(cfs_rq, se);</a>
<a name="3839"><span class="lineNum">    3839 </span>            :         cfs_rq-&gt;avg.util_avg += se-&gt;avg.util_avg;</a>
<a name="3840"><span class="lineNum">    3840 </span>            :         cfs_rq-&gt;avg.util_sum += se-&gt;avg.util_sum;</a>
<a name="3841"><span class="lineNum">    3841 </span>            :         cfs_rq-&gt;avg.runnable_avg += se-&gt;avg.runnable_avg;</a>
<a name="3842"><span class="lineNum">    3842 </span>            :         cfs_rq-&gt;avg.runnable_sum += se-&gt;avg.runnable_sum;</a>
<a name="3843"><span class="lineNum">    3843 </span>            : </a>
<a name="3844"><span class="lineNum">    3844 </span>            :         add_tg_cfs_propagate(cfs_rq, se-&gt;avg.load_sum);</a>
<a name="3845"><span class="lineNum">    3845 </span>            : </a>
<a name="3846"><span class="lineNum">    3846 </span>            :         cfs_rq_util_change(cfs_rq, 0);</a>
<a name="3847"><span class="lineNum">    3847 </span>            : </a>
<a name="3848"><span class="lineNum">    3848 </span>            :         trace_pelt_cfs_tp(cfs_rq);</a>
<a name="3849"><span class="lineNum">    3849 </span>            : }</a>
<a name="3850"><span class="lineNum">    3850 </span>            : </a>
<a name="3851"><span class="lineNum">    3851 </span>            : /**</a>
<a name="3852"><span class="lineNum">    3852 </span>            :  * detach_entity_load_avg - detach this entity from its cfs_rq load avg</a>
<a name="3853"><span class="lineNum">    3853 </span>            :  * @cfs_rq: cfs_rq to detach from</a>
<a name="3854"><span class="lineNum">    3854 </span>            :  * @se: sched_entity to detach</a>
<a name="3855"><span class="lineNum">    3855 </span>            :  *</a>
<a name="3856"><span class="lineNum">    3856 </span>            :  * Must call update_cfs_rq_load_avg() before this, since we rely on</a>
<a name="3857"><span class="lineNum">    3857 </span>            :  * cfs_rq-&gt;avg.last_update_time being current.</a>
<a name="3858"><span class="lineNum">    3858 </span>            :  */</a>
<a name="3859"><span class="lineNum">    3859 </span>            : static void detach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="3860"><span class="lineNum">    3860 </span>            : {</a>
<a name="3861"><span class="lineNum">    3861 </span>            :         dequeue_load_avg(cfs_rq, se);</a>
<a name="3862"><span class="lineNum">    3862 </span>            :         sub_positive(&amp;cfs_rq-&gt;avg.util_avg, se-&gt;avg.util_avg);</a>
<a name="3863"><span class="lineNum">    3863 </span>            :         sub_positive(&amp;cfs_rq-&gt;avg.util_sum, se-&gt;avg.util_sum);</a>
<a name="3864"><span class="lineNum">    3864 </span>            :         /* See update_cfs_rq_load_avg() */</a>
<a name="3865"><span class="lineNum">    3865 </span>            :         cfs_rq-&gt;avg.util_sum = max_t(u32, cfs_rq-&gt;avg.util_sum,</a>
<a name="3866"><span class="lineNum">    3866 </span>            :                                           cfs_rq-&gt;avg.util_avg * PELT_MIN_DIVIDER);</a>
<a name="3867"><span class="lineNum">    3867 </span>            : </a>
<a name="3868"><span class="lineNum">    3868 </span>            :         sub_positive(&amp;cfs_rq-&gt;avg.runnable_avg, se-&gt;avg.runnable_avg);</a>
<a name="3869"><span class="lineNum">    3869 </span>            :         sub_positive(&amp;cfs_rq-&gt;avg.runnable_sum, se-&gt;avg.runnable_sum);</a>
<a name="3870"><span class="lineNum">    3870 </span>            :         /* See update_cfs_rq_load_avg() */</a>
<a name="3871"><span class="lineNum">    3871 </span>            :         cfs_rq-&gt;avg.runnable_sum = max_t(u32, cfs_rq-&gt;avg.runnable_sum,</a>
<a name="3872"><span class="lineNum">    3872 </span>            :                                               cfs_rq-&gt;avg.runnable_avg * PELT_MIN_DIVIDER);</a>
<a name="3873"><span class="lineNum">    3873 </span>            : </a>
<a name="3874"><span class="lineNum">    3874 </span>            :         add_tg_cfs_propagate(cfs_rq, -se-&gt;avg.load_sum);</a>
<a name="3875"><span class="lineNum">    3875 </span>            : </a>
<a name="3876"><span class="lineNum">    3876 </span>            :         cfs_rq_util_change(cfs_rq, 0);</a>
<a name="3877"><span class="lineNum">    3877 </span>            : </a>
<a name="3878"><span class="lineNum">    3878 </span>            :         trace_pelt_cfs_tp(cfs_rq);</a>
<a name="3879"><span class="lineNum">    3879 </span>            : }</a>
<a name="3880"><span class="lineNum">    3880 </span>            : </a>
<a name="3881"><span class="lineNum">    3881 </span>            : /*</a>
<a name="3882"><span class="lineNum">    3882 </span>            :  * Optional action to be done while updating the load average</a>
<a name="3883"><span class="lineNum">    3883 </span>            :  */</a>
<a name="3884"><span class="lineNum">    3884 </span>            : #define UPDATE_TG       0x1</a>
<a name="3885"><span class="lineNum">    3885 </span>            : #define SKIP_AGE_LOAD   0x2</a>
<a name="3886"><span class="lineNum">    3886 </span>            : #define DO_ATTACH       0x4</a>
<a name="3887"><span class="lineNum">    3887 </span>            : </a>
<a name="3888"><span class="lineNum">    3888 </span>            : /* Update task and its cfs_rq load average */</a>
<a name="3889"><span class="lineNum">    3889 </span>            : static inline void update_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)</a>
<a name="3890"><span class="lineNum">    3890 </span>            : {</a>
<a name="3891"><span class="lineNum">    3891 </span>            :         u64 now = cfs_rq_clock_pelt(cfs_rq);</a>
<a name="3892"><span class="lineNum">    3892 </span>            :         int decayed;</a>
<a name="3893"><span class="lineNum">    3893 </span>            : </a>
<a name="3894"><span class="lineNum">    3894 </span>            :         /*</a>
<a name="3895"><span class="lineNum">    3895 </span>            :          * Track task load average for carrying it to new CPU after migrated, and</a>
<a name="3896"><span class="lineNum">    3896 </span>            :          * track group sched_entity load average for task_h_load calc in migration</a>
<a name="3897"><span class="lineNum">    3897 </span>            :          */</a>
<a name="3898"><span class="lineNum">    3898 </span>            :         if (se-&gt;avg.last_update_time &amp;&amp; !(flags &amp; SKIP_AGE_LOAD))</a>
<a name="3899"><span class="lineNum">    3899 </span>            :                 __update_load_avg_se(now, cfs_rq, se);</a>
<a name="3900"><span class="lineNum">    3900 </span>            : </a>
<a name="3901"><span class="lineNum">    3901 </span>            :         decayed  = update_cfs_rq_load_avg(now, cfs_rq);</a>
<a name="3902"><span class="lineNum">    3902 </span>            :         decayed |= propagate_entity_load_avg(se);</a>
<a name="3903"><span class="lineNum">    3903 </span>            : </a>
<a name="3904"><span class="lineNum">    3904 </span>            :         if (!se-&gt;avg.last_update_time &amp;&amp; (flags &amp; DO_ATTACH)) {</a>
<a name="3905"><span class="lineNum">    3905 </span>            : </a>
<a name="3906"><span class="lineNum">    3906 </span>            :                 /*</a>
<a name="3907"><span class="lineNum">    3907 </span>            :                  * DO_ATTACH means we're here from enqueue_entity().</a>
<a name="3908"><span class="lineNum">    3908 </span>            :                  * !last_update_time means we've passed through</a>
<a name="3909"><span class="lineNum">    3909 </span>            :                  * migrate_task_rq_fair() indicating we migrated.</a>
<a name="3910"><span class="lineNum">    3910 </span>            :                  *</a>
<a name="3911"><span class="lineNum">    3911 </span>            :                  * IOW we're enqueueing a task on a new CPU.</a>
<a name="3912"><span class="lineNum">    3912 </span>            :                  */</a>
<a name="3913"><span class="lineNum">    3913 </span>            :                 attach_entity_load_avg(cfs_rq, se);</a>
<a name="3914"><span class="lineNum">    3914 </span>            :                 update_tg_load_avg(cfs_rq);</a>
<a name="3915"><span class="lineNum">    3915 </span>            : </a>
<a name="3916"><span class="lineNum">    3916 </span>            :         } else if (decayed) {</a>
<a name="3917"><span class="lineNum">    3917 </span>            :                 cfs_rq_util_change(cfs_rq, 0);</a>
<a name="3918"><span class="lineNum">    3918 </span>            : </a>
<a name="3919"><span class="lineNum">    3919 </span>            :                 if (flags &amp; UPDATE_TG)</a>
<a name="3920"><span class="lineNum">    3920 </span>            :                         update_tg_load_avg(cfs_rq);</a>
<a name="3921"><span class="lineNum">    3921 </span>            :         }</a>
<a name="3922"><span class="lineNum">    3922 </span>            : }</a>
<a name="3923"><span class="lineNum">    3923 </span>            : </a>
<a name="3924"><span class="lineNum">    3924 </span>            : #ifndef CONFIG_64BIT</a>
<a name="3925"><span class="lineNum">    3925 </span>            : static inline u64 cfs_rq_last_update_time(struct cfs_rq *cfs_rq)</a>
<a name="3926"><span class="lineNum">    3926 </span>            : {</a>
<a name="3927"><span class="lineNum">    3927 </span>            :         u64 last_update_time_copy;</a>
<a name="3928"><span class="lineNum">    3928 </span>            :         u64 last_update_time;</a>
<a name="3929"><span class="lineNum">    3929 </span>            : </a>
<a name="3930"><span class="lineNum">    3930 </span>            :         do {</a>
<a name="3931"><span class="lineNum">    3931 </span>            :                 last_update_time_copy = cfs_rq-&gt;load_last_update_time_copy;</a>
<a name="3932"><span class="lineNum">    3932 </span>            :                 smp_rmb();</a>
<a name="3933"><span class="lineNum">    3933 </span>            :                 last_update_time = cfs_rq-&gt;avg.last_update_time;</a>
<a name="3934"><span class="lineNum">    3934 </span>            :         } while (last_update_time != last_update_time_copy);</a>
<a name="3935"><span class="lineNum">    3935 </span>            : </a>
<a name="3936"><span class="lineNum">    3936 </span>            :         return last_update_time;</a>
<a name="3937"><span class="lineNum">    3937 </span>            : }</a>
<a name="3938"><span class="lineNum">    3938 </span>            : #else</a>
<a name="3939"><span class="lineNum">    3939 </span>            : static inline u64 cfs_rq_last_update_time(struct cfs_rq *cfs_rq)</a>
<a name="3940"><span class="lineNum">    3940 </span>            : {</a>
<a name="3941"><span class="lineNum">    3941 </span>            :         return cfs_rq-&gt;avg.last_update_time;</a>
<a name="3942"><span class="lineNum">    3942 </span>            : }</a>
<a name="3943"><span class="lineNum">    3943 </span>            : #endif</a>
<a name="3944"><span class="lineNum">    3944 </span>            : </a>
<a name="3945"><span class="lineNum">    3945 </span>            : /*</a>
<a name="3946"><span class="lineNum">    3946 </span>            :  * Synchronize entity load avg of dequeued entity without locking</a>
<a name="3947"><span class="lineNum">    3947 </span>            :  * the previous rq.</a>
<a name="3948"><span class="lineNum">    3948 </span>            :  */</a>
<a name="3949"><span class="lineNum">    3949 </span>            : static void sync_entity_load_avg(struct sched_entity *se)</a>
<a name="3950"><span class="lineNum">    3950 </span>            : {</a>
<a name="3951"><span class="lineNum">    3951 </span>            :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</a>
<a name="3952"><span class="lineNum">    3952 </span>            :         u64 last_update_time;</a>
<a name="3953"><span class="lineNum">    3953 </span>            : </a>
<a name="3954"><span class="lineNum">    3954 </span>            :         last_update_time = cfs_rq_last_update_time(cfs_rq);</a>
<a name="3955"><span class="lineNum">    3955 </span>            :         __update_load_avg_blocked_se(last_update_time, se);</a>
<a name="3956"><span class="lineNum">    3956 </span>            : }</a>
<a name="3957"><span class="lineNum">    3957 </span>            : </a>
<a name="3958"><span class="lineNum">    3958 </span>            : /*</a>
<a name="3959"><span class="lineNum">    3959 </span>            :  * Task first catches up with cfs_rq, and then subtract</a>
<a name="3960"><span class="lineNum">    3960 </span>            :  * itself from the cfs_rq (task must be off the queue now).</a>
<a name="3961"><span class="lineNum">    3961 </span>            :  */</a>
<a name="3962"><span class="lineNum">    3962 </span>            : static void remove_entity_load_avg(struct sched_entity *se)</a>
<a name="3963"><span class="lineNum">    3963 </span>            : {</a>
<a name="3964"><span class="lineNum">    3964 </span>            :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</a>
<a name="3965"><span class="lineNum">    3965 </span>            :         unsigned long flags;</a>
<a name="3966"><span class="lineNum">    3966 </span>            : </a>
<a name="3967"><span class="lineNum">    3967 </span>            :         /*</a>
<a name="3968"><span class="lineNum">    3968 </span>            :          * tasks cannot exit without having gone through wake_up_new_task() -&gt;</a>
<a name="3969"><span class="lineNum">    3969 </span>            :          * post_init_entity_util_avg() which will have added things to the</a>
<a name="3970"><span class="lineNum">    3970 </span>            :          * cfs_rq, so we can remove unconditionally.</a>
<a name="3971"><span class="lineNum">    3971 </span>            :          */</a>
<a name="3972"><span class="lineNum">    3972 </span>            : </a>
<a name="3973"><span class="lineNum">    3973 </span>            :         sync_entity_load_avg(se);</a>
<a name="3974"><span class="lineNum">    3974 </span>            : </a>
<a name="3975"><span class="lineNum">    3975 </span>            :         raw_spin_lock_irqsave(&amp;cfs_rq-&gt;removed.lock, flags);</a>
<a name="3976"><span class="lineNum">    3976 </span>            :         ++cfs_rq-&gt;removed.nr;</a>
<a name="3977"><span class="lineNum">    3977 </span>            :         cfs_rq-&gt;removed.util_avg     += se-&gt;avg.util_avg;</a>
<a name="3978"><span class="lineNum">    3978 </span>            :         cfs_rq-&gt;removed.load_avg     += se-&gt;avg.load_avg;</a>
<a name="3979"><span class="lineNum">    3979 </span>            :         cfs_rq-&gt;removed.runnable_avg += se-&gt;avg.runnable_avg;</a>
<a name="3980"><span class="lineNum">    3980 </span>            :         raw_spin_unlock_irqrestore(&amp;cfs_rq-&gt;removed.lock, flags);</a>
<a name="3981"><span class="lineNum">    3981 </span>            : }</a>
<a name="3982"><span class="lineNum">    3982 </span>            : </a>
<a name="3983"><span class="lineNum">    3983 </span>            : static inline unsigned long cfs_rq_runnable_avg(struct cfs_rq *cfs_rq)</a>
<a name="3984"><span class="lineNum">    3984 </span>            : {</a>
<a name="3985"><span class="lineNum">    3985 </span>            :         return cfs_rq-&gt;avg.runnable_avg;</a>
<a name="3986"><span class="lineNum">    3986 </span>            : }</a>
<a name="3987"><span class="lineNum">    3987 </span>            : </a>
<a name="3988"><span class="lineNum">    3988 </span>            : static inline unsigned long cfs_rq_load_avg(struct cfs_rq *cfs_rq)</a>
<a name="3989"><span class="lineNum">    3989 </span>            : {</a>
<a name="3990"><span class="lineNum">    3990 </span>            :         return cfs_rq-&gt;avg.load_avg;</a>
<a name="3991"><span class="lineNum">    3991 </span>            : }</a>
<a name="3992"><span class="lineNum">    3992 </span>            : </a>
<a name="3993"><span class="lineNum">    3993 </span>            : static int newidle_balance(struct rq *this_rq, struct rq_flags *rf);</a>
<a name="3994"><span class="lineNum">    3994 </span>            : </a>
<a name="3995"><span class="lineNum">    3995 </span>            : static inline unsigned long task_util(struct task_struct *p)</a>
<a name="3996"><span class="lineNum">    3996 </span>            : {</a>
<a name="3997"><span class="lineNum">    3997 </span>            :         return READ_ONCE(p-&gt;se.avg.util_avg);</a>
<a name="3998"><span class="lineNum">    3998 </span>            : }</a>
<a name="3999"><span class="lineNum">    3999 </span>            : </a>
<a name="4000"><span class="lineNum">    4000 </span>            : static inline unsigned long _task_util_est(struct task_struct *p)</a>
<a name="4001"><span class="lineNum">    4001 </span>            : {</a>
<a name="4002"><span class="lineNum">    4002 </span>            :         struct util_est ue = READ_ONCE(p-&gt;se.avg.util_est);</a>
<a name="4003"><span class="lineNum">    4003 </span>            : </a>
<a name="4004"><span class="lineNum">    4004 </span>            :         return max(ue.ewma, (ue.enqueued &amp; ~UTIL_AVG_UNCHANGED));</a>
<a name="4005"><span class="lineNum">    4005 </span>            : }</a>
<a name="4006"><span class="lineNum">    4006 </span>            : </a>
<a name="4007"><span class="lineNum">    4007 </span>            : static inline unsigned long task_util_est(struct task_struct *p)</a>
<a name="4008"><span class="lineNum">    4008 </span>            : {</a>
<a name="4009"><span class="lineNum">    4009 </span>            :         return max(task_util(p), _task_util_est(p));</a>
<a name="4010"><span class="lineNum">    4010 </span>            : }</a>
<a name="4011"><span class="lineNum">    4011 </span>            : </a>
<a name="4012"><span class="lineNum">    4012 </span>            : #ifdef CONFIG_UCLAMP_TASK</a>
<a name="4013"><span class="lineNum">    4013 </span>            : static inline unsigned long uclamp_task_util(struct task_struct *p)</a>
<a name="4014"><span class="lineNum">    4014 </span>            : {</a>
<a name="4015"><span class="lineNum">    4015 </span>            :         return clamp(task_util_est(p),</a>
<a name="4016"><span class="lineNum">    4016 </span>            :                      uclamp_eff_value(p, UCLAMP_MIN),</a>
<a name="4017"><span class="lineNum">    4017 </span>            :                      uclamp_eff_value(p, UCLAMP_MAX));</a>
<a name="4018"><span class="lineNum">    4018 </span>            : }</a>
<a name="4019"><span class="lineNum">    4019 </span>            : #else</a>
<a name="4020"><span class="lineNum">    4020 </span>            : static inline unsigned long uclamp_task_util(struct task_struct *p)</a>
<a name="4021"><span class="lineNum">    4021 </span>            : {</a>
<a name="4022"><span class="lineNum">    4022 </span>            :         return task_util_est(p);</a>
<a name="4023"><span class="lineNum">    4023 </span>            : }</a>
<a name="4024"><span class="lineNum">    4024 </span>            : #endif</a>
<a name="4025"><span class="lineNum">    4025 </span>            : </a>
<a name="4026"><span class="lineNum">    4026 </span>            : static inline void util_est_enqueue(struct cfs_rq *cfs_rq,</a>
<a name="4027"><span class="lineNum">    4027 </span>            :                                     struct task_struct *p)</a>
<a name="4028"><span class="lineNum">    4028 </span>            : {</a>
<a name="4029"><span class="lineNum">    4029 </span>            :         unsigned int enqueued;</a>
<a name="4030"><span class="lineNum">    4030 </span>            : </a>
<a name="4031"><span class="lineNum">    4031 </span>            :         if (!sched_feat(UTIL_EST))</a>
<a name="4032"><span class="lineNum">    4032 </span>            :                 return;</a>
<a name="4033"><span class="lineNum">    4033 </span>            : </a>
<a name="4034"><span class="lineNum">    4034 </span>            :         /* Update root cfs_rq's estimated utilization */</a>
<a name="4035"><span class="lineNum">    4035 </span>            :         enqueued  = cfs_rq-&gt;avg.util_est.enqueued;</a>
<a name="4036"><span class="lineNum">    4036 </span>            :         enqueued += _task_util_est(p);</a>
<a name="4037"><span class="lineNum">    4037 </span>            :         WRITE_ONCE(cfs_rq-&gt;avg.util_est.enqueued, enqueued);</a>
<a name="4038"><span class="lineNum">    4038 </span>            : </a>
<a name="4039"><span class="lineNum">    4039 </span>            :         trace_sched_util_est_cfs_tp(cfs_rq);</a>
<a name="4040"><span class="lineNum">    4040 </span>            : }</a>
<a name="4041"><span class="lineNum">    4041 </span>            : </a>
<a name="4042"><span class="lineNum">    4042 </span>            : static inline void util_est_dequeue(struct cfs_rq *cfs_rq,</a>
<a name="4043"><span class="lineNum">    4043 </span>            :                                     struct task_struct *p)</a>
<a name="4044"><span class="lineNum">    4044 </span>            : {</a>
<a name="4045"><span class="lineNum">    4045 </span>            :         unsigned int enqueued;</a>
<a name="4046"><span class="lineNum">    4046 </span>            : </a>
<a name="4047"><span class="lineNum">    4047 </span>            :         if (!sched_feat(UTIL_EST))</a>
<a name="4048"><span class="lineNum">    4048 </span>            :                 return;</a>
<a name="4049"><span class="lineNum">    4049 </span>            : </a>
<a name="4050"><span class="lineNum">    4050 </span>            :         /* Update root cfs_rq's estimated utilization */</a>
<a name="4051"><span class="lineNum">    4051 </span>            :         enqueued  = cfs_rq-&gt;avg.util_est.enqueued;</a>
<a name="4052"><span class="lineNum">    4052 </span>            :         enqueued -= min_t(unsigned int, enqueued, _task_util_est(p));</a>
<a name="4053"><span class="lineNum">    4053 </span>            :         WRITE_ONCE(cfs_rq-&gt;avg.util_est.enqueued, enqueued);</a>
<a name="4054"><span class="lineNum">    4054 </span>            : </a>
<a name="4055"><span class="lineNum">    4055 </span>            :         trace_sched_util_est_cfs_tp(cfs_rq);</a>
<a name="4056"><span class="lineNum">    4056 </span>            : }</a>
<a name="4057"><span class="lineNum">    4057 </span>            : </a>
<a name="4058"><span class="lineNum">    4058 </span>            : #define UTIL_EST_MARGIN (SCHED_CAPACITY_SCALE / 100)</a>
<a name="4059"><span class="lineNum">    4059 </span>            : </a>
<a name="4060"><span class="lineNum">    4060 </span>            : /*</a>
<a name="4061"><span class="lineNum">    4061 </span>            :  * Check if a (signed) value is within a specified (unsigned) margin,</a>
<a name="4062"><span class="lineNum">    4062 </span>            :  * based on the observation that:</a>
<a name="4063"><span class="lineNum">    4063 </span>            :  *</a>
<a name="4064"><span class="lineNum">    4064 </span>            :  *     abs(x) &lt; y := (unsigned)(x + y - 1) &lt; (2 * y - 1)</a>
<a name="4065"><span class="lineNum">    4065 </span>            :  *</a>
<a name="4066"><span class="lineNum">    4066 </span>            :  * NOTE: this only works when value + margin &lt; INT_MAX.</a>
<a name="4067"><span class="lineNum">    4067 </span>            :  */</a>
<a name="4068"><span class="lineNum">    4068 </span>            : static inline bool within_margin(int value, int margin)</a>
<a name="4069"><span class="lineNum">    4069 </span>            : {</a>
<a name="4070"><span class="lineNum">    4070 </span>            :         return ((unsigned int)(value + margin - 1) &lt; (2 * margin - 1));</a>
<a name="4071"><span class="lineNum">    4071 </span>            : }</a>
<a name="4072"><span class="lineNum">    4072 </span>            : </a>
<a name="4073"><span class="lineNum">    4073 </span>            : static inline void util_est_update(struct cfs_rq *cfs_rq,</a>
<a name="4074"><span class="lineNum">    4074 </span>            :                                    struct task_struct *p,</a>
<a name="4075"><span class="lineNum">    4075 </span>            :                                    bool task_sleep)</a>
<a name="4076"><span class="lineNum">    4076 </span>            : {</a>
<a name="4077"><span class="lineNum">    4077 </span>            :         long last_ewma_diff, last_enqueued_diff;</a>
<a name="4078"><span class="lineNum">    4078 </span>            :         struct util_est ue;</a>
<a name="4079"><span class="lineNum">    4079 </span>            : </a>
<a name="4080"><span class="lineNum">    4080 </span>            :         if (!sched_feat(UTIL_EST))</a>
<a name="4081"><span class="lineNum">    4081 </span>            :                 return;</a>
<a name="4082"><span class="lineNum">    4082 </span>            : </a>
<a name="4083"><span class="lineNum">    4083 </span>            :         /*</a>
<a name="4084"><span class="lineNum">    4084 </span>            :          * Skip update of task's estimated utilization when the task has not</a>
<a name="4085"><span class="lineNum">    4085 </span>            :          * yet completed an activation, e.g. being migrated.</a>
<a name="4086"><span class="lineNum">    4086 </span>            :          */</a>
<a name="4087"><span class="lineNum">    4087 </span>            :         if (!task_sleep)</a>
<a name="4088"><span class="lineNum">    4088 </span>            :                 return;</a>
<a name="4089"><span class="lineNum">    4089 </span>            : </a>
<a name="4090"><span class="lineNum">    4090 </span>            :         /*</a>
<a name="4091"><span class="lineNum">    4091 </span>            :          * If the PELT values haven't changed since enqueue time,</a>
<a name="4092"><span class="lineNum">    4092 </span>            :          * skip the util_est update.</a>
<a name="4093"><span class="lineNum">    4093 </span>            :          */</a>
<a name="4094"><span class="lineNum">    4094 </span>            :         ue = p-&gt;se.avg.util_est;</a>
<a name="4095"><span class="lineNum">    4095 </span>            :         if (ue.enqueued &amp; UTIL_AVG_UNCHANGED)</a>
<a name="4096"><span class="lineNum">    4096 </span>            :                 return;</a>
<a name="4097"><span class="lineNum">    4097 </span>            : </a>
<a name="4098"><span class="lineNum">    4098 </span>            :         last_enqueued_diff = ue.enqueued;</a>
<a name="4099"><span class="lineNum">    4099 </span>            : </a>
<a name="4100"><span class="lineNum">    4100 </span>            :         /*</a>
<a name="4101"><span class="lineNum">    4101 </span>            :          * Reset EWMA on utilization increases, the moving average is used only</a>
<a name="4102"><span class="lineNum">    4102 </span>            :          * to smooth utilization decreases.</a>
<a name="4103"><span class="lineNum">    4103 </span>            :          */</a>
<a name="4104"><span class="lineNum">    4104 </span>            :         ue.enqueued = task_util(p);</a>
<a name="4105"><span class="lineNum">    4105 </span>            :         if (sched_feat(UTIL_EST_FASTUP)) {</a>
<a name="4106"><span class="lineNum">    4106 </span>            :                 if (ue.ewma &lt; ue.enqueued) {</a>
<a name="4107"><span class="lineNum">    4107 </span>            :                         ue.ewma = ue.enqueued;</a>
<a name="4108"><span class="lineNum">    4108 </span>            :                         goto done;</a>
<a name="4109"><span class="lineNum">    4109 </span>            :                 }</a>
<a name="4110"><span class="lineNum">    4110 </span>            :         }</a>
<a name="4111"><span class="lineNum">    4111 </span>            : </a>
<a name="4112"><span class="lineNum">    4112 </span>            :         /*</a>
<a name="4113"><span class="lineNum">    4113 </span>            :          * Skip update of task's estimated utilization when its members are</a>
<a name="4114"><span class="lineNum">    4114 </span>            :          * already ~1% close to its last activation value.</a>
<a name="4115"><span class="lineNum">    4115 </span>            :          */</a>
<a name="4116"><span class="lineNum">    4116 </span>            :         last_ewma_diff = ue.enqueued - ue.ewma;</a>
<a name="4117"><span class="lineNum">    4117 </span>            :         last_enqueued_diff -= ue.enqueued;</a>
<a name="4118"><span class="lineNum">    4118 </span>            :         if (within_margin(last_ewma_diff, UTIL_EST_MARGIN)) {</a>
<a name="4119"><span class="lineNum">    4119 </span>            :                 if (!within_margin(last_enqueued_diff, UTIL_EST_MARGIN))</a>
<a name="4120"><span class="lineNum">    4120 </span>            :                         goto done;</a>
<a name="4121"><span class="lineNum">    4121 </span>            : </a>
<a name="4122"><span class="lineNum">    4122 </span>            :                 return;</a>
<a name="4123"><span class="lineNum">    4123 </span>            :         }</a>
<a name="4124"><span class="lineNum">    4124 </span>            : </a>
<a name="4125"><span class="lineNum">    4125 </span>            :         /*</a>
<a name="4126"><span class="lineNum">    4126 </span>            :          * To avoid overestimation of actual task utilization, skip updates if</a>
<a name="4127"><span class="lineNum">    4127 </span>            :          * we cannot grant there is idle time in this CPU.</a>
<a name="4128"><span class="lineNum">    4128 </span>            :          */</a>
<a name="4129"><span class="lineNum">    4129 </span>            :         if (task_util(p) &gt; capacity_orig_of(cpu_of(rq_of(cfs_rq))))</a>
<a name="4130"><span class="lineNum">    4130 </span>            :                 return;</a>
<a name="4131"><span class="lineNum">    4131 </span>            : </a>
<a name="4132"><span class="lineNum">    4132 </span>            :         /*</a>
<a name="4133"><span class="lineNum">    4133 </span>            :          * Update Task's estimated utilization</a>
<a name="4134"><span class="lineNum">    4134 </span>            :          *</a>
<a name="4135"><span class="lineNum">    4135 </span>            :          * When *p completes an activation we can consolidate another sample</a>
<a name="4136"><span class="lineNum">    4136 </span>            :          * of the task size. This is done by storing the current PELT value</a>
<a name="4137"><span class="lineNum">    4137 </span>            :          * as ue.enqueued and by using this value to update the Exponential</a>
<a name="4138"><span class="lineNum">    4138 </span>            :          * Weighted Moving Average (EWMA):</a>
<a name="4139"><span class="lineNum">    4139 </span>            :          *</a>
<a name="4140"><span class="lineNum">    4140 </span>            :          *  ewma(t) = w *  task_util(p) + (1-w) * ewma(t-1)</a>
<a name="4141"><span class="lineNum">    4141 </span>            :          *          = w *  task_util(p) +         ewma(t-1)  - w * ewma(t-1)</a>
<a name="4142"><span class="lineNum">    4142 </span>            :          *          = w * (task_util(p) -         ewma(t-1)) +     ewma(t-1)</a>
<a name="4143"><span class="lineNum">    4143 </span>            :          *          = w * (      last_ewma_diff            ) +     ewma(t-1)</a>
<a name="4144"><span class="lineNum">    4144 </span>            :          *          = w * (last_ewma_diff  +  ewma(t-1) / w)</a>
<a name="4145"><span class="lineNum">    4145 </span>            :          *</a>
<a name="4146"><span class="lineNum">    4146 </span>            :          * Where 'w' is the weight of new samples, which is configured to be</a>
<a name="4147"><span class="lineNum">    4147 </span>            :          * 0.25, thus making w=1/4 ( &gt;&gt;= UTIL_EST_WEIGHT_SHIFT)</a>
<a name="4148"><span class="lineNum">    4148 </span>            :          */</a>
<a name="4149"><span class="lineNum">    4149 </span>            :         ue.ewma &lt;&lt;= UTIL_EST_WEIGHT_SHIFT;</a>
<a name="4150"><span class="lineNum">    4150 </span>            :         ue.ewma  += last_ewma_diff;</a>
<a name="4151"><span class="lineNum">    4151 </span>            :         ue.ewma &gt;&gt;= UTIL_EST_WEIGHT_SHIFT;</a>
<a name="4152"><span class="lineNum">    4152 </span>            : done:</a>
<a name="4153"><span class="lineNum">    4153 </span>            :         ue.enqueued |= UTIL_AVG_UNCHANGED;</a>
<a name="4154"><span class="lineNum">    4154 </span>            :         WRITE_ONCE(p-&gt;se.avg.util_est, ue);</a>
<a name="4155"><span class="lineNum">    4155 </span>            : </a>
<a name="4156"><span class="lineNum">    4156 </span>            :         trace_sched_util_est_se_tp(&amp;p-&gt;se);</a>
<a name="4157"><span class="lineNum">    4157 </span>            : }</a>
<a name="4158"><span class="lineNum">    4158 </span>            : </a>
<a name="4159"><span class="lineNum">    4159 </span>            : static inline int task_fits_capacity(struct task_struct *p,</a>
<a name="4160"><span class="lineNum">    4160 </span>            :                                      unsigned long capacity)</a>
<a name="4161"><span class="lineNum">    4161 </span>            : {</a>
<a name="4162"><span class="lineNum">    4162 </span>            :         return fits_capacity(uclamp_task_util(p), capacity);</a>
<a name="4163"><span class="lineNum">    4163 </span>            : }</a>
<a name="4164"><span class="lineNum">    4164 </span>            : </a>
<a name="4165"><span class="lineNum">    4165 </span>            : static inline void update_misfit_status(struct task_struct *p, struct rq *rq)</a>
<a name="4166"><span class="lineNum">    4166 </span>            : {</a>
<a name="4167"><span class="lineNum">    4167 </span>            :         if (!static_branch_unlikely(&amp;sched_asym_cpucapacity))</a>
<a name="4168"><span class="lineNum">    4168 </span>            :                 return;</a>
<a name="4169"><span class="lineNum">    4169 </span>            : </a>
<a name="4170"><span class="lineNum">    4170 </span>            :         if (!p || p-&gt;nr_cpus_allowed == 1) {</a>
<a name="4171"><span class="lineNum">    4171 </span>            :                 rq-&gt;misfit_task_load = 0;</a>
<a name="4172"><span class="lineNum">    4172 </span>            :                 return;</a>
<a name="4173"><span class="lineNum">    4173 </span>            :         }</a>
<a name="4174"><span class="lineNum">    4174 </span>            : </a>
<a name="4175"><span class="lineNum">    4175 </span>            :         if (task_fits_capacity(p, capacity_of(cpu_of(rq)))) {</a>
<a name="4176"><span class="lineNum">    4176 </span>            :                 rq-&gt;misfit_task_load = 0;</a>
<a name="4177"><span class="lineNum">    4177 </span>            :                 return;</a>
<a name="4178"><span class="lineNum">    4178 </span>            :         }</a>
<a name="4179"><span class="lineNum">    4179 </span>            : </a>
<a name="4180"><span class="lineNum">    4180 </span>            :         /*</a>
<a name="4181"><span class="lineNum">    4181 </span>            :          * Make sure that misfit_task_load will not be null even if</a>
<a name="4182"><span class="lineNum">    4182 </span>            :          * task_h_load() returns 0.</a>
<a name="4183"><span class="lineNum">    4183 </span>            :          */</a>
<a name="4184"><span class="lineNum">    4184 </span>            :         rq-&gt;misfit_task_load = max_t(unsigned long, task_h_load(p), 1);</a>
<a name="4185"><span class="lineNum">    4185 </span>            : }</a>
<a name="4186"><span class="lineNum">    4186 </span>            : </a>
<a name="4187"><span class="lineNum">    4187 </span>            : #else /* CONFIG_SMP */</a>
<a name="4188"><span class="lineNum">    4188 </span>            : </a>
<a name="4189"><span class="lineNum">    4189 </span>            : static inline bool cfs_rq_is_decayed(struct cfs_rq *cfs_rq)</a>
<a name="4190"><span class="lineNum">    4190 </span>            : {</a>
<a name="4191"><span class="lineNum">    4191 </span>            :         return true;</a>
<a name="4192"><span class="lineNum">    4192 </span>            : }</a>
<a name="4193"><span class="lineNum">    4193 </span>            : </a>
<a name="4194"><span class="lineNum">    4194 </span>            : #define UPDATE_TG       0x0</a>
<a name="4195"><span class="lineNum">    4195 </span>            : #define SKIP_AGE_LOAD   0x0</a>
<a name="4196"><span class="lineNum">    4196 </span>            : #define DO_ATTACH       0x0</a>
<a name="4197"><span class="lineNum">    4197 </span>            : </a>
<a name="4198"><span class="lineNum">    4198 </span>            : static inline void update_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se, int not_used1)</a>
<a name="4199"><span class="lineNum">    4199 </span>            : {</a>
<a name="4200"><span class="lineNum">    4200 </span><span class="lineCov">       1236 :         cfs_rq_util_change(cfs_rq, 0);</span></a>
<a name="4201"><span class="lineNum">    4201 </span>            : }</a>
<a name="4202"><span class="lineNum">    4202 </span>            : </a>
<a name="4203"><span class="lineNum">    4203 </span>            : static inline void remove_entity_load_avg(struct sched_entity *se) {}</a>
<a name="4204"><span class="lineNum">    4204 </span>            : </a>
<a name="4205"><span class="lineNum">    4205 </span>            : static inline void</a>
<a name="4206"><span class="lineNum">    4206 </span>            : attach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) {}</a>
<a name="4207"><span class="lineNum">    4207 </span>            : static inline void</a>
<a name="4208"><span class="lineNum">    4208 </span>            : detach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) {}</a>
<a name="4209"><span class="lineNum">    4209 </span>            : </a>
<a name="4210"><span class="lineNum">    4210 </span>            : static inline int newidle_balance(struct rq *rq, struct rq_flags *rf)</a>
<a name="4211"><span class="lineNum">    4211 </span>            : {</a>
<a name="4212"><span class="lineNum">    4212 </span>            :         return 0;</a>
<a name="4213"><span class="lineNum">    4213 </span>            : }</a>
<a name="4214"><span class="lineNum">    4214 </span>            : </a>
<a name="4215"><span class="lineNum">    4215 </span>            : static inline void</a>
<a name="4216"><span class="lineNum">    4216 </span>            : util_est_enqueue(struct cfs_rq *cfs_rq, struct task_struct *p) {}</a>
<a name="4217"><span class="lineNum">    4217 </span>            : </a>
<a name="4218"><span class="lineNum">    4218 </span>            : static inline void</a>
<a name="4219"><span class="lineNum">    4219 </span>            : util_est_dequeue(struct cfs_rq *cfs_rq, struct task_struct *p) {}</a>
<a name="4220"><span class="lineNum">    4220 </span>            : </a>
<a name="4221"><span class="lineNum">    4221 </span>            : static inline void</a>
<a name="4222"><span class="lineNum">    4222 </span>            : util_est_update(struct cfs_rq *cfs_rq, struct task_struct *p,</a>
<a name="4223"><span class="lineNum">    4223 </span>            :                 bool task_sleep) {}</a>
<a name="4224"><span class="lineNum">    4224 </span>            : static inline void update_misfit_status(struct task_struct *p, struct rq *rq) {}</a>
<a name="4225"><span class="lineNum">    4225 </span>            : </a>
<a name="4226"><span class="lineNum">    4226 </span>            : #endif /* CONFIG_SMP */</a>
<a name="4227"><span class="lineNum">    4227 </span>            : </a>
<a name="4228"><span class="lineNum">    4228 </span>            : static void check_spread(struct cfs_rq *cfs_rq, struct sched_entity *se)</a>
<a name="4229"><span class="lineNum">    4229 </span>            : {</a>
<a name="4230"><span class="lineNum">    4230 </span>            : #ifdef CONFIG_SCHED_DEBUG</a>
<a name="4231"><span class="lineNum">    4231 </span><span class="lineCov">       1235 :         s64 d = se-&gt;vruntime - cfs_rq-&gt;min_vruntime;</span></a>
<a name="4232"><span class="lineNum">    4232 </span>            : </a>
<a name="4233"><span class="lineNum">    4233 </span>            :         if (d &lt; 0)</a>
<a name="4234"><span class="lineNum">    4234 </span>            :                 d = -d;</a>
<a name="4235"><span class="lineNum">    4235 </span>            : </a>
<a name="4236"><span class="lineNum">    4236 </span>            :         if (d &gt; 3*sysctl_sched_latency)</a>
<a name="4237"><span class="lineNum">    4237 </span>            :                 schedstat_inc(cfs_rq-&gt;nr_spread_over);</a>
<a name="4238"><span class="lineNum">    4238 </span>            : #endif</a>
<a name="4239"><span class="lineNum">    4239 </span>            : }</a>
<a name="4240"><span class="lineNum">    4240 </span>            : </a>
<a name="4241"><span class="lineNum">    4241 </span>            : static void</a>
<a name="4242"><span class="lineNum">    4242 </span><span class="lineCov">        615 : place_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int initial)</span></a>
<a name="4243"><span class="lineNum">    4243 </span>            : {</a>
<a name="4244"><span class="lineNum">    4244 </span><span class="lineCov">        615 :         u64 vruntime = cfs_rq-&gt;min_vruntime;</span></a>
<a name="4245"><span class="lineNum">    4245 </span>            : </a>
<a name="4246"><span class="lineNum">    4246 </span>            :         /*</a>
<a name="4247"><span class="lineNum">    4247 </span>            :          * The 'current' period is already promised to the current tasks,</a>
<a name="4248"><span class="lineNum">    4248 </span>            :          * however the extra weight of the new task will slow them down a</a>
<a name="4249"><span class="lineNum">    4249 </span>            :          * little, place the new task so that it fits in the slot that</a>
<a name="4250"><span class="lineNum">    4250 </span>            :          * stays open at the end.</a>
<a name="4251"><span class="lineNum">    4251 </span>            :          */</a>
<a name="4252"><span class="lineNum">    4252 </span><span class="lineCov">        615 :         if (initial &amp;&amp; sched_feat(START_DEBIT))</span></a>
<a name="4253"><span class="lineNum">    4253 </span><span class="lineCov">        107 :                 vruntime += sched_vslice(cfs_rq, se);</span></a>
<a name="4254"><span class="lineNum">    4254 </span>            : </a>
<a name="4255"><span class="lineNum">    4255 </span>            :         /* sleeps up to a single latency don't count. */</a>
<a name="4256"><span class="lineNum">    4256 </span><span class="lineCov">        615 :         if (!initial) {</span></a>
<a name="4257"><span class="lineNum">    4257 </span>            :                 unsigned long thresh;</a>
<a name="4258"><span class="lineNum">    4258 </span>            : </a>
<a name="4259"><span class="lineNum">    4259 </span><span class="lineCov">        508 :                 if (se_is_idle(se))</span></a>
<a name="4260"><span class="lineNum">    4260 </span>            :                         thresh = sysctl_sched_min_granularity;</a>
<a name="4261"><span class="lineNum">    4261 </span>            :                 else</a>
<a name="4262"><span class="lineNum">    4262 </span><span class="lineCov">        508 :                         thresh = sysctl_sched_latency;</span></a>
<a name="4263"><span class="lineNum">    4263 </span>            : </a>
<a name="4264"><span class="lineNum">    4264 </span>            :                 /*</a>
<a name="4265"><span class="lineNum">    4265 </span>            :                  * Halve their sleep time's effect, to allow</a>
<a name="4266"><span class="lineNum">    4266 </span>            :                  * for a gentler effect of sleepers:</a>
<a name="4267"><span class="lineNum">    4267 </span>            :                  */</a>
<a name="4268"><span class="lineNum">    4268 </span><span class="lineCov">        508 :                 if (sched_feat(GENTLE_FAIR_SLEEPERS))</span></a>
<a name="4269"><span class="lineNum">    4269 </span><span class="lineCov">        508 :                         thresh &gt;&gt;= 1;</span></a>
<a name="4270"><span class="lineNum">    4270 </span>            : </a>
<a name="4271"><span class="lineNum">    4271 </span><span class="lineCov">        508 :                 vruntime -= thresh;</span></a>
<a name="4272"><span class="lineNum">    4272 </span>            :         }</a>
<a name="4273"><span class="lineNum">    4273 </span>            : </a>
<a name="4274"><span class="lineNum">    4274 </span>            :         /* ensure we never gain time by being placed backwards. */</a>
<a name="4275"><span class="lineNum">    4275 </span><span class="lineCov">       1230 :         se-&gt;vruntime = max_vruntime(se-&gt;vruntime, vruntime);</span></a>
<a name="4276"><span class="lineNum">    4276 </span><span class="lineCov">        615 : }</span></a>
<a name="4277"><span class="lineNum">    4277 </span>            : </a>
<a name="4278"><span class="lineNum">    4278 </span>            : static void check_enqueue_throttle(struct cfs_rq *cfs_rq);</a>
<a name="4279"><span class="lineNum">    4279 </span>            : </a>
<a name="4280"><span class="lineNum">    4280 </span>            : static inline bool cfs_bandwidth_used(void);</a>
<a name="4281"><span class="lineNum">    4281 </span>            : </a>
<a name="4282"><span class="lineNum">    4282 </span>            : /*</a>
<a name="4283"><span class="lineNum">    4283 </span>            :  * MIGRATION</a>
<a name="4284"><span class="lineNum">    4284 </span>            :  *</a>
<a name="4285"><span class="lineNum">    4285 </span>            :  *      dequeue</a>
<a name="4286"><span class="lineNum">    4286 </span>            :  *        update_curr()</a>
<a name="4287"><span class="lineNum">    4287 </span>            :  *          update_min_vruntime()</a>
<a name="4288"><span class="lineNum">    4288 </span>            :  *        vruntime -= min_vruntime</a>
<a name="4289"><span class="lineNum">    4289 </span>            :  *</a>
<a name="4290"><span class="lineNum">    4290 </span>            :  *      enqueue</a>
<a name="4291"><span class="lineNum">    4291 </span>            :  *        update_curr()</a>
<a name="4292"><span class="lineNum">    4292 </span>            :  *          update_min_vruntime()</a>
<a name="4293"><span class="lineNum">    4293 </span>            :  *        vruntime += min_vruntime</a>
<a name="4294"><span class="lineNum">    4294 </span>            :  *</a>
<a name="4295"><span class="lineNum">    4295 </span>            :  * this way the vruntime transition between RQs is done when both</a>
<a name="4296"><span class="lineNum">    4296 </span>            :  * min_vruntime are up-to-date.</a>
<a name="4297"><span class="lineNum">    4297 </span>            :  *</a>
<a name="4298"><span class="lineNum">    4298 </span>            :  * WAKEUP (remote)</a>
<a name="4299"><span class="lineNum">    4299 </span>            :  *</a>
<a name="4300"><span class="lineNum">    4300 </span>            :  *      -&gt;migrate_task_rq_fair() (p-&gt;state == TASK_WAKING)</a>
<a name="4301"><span class="lineNum">    4301 </span>            :  *        vruntime -= min_vruntime</a>
<a name="4302"><span class="lineNum">    4302 </span>            :  *</a>
<a name="4303"><span class="lineNum">    4303 </span>            :  *      enqueue</a>
<a name="4304"><span class="lineNum">    4304 </span>            :  *        update_curr()</a>
<a name="4305"><span class="lineNum">    4305 </span>            :  *          update_min_vruntime()</a>
<a name="4306"><span class="lineNum">    4306 </span>            :  *        vruntime += min_vruntime</a>
<a name="4307"><span class="lineNum">    4307 </span>            :  *</a>
<a name="4308"><span class="lineNum">    4308 </span>            :  * this way we don't have the most up-to-date min_vruntime on the originating</a>
<a name="4309"><span class="lineNum">    4309 </span>            :  * CPU and an up-to-date min_vruntime on the destination CPU.</a>
<a name="4310"><span class="lineNum">    4310 </span>            :  */</a>
<a name="4311"><span class="lineNum">    4311 </span>            : </a>
<a name="4312"><span class="lineNum">    4312 </span>            : static void</a>
<a name="4313"><span class="lineNum">    4313 </span><span class="lineCov">        618 : enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)</span></a>
<a name="4314"><span class="lineNum">    4314 </span>            : {</a>
<a name="4315"><span class="lineNum">    4315 </span><span class="lineCov">        618 :         bool renorm = !(flags &amp; ENQUEUE_WAKEUP) || (flags &amp; ENQUEUE_MIGRATED);</span></a>
<a name="4316"><span class="lineNum">    4316 </span><span class="lineCov">        618 :         bool curr = cfs_rq-&gt;curr == se;</span></a>
<a name="4317"><span class="lineNum">    4317 </span>            : </a>
<a name="4318"><span class="lineNum">    4318 </span>            :         /*</a>
<a name="4319"><span class="lineNum">    4319 </span>            :          * If we're the current task, we must renormalise before calling</a>
<a name="4320"><span class="lineNum">    4320 </span>            :          * update_curr().</a>
<a name="4321"><span class="lineNum">    4321 </span>            :          */</a>
<a name="4322"><span class="lineNum">    4322 </span><span class="lineCov">        618 :         if (renorm &amp;&amp; curr)</span></a>
<a name="4323"><span class="lineNum">    4323 </span><span class="lineNoCov">          0 :                 se-&gt;vruntime += cfs_rq-&gt;min_vruntime;</span></a>
<a name="4324"><span class="lineNum">    4324 </span>            : </a>
<a name="4325"><span class="lineNum">    4325 </span><span class="lineCov">        618 :         update_curr(cfs_rq);</span></a>
<a name="4326"><span class="lineNum">    4326 </span>            : </a>
<a name="4327"><span class="lineNum">    4327 </span>            :         /*</a>
<a name="4328"><span class="lineNum">    4328 </span>            :          * Otherwise, renormalise after, such that we're placed at the current</a>
<a name="4329"><span class="lineNum">    4329 </span>            :          * moment in time, instead of some random moment in the past. Being</a>
<a name="4330"><span class="lineNum">    4330 </span>            :          * placed in the past could significantly boost this task to the</a>
<a name="4331"><span class="lineNum">    4331 </span>            :          * fairness detriment of existing tasks.</a>
<a name="4332"><span class="lineNum">    4332 </span>            :          */</a>
<a name="4333"><span class="lineNum">    4333 </span><span class="lineCov">        618 :         if (renorm &amp;&amp; !curr)</span></a>
<a name="4334"><span class="lineNum">    4334 </span><span class="lineCov">        110 :                 se-&gt;vruntime += cfs_rq-&gt;min_vruntime;</span></a>
<a name="4335"><span class="lineNum">    4335 </span>            : </a>
<a name="4336"><span class="lineNum">    4336 </span>            :         /*</a>
<a name="4337"><span class="lineNum">    4337 </span>            :          * When enqueuing a sched_entity, we must:</a>
<a name="4338"><span class="lineNum">    4338 </span>            :          *   - Update loads to have both entity and cfs_rq synced with now.</a>
<a name="4339"><span class="lineNum">    4339 </span>            :          *   - Add its load to cfs_rq-&gt;runnable_avg</a>
<a name="4340"><span class="lineNum">    4340 </span>            :          *   - For group_entity, update its weight to reflect the new share of</a>
<a name="4341"><span class="lineNum">    4341 </span>            :          *     its group cfs_rq</a>
<a name="4342"><span class="lineNum">    4342 </span>            :          *   - Add its new weight to cfs_rq-&gt;load.weight</a>
<a name="4343"><span class="lineNum">    4343 </span>            :          */</a>
<a name="4344"><span class="lineNum">    4344 </span><span class="lineCov">        618 :         update_load_avg(cfs_rq, se, UPDATE_TG | DO_ATTACH);</span></a>
<a name="4345"><span class="lineNum">    4345 </span><span class="lineCov">        618 :         se_update_runnable(se);</span></a>
<a name="4346"><span class="lineNum">    4346 </span><span class="lineCov">        618 :         update_cfs_group(se);</span></a>
<a name="4347"><span class="lineNum">    4347 </span><span class="lineCov">       1236 :         account_entity_enqueue(cfs_rq, se);</span></a>
<a name="4348"><span class="lineNum">    4348 </span>            : </a>
<a name="4349"><span class="lineNum">    4349 </span><span class="lineCov">        618 :         if (flags &amp; ENQUEUE_WAKEUP)</span></a>
<a name="4350"><span class="lineNum">    4350 </span><span class="lineCov">        508 :                 place_entity(cfs_rq, se, 0);</span></a>
<a name="4351"><span class="lineNum">    4351 </span>            : </a>
<a name="4352"><span class="lineNum">    4352 </span>            :         check_schedstat_required();</a>
<a name="4353"><span class="lineNum">    4353 </span><span class="lineCov">        618 :         update_stats_enqueue_fair(cfs_rq, se, flags);</span></a>
<a name="4354"><span class="lineNum">    4354 </span><span class="lineCov">        618 :         check_spread(cfs_rq, se);</span></a>
<a name="4355"><span class="lineNum">    4355 </span><span class="lineCov">        618 :         if (!curr)</span></a>
<a name="4356"><span class="lineNum">    4356 </span><span class="lineCov">        618 :                 __enqueue_entity(cfs_rq, se);</span></a>
<a name="4357"><span class="lineNum">    4357 </span><span class="lineCov">        618 :         se-&gt;on_rq = 1;</span></a>
<a name="4358"><span class="lineNum">    4358 </span>            : </a>
<a name="4359"><span class="lineNum">    4359 </span>            :         /*</a>
<a name="4360"><span class="lineNum">    4360 </span>            :          * When bandwidth control is enabled, cfs might have been removed</a>
<a name="4361"><span class="lineNum">    4361 </span>            :          * because of a parent been throttled but cfs-&gt;nr_running &gt; 1. Try to</a>
<a name="4362"><span class="lineNum">    4362 </span>            :          * add it unconditionally.</a>
<a name="4363"><span class="lineNum">    4363 </span>            :          */</a>
<a name="4364"><span class="lineNum">    4364 </span>            :         if (cfs_rq-&gt;nr_running == 1 || cfs_bandwidth_used())</a>
<a name="4365"><span class="lineNum">    4365 </span>            :                 list_add_leaf_cfs_rq(cfs_rq);</a>
<a name="4366"><span class="lineNum">    4366 </span>            : </a>
<a name="4367"><span class="lineNum">    4367 </span>            :         if (cfs_rq-&gt;nr_running == 1)</a>
<a name="4368"><span class="lineNum">    4368 </span>            :                 check_enqueue_throttle(cfs_rq);</a>
<a name="4369"><span class="lineNum">    4369 </span><span class="lineCov">        618 : }</span></a>
<a name="4370"><span class="lineNum">    4370 </span>            : </a>
<a name="4371"><span class="lineNum">    4371 </span>            : static void __clear_buddies_last(struct sched_entity *se)</a>
<a name="4372"><span class="lineNum">    4372 </span>            : {</a>
<a name="4373"><span class="lineNum">    4373 </span><span class="lineNoCov">          0 :         for_each_sched_entity(se) {</span></a>
<a name="4374"><span class="lineNum">    4374 </span><span class="lineNoCov">          0 :                 struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="4375"><span class="lineNum">    4375 </span><span class="lineNoCov">          0 :                 if (cfs_rq-&gt;last != se)</span></a>
<a name="4376"><span class="lineNum">    4376 </span>            :                         break;</a>
<a name="4377"><span class="lineNum">    4377 </span>            : </a>
<a name="4378"><span class="lineNum">    4378 </span><span class="lineNoCov">          0 :                 cfs_rq-&gt;last = NULL;</span></a>
<a name="4379"><span class="lineNum">    4379 </span>            :         }</a>
<a name="4380"><span class="lineNum">    4380 </span>            : }</a>
<a name="4381"><span class="lineNum">    4381 </span>            : </a>
<a name="4382"><span class="lineNum">    4382 </span>            : static void __clear_buddies_next(struct sched_entity *se)</a>
<a name="4383"><span class="lineNum">    4383 </span>            : {</a>
<a name="4384"><span class="lineNum">    4384 </span><span class="lineCov">        199 :         for_each_sched_entity(se) {</span></a>
<a name="4385"><span class="lineNum">    4385 </span><span class="lineCov">        398 :                 struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="4386"><span class="lineNum">    4386 </span><span class="lineCov">        199 :                 if (cfs_rq-&gt;next != se)</span></a>
<a name="4387"><span class="lineNum">    4387 </span>            :                         break;</a>
<a name="4388"><span class="lineNum">    4388 </span>            : </a>
<a name="4389"><span class="lineNum">    4389 </span><span class="lineCov">        199 :                 cfs_rq-&gt;next = NULL;</span></a>
<a name="4390"><span class="lineNum">    4390 </span>            :         }</a>
<a name="4391"><span class="lineNum">    4391 </span>            : }</a>
<a name="4392"><span class="lineNum">    4392 </span>            : </a>
<a name="4393"><span class="lineNum">    4393 </span>            : static void __clear_buddies_skip(struct sched_entity *se)</a>
<a name="4394"><span class="lineNum">    4394 </span>            : {</a>
<a name="4395"><span class="lineNum">    4395 </span><span class="lineNoCov">          0 :         for_each_sched_entity(se) {</span></a>
<a name="4396"><span class="lineNum">    4396 </span><span class="lineNoCov">          0 :                 struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="4397"><span class="lineNum">    4397 </span><span class="lineNoCov">          0 :                 if (cfs_rq-&gt;skip != se)</span></a>
<a name="4398"><span class="lineNum">    4398 </span>            :                         break;</a>
<a name="4399"><span class="lineNum">    4399 </span>            : </a>
<a name="4400"><span class="lineNum">    4400 </span><span class="lineNoCov">          0 :                 cfs_rq-&gt;skip = NULL;</span></a>
<a name="4401"><span class="lineNum">    4401 </span>            :         }</a>
<a name="4402"><span class="lineNum">    4402 </span>            : }</a>
<a name="4403"><span class="lineNum">    4403 </span>            : </a>
<a name="4404"><span class="lineNum">    4404 </span><span class="lineCov">       1235 : static void clear_buddies(struct cfs_rq *cfs_rq, struct sched_entity *se)</span></a>
<a name="4405"><span class="lineNum">    4405 </span>            : {</a>
<a name="4406"><span class="lineNum">    4406 </span><span class="lineCov">       1235 :         if (cfs_rq-&gt;last == se)</span></a>
<a name="4407"><span class="lineNum">    4407 </span>            :                 __clear_buddies_last(se);</a>
<a name="4408"><span class="lineNum">    4408 </span>            : </a>
<a name="4409"><span class="lineNum">    4409 </span><span class="lineCov">       1235 :         if (cfs_rq-&gt;next == se)</span></a>
<a name="4410"><span class="lineNum">    4410 </span>            :                 __clear_buddies_next(se);</a>
<a name="4411"><span class="lineNum">    4411 </span>            : </a>
<a name="4412"><span class="lineNum">    4412 </span><span class="lineCov">       1235 :         if (cfs_rq-&gt;skip == se)</span></a>
<a name="4413"><span class="lineNum">    4413 </span>            :                 __clear_buddies_skip(se);</a>
<a name="4414"><span class="lineNum">    4414 </span><span class="lineCov">       1235 : }</span></a>
<a name="4415"><span class="lineNum">    4415 </span>            : </a>
<a name="4416"><span class="lineNum">    4416 </span>            : static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);</a>
<a name="4417"><span class="lineNum">    4417 </span>            : </a>
<a name="4418"><span class="lineNum">    4418 </span>            : static void</a>
<a name="4419"><span class="lineNum">    4419 </span><span class="lineCov">        616 : dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)</span></a>
<a name="4420"><span class="lineNum">    4420 </span>            : {</a>
<a name="4421"><span class="lineNum">    4421 </span>            :         /*</a>
<a name="4422"><span class="lineNum">    4422 </span>            :          * Update run-time statistics of the 'current'.</a>
<a name="4423"><span class="lineNum">    4423 </span>            :          */</a>
<a name="4424"><span class="lineNum">    4424 </span><span class="lineCov">        616 :         update_curr(cfs_rq);</span></a>
<a name="4425"><span class="lineNum">    4425 </span>            : </a>
<a name="4426"><span class="lineNum">    4426 </span>            :         /*</a>
<a name="4427"><span class="lineNum">    4427 </span>            :          * When dequeuing a sched_entity, we must:</a>
<a name="4428"><span class="lineNum">    4428 </span>            :          *   - Update loads to have both entity and cfs_rq synced with now.</a>
<a name="4429"><span class="lineNum">    4429 </span>            :          *   - Subtract its load from the cfs_rq-&gt;runnable_avg.</a>
<a name="4430"><span class="lineNum">    4430 </span>            :          *   - Subtract its previous weight from cfs_rq-&gt;load.weight.</a>
<a name="4431"><span class="lineNum">    4431 </span>            :          *   - For group entity, update its weight to reflect the new share</a>
<a name="4432"><span class="lineNum">    4432 </span>            :          *     of its group cfs_rq.</a>
<a name="4433"><span class="lineNum">    4433 </span>            :          */</a>
<a name="4434"><span class="lineNum">    4434 </span><span class="lineCov">        616 :         update_load_avg(cfs_rq, se, UPDATE_TG);</span></a>
<a name="4435"><span class="lineNum">    4435 </span><span class="lineCov">        616 :         se_update_runnable(se);</span></a>
<a name="4436"><span class="lineNum">    4436 </span>            : </a>
<a name="4437"><span class="lineNum">    4437 </span><span class="lineCov">        616 :         update_stats_dequeue_fair(cfs_rq, se, flags);</span></a>
<a name="4438"><span class="lineNum">    4438 </span>            : </a>
<a name="4439"><span class="lineNum">    4439 </span><span class="lineCov">        616 :         clear_buddies(cfs_rq, se);</span></a>
<a name="4440"><span class="lineNum">    4440 </span>            : </a>
<a name="4441"><span class="lineNum">    4441 </span><span class="lineCov">        616 :         if (se != cfs_rq-&gt;curr)</span></a>
<a name="4442"><span class="lineNum">    4442 </span>            :                 __dequeue_entity(cfs_rq, se);</a>
<a name="4443"><span class="lineNum">    4443 </span><span class="lineCov">        616 :         se-&gt;on_rq = 0;</span></a>
<a name="4444"><span class="lineNum">    4444 </span><span class="lineCov">       1232 :         account_entity_dequeue(cfs_rq, se);</span></a>
<a name="4445"><span class="lineNum">    4445 </span>            : </a>
<a name="4446"><span class="lineNum">    4446 </span>            :         /*</a>
<a name="4447"><span class="lineNum">    4447 </span>            :          * Normalize after update_curr(); which will also have moved</a>
<a name="4448"><span class="lineNum">    4448 </span>            :          * min_vruntime if @se is the one holding it back. But before doing</a>
<a name="4449"><span class="lineNum">    4449 </span>            :          * update_min_vruntime() again, which will discount @se's position and</a>
<a name="4450"><span class="lineNum">    4450 </span>            :          * can move min_vruntime forward still more.</a>
<a name="4451"><span class="lineNum">    4451 </span>            :          */</a>
<a name="4452"><span class="lineNum">    4452 </span><span class="lineCov">        616 :         if (!(flags &amp; DEQUEUE_SLEEP))</span></a>
<a name="4453"><span class="lineNum">    4453 </span><span class="lineCov">          3 :                 se-&gt;vruntime -= cfs_rq-&gt;min_vruntime;</span></a>
<a name="4454"><span class="lineNum">    4454 </span>            : </a>
<a name="4455"><span class="lineNum">    4455 </span>            :         /* return excess runtime on last dequeue */</a>
<a name="4456"><span class="lineNum">    4456 </span><span class="lineCov">        616 :         return_cfs_rq_runtime(cfs_rq);</span></a>
<a name="4457"><span class="lineNum">    4457 </span>            : </a>
<a name="4458"><span class="lineNum">    4458 </span><span class="lineCov">        616 :         update_cfs_group(se);</span></a>
<a name="4459"><span class="lineNum">    4459 </span>            : </a>
<a name="4460"><span class="lineNum">    4460 </span>            :         /*</a>
<a name="4461"><span class="lineNum">    4461 </span>            :          * Now advance min_vruntime if @se was the entity holding it back,</a>
<a name="4462"><span class="lineNum">    4462 </span>            :          * except when: DEQUEUE_SAVE &amp;&amp; !DEQUEUE_MOVE, in this case we'll be</a>
<a name="4463"><span class="lineNum">    4463 </span>            :          * put back on, and if we advance min_vruntime, we'll be placed back</a>
<a name="4464"><span class="lineNum">    4464 </span>            :          * further than we started -- ie. we'll be penalized.</a>
<a name="4465"><span class="lineNum">    4465 </span>            :          */</a>
<a name="4466"><span class="lineNum">    4466 </span><span class="lineCov">        616 :         if ((flags &amp; (DEQUEUE_SAVE | DEQUEUE_MOVE)) != DEQUEUE_SAVE)</span></a>
<a name="4467"><span class="lineNum">    4467 </span><span class="lineCov">        613 :                 update_min_vruntime(cfs_rq);</span></a>
<a name="4468"><span class="lineNum">    4468 </span><span class="lineCov">        616 : }</span></a>
<a name="4469"><span class="lineNum">    4469 </span>            : </a>
<a name="4470"><span class="lineNum">    4470 </span>            : /*</a>
<a name="4471"><span class="lineNum">    4471 </span>            :  * Preempt the current task with a newly woken task if needed:</a>
<a name="4472"><span class="lineNum">    4472 </span>            :  */</a>
<a name="4473"><span class="lineNum">    4473 </span>            : static void</a>
<a name="4474"><span class="lineNum">    4474 </span><span class="lineCov">          1 : check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)</span></a>
<a name="4475"><span class="lineNum">    4475 </span>            : {</a>
<a name="4476"><span class="lineNum">    4476 </span>            :         unsigned long ideal_runtime, delta_exec;</a>
<a name="4477"><span class="lineNum">    4477 </span>            :         struct sched_entity *se;</a>
<a name="4478"><span class="lineNum">    4478 </span>            :         s64 delta;</a>
<a name="4479"><span class="lineNum">    4479 </span>            : </a>
<a name="4480"><span class="lineNum">    4480 </span><span class="lineCov">          1 :         ideal_runtime = sched_slice(cfs_rq, curr);</span></a>
<a name="4481"><span class="lineNum">    4481 </span><span class="lineCov">          1 :         delta_exec = curr-&gt;sum_exec_runtime - curr-&gt;prev_sum_exec_runtime;</span></a>
<a name="4482"><span class="lineNum">    4482 </span><span class="lineCov">          1 :         if (delta_exec &gt; ideal_runtime) {</span></a>
<a name="4483"><span class="lineNum">    4483 </span><span class="lineCov">          1 :                 resched_curr(rq_of(cfs_rq));</span></a>
<a name="4484"><span class="lineNum">    4484 </span>            :                 /*</a>
<a name="4485"><span class="lineNum">    4485 </span>            :                  * The current task ran long enough, ensure it doesn't get</a>
<a name="4486"><span class="lineNum">    4486 </span>            :                  * re-elected due to buddy favours.</a>
<a name="4487"><span class="lineNum">    4487 </span>            :                  */</a>
<a name="4488"><span class="lineNum">    4488 </span><span class="lineCov">          1 :                 clear_buddies(cfs_rq, curr);</span></a>
<a name="4489"><span class="lineNum">    4489 </span><span class="lineCov">          1 :                 return;</span></a>
<a name="4490"><span class="lineNum">    4490 </span>            :         }</a>
<a name="4491"><span class="lineNum">    4491 </span>            : </a>
<a name="4492"><span class="lineNum">    4492 </span>            :         /*</a>
<a name="4493"><span class="lineNum">    4493 </span>            :          * Ensure that a task that missed wakeup preemption by a</a>
<a name="4494"><span class="lineNum">    4494 </span>            :          * narrow margin doesn't have to wait for a full slice.</a>
<a name="4495"><span class="lineNum">    4495 </span>            :          * This also mitigates buddy induced latencies under load.</a>
<a name="4496"><span class="lineNum">    4496 </span>            :          */</a>
<a name="4497"><span class="lineNum">    4497 </span><span class="lineNoCov">          0 :         if (delta_exec &lt; sysctl_sched_min_granularity)</span></a>
<a name="4498"><span class="lineNum">    4498 </span>            :                 return;</a>
<a name="4499"><span class="lineNum">    4499 </span>            : </a>
<a name="4500"><span class="lineNum">    4500 </span><span class="lineNoCov">          0 :         se = __pick_first_entity(cfs_rq);</span></a>
<a name="4501"><span class="lineNum">    4501 </span><span class="lineNoCov">          0 :         delta = curr-&gt;vruntime - se-&gt;vruntime;</span></a>
<a name="4502"><span class="lineNum">    4502 </span>            : </a>
<a name="4503"><span class="lineNum">    4503 </span><span class="lineNoCov">          0 :         if (delta &lt; 0)</span></a>
<a name="4504"><span class="lineNum">    4504 </span>            :                 return;</a>
<a name="4505"><span class="lineNum">    4505 </span>            : </a>
<a name="4506"><span class="lineNum">    4506 </span><span class="lineNoCov">          0 :         if (delta &gt; ideal_runtime)</span></a>
<a name="4507"><span class="lineNum">    4507 </span><span class="lineNoCov">          0 :                 resched_curr(rq_of(cfs_rq));</span></a>
<a name="4508"><span class="lineNum">    4508 </span>            : }</a>
<a name="4509"><span class="lineNum">    4509 </span>            : </a>
<a name="4510"><span class="lineNum">    4510 </span>            : static void</a>
<a name="4511"><span class="lineNum">    4511 </span><span class="lineCov">        618 : set_next_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)</span></a>
<a name="4512"><span class="lineNum">    4512 </span>            : {</a>
<a name="4513"><span class="lineNum">    4513 </span><span class="lineCov">        618 :         clear_buddies(cfs_rq, se);</span></a>
<a name="4514"><span class="lineNum">    4514 </span>            : </a>
<a name="4515"><span class="lineNum">    4515 </span>            :         /* 'current' is not kept within the tree. */</a>
<a name="4516"><span class="lineNum">    4516 </span><span class="lineCov">        618 :         if (se-&gt;on_rq) {</span></a>
<a name="4517"><span class="lineNum">    4517 </span>            :                 /*</a>
<a name="4518"><span class="lineNum">    4518 </span>            :                  * Any task has to be enqueued before it get to execute on</a>
<a name="4519"><span class="lineNum">    4519 </span>            :                  * a CPU. So account for the time it spent waiting on the</a>
<a name="4520"><span class="lineNum">    4520 </span>            :                  * runqueue.</a>
<a name="4521"><span class="lineNum">    4521 </span>            :                  */</a>
<a name="4522"><span class="lineNum">    4522 </span><span class="lineCov">       1236 :                 update_stats_wait_end_fair(cfs_rq, se);</span></a>
<a name="4523"><span class="lineNum">    4523 </span>            :                 __dequeue_entity(cfs_rq, se);</a>
<a name="4524"><span class="lineNum">    4524 </span>            :                 update_load_avg(cfs_rq, se, UPDATE_TG);</a>
<a name="4525"><span class="lineNum">    4525 </span>            :         }</a>
<a name="4526"><span class="lineNum">    4526 </span>            : </a>
<a name="4527"><span class="lineNum">    4527 </span><span class="lineCov">       1236 :         update_stats_curr_start(cfs_rq, se);</span></a>
<a name="4528"><span class="lineNum">    4528 </span><span class="lineCov">        618 :         cfs_rq-&gt;curr = se;</span></a>
<a name="4529"><span class="lineNum">    4529 </span>            : </a>
<a name="4530"><span class="lineNum">    4530 </span>            :         /*</a>
<a name="4531"><span class="lineNum">    4531 </span>            :          * Track our maximum slice length, if the CPU's load is at</a>
<a name="4532"><span class="lineNum">    4532 </span>            :          * least twice that of our own weight (i.e. dont track it</a>
<a name="4533"><span class="lineNum">    4533 </span>            :          * when there are only lesser-weight tasks around):</a>
<a name="4534"><span class="lineNum">    4534 </span>            :          */</a>
<a name="4535"><span class="lineNum">    4535 </span>            :         if (schedstat_enabled() &amp;&amp;</a>
<a name="4536"><span class="lineNum">    4536 </span>            :             rq_of(cfs_rq)-&gt;cfs.load.weight &gt;= 2*se-&gt;load.weight) {</a>
<a name="4537"><span class="lineNum">    4537 </span>            :                 struct sched_statistics *stats;</a>
<a name="4538"><span class="lineNum">    4538 </span>            : </a>
<a name="4539"><span class="lineNum">    4539 </span>            :                 stats = __schedstats_from_se(se);</a>
<a name="4540"><span class="lineNum">    4540 </span>            :                 __schedstat_set(stats-&gt;slice_max,</a>
<a name="4541"><span class="lineNum">    4541 </span>            :                                 max((u64)stats-&gt;slice_max,</a>
<a name="4542"><span class="lineNum">    4542 </span>            :                                     se-&gt;sum_exec_runtime - se-&gt;prev_sum_exec_runtime));</a>
<a name="4543"><span class="lineNum">    4543 </span>            :         }</a>
<a name="4544"><span class="lineNum">    4544 </span>            : </a>
<a name="4545"><span class="lineNum">    4545 </span><span class="lineCov">        618 :         se-&gt;prev_sum_exec_runtime = se-&gt;sum_exec_runtime;</span></a>
<a name="4546"><span class="lineNum">    4546 </span><span class="lineCov">        618 : }</span></a>
<a name="4547"><span class="lineNum">    4547 </span>            : </a>
<a name="4548"><span class="lineNum">    4548 </span>            : static int</a>
<a name="4549"><span class="lineNum">    4549 </span>            : wakeup_preempt_entity(struct sched_entity *curr, struct sched_entity *se);</a>
<a name="4550"><span class="lineNum">    4550 </span>            : </a>
<a name="4551"><span class="lineNum">    4551 </span>            : /*</a>
<a name="4552"><span class="lineNum">    4552 </span>            :  * Pick the next process, keeping these things in mind, in this order:</a>
<a name="4553"><span class="lineNum">    4553 </span>            :  * 1) keep things fair between processes/task groups</a>
<a name="4554"><span class="lineNum">    4554 </span>            :  * 2) pick the &quot;next&quot; process, since someone really wants that to run</a>
<a name="4555"><span class="lineNum">    4555 </span>            :  * 3) pick the &quot;last&quot; process, for cache locality</a>
<a name="4556"><span class="lineNum">    4556 </span>            :  * 4) do not run the &quot;skip&quot; process, if something else is available</a>
<a name="4557"><span class="lineNum">    4557 </span>            :  */</a>
<a name="4558"><span class="lineNum">    4558 </span>            : static struct sched_entity *</a>
<a name="4559"><span class="lineNum">    4559 </span><span class="lineCov">        615 : pick_next_entity(struct cfs_rq *cfs_rq, struct sched_entity *curr)</span></a>
<a name="4560"><span class="lineNum">    4560 </span>            : {</a>
<a name="4561"><span class="lineNum">    4561 </span><span class="lineCov">        615 :         struct sched_entity *left = __pick_first_entity(cfs_rq);</span></a>
<a name="4562"><span class="lineNum">    4562 </span>            :         struct sched_entity *se;</a>
<a name="4563"><span class="lineNum">    4563 </span>            : </a>
<a name="4564"><span class="lineNum">    4564 </span>            :         /*</a>
<a name="4565"><span class="lineNum">    4565 </span>            :          * If curr is set we have to see if its left of the leftmost entity</a>
<a name="4566"><span class="lineNum">    4566 </span>            :          * still in the tree, provided there was anything in the tree at all.</a>
<a name="4567"><span class="lineNum">    4567 </span>            :          */</a>
<a name="4568"><span class="lineNum">    4568 </span><span class="lineCov">        615 :         if (!left || (curr &amp;&amp; entity_before(curr, left)))</span></a>
<a name="4569"><span class="lineNum">    4569 </span>            :                 left = curr;</a>
<a name="4570"><span class="lineNum">    4570 </span>            : </a>
<a name="4571"><span class="lineNum">    4571 </span><span class="lineCov">        615 :         se = left; /* ideally we run the leftmost entity */</span></a>
<a name="4572"><span class="lineNum">    4572 </span>            : </a>
<a name="4573"><span class="lineNum">    4573 </span>            :         /*</a>
<a name="4574"><span class="lineNum">    4574 </span>            :          * Avoid running the skip buddy, if running something else can</a>
<a name="4575"><span class="lineNum">    4575 </span>            :          * be done without getting too unfair.</a>
<a name="4576"><span class="lineNum">    4576 </span>            :          */</a>
<a name="4577"><span class="lineNum">    4577 </span><span class="lineCov">        615 :         if (cfs_rq-&gt;skip &amp;&amp; cfs_rq-&gt;skip == se) {</span></a>
<a name="4578"><span class="lineNum">    4578 </span>            :                 struct sched_entity *second;</a>
<a name="4579"><span class="lineNum">    4579 </span>            : </a>
<a name="4580"><span class="lineNum">    4580 </span><span class="lineNoCov">          0 :                 if (se == curr) {</span></a>
<a name="4581"><span class="lineNum">    4581 </span>            :                         second = __pick_first_entity(cfs_rq);</a>
<a name="4582"><span class="lineNum">    4582 </span>            :                 } else {</a>
<a name="4583"><span class="lineNum">    4583 </span><span class="lineNoCov">          0 :                         second = __pick_next_entity(se);</span></a>
<a name="4584"><span class="lineNum">    4584 </span><span class="lineNoCov">          0 :                         if (!second || (curr &amp;&amp; entity_before(curr, second)))</span></a>
<a name="4585"><span class="lineNum">    4585 </span>            :                                 second = curr;</a>
<a name="4586"><span class="lineNum">    4586 </span>            :                 }</a>
<a name="4587"><span class="lineNum">    4587 </span>            : </a>
<a name="4588"><span class="lineNum">    4588 </span><span class="lineNoCov">          0 :                 if (second &amp;&amp; wakeup_preempt_entity(second, left) &lt; 1)</span></a>
<a name="4589"><span class="lineNum">    4589 </span><span class="lineNoCov">          0 :                         se = second;</span></a>
<a name="4590"><span class="lineNum">    4590 </span>            :         }</a>
<a name="4591"><span class="lineNum">    4591 </span>            : </a>
<a name="4592"><span class="lineNum">    4592 </span><span class="lineCov">        615 :         if (cfs_rq-&gt;next &amp;&amp; wakeup_preempt_entity(cfs_rq-&gt;next, left) &lt; 1) {</span></a>
<a name="4593"><span class="lineNum">    4593 </span>            :                 /*</a>
<a name="4594"><span class="lineNum">    4594 </span>            :                  * Someone really wants this to run. If it's not unfair, run it.</a>
<a name="4595"><span class="lineNum">    4595 </span>            :                  */</a>
<a name="4596"><span class="lineNum">    4596 </span><span class="lineCov">        199 :                 se = cfs_rq-&gt;next;</span></a>
<a name="4597"><span class="lineNum">    4597 </span><span class="lineCov">        416 :         } else if (cfs_rq-&gt;last &amp;&amp; wakeup_preempt_entity(cfs_rq-&gt;last, left) &lt; 1) {</span></a>
<a name="4598"><span class="lineNum">    4598 </span>            :                 /*</a>
<a name="4599"><span class="lineNum">    4599 </span>            :                  * Prefer last buddy, try to return the CPU to a preempted task.</a>
<a name="4600"><span class="lineNum">    4600 </span>            :                  */</a>
<a name="4601"><span class="lineNum">    4601 </span><span class="lineNoCov">          0 :                 se = cfs_rq-&gt;last;</span></a>
<a name="4602"><span class="lineNum">    4602 </span>            :         }</a>
<a name="4603"><span class="lineNum">    4603 </span>            : </a>
<a name="4604"><span class="lineNum">    4604 </span><span class="lineCov">        615 :         return se;</span></a>
<a name="4605"><span class="lineNum">    4605 </span>            : }</a>
<a name="4606"><span class="lineNum">    4606 </span>            : </a>
<a name="4607"><span class="lineNum">    4607 </span>            : static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);</a>
<a name="4608"><span class="lineNum">    4608 </span>            : </a>
<a name="4609"><span class="lineNum">    4609 </span><span class="lineCov">        617 : static void put_prev_entity(struct cfs_rq *cfs_rq, struct sched_entity *prev)</span></a>
<a name="4610"><span class="lineNum">    4610 </span>            : {</a>
<a name="4611"><span class="lineNum">    4611 </span>            :         /*</a>
<a name="4612"><span class="lineNum">    4612 </span>            :          * If still on the runqueue then deactivate_task()</a>
<a name="4613"><span class="lineNum">    4613 </span>            :          * was not called and update_curr() has to be done:</a>
<a name="4614"><span class="lineNum">    4614 </span>            :          */</a>
<a name="4615"><span class="lineNum">    4615 </span><span class="lineCov">        617 :         if (prev-&gt;on_rq)</span></a>
<a name="4616"><span class="lineNum">    4616 </span><span class="lineCov">          1 :                 update_curr(cfs_rq);</span></a>
<a name="4617"><span class="lineNum">    4617 </span>            : </a>
<a name="4618"><span class="lineNum">    4618 </span>            :         /* throttle cfs_rqs exceeding runtime */</a>
<a name="4619"><span class="lineNum">    4619 </span><span class="lineCov">        617 :         check_cfs_rq_runtime(cfs_rq);</span></a>
<a name="4620"><span class="lineNum">    4620 </span>            : </a>
<a name="4621"><span class="lineNum">    4621 </span><span class="lineCov">        617 :         check_spread(cfs_rq, prev);</span></a>
<a name="4622"><span class="lineNum">    4622 </span>            : </a>
<a name="4623"><span class="lineNum">    4623 </span><span class="lineCov">        617 :         if (prev-&gt;on_rq) {</span></a>
<a name="4624"><span class="lineNum">    4624 </span><span class="lineCov">          1 :                 update_stats_wait_start_fair(cfs_rq, prev);</span></a>
<a name="4625"><span class="lineNum">    4625 </span>            :                 /* Put 'current' back into the tree. */</a>
<a name="4626"><span class="lineNum">    4626 </span><span class="lineCov">          1 :                 __enqueue_entity(cfs_rq, prev);</span></a>
<a name="4627"><span class="lineNum">    4627 </span>            :                 /* in !on_rq case, update occurred at dequeue */</a>
<a name="4628"><span class="lineNum">    4628 </span><span class="lineCov">          1 :                 update_load_avg(cfs_rq, prev, 0);</span></a>
<a name="4629"><span class="lineNum">    4629 </span>            :         }</a>
<a name="4630"><span class="lineNum">    4630 </span><span class="lineCov">        617 :         cfs_rq-&gt;curr = NULL;</span></a>
<a name="4631"><span class="lineNum">    4631 </span><span class="lineCov">        617 : }</span></a>
<a name="4632"><span class="lineNum">    4632 </span>            : </a>
<a name="4633"><span class="lineNum">    4633 </span>            : static void</a>
<a name="4634"><span class="lineNum">    4634 </span><span class="lineCov">          2 : entity_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr, int queued)</span></a>
<a name="4635"><span class="lineNum">    4635 </span>            : {</a>
<a name="4636"><span class="lineNum">    4636 </span>            :         /*</a>
<a name="4637"><span class="lineNum">    4637 </span>            :          * Update run-time statistics of the 'current'.</a>
<a name="4638"><span class="lineNum">    4638 </span>            :          */</a>
<a name="4639"><span class="lineNum">    4639 </span><span class="lineCov">          2 :         update_curr(cfs_rq);</span></a>
<a name="4640"><span class="lineNum">    4640 </span>            : </a>
<a name="4641"><span class="lineNum">    4641 </span>            :         /*</a>
<a name="4642"><span class="lineNum">    4642 </span>            :          * Ensure that runnable average is periodically updated.</a>
<a name="4643"><span class="lineNum">    4643 </span>            :          */</a>
<a name="4644"><span class="lineNum">    4644 </span><span class="lineCov">          2 :         update_load_avg(cfs_rq, curr, UPDATE_TG);</span></a>
<a name="4645"><span class="lineNum">    4645 </span><span class="lineCov">          2 :         update_cfs_group(curr);</span></a>
<a name="4646"><span class="lineNum">    4646 </span>            : </a>
<a name="4647"><span class="lineNum">    4647 </span>            : #ifdef CONFIG_SCHED_HRTICK</a>
<a name="4648"><span class="lineNum">    4648 </span>            :         /*</a>
<a name="4649"><span class="lineNum">    4649 </span>            :          * queued ticks are scheduled to match the slice, so don't bother</a>
<a name="4650"><span class="lineNum">    4650 </span>            :          * validating it and just reschedule.</a>
<a name="4651"><span class="lineNum">    4651 </span>            :          */</a>
<a name="4652"><span class="lineNum">    4652 </span>            :         if (queued) {</a>
<a name="4653"><span class="lineNum">    4653 </span>            :                 resched_curr(rq_of(cfs_rq));</a>
<a name="4654"><span class="lineNum">    4654 </span>            :                 return;</a>
<a name="4655"><span class="lineNum">    4655 </span>            :         }</a>
<a name="4656"><span class="lineNum">    4656 </span>            :         /*</a>
<a name="4657"><span class="lineNum">    4657 </span>            :          * don't let the period tick interfere with the hrtick preemption</a>
<a name="4658"><span class="lineNum">    4658 </span>            :          */</a>
<a name="4659"><span class="lineNum">    4659 </span>            :         if (!sched_feat(DOUBLE_TICK) &amp;&amp;</a>
<a name="4660"><span class="lineNum">    4660 </span>            :                         hrtimer_active(&amp;rq_of(cfs_rq)-&gt;hrtick_timer))</a>
<a name="4661"><span class="lineNum">    4661 </span>            :                 return;</a>
<a name="4662"><span class="lineNum">    4662 </span>            : #endif</a>
<a name="4663"><span class="lineNum">    4663 </span>            : </a>
<a name="4664"><span class="lineNum">    4664 </span><span class="lineCov">          2 :         if (cfs_rq-&gt;nr_running &gt; 1)</span></a>
<a name="4665"><span class="lineNum">    4665 </span><span class="lineCov">          1 :                 check_preempt_tick(cfs_rq, curr);</span></a>
<a name="4666"><span class="lineNum">    4666 </span><span class="lineCov">          2 : }</span></a>
<a name="4667"><span class="lineNum">    4667 </span>            : </a>
<a name="4668"><span class="lineNum">    4668 </span>            : </a>
<a name="4669"><span class="lineNum">    4669 </span>            : /**************************************************</a>
<a name="4670"><span class="lineNum">    4670 </span>            :  * CFS bandwidth control machinery</a>
<a name="4671"><span class="lineNum">    4671 </span>            :  */</a>
<a name="4672"><span class="lineNum">    4672 </span>            : </a>
<a name="4673"><span class="lineNum">    4673 </span>            : #ifdef CONFIG_CFS_BANDWIDTH</a>
<a name="4674"><span class="lineNum">    4674 </span>            : </a>
<a name="4675"><span class="lineNum">    4675 </span>            : #ifdef CONFIG_JUMP_LABEL</a>
<a name="4676"><span class="lineNum">    4676 </span>            : static struct static_key __cfs_bandwidth_used;</a>
<a name="4677"><span class="lineNum">    4677 </span>            : </a>
<a name="4678"><span class="lineNum">    4678 </span>            : static inline bool cfs_bandwidth_used(void)</a>
<a name="4679"><span class="lineNum">    4679 </span>            : {</a>
<a name="4680"><span class="lineNum">    4680 </span>            :         return static_key_false(&amp;__cfs_bandwidth_used);</a>
<a name="4681"><span class="lineNum">    4681 </span>            : }</a>
<a name="4682"><span class="lineNum">    4682 </span>            : </a>
<a name="4683"><span class="lineNum">    4683 </span>            : void cfs_bandwidth_usage_inc(void)</a>
<a name="4684"><span class="lineNum">    4684 </span>            : {</a>
<a name="4685"><span class="lineNum">    4685 </span>            :         static_key_slow_inc_cpuslocked(&amp;__cfs_bandwidth_used);</a>
<a name="4686"><span class="lineNum">    4686 </span>            : }</a>
<a name="4687"><span class="lineNum">    4687 </span>            : </a>
<a name="4688"><span class="lineNum">    4688 </span>            : void cfs_bandwidth_usage_dec(void)</a>
<a name="4689"><span class="lineNum">    4689 </span>            : {</a>
<a name="4690"><span class="lineNum">    4690 </span>            :         static_key_slow_dec_cpuslocked(&amp;__cfs_bandwidth_used);</a>
<a name="4691"><span class="lineNum">    4691 </span>            : }</a>
<a name="4692"><span class="lineNum">    4692 </span>            : #else /* CONFIG_JUMP_LABEL */</a>
<a name="4693"><span class="lineNum">    4693 </span>            : static bool cfs_bandwidth_used(void)</a>
<a name="4694"><span class="lineNum">    4694 </span>            : {</a>
<a name="4695"><span class="lineNum">    4695 </span>            :         return true;</a>
<a name="4696"><span class="lineNum">    4696 </span>            : }</a>
<a name="4697"><span class="lineNum">    4697 </span>            : </a>
<a name="4698"><span class="lineNum">    4698 </span>            : void cfs_bandwidth_usage_inc(void) {}</a>
<a name="4699"><span class="lineNum">    4699 </span>            : void cfs_bandwidth_usage_dec(void) {}</a>
<a name="4700"><span class="lineNum">    4700 </span>            : #endif /* CONFIG_JUMP_LABEL */</a>
<a name="4701"><span class="lineNum">    4701 </span>            : </a>
<a name="4702"><span class="lineNum">    4702 </span>            : /*</a>
<a name="4703"><span class="lineNum">    4703 </span>            :  * default period for cfs group bandwidth.</a>
<a name="4704"><span class="lineNum">    4704 </span>            :  * default: 0.1s, units: nanoseconds</a>
<a name="4705"><span class="lineNum">    4705 </span>            :  */</a>
<a name="4706"><span class="lineNum">    4706 </span>            : static inline u64 default_cfs_period(void)</a>
<a name="4707"><span class="lineNum">    4707 </span>            : {</a>
<a name="4708"><span class="lineNum">    4708 </span>            :         return 100000000ULL;</a>
<a name="4709"><span class="lineNum">    4709 </span>            : }</a>
<a name="4710"><span class="lineNum">    4710 </span>            : </a>
<a name="4711"><span class="lineNum">    4711 </span>            : static inline u64 sched_cfs_bandwidth_slice(void)</a>
<a name="4712"><span class="lineNum">    4712 </span>            : {</a>
<a name="4713"><span class="lineNum">    4713 </span>            :         return (u64)sysctl_sched_cfs_bandwidth_slice * NSEC_PER_USEC;</a>
<a name="4714"><span class="lineNum">    4714 </span>            : }</a>
<a name="4715"><span class="lineNum">    4715 </span>            : </a>
<a name="4716"><span class="lineNum">    4716 </span>            : /*</a>
<a name="4717"><span class="lineNum">    4717 </span>            :  * Replenish runtime according to assigned quota. We use sched_clock_cpu</a>
<a name="4718"><span class="lineNum">    4718 </span>            :  * directly instead of rq-&gt;clock to avoid adding additional synchronization</a>
<a name="4719"><span class="lineNum">    4719 </span>            :  * around rq-&gt;lock.</a>
<a name="4720"><span class="lineNum">    4720 </span>            :  *</a>
<a name="4721"><span class="lineNum">    4721 </span>            :  * requires cfs_b-&gt;lock</a>
<a name="4722"><span class="lineNum">    4722 </span>            :  */</a>
<a name="4723"><span class="lineNum">    4723 </span>            : void __refill_cfs_bandwidth_runtime(struct cfs_bandwidth *cfs_b)</a>
<a name="4724"><span class="lineNum">    4724 </span>            : {</a>
<a name="4725"><span class="lineNum">    4725 </span>            :         s64 runtime;</a>
<a name="4726"><span class="lineNum">    4726 </span>            : </a>
<a name="4727"><span class="lineNum">    4727 </span>            :         if (unlikely(cfs_b-&gt;quota == RUNTIME_INF))</a>
<a name="4728"><span class="lineNum">    4728 </span>            :                 return;</a>
<a name="4729"><span class="lineNum">    4729 </span>            : </a>
<a name="4730"><span class="lineNum">    4730 </span>            :         cfs_b-&gt;runtime += cfs_b-&gt;quota;</a>
<a name="4731"><span class="lineNum">    4731 </span>            :         runtime = cfs_b-&gt;runtime_snap - cfs_b-&gt;runtime;</a>
<a name="4732"><span class="lineNum">    4732 </span>            :         if (runtime &gt; 0) {</a>
<a name="4733"><span class="lineNum">    4733 </span>            :                 cfs_b-&gt;burst_time += runtime;</a>
<a name="4734"><span class="lineNum">    4734 </span>            :                 cfs_b-&gt;nr_burst++;</a>
<a name="4735"><span class="lineNum">    4735 </span>            :         }</a>
<a name="4736"><span class="lineNum">    4736 </span>            : </a>
<a name="4737"><span class="lineNum">    4737 </span>            :         cfs_b-&gt;runtime = min(cfs_b-&gt;runtime, cfs_b-&gt;quota + cfs_b-&gt;burst);</a>
<a name="4738"><span class="lineNum">    4738 </span>            :         cfs_b-&gt;runtime_snap = cfs_b-&gt;runtime;</a>
<a name="4739"><span class="lineNum">    4739 </span>            : }</a>
<a name="4740"><span class="lineNum">    4740 </span>            : </a>
<a name="4741"><span class="lineNum">    4741 </span>            : static inline struct cfs_bandwidth *tg_cfs_bandwidth(struct task_group *tg)</a>
<a name="4742"><span class="lineNum">    4742 </span>            : {</a>
<a name="4743"><span class="lineNum">    4743 </span>            :         return &amp;tg-&gt;cfs_bandwidth;</a>
<a name="4744"><span class="lineNum">    4744 </span>            : }</a>
<a name="4745"><span class="lineNum">    4745 </span>            : </a>
<a name="4746"><span class="lineNum">    4746 </span>            : /* returns 0 on failure to allocate runtime */</a>
<a name="4747"><span class="lineNum">    4747 </span>            : static int __assign_cfs_rq_runtime(struct cfs_bandwidth *cfs_b,</a>
<a name="4748"><span class="lineNum">    4748 </span>            :                                    struct cfs_rq *cfs_rq, u64 target_runtime)</a>
<a name="4749"><span class="lineNum">    4749 </span>            : {</a>
<a name="4750"><span class="lineNum">    4750 </span>            :         u64 min_amount, amount = 0;</a>
<a name="4751"><span class="lineNum">    4751 </span>            : </a>
<a name="4752"><span class="lineNum">    4752 </span>            :         lockdep_assert_held(&amp;cfs_b-&gt;lock);</a>
<a name="4753"><span class="lineNum">    4753 </span>            : </a>
<a name="4754"><span class="lineNum">    4754 </span>            :         /* note: this is a positive sum as runtime_remaining &lt;= 0 */</a>
<a name="4755"><span class="lineNum">    4755 </span>            :         min_amount = target_runtime - cfs_rq-&gt;runtime_remaining;</a>
<a name="4756"><span class="lineNum">    4756 </span>            : </a>
<a name="4757"><span class="lineNum">    4757 </span>            :         if (cfs_b-&gt;quota == RUNTIME_INF)</a>
<a name="4758"><span class="lineNum">    4758 </span>            :                 amount = min_amount;</a>
<a name="4759"><span class="lineNum">    4759 </span>            :         else {</a>
<a name="4760"><span class="lineNum">    4760 </span>            :                 start_cfs_bandwidth(cfs_b);</a>
<a name="4761"><span class="lineNum">    4761 </span>            : </a>
<a name="4762"><span class="lineNum">    4762 </span>            :                 if (cfs_b-&gt;runtime &gt; 0) {</a>
<a name="4763"><span class="lineNum">    4763 </span>            :                         amount = min(cfs_b-&gt;runtime, min_amount);</a>
<a name="4764"><span class="lineNum">    4764 </span>            :                         cfs_b-&gt;runtime -= amount;</a>
<a name="4765"><span class="lineNum">    4765 </span>            :                         cfs_b-&gt;idle = 0;</a>
<a name="4766"><span class="lineNum">    4766 </span>            :                 }</a>
<a name="4767"><span class="lineNum">    4767 </span>            :         }</a>
<a name="4768"><span class="lineNum">    4768 </span>            : </a>
<a name="4769"><span class="lineNum">    4769 </span>            :         cfs_rq-&gt;runtime_remaining += amount;</a>
<a name="4770"><span class="lineNum">    4770 </span>            : </a>
<a name="4771"><span class="lineNum">    4771 </span>            :         return cfs_rq-&gt;runtime_remaining &gt; 0;</a>
<a name="4772"><span class="lineNum">    4772 </span>            : }</a>
<a name="4773"><span class="lineNum">    4773 </span>            : </a>
<a name="4774"><span class="lineNum">    4774 </span>            : /* returns 0 on failure to allocate runtime */</a>
<a name="4775"><span class="lineNum">    4775 </span>            : static int assign_cfs_rq_runtime(struct cfs_rq *cfs_rq)</a>
<a name="4776"><span class="lineNum">    4776 </span>            : {</a>
<a name="4777"><span class="lineNum">    4777 </span>            :         struct cfs_bandwidth *cfs_b = tg_cfs_bandwidth(cfs_rq-&gt;tg);</a>
<a name="4778"><span class="lineNum">    4778 </span>            :         int ret;</a>
<a name="4779"><span class="lineNum">    4779 </span>            : </a>
<a name="4780"><span class="lineNum">    4780 </span>            :         raw_spin_lock(&amp;cfs_b-&gt;lock);</a>
<a name="4781"><span class="lineNum">    4781 </span>            :         ret = __assign_cfs_rq_runtime(cfs_b, cfs_rq, sched_cfs_bandwidth_slice());</a>
<a name="4782"><span class="lineNum">    4782 </span>            :         raw_spin_unlock(&amp;cfs_b-&gt;lock);</a>
<a name="4783"><span class="lineNum">    4783 </span>            : </a>
<a name="4784"><span class="lineNum">    4784 </span>            :         return ret;</a>
<a name="4785"><span class="lineNum">    4785 </span>            : }</a>
<a name="4786"><span class="lineNum">    4786 </span>            : </a>
<a name="4787"><span class="lineNum">    4787 </span>            : static void __account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec)</a>
<a name="4788"><span class="lineNum">    4788 </span>            : {</a>
<a name="4789"><span class="lineNum">    4789 </span>            :         /* dock delta_exec before expiring quota (as it could span periods) */</a>
<a name="4790"><span class="lineNum">    4790 </span>            :         cfs_rq-&gt;runtime_remaining -= delta_exec;</a>
<a name="4791"><span class="lineNum">    4791 </span>            : </a>
<a name="4792"><span class="lineNum">    4792 </span>            :         if (likely(cfs_rq-&gt;runtime_remaining &gt; 0))</a>
<a name="4793"><span class="lineNum">    4793 </span>            :                 return;</a>
<a name="4794"><span class="lineNum">    4794 </span>            : </a>
<a name="4795"><span class="lineNum">    4795 </span>            :         if (cfs_rq-&gt;throttled)</a>
<a name="4796"><span class="lineNum">    4796 </span>            :                 return;</a>
<a name="4797"><span class="lineNum">    4797 </span>            :         /*</a>
<a name="4798"><span class="lineNum">    4798 </span>            :          * if we're unable to extend our runtime we resched so that the active</a>
<a name="4799"><span class="lineNum">    4799 </span>            :          * hierarchy can be throttled</a>
<a name="4800"><span class="lineNum">    4800 </span>            :          */</a>
<a name="4801"><span class="lineNum">    4801 </span>            :         if (!assign_cfs_rq_runtime(cfs_rq) &amp;&amp; likely(cfs_rq-&gt;curr))</a>
<a name="4802"><span class="lineNum">    4802 </span>            :                 resched_curr(rq_of(cfs_rq));</a>
<a name="4803"><span class="lineNum">    4803 </span>            : }</a>
<a name="4804"><span class="lineNum">    4804 </span>            : </a>
<a name="4805"><span class="lineNum">    4805 </span>            : static __always_inline</a>
<a name="4806"><span class="lineNum">    4806 </span>            : void account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec)</a>
<a name="4807"><span class="lineNum">    4807 </span>            : {</a>
<a name="4808"><span class="lineNum">    4808 </span>            :         if (!cfs_bandwidth_used() || !cfs_rq-&gt;runtime_enabled)</a>
<a name="4809"><span class="lineNum">    4809 </span>            :                 return;</a>
<a name="4810"><span class="lineNum">    4810 </span>            : </a>
<a name="4811"><span class="lineNum">    4811 </span>            :         __account_cfs_rq_runtime(cfs_rq, delta_exec);</a>
<a name="4812"><span class="lineNum">    4812 </span>            : }</a>
<a name="4813"><span class="lineNum">    4813 </span>            : </a>
<a name="4814"><span class="lineNum">    4814 </span>            : static inline int cfs_rq_throttled(struct cfs_rq *cfs_rq)</a>
<a name="4815"><span class="lineNum">    4815 </span>            : {</a>
<a name="4816"><span class="lineNum">    4816 </span>            :         return cfs_bandwidth_used() &amp;&amp; cfs_rq-&gt;throttled;</a>
<a name="4817"><span class="lineNum">    4817 </span>            : }</a>
<a name="4818"><span class="lineNum">    4818 </span>            : </a>
<a name="4819"><span class="lineNum">    4819 </span>            : /* check whether cfs_rq, or any parent, is throttled */</a>
<a name="4820"><span class="lineNum">    4820 </span>            : static inline int throttled_hierarchy(struct cfs_rq *cfs_rq)</a>
<a name="4821"><span class="lineNum">    4821 </span>            : {</a>
<a name="4822"><span class="lineNum">    4822 </span>            :         return cfs_bandwidth_used() &amp;&amp; cfs_rq-&gt;throttle_count;</a>
<a name="4823"><span class="lineNum">    4823 </span>            : }</a>
<a name="4824"><span class="lineNum">    4824 </span>            : </a>
<a name="4825"><span class="lineNum">    4825 </span>            : /*</a>
<a name="4826"><span class="lineNum">    4826 </span>            :  * Ensure that neither of the group entities corresponding to src_cpu or</a>
<a name="4827"><span class="lineNum">    4827 </span>            :  * dest_cpu are members of a throttled hierarchy when performing group</a>
<a name="4828"><span class="lineNum">    4828 </span>            :  * load-balance operations.</a>
<a name="4829"><span class="lineNum">    4829 </span>            :  */</a>
<a name="4830"><span class="lineNum">    4830 </span>            : static inline int throttled_lb_pair(struct task_group *tg,</a>
<a name="4831"><span class="lineNum">    4831 </span>            :                                     int src_cpu, int dest_cpu)</a>
<a name="4832"><span class="lineNum">    4832 </span>            : {</a>
<a name="4833"><span class="lineNum">    4833 </span>            :         struct cfs_rq *src_cfs_rq, *dest_cfs_rq;</a>
<a name="4834"><span class="lineNum">    4834 </span>            : </a>
<a name="4835"><span class="lineNum">    4835 </span>            :         src_cfs_rq = tg-&gt;cfs_rq[src_cpu];</a>
<a name="4836"><span class="lineNum">    4836 </span>            :         dest_cfs_rq = tg-&gt;cfs_rq[dest_cpu];</a>
<a name="4837"><span class="lineNum">    4837 </span>            : </a>
<a name="4838"><span class="lineNum">    4838 </span>            :         return throttled_hierarchy(src_cfs_rq) ||</a>
<a name="4839"><span class="lineNum">    4839 </span>            :                throttled_hierarchy(dest_cfs_rq);</a>
<a name="4840"><span class="lineNum">    4840 </span>            : }</a>
<a name="4841"><span class="lineNum">    4841 </span>            : </a>
<a name="4842"><span class="lineNum">    4842 </span>            : static int tg_unthrottle_up(struct task_group *tg, void *data)</a>
<a name="4843"><span class="lineNum">    4843 </span>            : {</a>
<a name="4844"><span class="lineNum">    4844 </span>            :         struct rq *rq = data;</a>
<a name="4845"><span class="lineNum">    4845 </span>            :         struct cfs_rq *cfs_rq = tg-&gt;cfs_rq[cpu_of(rq)];</a>
<a name="4846"><span class="lineNum">    4846 </span>            : </a>
<a name="4847"><span class="lineNum">    4847 </span>            :         cfs_rq-&gt;throttle_count--;</a>
<a name="4848"><span class="lineNum">    4848 </span>            :         if (!cfs_rq-&gt;throttle_count) {</a>
<a name="4849"><span class="lineNum">    4849 </span>            :                 cfs_rq-&gt;throttled_clock_task_time += rq_clock_task(rq) -</a>
<a name="4850"><span class="lineNum">    4850 </span>            :                                              cfs_rq-&gt;throttled_clock_task;</a>
<a name="4851"><span class="lineNum">    4851 </span>            : </a>
<a name="4852"><span class="lineNum">    4852 </span>            :                 /* Add cfs_rq with load or one or more already running entities to the list */</a>
<a name="4853"><span class="lineNum">    4853 </span>            :                 if (!cfs_rq_is_decayed(cfs_rq) || cfs_rq-&gt;nr_running)</a>
<a name="4854"><span class="lineNum">    4854 </span>            :                         list_add_leaf_cfs_rq(cfs_rq);</a>
<a name="4855"><span class="lineNum">    4855 </span>            :         }</a>
<a name="4856"><span class="lineNum">    4856 </span>            : </a>
<a name="4857"><span class="lineNum">    4857 </span>            :         return 0;</a>
<a name="4858"><span class="lineNum">    4858 </span>            : }</a>
<a name="4859"><span class="lineNum">    4859 </span>            : </a>
<a name="4860"><span class="lineNum">    4860 </span>            : static int tg_throttle_down(struct task_group *tg, void *data)</a>
<a name="4861"><span class="lineNum">    4861 </span>            : {</a>
<a name="4862"><span class="lineNum">    4862 </span>            :         struct rq *rq = data;</a>
<a name="4863"><span class="lineNum">    4863 </span>            :         struct cfs_rq *cfs_rq = tg-&gt;cfs_rq[cpu_of(rq)];</a>
<a name="4864"><span class="lineNum">    4864 </span>            : </a>
<a name="4865"><span class="lineNum">    4865 </span>            :         /* group is entering throttled state, stop time */</a>
<a name="4866"><span class="lineNum">    4866 </span>            :         if (!cfs_rq-&gt;throttle_count) {</a>
<a name="4867"><span class="lineNum">    4867 </span>            :                 cfs_rq-&gt;throttled_clock_task = rq_clock_task(rq);</a>
<a name="4868"><span class="lineNum">    4868 </span>            :                 list_del_leaf_cfs_rq(cfs_rq);</a>
<a name="4869"><span class="lineNum">    4869 </span>            :         }</a>
<a name="4870"><span class="lineNum">    4870 </span>            :         cfs_rq-&gt;throttle_count++;</a>
<a name="4871"><span class="lineNum">    4871 </span>            : </a>
<a name="4872"><span class="lineNum">    4872 </span>            :         return 0;</a>
<a name="4873"><span class="lineNum">    4873 </span>            : }</a>
<a name="4874"><span class="lineNum">    4874 </span>            : </a>
<a name="4875"><span class="lineNum">    4875 </span>            : static bool throttle_cfs_rq(struct cfs_rq *cfs_rq)</a>
<a name="4876"><span class="lineNum">    4876 </span>            : {</a>
<a name="4877"><span class="lineNum">    4877 </span>            :         struct rq *rq = rq_of(cfs_rq);</a>
<a name="4878"><span class="lineNum">    4878 </span>            :         struct cfs_bandwidth *cfs_b = tg_cfs_bandwidth(cfs_rq-&gt;tg);</a>
<a name="4879"><span class="lineNum">    4879 </span>            :         struct sched_entity *se;</a>
<a name="4880"><span class="lineNum">    4880 </span>            :         long task_delta, idle_task_delta, dequeue = 1;</a>
<a name="4881"><span class="lineNum">    4881 </span>            : </a>
<a name="4882"><span class="lineNum">    4882 </span>            :         raw_spin_lock(&amp;cfs_b-&gt;lock);</a>
<a name="4883"><span class="lineNum">    4883 </span>            :         /* This will start the period timer if necessary */</a>
<a name="4884"><span class="lineNum">    4884 </span>            :         if (__assign_cfs_rq_runtime(cfs_b, cfs_rq, 1)) {</a>
<a name="4885"><span class="lineNum">    4885 </span>            :                 /*</a>
<a name="4886"><span class="lineNum">    4886 </span>            :                  * We have raced with bandwidth becoming available, and if we</a>
<a name="4887"><span class="lineNum">    4887 </span>            :                  * actually throttled the timer might not unthrottle us for an</a>
<a name="4888"><span class="lineNum">    4888 </span>            :                  * entire period. We additionally needed to make sure that any</a>
<a name="4889"><span class="lineNum">    4889 </span>            :                  * subsequent check_cfs_rq_runtime calls agree not to throttle</a>
<a name="4890"><span class="lineNum">    4890 </span>            :                  * us, as we may commit to do cfs put_prev+pick_next, so we ask</a>
<a name="4891"><span class="lineNum">    4891 </span>            :                  * for 1ns of runtime rather than just check cfs_b.</a>
<a name="4892"><span class="lineNum">    4892 </span>            :                  */</a>
<a name="4893"><span class="lineNum">    4893 </span>            :                 dequeue = 0;</a>
<a name="4894"><span class="lineNum">    4894 </span>            :         } else {</a>
<a name="4895"><span class="lineNum">    4895 </span>            :                 list_add_tail_rcu(&amp;cfs_rq-&gt;throttled_list,</a>
<a name="4896"><span class="lineNum">    4896 </span>            :                                   &amp;cfs_b-&gt;throttled_cfs_rq);</a>
<a name="4897"><span class="lineNum">    4897 </span>            :         }</a>
<a name="4898"><span class="lineNum">    4898 </span>            :         raw_spin_unlock(&amp;cfs_b-&gt;lock);</a>
<a name="4899"><span class="lineNum">    4899 </span>            : </a>
<a name="4900"><span class="lineNum">    4900 </span>            :         if (!dequeue)</a>
<a name="4901"><span class="lineNum">    4901 </span>            :                 return false;  /* Throttle no longer required. */</a>
<a name="4902"><span class="lineNum">    4902 </span>            : </a>
<a name="4903"><span class="lineNum">    4903 </span>            :         se = cfs_rq-&gt;tg-&gt;se[cpu_of(rq_of(cfs_rq))];</a>
<a name="4904"><span class="lineNum">    4904 </span>            : </a>
<a name="4905"><span class="lineNum">    4905 </span>            :         /* freeze hierarchy runnable averages while throttled */</a>
<a name="4906"><span class="lineNum">    4906 </span>            :         rcu_read_lock();</a>
<a name="4907"><span class="lineNum">    4907 </span>            :         walk_tg_tree_from(cfs_rq-&gt;tg, tg_throttle_down, tg_nop, (void *)rq);</a>
<a name="4908"><span class="lineNum">    4908 </span>            :         rcu_read_unlock();</a>
<a name="4909"><span class="lineNum">    4909 </span>            : </a>
<a name="4910"><span class="lineNum">    4910 </span>            :         task_delta = cfs_rq-&gt;h_nr_running;</a>
<a name="4911"><span class="lineNum">    4911 </span>            :         idle_task_delta = cfs_rq-&gt;idle_h_nr_running;</a>
<a name="4912"><span class="lineNum">    4912 </span>            :         for_each_sched_entity(se) {</a>
<a name="4913"><span class="lineNum">    4913 </span>            :                 struct cfs_rq *qcfs_rq = cfs_rq_of(se);</a>
<a name="4914"><span class="lineNum">    4914 </span>            :                 /* throttled entity or throttle-on-deactivate */</a>
<a name="4915"><span class="lineNum">    4915 </span>            :                 if (!se-&gt;on_rq)</a>
<a name="4916"><span class="lineNum">    4916 </span>            :                         goto done;</a>
<a name="4917"><span class="lineNum">    4917 </span>            : </a>
<a name="4918"><span class="lineNum">    4918 </span>            :                 dequeue_entity(qcfs_rq, se, DEQUEUE_SLEEP);</a>
<a name="4919"><span class="lineNum">    4919 </span>            : </a>
<a name="4920"><span class="lineNum">    4920 </span>            :                 if (cfs_rq_is_idle(group_cfs_rq(se)))</a>
<a name="4921"><span class="lineNum">    4921 </span>            :                         idle_task_delta = cfs_rq-&gt;h_nr_running;</a>
<a name="4922"><span class="lineNum">    4922 </span>            : </a>
<a name="4923"><span class="lineNum">    4923 </span>            :                 qcfs_rq-&gt;h_nr_running -= task_delta;</a>
<a name="4924"><span class="lineNum">    4924 </span>            :                 qcfs_rq-&gt;idle_h_nr_running -= idle_task_delta;</a>
<a name="4925"><span class="lineNum">    4925 </span>            : </a>
<a name="4926"><span class="lineNum">    4926 </span>            :                 if (qcfs_rq-&gt;load.weight) {</a>
<a name="4927"><span class="lineNum">    4927 </span>            :                         /* Avoid re-evaluating load for this entity: */</a>
<a name="4928"><span class="lineNum">    4928 </span>            :                         se = parent_entity(se);</a>
<a name="4929"><span class="lineNum">    4929 </span>            :                         break;</a>
<a name="4930"><span class="lineNum">    4930 </span>            :                 }</a>
<a name="4931"><span class="lineNum">    4931 </span>            :         }</a>
<a name="4932"><span class="lineNum">    4932 </span>            : </a>
<a name="4933"><span class="lineNum">    4933 </span>            :         for_each_sched_entity(se) {</a>
<a name="4934"><span class="lineNum">    4934 </span>            :                 struct cfs_rq *qcfs_rq = cfs_rq_of(se);</a>
<a name="4935"><span class="lineNum">    4935 </span>            :                 /* throttled entity or throttle-on-deactivate */</a>
<a name="4936"><span class="lineNum">    4936 </span>            :                 if (!se-&gt;on_rq)</a>
<a name="4937"><span class="lineNum">    4937 </span>            :                         goto done;</a>
<a name="4938"><span class="lineNum">    4938 </span>            : </a>
<a name="4939"><span class="lineNum">    4939 </span>            :                 update_load_avg(qcfs_rq, se, 0);</a>
<a name="4940"><span class="lineNum">    4940 </span>            :                 se_update_runnable(se);</a>
<a name="4941"><span class="lineNum">    4941 </span>            : </a>
<a name="4942"><span class="lineNum">    4942 </span>            :                 if (cfs_rq_is_idle(group_cfs_rq(se)))</a>
<a name="4943"><span class="lineNum">    4943 </span>            :                         idle_task_delta = cfs_rq-&gt;h_nr_running;</a>
<a name="4944"><span class="lineNum">    4944 </span>            : </a>
<a name="4945"><span class="lineNum">    4945 </span>            :                 qcfs_rq-&gt;h_nr_running -= task_delta;</a>
<a name="4946"><span class="lineNum">    4946 </span>            :                 qcfs_rq-&gt;idle_h_nr_running -= idle_task_delta;</a>
<a name="4947"><span class="lineNum">    4947 </span>            :         }</a>
<a name="4948"><span class="lineNum">    4948 </span>            : </a>
<a name="4949"><span class="lineNum">    4949 </span>            :         /* At this point se is NULL and we are at root level*/</a>
<a name="4950"><span class="lineNum">    4950 </span>            :         sub_nr_running(rq, task_delta);</a>
<a name="4951"><span class="lineNum">    4951 </span>            : </a>
<a name="4952"><span class="lineNum">    4952 </span>            : done:</a>
<a name="4953"><span class="lineNum">    4953 </span>            :         /*</a>
<a name="4954"><span class="lineNum">    4954 </span>            :          * Note: distribution will already see us throttled via the</a>
<a name="4955"><span class="lineNum">    4955 </span>            :          * throttled-list.  rq-&gt;lock protects completion.</a>
<a name="4956"><span class="lineNum">    4956 </span>            :          */</a>
<a name="4957"><span class="lineNum">    4957 </span>            :         cfs_rq-&gt;throttled = 1;</a>
<a name="4958"><span class="lineNum">    4958 </span>            :         cfs_rq-&gt;throttled_clock = rq_clock(rq);</a>
<a name="4959"><span class="lineNum">    4959 </span>            :         return true;</a>
<a name="4960"><span class="lineNum">    4960 </span>            : }</a>
<a name="4961"><span class="lineNum">    4961 </span>            : </a>
<a name="4962"><span class="lineNum">    4962 </span>            : void unthrottle_cfs_rq(struct cfs_rq *cfs_rq)</a>
<a name="4963"><span class="lineNum">    4963 </span>            : {</a>
<a name="4964"><span class="lineNum">    4964 </span>            :         struct rq *rq = rq_of(cfs_rq);</a>
<a name="4965"><span class="lineNum">    4965 </span>            :         struct cfs_bandwidth *cfs_b = tg_cfs_bandwidth(cfs_rq-&gt;tg);</a>
<a name="4966"><span class="lineNum">    4966 </span>            :         struct sched_entity *se;</a>
<a name="4967"><span class="lineNum">    4967 </span>            :         long task_delta, idle_task_delta;</a>
<a name="4968"><span class="lineNum">    4968 </span>            : </a>
<a name="4969"><span class="lineNum">    4969 </span>            :         se = cfs_rq-&gt;tg-&gt;se[cpu_of(rq)];</a>
<a name="4970"><span class="lineNum">    4970 </span>            : </a>
<a name="4971"><span class="lineNum">    4971 </span>            :         cfs_rq-&gt;throttled = 0;</a>
<a name="4972"><span class="lineNum">    4972 </span>            : </a>
<a name="4973"><span class="lineNum">    4973 </span>            :         update_rq_clock(rq);</a>
<a name="4974"><span class="lineNum">    4974 </span>            : </a>
<a name="4975"><span class="lineNum">    4975 </span>            :         raw_spin_lock(&amp;cfs_b-&gt;lock);</a>
<a name="4976"><span class="lineNum">    4976 </span>            :         cfs_b-&gt;throttled_time += rq_clock(rq) - cfs_rq-&gt;throttled_clock;</a>
<a name="4977"><span class="lineNum">    4977 </span>            :         list_del_rcu(&amp;cfs_rq-&gt;throttled_list);</a>
<a name="4978"><span class="lineNum">    4978 </span>            :         raw_spin_unlock(&amp;cfs_b-&gt;lock);</a>
<a name="4979"><span class="lineNum">    4979 </span>            : </a>
<a name="4980"><span class="lineNum">    4980 </span>            :         /* update hierarchical throttle state */</a>
<a name="4981"><span class="lineNum">    4981 </span>            :         walk_tg_tree_from(cfs_rq-&gt;tg, tg_nop, tg_unthrottle_up, (void *)rq);</a>
<a name="4982"><span class="lineNum">    4982 </span>            : </a>
<a name="4983"><span class="lineNum">    4983 </span>            :         /* Nothing to run but something to decay (on_list)? Complete the branch */</a>
<a name="4984"><span class="lineNum">    4984 </span>            :         if (!cfs_rq-&gt;load.weight) {</a>
<a name="4985"><span class="lineNum">    4985 </span>            :                 if (cfs_rq-&gt;on_list)</a>
<a name="4986"><span class="lineNum">    4986 </span>            :                         goto unthrottle_throttle;</a>
<a name="4987"><span class="lineNum">    4987 </span>            :                 return;</a>
<a name="4988"><span class="lineNum">    4988 </span>            :         }</a>
<a name="4989"><span class="lineNum">    4989 </span>            : </a>
<a name="4990"><span class="lineNum">    4990 </span>            :         task_delta = cfs_rq-&gt;h_nr_running;</a>
<a name="4991"><span class="lineNum">    4991 </span>            :         idle_task_delta = cfs_rq-&gt;idle_h_nr_running;</a>
<a name="4992"><span class="lineNum">    4992 </span>            :         for_each_sched_entity(se) {</a>
<a name="4993"><span class="lineNum">    4993 </span>            :                 struct cfs_rq *qcfs_rq = cfs_rq_of(se);</a>
<a name="4994"><span class="lineNum">    4994 </span>            : </a>
<a name="4995"><span class="lineNum">    4995 </span>            :                 if (se-&gt;on_rq)</a>
<a name="4996"><span class="lineNum">    4996 </span>            :                         break;</a>
<a name="4997"><span class="lineNum">    4997 </span>            :                 enqueue_entity(qcfs_rq, se, ENQUEUE_WAKEUP);</a>
<a name="4998"><span class="lineNum">    4998 </span>            : </a>
<a name="4999"><span class="lineNum">    4999 </span>            :                 if (cfs_rq_is_idle(group_cfs_rq(se)))</a>
<a name="5000"><span class="lineNum">    5000 </span>            :                         idle_task_delta = cfs_rq-&gt;h_nr_running;</a>
<a name="5001"><span class="lineNum">    5001 </span>            : </a>
<a name="5002"><span class="lineNum">    5002 </span>            :                 qcfs_rq-&gt;h_nr_running += task_delta;</a>
<a name="5003"><span class="lineNum">    5003 </span>            :                 qcfs_rq-&gt;idle_h_nr_running += idle_task_delta;</a>
<a name="5004"><span class="lineNum">    5004 </span>            : </a>
<a name="5005"><span class="lineNum">    5005 </span>            :                 /* end evaluation on encountering a throttled cfs_rq */</a>
<a name="5006"><span class="lineNum">    5006 </span>            :                 if (cfs_rq_throttled(qcfs_rq))</a>
<a name="5007"><span class="lineNum">    5007 </span>            :                         goto unthrottle_throttle;</a>
<a name="5008"><span class="lineNum">    5008 </span>            :         }</a>
<a name="5009"><span class="lineNum">    5009 </span>            : </a>
<a name="5010"><span class="lineNum">    5010 </span>            :         for_each_sched_entity(se) {</a>
<a name="5011"><span class="lineNum">    5011 </span>            :                 struct cfs_rq *qcfs_rq = cfs_rq_of(se);</a>
<a name="5012"><span class="lineNum">    5012 </span>            : </a>
<a name="5013"><span class="lineNum">    5013 </span>            :                 update_load_avg(qcfs_rq, se, UPDATE_TG);</a>
<a name="5014"><span class="lineNum">    5014 </span>            :                 se_update_runnable(se);</a>
<a name="5015"><span class="lineNum">    5015 </span>            : </a>
<a name="5016"><span class="lineNum">    5016 </span>            :                 if (cfs_rq_is_idle(group_cfs_rq(se)))</a>
<a name="5017"><span class="lineNum">    5017 </span>            :                         idle_task_delta = cfs_rq-&gt;h_nr_running;</a>
<a name="5018"><span class="lineNum">    5018 </span>            : </a>
<a name="5019"><span class="lineNum">    5019 </span>            :                 qcfs_rq-&gt;h_nr_running += task_delta;</a>
<a name="5020"><span class="lineNum">    5020 </span>            :                 qcfs_rq-&gt;idle_h_nr_running += idle_task_delta;</a>
<a name="5021"><span class="lineNum">    5021 </span>            : </a>
<a name="5022"><span class="lineNum">    5022 </span>            :                 /* end evaluation on encountering a throttled cfs_rq */</a>
<a name="5023"><span class="lineNum">    5023 </span>            :                 if (cfs_rq_throttled(qcfs_rq))</a>
<a name="5024"><span class="lineNum">    5024 </span>            :                         goto unthrottle_throttle;</a>
<a name="5025"><span class="lineNum">    5025 </span>            : </a>
<a name="5026"><span class="lineNum">    5026 </span>            :                 /*</a>
<a name="5027"><span class="lineNum">    5027 </span>            :                  * One parent has been throttled and cfs_rq removed from the</a>
<a name="5028"><span class="lineNum">    5028 </span>            :                  * list. Add it back to not break the leaf list.</a>
<a name="5029"><span class="lineNum">    5029 </span>            :                  */</a>
<a name="5030"><span class="lineNum">    5030 </span>            :                 if (throttled_hierarchy(qcfs_rq))</a>
<a name="5031"><span class="lineNum">    5031 </span>            :                         list_add_leaf_cfs_rq(qcfs_rq);</a>
<a name="5032"><span class="lineNum">    5032 </span>            :         }</a>
<a name="5033"><span class="lineNum">    5033 </span>            : </a>
<a name="5034"><span class="lineNum">    5034 </span>            :         /* At this point se is NULL and we are at root level*/</a>
<a name="5035"><span class="lineNum">    5035 </span>            :         add_nr_running(rq, task_delta);</a>
<a name="5036"><span class="lineNum">    5036 </span>            : </a>
<a name="5037"><span class="lineNum">    5037 </span>            : unthrottle_throttle:</a>
<a name="5038"><span class="lineNum">    5038 </span>            :         /*</a>
<a name="5039"><span class="lineNum">    5039 </span>            :          * The cfs_rq_throttled() breaks in the above iteration can result in</a>
<a name="5040"><span class="lineNum">    5040 </span>            :          * incomplete leaf list maintenance, resulting in triggering the</a>
<a name="5041"><span class="lineNum">    5041 </span>            :          * assertion below.</a>
<a name="5042"><span class="lineNum">    5042 </span>            :          */</a>
<a name="5043"><span class="lineNum">    5043 </span>            :         for_each_sched_entity(se) {</a>
<a name="5044"><span class="lineNum">    5044 </span>            :                 struct cfs_rq *qcfs_rq = cfs_rq_of(se);</a>
<a name="5045"><span class="lineNum">    5045 </span>            : </a>
<a name="5046"><span class="lineNum">    5046 </span>            :                 if (list_add_leaf_cfs_rq(qcfs_rq))</a>
<a name="5047"><span class="lineNum">    5047 </span>            :                         break;</a>
<a name="5048"><span class="lineNum">    5048 </span>            :         }</a>
<a name="5049"><span class="lineNum">    5049 </span>            : </a>
<a name="5050"><span class="lineNum">    5050 </span>            :         assert_list_leaf_cfs_rq(rq);</a>
<a name="5051"><span class="lineNum">    5051 </span>            : </a>
<a name="5052"><span class="lineNum">    5052 </span>            :         /* Determine whether we need to wake up potentially idle CPU: */</a>
<a name="5053"><span class="lineNum">    5053 </span>            :         if (rq-&gt;curr == rq-&gt;idle &amp;&amp; rq-&gt;cfs.nr_running)</a>
<a name="5054"><span class="lineNum">    5054 </span>            :                 resched_curr(rq);</a>
<a name="5055"><span class="lineNum">    5055 </span>            : }</a>
<a name="5056"><span class="lineNum">    5056 </span>            : </a>
<a name="5057"><span class="lineNum">    5057 </span>            : static void distribute_cfs_runtime(struct cfs_bandwidth *cfs_b)</a>
<a name="5058"><span class="lineNum">    5058 </span>            : {</a>
<a name="5059"><span class="lineNum">    5059 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="5060"><span class="lineNum">    5060 </span>            :         u64 runtime, remaining = 1;</a>
<a name="5061"><span class="lineNum">    5061 </span>            : </a>
<a name="5062"><span class="lineNum">    5062 </span>            :         rcu_read_lock();</a>
<a name="5063"><span class="lineNum">    5063 </span>            :         list_for_each_entry_rcu(cfs_rq, &amp;cfs_b-&gt;throttled_cfs_rq,</a>
<a name="5064"><span class="lineNum">    5064 </span>            :                                 throttled_list) {</a>
<a name="5065"><span class="lineNum">    5065 </span>            :                 struct rq *rq = rq_of(cfs_rq);</a>
<a name="5066"><span class="lineNum">    5066 </span>            :                 struct rq_flags rf;</a>
<a name="5067"><span class="lineNum">    5067 </span>            : </a>
<a name="5068"><span class="lineNum">    5068 </span>            :                 rq_lock_irqsave(rq, &amp;rf);</a>
<a name="5069"><span class="lineNum">    5069 </span>            :                 if (!cfs_rq_throttled(cfs_rq))</a>
<a name="5070"><span class="lineNum">    5070 </span>            :                         goto next;</a>
<a name="5071"><span class="lineNum">    5071 </span>            : </a>
<a name="5072"><span class="lineNum">    5072 </span>            :                 /* By the above check, this should never be true */</a>
<a name="5073"><span class="lineNum">    5073 </span>            :                 SCHED_WARN_ON(cfs_rq-&gt;runtime_remaining &gt; 0);</a>
<a name="5074"><span class="lineNum">    5074 </span>            : </a>
<a name="5075"><span class="lineNum">    5075 </span>            :                 raw_spin_lock(&amp;cfs_b-&gt;lock);</a>
<a name="5076"><span class="lineNum">    5076 </span>            :                 runtime = -cfs_rq-&gt;runtime_remaining + 1;</a>
<a name="5077"><span class="lineNum">    5077 </span>            :                 if (runtime &gt; cfs_b-&gt;runtime)</a>
<a name="5078"><span class="lineNum">    5078 </span>            :                         runtime = cfs_b-&gt;runtime;</a>
<a name="5079"><span class="lineNum">    5079 </span>            :                 cfs_b-&gt;runtime -= runtime;</a>
<a name="5080"><span class="lineNum">    5080 </span>            :                 remaining = cfs_b-&gt;runtime;</a>
<a name="5081"><span class="lineNum">    5081 </span>            :                 raw_spin_unlock(&amp;cfs_b-&gt;lock);</a>
<a name="5082"><span class="lineNum">    5082 </span>            : </a>
<a name="5083"><span class="lineNum">    5083 </span>            :                 cfs_rq-&gt;runtime_remaining += runtime;</a>
<a name="5084"><span class="lineNum">    5084 </span>            : </a>
<a name="5085"><span class="lineNum">    5085 </span>            :                 /* we check whether we're throttled above */</a>
<a name="5086"><span class="lineNum">    5086 </span>            :                 if (cfs_rq-&gt;runtime_remaining &gt; 0)</a>
<a name="5087"><span class="lineNum">    5087 </span>            :                         unthrottle_cfs_rq(cfs_rq);</a>
<a name="5088"><span class="lineNum">    5088 </span>            : </a>
<a name="5089"><span class="lineNum">    5089 </span>            : next:</a>
<a name="5090"><span class="lineNum">    5090 </span>            :                 rq_unlock_irqrestore(rq, &amp;rf);</a>
<a name="5091"><span class="lineNum">    5091 </span>            : </a>
<a name="5092"><span class="lineNum">    5092 </span>            :                 if (!remaining)</a>
<a name="5093"><span class="lineNum">    5093 </span>            :                         break;</a>
<a name="5094"><span class="lineNum">    5094 </span>            :         }</a>
<a name="5095"><span class="lineNum">    5095 </span>            :         rcu_read_unlock();</a>
<a name="5096"><span class="lineNum">    5096 </span>            : }</a>
<a name="5097"><span class="lineNum">    5097 </span>            : </a>
<a name="5098"><span class="lineNum">    5098 </span>            : /*</a>
<a name="5099"><span class="lineNum">    5099 </span>            :  * Responsible for refilling a task_group's bandwidth and unthrottling its</a>
<a name="5100"><span class="lineNum">    5100 </span>            :  * cfs_rqs as appropriate. If there has been no activity within the last</a>
<a name="5101"><span class="lineNum">    5101 </span>            :  * period the timer is deactivated until scheduling resumes; cfs_b-&gt;idle is</a>
<a name="5102"><span class="lineNum">    5102 </span>            :  * used to track this state.</a>
<a name="5103"><span class="lineNum">    5103 </span>            :  */</a>
<a name="5104"><span class="lineNum">    5104 </span>            : static int do_sched_cfs_period_timer(struct cfs_bandwidth *cfs_b, int overrun, unsigned long flags)</a>
<a name="5105"><span class="lineNum">    5105 </span>            : {</a>
<a name="5106"><span class="lineNum">    5106 </span>            :         int throttled;</a>
<a name="5107"><span class="lineNum">    5107 </span>            : </a>
<a name="5108"><span class="lineNum">    5108 </span>            :         /* no need to continue the timer with no bandwidth constraint */</a>
<a name="5109"><span class="lineNum">    5109 </span>            :         if (cfs_b-&gt;quota == RUNTIME_INF)</a>
<a name="5110"><span class="lineNum">    5110 </span>            :                 goto out_deactivate;</a>
<a name="5111"><span class="lineNum">    5111 </span>            : </a>
<a name="5112"><span class="lineNum">    5112 </span>            :         throttled = !list_empty(&amp;cfs_b-&gt;throttled_cfs_rq);</a>
<a name="5113"><span class="lineNum">    5113 </span>            :         cfs_b-&gt;nr_periods += overrun;</a>
<a name="5114"><span class="lineNum">    5114 </span>            : </a>
<a name="5115"><span class="lineNum">    5115 </span>            :         /* Refill extra burst quota even if cfs_b-&gt;idle */</a>
<a name="5116"><span class="lineNum">    5116 </span>            :         __refill_cfs_bandwidth_runtime(cfs_b);</a>
<a name="5117"><span class="lineNum">    5117 </span>            : </a>
<a name="5118"><span class="lineNum">    5118 </span>            :         /*</a>
<a name="5119"><span class="lineNum">    5119 </span>            :          * idle depends on !throttled (for the case of a large deficit), and if</a>
<a name="5120"><span class="lineNum">    5120 </span>            :          * we're going inactive then everything else can be deferred</a>
<a name="5121"><span class="lineNum">    5121 </span>            :          */</a>
<a name="5122"><span class="lineNum">    5122 </span>            :         if (cfs_b-&gt;idle &amp;&amp; !throttled)</a>
<a name="5123"><span class="lineNum">    5123 </span>            :                 goto out_deactivate;</a>
<a name="5124"><span class="lineNum">    5124 </span>            : </a>
<a name="5125"><span class="lineNum">    5125 </span>            :         if (!throttled) {</a>
<a name="5126"><span class="lineNum">    5126 </span>            :                 /* mark as potentially idle for the upcoming period */</a>
<a name="5127"><span class="lineNum">    5127 </span>            :                 cfs_b-&gt;idle = 1;</a>
<a name="5128"><span class="lineNum">    5128 </span>            :                 return 0;</a>
<a name="5129"><span class="lineNum">    5129 </span>            :         }</a>
<a name="5130"><span class="lineNum">    5130 </span>            : </a>
<a name="5131"><span class="lineNum">    5131 </span>            :         /* account preceding periods in which throttling occurred */</a>
<a name="5132"><span class="lineNum">    5132 </span>            :         cfs_b-&gt;nr_throttled += overrun;</a>
<a name="5133"><span class="lineNum">    5133 </span>            : </a>
<a name="5134"><span class="lineNum">    5134 </span>            :         /*</a>
<a name="5135"><span class="lineNum">    5135 </span>            :          * This check is repeated as we release cfs_b-&gt;lock while we unthrottle.</a>
<a name="5136"><span class="lineNum">    5136 </span>            :          */</a>
<a name="5137"><span class="lineNum">    5137 </span>            :         while (throttled &amp;&amp; cfs_b-&gt;runtime &gt; 0) {</a>
<a name="5138"><span class="lineNum">    5138 </span>            :                 raw_spin_unlock_irqrestore(&amp;cfs_b-&gt;lock, flags);</a>
<a name="5139"><span class="lineNum">    5139 </span>            :                 /* we can't nest cfs_b-&gt;lock while distributing bandwidth */</a>
<a name="5140"><span class="lineNum">    5140 </span>            :                 distribute_cfs_runtime(cfs_b);</a>
<a name="5141"><span class="lineNum">    5141 </span>            :                 raw_spin_lock_irqsave(&amp;cfs_b-&gt;lock, flags);</a>
<a name="5142"><span class="lineNum">    5142 </span>            : </a>
<a name="5143"><span class="lineNum">    5143 </span>            :                 throttled = !list_empty(&amp;cfs_b-&gt;throttled_cfs_rq);</a>
<a name="5144"><span class="lineNum">    5144 </span>            :         }</a>
<a name="5145"><span class="lineNum">    5145 </span>            : </a>
<a name="5146"><span class="lineNum">    5146 </span>            :         /*</a>
<a name="5147"><span class="lineNum">    5147 </span>            :          * While we are ensured activity in the period following an</a>
<a name="5148"><span class="lineNum">    5148 </span>            :          * unthrottle, this also covers the case in which the new bandwidth is</a>
<a name="5149"><span class="lineNum">    5149 </span>            :          * insufficient to cover the existing bandwidth deficit.  (Forcing the</a>
<a name="5150"><span class="lineNum">    5150 </span>            :          * timer to remain active while there are any throttled entities.)</a>
<a name="5151"><span class="lineNum">    5151 </span>            :          */</a>
<a name="5152"><span class="lineNum">    5152 </span>            :         cfs_b-&gt;idle = 0;</a>
<a name="5153"><span class="lineNum">    5153 </span>            : </a>
<a name="5154"><span class="lineNum">    5154 </span>            :         return 0;</a>
<a name="5155"><span class="lineNum">    5155 </span>            : </a>
<a name="5156"><span class="lineNum">    5156 </span>            : out_deactivate:</a>
<a name="5157"><span class="lineNum">    5157 </span>            :         return 1;</a>
<a name="5158"><span class="lineNum">    5158 </span>            : }</a>
<a name="5159"><span class="lineNum">    5159 </span>            : </a>
<a name="5160"><span class="lineNum">    5160 </span>            : /* a cfs_rq won't donate quota below this amount */</a>
<a name="5161"><span class="lineNum">    5161 </span>            : static const u64 min_cfs_rq_runtime = 1 * NSEC_PER_MSEC;</a>
<a name="5162"><span class="lineNum">    5162 </span>            : /* minimum remaining period time to redistribute slack quota */</a>
<a name="5163"><span class="lineNum">    5163 </span>            : static const u64 min_bandwidth_expiration = 2 * NSEC_PER_MSEC;</a>
<a name="5164"><span class="lineNum">    5164 </span>            : /* how long we wait to gather additional slack before distributing */</a>
<a name="5165"><span class="lineNum">    5165 </span>            : static const u64 cfs_bandwidth_slack_period = 5 * NSEC_PER_MSEC;</a>
<a name="5166"><span class="lineNum">    5166 </span>            : </a>
<a name="5167"><span class="lineNum">    5167 </span>            : /*</a>
<a name="5168"><span class="lineNum">    5168 </span>            :  * Are we near the end of the current quota period?</a>
<a name="5169"><span class="lineNum">    5169 </span>            :  *</a>
<a name="5170"><span class="lineNum">    5170 </span>            :  * Requires cfs_b-&gt;lock for hrtimer_expires_remaining to be safe against the</a>
<a name="5171"><span class="lineNum">    5171 </span>            :  * hrtimer base being cleared by hrtimer_start. In the case of</a>
<a name="5172"><span class="lineNum">    5172 </span>            :  * migrate_hrtimers, base is never cleared, so we are fine.</a>
<a name="5173"><span class="lineNum">    5173 </span>            :  */</a>
<a name="5174"><span class="lineNum">    5174 </span>            : static int runtime_refresh_within(struct cfs_bandwidth *cfs_b, u64 min_expire)</a>
<a name="5175"><span class="lineNum">    5175 </span>            : {</a>
<a name="5176"><span class="lineNum">    5176 </span>            :         struct hrtimer *refresh_timer = &amp;cfs_b-&gt;period_timer;</a>
<a name="5177"><span class="lineNum">    5177 </span>            :         s64 remaining;</a>
<a name="5178"><span class="lineNum">    5178 </span>            : </a>
<a name="5179"><span class="lineNum">    5179 </span>            :         /* if the call-back is running a quota refresh is already occurring */</a>
<a name="5180"><span class="lineNum">    5180 </span>            :         if (hrtimer_callback_running(refresh_timer))</a>
<a name="5181"><span class="lineNum">    5181 </span>            :                 return 1;</a>
<a name="5182"><span class="lineNum">    5182 </span>            : </a>
<a name="5183"><span class="lineNum">    5183 </span>            :         /* is a quota refresh about to occur? */</a>
<a name="5184"><span class="lineNum">    5184 </span>            :         remaining = ktime_to_ns(hrtimer_expires_remaining(refresh_timer));</a>
<a name="5185"><span class="lineNum">    5185 </span>            :         if (remaining &lt; (s64)min_expire)</a>
<a name="5186"><span class="lineNum">    5186 </span>            :                 return 1;</a>
<a name="5187"><span class="lineNum">    5187 </span>            : </a>
<a name="5188"><span class="lineNum">    5188 </span>            :         return 0;</a>
<a name="5189"><span class="lineNum">    5189 </span>            : }</a>
<a name="5190"><span class="lineNum">    5190 </span>            : </a>
<a name="5191"><span class="lineNum">    5191 </span>            : static void start_cfs_slack_bandwidth(struct cfs_bandwidth *cfs_b)</a>
<a name="5192"><span class="lineNum">    5192 </span>            : {</a>
<a name="5193"><span class="lineNum">    5193 </span>            :         u64 min_left = cfs_bandwidth_slack_period + min_bandwidth_expiration;</a>
<a name="5194"><span class="lineNum">    5194 </span>            : </a>
<a name="5195"><span class="lineNum">    5195 </span>            :         /* if there's a quota refresh soon don't bother with slack */</a>
<a name="5196"><span class="lineNum">    5196 </span>            :         if (runtime_refresh_within(cfs_b, min_left))</a>
<a name="5197"><span class="lineNum">    5197 </span>            :                 return;</a>
<a name="5198"><span class="lineNum">    5198 </span>            : </a>
<a name="5199"><span class="lineNum">    5199 </span>            :         /* don't push forwards an existing deferred unthrottle */</a>
<a name="5200"><span class="lineNum">    5200 </span>            :         if (cfs_b-&gt;slack_started)</a>
<a name="5201"><span class="lineNum">    5201 </span>            :                 return;</a>
<a name="5202"><span class="lineNum">    5202 </span>            :         cfs_b-&gt;slack_started = true;</a>
<a name="5203"><span class="lineNum">    5203 </span>            : </a>
<a name="5204"><span class="lineNum">    5204 </span>            :         hrtimer_start(&amp;cfs_b-&gt;slack_timer,</a>
<a name="5205"><span class="lineNum">    5205 </span>            :                         ns_to_ktime(cfs_bandwidth_slack_period),</a>
<a name="5206"><span class="lineNum">    5206 </span>            :                         HRTIMER_MODE_REL);</a>
<a name="5207"><span class="lineNum">    5207 </span>            : }</a>
<a name="5208"><span class="lineNum">    5208 </span>            : </a>
<a name="5209"><span class="lineNum">    5209 </span>            : /* we know any runtime found here is valid as update_curr() precedes return */</a>
<a name="5210"><span class="lineNum">    5210 </span>            : static void __return_cfs_rq_runtime(struct cfs_rq *cfs_rq)</a>
<a name="5211"><span class="lineNum">    5211 </span>            : {</a>
<a name="5212"><span class="lineNum">    5212 </span>            :         struct cfs_bandwidth *cfs_b = tg_cfs_bandwidth(cfs_rq-&gt;tg);</a>
<a name="5213"><span class="lineNum">    5213 </span>            :         s64 slack_runtime = cfs_rq-&gt;runtime_remaining - min_cfs_rq_runtime;</a>
<a name="5214"><span class="lineNum">    5214 </span>            : </a>
<a name="5215"><span class="lineNum">    5215 </span>            :         if (slack_runtime &lt;= 0)</a>
<a name="5216"><span class="lineNum">    5216 </span>            :                 return;</a>
<a name="5217"><span class="lineNum">    5217 </span>            : </a>
<a name="5218"><span class="lineNum">    5218 </span>            :         raw_spin_lock(&amp;cfs_b-&gt;lock);</a>
<a name="5219"><span class="lineNum">    5219 </span>            :         if (cfs_b-&gt;quota != RUNTIME_INF) {</a>
<a name="5220"><span class="lineNum">    5220 </span>            :                 cfs_b-&gt;runtime += slack_runtime;</a>
<a name="5221"><span class="lineNum">    5221 </span>            : </a>
<a name="5222"><span class="lineNum">    5222 </span>            :                 /* we are under rq-&gt;lock, defer unthrottling using a timer */</a>
<a name="5223"><span class="lineNum">    5223 </span>            :                 if (cfs_b-&gt;runtime &gt; sched_cfs_bandwidth_slice() &amp;&amp;</a>
<a name="5224"><span class="lineNum">    5224 </span>            :                     !list_empty(&amp;cfs_b-&gt;throttled_cfs_rq))</a>
<a name="5225"><span class="lineNum">    5225 </span>            :                         start_cfs_slack_bandwidth(cfs_b);</a>
<a name="5226"><span class="lineNum">    5226 </span>            :         }</a>
<a name="5227"><span class="lineNum">    5227 </span>            :         raw_spin_unlock(&amp;cfs_b-&gt;lock);</a>
<a name="5228"><span class="lineNum">    5228 </span>            : </a>
<a name="5229"><span class="lineNum">    5229 </span>            :         /* even if it's not valid for return we don't want to try again */</a>
<a name="5230"><span class="lineNum">    5230 </span>            :         cfs_rq-&gt;runtime_remaining -= slack_runtime;</a>
<a name="5231"><span class="lineNum">    5231 </span>            : }</a>
<a name="5232"><span class="lineNum">    5232 </span>            : </a>
<a name="5233"><span class="lineNum">    5233 </span>            : static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq)</a>
<a name="5234"><span class="lineNum">    5234 </span>            : {</a>
<a name="5235"><span class="lineNum">    5235 </span>            :         if (!cfs_bandwidth_used())</a>
<a name="5236"><span class="lineNum">    5236 </span>            :                 return;</a>
<a name="5237"><span class="lineNum">    5237 </span>            : </a>
<a name="5238"><span class="lineNum">    5238 </span>            :         if (!cfs_rq-&gt;runtime_enabled || cfs_rq-&gt;nr_running)</a>
<a name="5239"><span class="lineNum">    5239 </span>            :                 return;</a>
<a name="5240"><span class="lineNum">    5240 </span>            : </a>
<a name="5241"><span class="lineNum">    5241 </span>            :         __return_cfs_rq_runtime(cfs_rq);</a>
<a name="5242"><span class="lineNum">    5242 </span>            : }</a>
<a name="5243"><span class="lineNum">    5243 </span>            : </a>
<a name="5244"><span class="lineNum">    5244 </span>            : /*</a>
<a name="5245"><span class="lineNum">    5245 </span>            :  * This is done with a timer (instead of inline with bandwidth return) since</a>
<a name="5246"><span class="lineNum">    5246 </span>            :  * it's necessary to juggle rq-&gt;locks to unthrottle their respective cfs_rqs.</a>
<a name="5247"><span class="lineNum">    5247 </span>            :  */</a>
<a name="5248"><span class="lineNum">    5248 </span>            : static void do_sched_cfs_slack_timer(struct cfs_bandwidth *cfs_b)</a>
<a name="5249"><span class="lineNum">    5249 </span>            : {</a>
<a name="5250"><span class="lineNum">    5250 </span>            :         u64 runtime = 0, slice = sched_cfs_bandwidth_slice();</a>
<a name="5251"><span class="lineNum">    5251 </span>            :         unsigned long flags;</a>
<a name="5252"><span class="lineNum">    5252 </span>            : </a>
<a name="5253"><span class="lineNum">    5253 </span>            :         /* confirm we're still not at a refresh boundary */</a>
<a name="5254"><span class="lineNum">    5254 </span>            :         raw_spin_lock_irqsave(&amp;cfs_b-&gt;lock, flags);</a>
<a name="5255"><span class="lineNum">    5255 </span>            :         cfs_b-&gt;slack_started = false;</a>
<a name="5256"><span class="lineNum">    5256 </span>            : </a>
<a name="5257"><span class="lineNum">    5257 </span>            :         if (runtime_refresh_within(cfs_b, min_bandwidth_expiration)) {</a>
<a name="5258"><span class="lineNum">    5258 </span>            :                 raw_spin_unlock_irqrestore(&amp;cfs_b-&gt;lock, flags);</a>
<a name="5259"><span class="lineNum">    5259 </span>            :                 return;</a>
<a name="5260"><span class="lineNum">    5260 </span>            :         }</a>
<a name="5261"><span class="lineNum">    5261 </span>            : </a>
<a name="5262"><span class="lineNum">    5262 </span>            :         if (cfs_b-&gt;quota != RUNTIME_INF &amp;&amp; cfs_b-&gt;runtime &gt; slice)</a>
<a name="5263"><span class="lineNum">    5263 </span>            :                 runtime = cfs_b-&gt;runtime;</a>
<a name="5264"><span class="lineNum">    5264 </span>            : </a>
<a name="5265"><span class="lineNum">    5265 </span>            :         raw_spin_unlock_irqrestore(&amp;cfs_b-&gt;lock, flags);</a>
<a name="5266"><span class="lineNum">    5266 </span>            : </a>
<a name="5267"><span class="lineNum">    5267 </span>            :         if (!runtime)</a>
<a name="5268"><span class="lineNum">    5268 </span>            :                 return;</a>
<a name="5269"><span class="lineNum">    5269 </span>            : </a>
<a name="5270"><span class="lineNum">    5270 </span>            :         distribute_cfs_runtime(cfs_b);</a>
<a name="5271"><span class="lineNum">    5271 </span>            : }</a>
<a name="5272"><span class="lineNum">    5272 </span>            : </a>
<a name="5273"><span class="lineNum">    5273 </span>            : /*</a>
<a name="5274"><span class="lineNum">    5274 </span>            :  * When a group wakes up we want to make sure that its quota is not already</a>
<a name="5275"><span class="lineNum">    5275 </span>            :  * expired/exceeded, otherwise it may be allowed to steal additional ticks of</a>
<a name="5276"><span class="lineNum">    5276 </span>            :  * runtime as update_curr() throttling can not trigger until it's on-rq.</a>
<a name="5277"><span class="lineNum">    5277 </span>            :  */</a>
<a name="5278"><span class="lineNum">    5278 </span>            : static void check_enqueue_throttle(struct cfs_rq *cfs_rq)</a>
<a name="5279"><span class="lineNum">    5279 </span>            : {</a>
<a name="5280"><span class="lineNum">    5280 </span>            :         if (!cfs_bandwidth_used())</a>
<a name="5281"><span class="lineNum">    5281 </span>            :                 return;</a>
<a name="5282"><span class="lineNum">    5282 </span>            : </a>
<a name="5283"><span class="lineNum">    5283 </span>            :         /* an active group must be handled by the update_curr()-&gt;put() path */</a>
<a name="5284"><span class="lineNum">    5284 </span>            :         if (!cfs_rq-&gt;runtime_enabled || cfs_rq-&gt;curr)</a>
<a name="5285"><span class="lineNum">    5285 </span>            :                 return;</a>
<a name="5286"><span class="lineNum">    5286 </span>            : </a>
<a name="5287"><span class="lineNum">    5287 </span>            :         /* ensure the group is not already throttled */</a>
<a name="5288"><span class="lineNum">    5288 </span>            :         if (cfs_rq_throttled(cfs_rq))</a>
<a name="5289"><span class="lineNum">    5289 </span>            :                 return;</a>
<a name="5290"><span class="lineNum">    5290 </span>            : </a>
<a name="5291"><span class="lineNum">    5291 </span>            :         /* update runtime allocation */</a>
<a name="5292"><span class="lineNum">    5292 </span>            :         account_cfs_rq_runtime(cfs_rq, 0);</a>
<a name="5293"><span class="lineNum">    5293 </span>            :         if (cfs_rq-&gt;runtime_remaining &lt;= 0)</a>
<a name="5294"><span class="lineNum">    5294 </span>            :                 throttle_cfs_rq(cfs_rq);</a>
<a name="5295"><span class="lineNum">    5295 </span>            : }</a>
<a name="5296"><span class="lineNum">    5296 </span>            : </a>
<a name="5297"><span class="lineNum">    5297 </span>            : static void sync_throttle(struct task_group *tg, int cpu)</a>
<a name="5298"><span class="lineNum">    5298 </span>            : {</a>
<a name="5299"><span class="lineNum">    5299 </span>            :         struct cfs_rq *pcfs_rq, *cfs_rq;</a>
<a name="5300"><span class="lineNum">    5300 </span>            : </a>
<a name="5301"><span class="lineNum">    5301 </span>            :         if (!cfs_bandwidth_used())</a>
<a name="5302"><span class="lineNum">    5302 </span>            :                 return;</a>
<a name="5303"><span class="lineNum">    5303 </span>            : </a>
<a name="5304"><span class="lineNum">    5304 </span>            :         if (!tg-&gt;parent)</a>
<a name="5305"><span class="lineNum">    5305 </span>            :                 return;</a>
<a name="5306"><span class="lineNum">    5306 </span>            : </a>
<a name="5307"><span class="lineNum">    5307 </span>            :         cfs_rq = tg-&gt;cfs_rq[cpu];</a>
<a name="5308"><span class="lineNum">    5308 </span>            :         pcfs_rq = tg-&gt;parent-&gt;cfs_rq[cpu];</a>
<a name="5309"><span class="lineNum">    5309 </span>            : </a>
<a name="5310"><span class="lineNum">    5310 </span>            :         cfs_rq-&gt;throttle_count = pcfs_rq-&gt;throttle_count;</a>
<a name="5311"><span class="lineNum">    5311 </span>            :         cfs_rq-&gt;throttled_clock_task = rq_clock_task(cpu_rq(cpu));</a>
<a name="5312"><span class="lineNum">    5312 </span>            : }</a>
<a name="5313"><span class="lineNum">    5313 </span>            : </a>
<a name="5314"><span class="lineNum">    5314 </span>            : /* conditionally throttle active cfs_rq's from put_prev_entity() */</a>
<a name="5315"><span class="lineNum">    5315 </span>            : static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq)</a>
<a name="5316"><span class="lineNum">    5316 </span>            : {</a>
<a name="5317"><span class="lineNum">    5317 </span>            :         if (!cfs_bandwidth_used())</a>
<a name="5318"><span class="lineNum">    5318 </span>            :                 return false;</a>
<a name="5319"><span class="lineNum">    5319 </span>            : </a>
<a name="5320"><span class="lineNum">    5320 </span>            :         if (likely(!cfs_rq-&gt;runtime_enabled || cfs_rq-&gt;runtime_remaining &gt; 0))</a>
<a name="5321"><span class="lineNum">    5321 </span>            :                 return false;</a>
<a name="5322"><span class="lineNum">    5322 </span>            : </a>
<a name="5323"><span class="lineNum">    5323 </span>            :         /*</a>
<a name="5324"><span class="lineNum">    5324 </span>            :          * it's possible for a throttled entity to be forced into a running</a>
<a name="5325"><span class="lineNum">    5325 </span>            :          * state (e.g. set_curr_task), in this case we're finished.</a>
<a name="5326"><span class="lineNum">    5326 </span>            :          */</a>
<a name="5327"><span class="lineNum">    5327 </span>            :         if (cfs_rq_throttled(cfs_rq))</a>
<a name="5328"><span class="lineNum">    5328 </span>            :                 return true;</a>
<a name="5329"><span class="lineNum">    5329 </span>            : </a>
<a name="5330"><span class="lineNum">    5330 </span>            :         return throttle_cfs_rq(cfs_rq);</a>
<a name="5331"><span class="lineNum">    5331 </span>            : }</a>
<a name="5332"><span class="lineNum">    5332 </span>            : </a>
<a name="5333"><span class="lineNum">    5333 </span>            : static enum hrtimer_restart sched_cfs_slack_timer(struct hrtimer *timer)</a>
<a name="5334"><span class="lineNum">    5334 </span>            : {</a>
<a name="5335"><span class="lineNum">    5335 </span>            :         struct cfs_bandwidth *cfs_b =</a>
<a name="5336"><span class="lineNum">    5336 </span>            :                 container_of(timer, struct cfs_bandwidth, slack_timer);</a>
<a name="5337"><span class="lineNum">    5337 </span>            : </a>
<a name="5338"><span class="lineNum">    5338 </span>            :         do_sched_cfs_slack_timer(cfs_b);</a>
<a name="5339"><span class="lineNum">    5339 </span>            : </a>
<a name="5340"><span class="lineNum">    5340 </span>            :         return HRTIMER_NORESTART;</a>
<a name="5341"><span class="lineNum">    5341 </span>            : }</a>
<a name="5342"><span class="lineNum">    5342 </span>            : </a>
<a name="5343"><span class="lineNum">    5343 </span>            : extern const u64 max_cfs_quota_period;</a>
<a name="5344"><span class="lineNum">    5344 </span>            : </a>
<a name="5345"><span class="lineNum">    5345 </span>            : static enum hrtimer_restart sched_cfs_period_timer(struct hrtimer *timer)</a>
<a name="5346"><span class="lineNum">    5346 </span>            : {</a>
<a name="5347"><span class="lineNum">    5347 </span>            :         struct cfs_bandwidth *cfs_b =</a>
<a name="5348"><span class="lineNum">    5348 </span>            :                 container_of(timer, struct cfs_bandwidth, period_timer);</a>
<a name="5349"><span class="lineNum">    5349 </span>            :         unsigned long flags;</a>
<a name="5350"><span class="lineNum">    5350 </span>            :         int overrun;</a>
<a name="5351"><span class="lineNum">    5351 </span>            :         int idle = 0;</a>
<a name="5352"><span class="lineNum">    5352 </span>            :         int count = 0;</a>
<a name="5353"><span class="lineNum">    5353 </span>            : </a>
<a name="5354"><span class="lineNum">    5354 </span>            :         raw_spin_lock_irqsave(&amp;cfs_b-&gt;lock, flags);</a>
<a name="5355"><span class="lineNum">    5355 </span>            :         for (;;) {</a>
<a name="5356"><span class="lineNum">    5356 </span>            :                 overrun = hrtimer_forward_now(timer, cfs_b-&gt;period);</a>
<a name="5357"><span class="lineNum">    5357 </span>            :                 if (!overrun)</a>
<a name="5358"><span class="lineNum">    5358 </span>            :                         break;</a>
<a name="5359"><span class="lineNum">    5359 </span>            : </a>
<a name="5360"><span class="lineNum">    5360 </span>            :                 idle = do_sched_cfs_period_timer(cfs_b, overrun, flags);</a>
<a name="5361"><span class="lineNum">    5361 </span>            : </a>
<a name="5362"><span class="lineNum">    5362 </span>            :                 if (++count &gt; 3) {</a>
<a name="5363"><span class="lineNum">    5363 </span>            :                         u64 new, old = ktime_to_ns(cfs_b-&gt;period);</a>
<a name="5364"><span class="lineNum">    5364 </span>            : </a>
<a name="5365"><span class="lineNum">    5365 </span>            :                         /*</a>
<a name="5366"><span class="lineNum">    5366 </span>            :                          * Grow period by a factor of 2 to avoid losing precision.</a>
<a name="5367"><span class="lineNum">    5367 </span>            :                          * Precision loss in the quota/period ratio can cause __cfs_schedulable</a>
<a name="5368"><span class="lineNum">    5368 </span>            :                          * to fail.</a>
<a name="5369"><span class="lineNum">    5369 </span>            :                          */</a>
<a name="5370"><span class="lineNum">    5370 </span>            :                         new = old * 2;</a>
<a name="5371"><span class="lineNum">    5371 </span>            :                         if (new &lt; max_cfs_quota_period) {</a>
<a name="5372"><span class="lineNum">    5372 </span>            :                                 cfs_b-&gt;period = ns_to_ktime(new);</a>
<a name="5373"><span class="lineNum">    5373 </span>            :                                 cfs_b-&gt;quota *= 2;</a>
<a name="5374"><span class="lineNum">    5374 </span>            :                                 cfs_b-&gt;burst *= 2;</a>
<a name="5375"><span class="lineNum">    5375 </span>            : </a>
<a name="5376"><span class="lineNum">    5376 </span>            :                                 pr_warn_ratelimited(</a>
<a name="5377"><span class="lineNum">    5377 </span>            :         &quot;cfs_period_timer[cpu%d]: period too short, scaling up (new cfs_period_us = %lld, cfs_quota_us = %lld)\n&quot;,</a>
<a name="5378"><span class="lineNum">    5378 </span>            :                                         smp_processor_id(),</a>
<a name="5379"><span class="lineNum">    5379 </span>            :                                         div_u64(new, NSEC_PER_USEC),</a>
<a name="5380"><span class="lineNum">    5380 </span>            :                                         div_u64(cfs_b-&gt;quota, NSEC_PER_USEC));</a>
<a name="5381"><span class="lineNum">    5381 </span>            :                         } else {</a>
<a name="5382"><span class="lineNum">    5382 </span>            :                                 pr_warn_ratelimited(</a>
<a name="5383"><span class="lineNum">    5383 </span>            :         &quot;cfs_period_timer[cpu%d]: period too short, but cannot scale up without losing precision (cfs_period_us = %lld, cfs_quota_us = %lld)\n&quot;,</a>
<a name="5384"><span class="lineNum">    5384 </span>            :                                         smp_processor_id(),</a>
<a name="5385"><span class="lineNum">    5385 </span>            :                                         div_u64(old, NSEC_PER_USEC),</a>
<a name="5386"><span class="lineNum">    5386 </span>            :                                         div_u64(cfs_b-&gt;quota, NSEC_PER_USEC));</a>
<a name="5387"><span class="lineNum">    5387 </span>            :                         }</a>
<a name="5388"><span class="lineNum">    5388 </span>            : </a>
<a name="5389"><span class="lineNum">    5389 </span>            :                         /* reset count so we don't come right back in here */</a>
<a name="5390"><span class="lineNum">    5390 </span>            :                         count = 0;</a>
<a name="5391"><span class="lineNum">    5391 </span>            :                 }</a>
<a name="5392"><span class="lineNum">    5392 </span>            :         }</a>
<a name="5393"><span class="lineNum">    5393 </span>            :         if (idle)</a>
<a name="5394"><span class="lineNum">    5394 </span>            :                 cfs_b-&gt;period_active = 0;</a>
<a name="5395"><span class="lineNum">    5395 </span>            :         raw_spin_unlock_irqrestore(&amp;cfs_b-&gt;lock, flags);</a>
<a name="5396"><span class="lineNum">    5396 </span>            : </a>
<a name="5397"><span class="lineNum">    5397 </span>            :         return idle ? HRTIMER_NORESTART : HRTIMER_RESTART;</a>
<a name="5398"><span class="lineNum">    5398 </span>            : }</a>
<a name="5399"><span class="lineNum">    5399 </span>            : </a>
<a name="5400"><span class="lineNum">    5400 </span>            : void init_cfs_bandwidth(struct cfs_bandwidth *cfs_b)</a>
<a name="5401"><span class="lineNum">    5401 </span>            : {</a>
<a name="5402"><span class="lineNum">    5402 </span>            :         raw_spin_lock_init(&amp;cfs_b-&gt;lock);</a>
<a name="5403"><span class="lineNum">    5403 </span>            :         cfs_b-&gt;runtime = 0;</a>
<a name="5404"><span class="lineNum">    5404 </span>            :         cfs_b-&gt;quota = RUNTIME_INF;</a>
<a name="5405"><span class="lineNum">    5405 </span>            :         cfs_b-&gt;period = ns_to_ktime(default_cfs_period());</a>
<a name="5406"><span class="lineNum">    5406 </span>            :         cfs_b-&gt;burst = 0;</a>
<a name="5407"><span class="lineNum">    5407 </span>            : </a>
<a name="5408"><span class="lineNum">    5408 </span>            :         INIT_LIST_HEAD(&amp;cfs_b-&gt;throttled_cfs_rq);</a>
<a name="5409"><span class="lineNum">    5409 </span>            :         hrtimer_init(&amp;cfs_b-&gt;period_timer, CLOCK_MONOTONIC, HRTIMER_MODE_ABS_PINNED);</a>
<a name="5410"><span class="lineNum">    5410 </span>            :         cfs_b-&gt;period_timer.function = sched_cfs_period_timer;</a>
<a name="5411"><span class="lineNum">    5411 </span>            :         hrtimer_init(&amp;cfs_b-&gt;slack_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);</a>
<a name="5412"><span class="lineNum">    5412 </span>            :         cfs_b-&gt;slack_timer.function = sched_cfs_slack_timer;</a>
<a name="5413"><span class="lineNum">    5413 </span>            :         cfs_b-&gt;slack_started = false;</a>
<a name="5414"><span class="lineNum">    5414 </span>            : }</a>
<a name="5415"><span class="lineNum">    5415 </span>            : </a>
<a name="5416"><span class="lineNum">    5416 </span>            : static void init_cfs_rq_runtime(struct cfs_rq *cfs_rq)</a>
<a name="5417"><span class="lineNum">    5417 </span>            : {</a>
<a name="5418"><span class="lineNum">    5418 </span>            :         cfs_rq-&gt;runtime_enabled = 0;</a>
<a name="5419"><span class="lineNum">    5419 </span>            :         INIT_LIST_HEAD(&amp;cfs_rq-&gt;throttled_list);</a>
<a name="5420"><span class="lineNum">    5420 </span>            : }</a>
<a name="5421"><span class="lineNum">    5421 </span>            : </a>
<a name="5422"><span class="lineNum">    5422 </span>            : void start_cfs_bandwidth(struct cfs_bandwidth *cfs_b)</a>
<a name="5423"><span class="lineNum">    5423 </span>            : {</a>
<a name="5424"><span class="lineNum">    5424 </span>            :         lockdep_assert_held(&amp;cfs_b-&gt;lock);</a>
<a name="5425"><span class="lineNum">    5425 </span>            : </a>
<a name="5426"><span class="lineNum">    5426 </span>            :         if (cfs_b-&gt;period_active)</a>
<a name="5427"><span class="lineNum">    5427 </span>            :                 return;</a>
<a name="5428"><span class="lineNum">    5428 </span>            : </a>
<a name="5429"><span class="lineNum">    5429 </span>            :         cfs_b-&gt;period_active = 1;</a>
<a name="5430"><span class="lineNum">    5430 </span>            :         hrtimer_forward_now(&amp;cfs_b-&gt;period_timer, cfs_b-&gt;period);</a>
<a name="5431"><span class="lineNum">    5431 </span>            :         hrtimer_start_expires(&amp;cfs_b-&gt;period_timer, HRTIMER_MODE_ABS_PINNED);</a>
<a name="5432"><span class="lineNum">    5432 </span>            : }</a>
<a name="5433"><span class="lineNum">    5433 </span>            : </a>
<a name="5434"><span class="lineNum">    5434 </span>            : static void destroy_cfs_bandwidth(struct cfs_bandwidth *cfs_b)</a>
<a name="5435"><span class="lineNum">    5435 </span>            : {</a>
<a name="5436"><span class="lineNum">    5436 </span>            :         /* init_cfs_bandwidth() was not called */</a>
<a name="5437"><span class="lineNum">    5437 </span>            :         if (!cfs_b-&gt;throttled_cfs_rq.next)</a>
<a name="5438"><span class="lineNum">    5438 </span>            :                 return;</a>
<a name="5439"><span class="lineNum">    5439 </span>            : </a>
<a name="5440"><span class="lineNum">    5440 </span>            :         hrtimer_cancel(&amp;cfs_b-&gt;period_timer);</a>
<a name="5441"><span class="lineNum">    5441 </span>            :         hrtimer_cancel(&amp;cfs_b-&gt;slack_timer);</a>
<a name="5442"><span class="lineNum">    5442 </span>            : }</a>
<a name="5443"><span class="lineNum">    5443 </span>            : </a>
<a name="5444"><span class="lineNum">    5444 </span>            : /*</a>
<a name="5445"><span class="lineNum">    5445 </span>            :  * Both these CPU hotplug callbacks race against unregister_fair_sched_group()</a>
<a name="5446"><span class="lineNum">    5446 </span>            :  *</a>
<a name="5447"><span class="lineNum">    5447 </span>            :  * The race is harmless, since modifying bandwidth settings of unhooked group</a>
<a name="5448"><span class="lineNum">    5448 </span>            :  * bits doesn't do much.</a>
<a name="5449"><span class="lineNum">    5449 </span>            :  */</a>
<a name="5450"><span class="lineNum">    5450 </span>            : </a>
<a name="5451"><span class="lineNum">    5451 </span>            : /* cpu online callback */</a>
<a name="5452"><span class="lineNum">    5452 </span>            : static void __maybe_unused update_runtime_enabled(struct rq *rq)</a>
<a name="5453"><span class="lineNum">    5453 </span>            : {</a>
<a name="5454"><span class="lineNum">    5454 </span>            :         struct task_group *tg;</a>
<a name="5455"><span class="lineNum">    5455 </span>            : </a>
<a name="5456"><span class="lineNum">    5456 </span>            :         lockdep_assert_rq_held(rq);</a>
<a name="5457"><span class="lineNum">    5457 </span>            : </a>
<a name="5458"><span class="lineNum">    5458 </span>            :         rcu_read_lock();</a>
<a name="5459"><span class="lineNum">    5459 </span>            :         list_for_each_entry_rcu(tg, &amp;task_groups, list) {</a>
<a name="5460"><span class="lineNum">    5460 </span>            :                 struct cfs_bandwidth *cfs_b = &amp;tg-&gt;cfs_bandwidth;</a>
<a name="5461"><span class="lineNum">    5461 </span>            :                 struct cfs_rq *cfs_rq = tg-&gt;cfs_rq[cpu_of(rq)];</a>
<a name="5462"><span class="lineNum">    5462 </span>            : </a>
<a name="5463"><span class="lineNum">    5463 </span>            :                 raw_spin_lock(&amp;cfs_b-&gt;lock);</a>
<a name="5464"><span class="lineNum">    5464 </span>            :                 cfs_rq-&gt;runtime_enabled = cfs_b-&gt;quota != RUNTIME_INF;</a>
<a name="5465"><span class="lineNum">    5465 </span>            :                 raw_spin_unlock(&amp;cfs_b-&gt;lock);</a>
<a name="5466"><span class="lineNum">    5466 </span>            :         }</a>
<a name="5467"><span class="lineNum">    5467 </span>            :         rcu_read_unlock();</a>
<a name="5468"><span class="lineNum">    5468 </span>            : }</a>
<a name="5469"><span class="lineNum">    5469 </span>            : </a>
<a name="5470"><span class="lineNum">    5470 </span>            : /* cpu offline callback */</a>
<a name="5471"><span class="lineNum">    5471 </span>            : static void __maybe_unused unthrottle_offline_cfs_rqs(struct rq *rq)</a>
<a name="5472"><span class="lineNum">    5472 </span>            : {</a>
<a name="5473"><span class="lineNum">    5473 </span>            :         struct task_group *tg;</a>
<a name="5474"><span class="lineNum">    5474 </span>            : </a>
<a name="5475"><span class="lineNum">    5475 </span>            :         lockdep_assert_rq_held(rq);</a>
<a name="5476"><span class="lineNum">    5476 </span>            : </a>
<a name="5477"><span class="lineNum">    5477 </span>            :         rcu_read_lock();</a>
<a name="5478"><span class="lineNum">    5478 </span>            :         list_for_each_entry_rcu(tg, &amp;task_groups, list) {</a>
<a name="5479"><span class="lineNum">    5479 </span>            :                 struct cfs_rq *cfs_rq = tg-&gt;cfs_rq[cpu_of(rq)];</a>
<a name="5480"><span class="lineNum">    5480 </span>            : </a>
<a name="5481"><span class="lineNum">    5481 </span>            :                 if (!cfs_rq-&gt;runtime_enabled)</a>
<a name="5482"><span class="lineNum">    5482 </span>            :                         continue;</a>
<a name="5483"><span class="lineNum">    5483 </span>            : </a>
<a name="5484"><span class="lineNum">    5484 </span>            :                 /*</a>
<a name="5485"><span class="lineNum">    5485 </span>            :                  * clock_task is not advancing so we just need to make sure</a>
<a name="5486"><span class="lineNum">    5486 </span>            :                  * there's some valid quota amount</a>
<a name="5487"><span class="lineNum">    5487 </span>            :                  */</a>
<a name="5488"><span class="lineNum">    5488 </span>            :                 cfs_rq-&gt;runtime_remaining = 1;</a>
<a name="5489"><span class="lineNum">    5489 </span>            :                 /*</a>
<a name="5490"><span class="lineNum">    5490 </span>            :                  * Offline rq is schedulable till CPU is completely disabled</a>
<a name="5491"><span class="lineNum">    5491 </span>            :                  * in take_cpu_down(), so we prevent new cfs throttling here.</a>
<a name="5492"><span class="lineNum">    5492 </span>            :                  */</a>
<a name="5493"><span class="lineNum">    5493 </span>            :                 cfs_rq-&gt;runtime_enabled = 0;</a>
<a name="5494"><span class="lineNum">    5494 </span>            : </a>
<a name="5495"><span class="lineNum">    5495 </span>            :                 if (cfs_rq_throttled(cfs_rq))</a>
<a name="5496"><span class="lineNum">    5496 </span>            :                         unthrottle_cfs_rq(cfs_rq);</a>
<a name="5497"><span class="lineNum">    5497 </span>            :         }</a>
<a name="5498"><span class="lineNum">    5498 </span>            :         rcu_read_unlock();</a>
<a name="5499"><span class="lineNum">    5499 </span>            : }</a>
<a name="5500"><span class="lineNum">    5500 </span>            : </a>
<a name="5501"><span class="lineNum">    5501 </span>            : #else /* CONFIG_CFS_BANDWIDTH */</a>
<a name="5502"><span class="lineNum">    5502 </span>            : </a>
<a name="5503"><span class="lineNum">    5503 </span>            : static inline bool cfs_bandwidth_used(void)</a>
<a name="5504"><span class="lineNum">    5504 </span>            : {</a>
<a name="5505"><span class="lineNum">    5505 </span>            :         return false;</a>
<a name="5506"><span class="lineNum">    5506 </span>            : }</a>
<a name="5507"><span class="lineNum">    5507 </span>            : </a>
<a name="5508"><span class="lineNum">    5508 </span>            : static void account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec) {}</a>
<a name="5509"><span class="lineNum">    5509 </span>            : static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq) { return false; }</a>
<a name="5510"><span class="lineNum">    5510 </span>            : static void check_enqueue_throttle(struct cfs_rq *cfs_rq) {}</a>
<a name="5511"><span class="lineNum">    5511 </span>            : static inline void sync_throttle(struct task_group *tg, int cpu) {}</a>
<a name="5512"><span class="lineNum">    5512 </span>            : static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq) {}</a>
<a name="5513"><span class="lineNum">    5513 </span>            : </a>
<a name="5514"><span class="lineNum">    5514 </span>            : static inline int cfs_rq_throttled(struct cfs_rq *cfs_rq)</a>
<a name="5515"><span class="lineNum">    5515 </span>            : {</a>
<a name="5516"><span class="lineNum">    5516 </span>            :         return 0;</a>
<a name="5517"><span class="lineNum">    5517 </span>            : }</a>
<a name="5518"><span class="lineNum">    5518 </span>            : </a>
<a name="5519"><span class="lineNum">    5519 </span>            : static inline int throttled_hierarchy(struct cfs_rq *cfs_rq)</a>
<a name="5520"><span class="lineNum">    5520 </span>            : {</a>
<a name="5521"><span class="lineNum">    5521 </span>            :         return 0;</a>
<a name="5522"><span class="lineNum">    5522 </span>            : }</a>
<a name="5523"><span class="lineNum">    5523 </span>            : </a>
<a name="5524"><span class="lineNum">    5524 </span>            : static inline int throttled_lb_pair(struct task_group *tg,</a>
<a name="5525"><span class="lineNum">    5525 </span>            :                                     int src_cpu, int dest_cpu)</a>
<a name="5526"><span class="lineNum">    5526 </span>            : {</a>
<a name="5527"><span class="lineNum">    5527 </span>            :         return 0;</a>
<a name="5528"><span class="lineNum">    5528 </span>            : }</a>
<a name="5529"><span class="lineNum">    5529 </span>            : </a>
<a name="5530"><span class="lineNum">    5530 </span><span class="lineNoCov">          0 : void init_cfs_bandwidth(struct cfs_bandwidth *cfs_b) {}</span></a>
<a name="5531"><span class="lineNum">    5531 </span>            : </a>
<a name="5532"><span class="lineNum">    5532 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="5533"><span class="lineNum">    5533 </span>            : static void init_cfs_rq_runtime(struct cfs_rq *cfs_rq) {}</a>
<a name="5534"><span class="lineNum">    5534 </span>            : #endif</a>
<a name="5535"><span class="lineNum">    5535 </span>            : </a>
<a name="5536"><span class="lineNum">    5536 </span>            : static inline struct cfs_bandwidth *tg_cfs_bandwidth(struct task_group *tg)</a>
<a name="5537"><span class="lineNum">    5537 </span>            : {</a>
<a name="5538"><span class="lineNum">    5538 </span>            :         return NULL;</a>
<a name="5539"><span class="lineNum">    5539 </span>            : }</a>
<a name="5540"><span class="lineNum">    5540 </span>            : static inline void destroy_cfs_bandwidth(struct cfs_bandwidth *cfs_b) {}</a>
<a name="5541"><span class="lineNum">    5541 </span>            : static inline void update_runtime_enabled(struct rq *rq) {}</a>
<a name="5542"><span class="lineNum">    5542 </span>            : static inline void unthrottle_offline_cfs_rqs(struct rq *rq) {}</a>
<a name="5543"><span class="lineNum">    5543 </span>            : </a>
<a name="5544"><span class="lineNum">    5544 </span>            : #endif /* CONFIG_CFS_BANDWIDTH */</a>
<a name="5545"><span class="lineNum">    5545 </span>            : </a>
<a name="5546"><span class="lineNum">    5546 </span>            : /**************************************************</a>
<a name="5547"><span class="lineNum">    5547 </span>            :  * CFS operations on tasks:</a>
<a name="5548"><span class="lineNum">    5548 </span>            :  */</a>
<a name="5549"><span class="lineNum">    5549 </span>            : </a>
<a name="5550"><span class="lineNum">    5550 </span>            : #ifdef CONFIG_SCHED_HRTICK</a>
<a name="5551"><span class="lineNum">    5551 </span>            : static void hrtick_start_fair(struct rq *rq, struct task_struct *p)</a>
<a name="5552"><span class="lineNum">    5552 </span>            : {</a>
<a name="5553"><span class="lineNum">    5553 </span>            :         struct sched_entity *se = &amp;p-&gt;se;</a>
<a name="5554"><span class="lineNum">    5554 </span>            :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</a>
<a name="5555"><span class="lineNum">    5555 </span>            : </a>
<a name="5556"><span class="lineNum">    5556 </span>            :         SCHED_WARN_ON(task_rq(p) != rq);</a>
<a name="5557"><span class="lineNum">    5557 </span>            : </a>
<a name="5558"><span class="lineNum">    5558 </span>            :         if (rq-&gt;cfs.h_nr_running &gt; 1) {</a>
<a name="5559"><span class="lineNum">    5559 </span>            :                 u64 slice = sched_slice(cfs_rq, se);</a>
<a name="5560"><span class="lineNum">    5560 </span>            :                 u64 ran = se-&gt;sum_exec_runtime - se-&gt;prev_sum_exec_runtime;</a>
<a name="5561"><span class="lineNum">    5561 </span>            :                 s64 delta = slice - ran;</a>
<a name="5562"><span class="lineNum">    5562 </span>            : </a>
<a name="5563"><span class="lineNum">    5563 </span>            :                 if (delta &lt; 0) {</a>
<a name="5564"><span class="lineNum">    5564 </span>            :                         if (task_current(rq, p))</a>
<a name="5565"><span class="lineNum">    5565 </span>            :                                 resched_curr(rq);</a>
<a name="5566"><span class="lineNum">    5566 </span>            :                         return;</a>
<a name="5567"><span class="lineNum">    5567 </span>            :                 }</a>
<a name="5568"><span class="lineNum">    5568 </span>            :                 hrtick_start(rq, delta);</a>
<a name="5569"><span class="lineNum">    5569 </span>            :         }</a>
<a name="5570"><span class="lineNum">    5570 </span>            : }</a>
<a name="5571"><span class="lineNum">    5571 </span>            : </a>
<a name="5572"><span class="lineNum">    5572 </span>            : /*</a>
<a name="5573"><span class="lineNum">    5573 </span>            :  * called from enqueue/dequeue and updates the hrtick when the</a>
<a name="5574"><span class="lineNum">    5574 </span>            :  * current task is from our class and nr_running is low enough</a>
<a name="5575"><span class="lineNum">    5575 </span>            :  * to matter.</a>
<a name="5576"><span class="lineNum">    5576 </span>            :  */</a>
<a name="5577"><span class="lineNum">    5577 </span>            : static void hrtick_update(struct rq *rq)</a>
<a name="5578"><span class="lineNum">    5578 </span>            : {</a>
<a name="5579"><span class="lineNum">    5579 </span>            :         struct task_struct *curr = rq-&gt;curr;</a>
<a name="5580"><span class="lineNum">    5580 </span>            : </a>
<a name="5581"><span class="lineNum">    5581 </span>            :         if (!hrtick_enabled_fair(rq) || curr-&gt;sched_class != &amp;fair_sched_class)</a>
<a name="5582"><span class="lineNum">    5582 </span>            :                 return;</a>
<a name="5583"><span class="lineNum">    5583 </span>            : </a>
<a name="5584"><span class="lineNum">    5584 </span>            :         if (cfs_rq_of(&amp;curr-&gt;se)-&gt;nr_running &lt; sched_nr_latency)</a>
<a name="5585"><span class="lineNum">    5585 </span>            :                 hrtick_start_fair(rq, curr);</a>
<a name="5586"><span class="lineNum">    5586 </span>            : }</a>
<a name="5587"><span class="lineNum">    5587 </span>            : #else /* !CONFIG_SCHED_HRTICK */</a>
<a name="5588"><span class="lineNum">    5588 </span>            : static inline void</a>
<a name="5589"><span class="lineNum">    5589 </span>            : hrtick_start_fair(struct rq *rq, struct task_struct *p)</a>
<a name="5590"><span class="lineNum">    5590 </span>            : {</a>
<a name="5591"><span class="lineNum">    5591 </span>            : }</a>
<a name="5592"><span class="lineNum">    5592 </span>            : </a>
<a name="5593"><span class="lineNum">    5593 </span>            : static inline void hrtick_update(struct rq *rq)</a>
<a name="5594"><span class="lineNum">    5594 </span>            : {</a>
<a name="5595"><span class="lineNum">    5595 </span>            : }</a>
<a name="5596"><span class="lineNum">    5596 </span>            : #endif</a>
<a name="5597"><span class="lineNum">    5597 </span>            : </a>
<a name="5598"><span class="lineNum">    5598 </span>            : #ifdef CONFIG_SMP</a>
<a name="5599"><span class="lineNum">    5599 </span>            : static inline bool cpu_overutilized(int cpu)</a>
<a name="5600"><span class="lineNum">    5600 </span>            : {</a>
<a name="5601"><span class="lineNum">    5601 </span>            :         return !fits_capacity(cpu_util_cfs(cpu), capacity_of(cpu));</a>
<a name="5602"><span class="lineNum">    5602 </span>            : }</a>
<a name="5603"><span class="lineNum">    5603 </span>            : </a>
<a name="5604"><span class="lineNum">    5604 </span>            : static inline void update_overutilized_status(struct rq *rq)</a>
<a name="5605"><span class="lineNum">    5605 </span>            : {</a>
<a name="5606"><span class="lineNum">    5606 </span>            :         if (!READ_ONCE(rq-&gt;rd-&gt;overutilized) &amp;&amp; cpu_overutilized(rq-&gt;cpu)) {</a>
<a name="5607"><span class="lineNum">    5607 </span>            :                 WRITE_ONCE(rq-&gt;rd-&gt;overutilized, SG_OVERUTILIZED);</a>
<a name="5608"><span class="lineNum">    5608 </span>            :                 trace_sched_overutilized_tp(rq-&gt;rd, SG_OVERUTILIZED);</a>
<a name="5609"><span class="lineNum">    5609 </span>            :         }</a>
<a name="5610"><span class="lineNum">    5610 </span>            : }</a>
<a name="5611"><span class="lineNum">    5611 </span>            : #else</a>
<a name="5612"><span class="lineNum">    5612 </span>            : static inline void update_overutilized_status(struct rq *rq) { }</a>
<a name="5613"><span class="lineNum">    5613 </span>            : #endif</a>
<a name="5614"><span class="lineNum">    5614 </span>            : </a>
<a name="5615"><span class="lineNum">    5615 </span>            : /* Runqueue only has SCHED_IDLE tasks enqueued */</a>
<a name="5616"><span class="lineNum">    5616 </span>            : static int sched_idle_rq(struct rq *rq)</a>
<a name="5617"><span class="lineNum">    5617 </span>            : {</a>
<a name="5618"><span class="lineNum">    5618 </span><span class="lineCov">       1232 :         return unlikely(rq-&gt;nr_running == rq-&gt;cfs.idle_h_nr_running &amp;&amp;</span></a>
<a name="5619"><span class="lineNum">    5619 </span>            :                         rq-&gt;nr_running);</a>
<a name="5620"><span class="lineNum">    5620 </span>            : }</a>
<a name="5621"><span class="lineNum">    5621 </span>            : </a>
<a name="5622"><span class="lineNum">    5622 </span>            : /*</a>
<a name="5623"><span class="lineNum">    5623 </span>            :  * Returns true if cfs_rq only has SCHED_IDLE entities enqueued. Note the use</a>
<a name="5624"><span class="lineNum">    5624 </span>            :  * of idle_nr_running, which does not consider idle descendants of normal</a>
<a name="5625"><span class="lineNum">    5625 </span>            :  * entities.</a>
<a name="5626"><span class="lineNum">    5626 </span>            :  */</a>
<a name="5627"><span class="lineNum">    5627 </span>            : static bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq)</a>
<a name="5628"><span class="lineNum">    5628 </span>            : {</a>
<a name="5629"><span class="lineNum">    5629 </span>            :         return cfs_rq-&gt;nr_running &amp;&amp;</a>
<a name="5630"><span class="lineNum">    5630 </span>            :                 cfs_rq-&gt;nr_running == cfs_rq-&gt;idle_nr_running;</a>
<a name="5631"><span class="lineNum">    5631 </span>            : }</a>
<a name="5632"><span class="lineNum">    5632 </span>            : </a>
<a name="5633"><span class="lineNum">    5633 </span>            : #ifdef CONFIG_SMP</a>
<a name="5634"><span class="lineNum">    5634 </span>            : static int sched_idle_cpu(int cpu)</a>
<a name="5635"><span class="lineNum">    5635 </span>            : {</a>
<a name="5636"><span class="lineNum">    5636 </span>            :         return sched_idle_rq(cpu_rq(cpu));</a>
<a name="5637"><span class="lineNum">    5637 </span>            : }</a>
<a name="5638"><span class="lineNum">    5638 </span>            : #endif</a>
<a name="5639"><span class="lineNum">    5639 </span>            : </a>
<a name="5640"><span class="lineNum">    5640 </span>            : /*</a>
<a name="5641"><span class="lineNum">    5641 </span>            :  * The enqueue_task method is called before nr_running is</a>
<a name="5642"><span class="lineNum">    5642 </span>            :  * increased. Here we update the fair scheduling stats and</a>
<a name="5643"><span class="lineNum">    5643 </span>            :  * then put the task into the rbtree:</a>
<a name="5644"><span class="lineNum">    5644 </span>            :  */</a>
<a name="5645"><span class="lineNum">    5645 </span>            : static void</a>
<a name="5646"><span class="lineNum">    5646 </span><span class="lineCov">        618 : enqueue_task_fair(struct rq *rq, struct task_struct *p, int flags)</span></a>
<a name="5647"><span class="lineNum">    5647 </span>            : {</a>
<a name="5648"><span class="lineNum">    5648 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="5649"><span class="lineNum">    5649 </span><span class="lineCov">        618 :         struct sched_entity *se = &amp;p-&gt;se;</span></a>
<a name="5650"><span class="lineNum">    5650 </span><span class="lineCov">       1236 :         int idle_h_nr_running = task_has_idle_policy(p);</span></a>
<a name="5651"><span class="lineNum">    5651 </span><span class="lineCov">        618 :         int task_new = !(flags &amp; ENQUEUE_WAKEUP);</span></a>
<a name="5652"><span class="lineNum">    5652 </span>            : </a>
<a name="5653"><span class="lineNum">    5653 </span>            :         /*</a>
<a name="5654"><span class="lineNum">    5654 </span>            :          * The code below (indirectly) updates schedutil which looks at</a>
<a name="5655"><span class="lineNum">    5655 </span>            :          * the cfs_rq utilization to select a frequency.</a>
<a name="5656"><span class="lineNum">    5656 </span>            :          * Let's add the task's estimated utilization to the cfs_rq's</a>
<a name="5657"><span class="lineNum">    5657 </span>            :          * estimated utilization, before we update schedutil.</a>
<a name="5658"><span class="lineNum">    5658 </span>            :          */</a>
<a name="5659"><span class="lineNum">    5659 </span><span class="lineCov">        618 :         util_est_enqueue(&amp;rq-&gt;cfs, p);</span></a>
<a name="5660"><span class="lineNum">    5660 </span>            : </a>
<a name="5661"><span class="lineNum">    5661 </span>            :         /*</a>
<a name="5662"><span class="lineNum">    5662 </span>            :          * If in_iowait is set, the code below may not trigger any cpufreq</a>
<a name="5663"><span class="lineNum">    5663 </span>            :          * utilization updates, so do it here explicitly with the IOWAIT flag</a>
<a name="5664"><span class="lineNum">    5664 </span>            :          * passed.</a>
<a name="5665"><span class="lineNum">    5665 </span>            :          */</a>
<a name="5666"><span class="lineNum">    5666 </span>            :         if (p-&gt;in_iowait)</a>
<a name="5667"><span class="lineNum">    5667 </span>            :                 cpufreq_update_util(rq, SCHED_CPUFREQ_IOWAIT);</a>
<a name="5668"><span class="lineNum">    5668 </span>            : </a>
<a name="5669"><span class="lineNum">    5669 </span><span class="lineCov">       1236 :         for_each_sched_entity(se) {</span></a>
<a name="5670"><span class="lineNum">    5670 </span><span class="lineCov">        618 :                 if (se-&gt;on_rq)</span></a>
<a name="5671"><span class="lineNum">    5671 </span>            :                         break;</a>
<a name="5672"><span class="lineNum">    5672 </span><span class="lineCov">       1236 :                 cfs_rq = cfs_rq_of(se);</span></a>
<a name="5673"><span class="lineNum">    5673 </span><span class="lineCov">        618 :                 enqueue_entity(cfs_rq, se, flags);</span></a>
<a name="5674"><span class="lineNum">    5674 </span>            : </a>
<a name="5675"><span class="lineNum">    5675 </span><span class="lineCov">        618 :                 cfs_rq-&gt;h_nr_running++;</span></a>
<a name="5676"><span class="lineNum">    5676 </span><span class="lineCov">        618 :                 cfs_rq-&gt;idle_h_nr_running += idle_h_nr_running;</span></a>
<a name="5677"><span class="lineNum">    5677 </span>            : </a>
<a name="5678"><span class="lineNum">    5678 </span>            :                 if (cfs_rq_is_idle(cfs_rq))</a>
<a name="5679"><span class="lineNum">    5679 </span>            :                         idle_h_nr_running = 1;</a>
<a name="5680"><span class="lineNum">    5680 </span>            : </a>
<a name="5681"><span class="lineNum">    5681 </span>            :                 /* end evaluation on encountering a throttled cfs_rq */</a>
<a name="5682"><span class="lineNum">    5682 </span>            :                 if (cfs_rq_throttled(cfs_rq))</a>
<a name="5683"><span class="lineNum">    5683 </span>            :                         goto enqueue_throttle;</a>
<a name="5684"><span class="lineNum">    5684 </span>            : </a>
<a name="5685"><span class="lineNum">    5685 </span>            :                 flags = ENQUEUE_WAKEUP;</a>
<a name="5686"><span class="lineNum">    5686 </span>            :         }</a>
<a name="5687"><span class="lineNum">    5687 </span>            : </a>
<a name="5688"><span class="lineNum">    5688 </span><span class="lineNoCov">          0 :         for_each_sched_entity(se) {</span></a>
<a name="5689"><span class="lineNum">    5689 </span><span class="lineNoCov">          0 :                 cfs_rq = cfs_rq_of(se);</span></a>
<a name="5690"><span class="lineNum">    5690 </span>            : </a>
<a name="5691"><span class="lineNum">    5691 </span><span class="lineNoCov">          0 :                 update_load_avg(cfs_rq, se, UPDATE_TG);</span></a>
<a name="5692"><span class="lineNum">    5692 </span><span class="lineNoCov">          0 :                 se_update_runnable(se);</span></a>
<a name="5693"><span class="lineNum">    5693 </span><span class="lineNoCov">          0 :                 update_cfs_group(se);</span></a>
<a name="5694"><span class="lineNum">    5694 </span>            : </a>
<a name="5695"><span class="lineNum">    5695 </span><span class="lineNoCov">          0 :                 cfs_rq-&gt;h_nr_running++;</span></a>
<a name="5696"><span class="lineNum">    5696 </span><span class="lineNoCov">          0 :                 cfs_rq-&gt;idle_h_nr_running += idle_h_nr_running;</span></a>
<a name="5697"><span class="lineNum">    5697 </span>            : </a>
<a name="5698"><span class="lineNum">    5698 </span>            :                 if (cfs_rq_is_idle(cfs_rq))</a>
<a name="5699"><span class="lineNum">    5699 </span>            :                         idle_h_nr_running = 1;</a>
<a name="5700"><span class="lineNum">    5700 </span>            : </a>
<a name="5701"><span class="lineNum">    5701 </span>            :                 /* end evaluation on encountering a throttled cfs_rq */</a>
<a name="5702"><span class="lineNum">    5702 </span>            :                 if (cfs_rq_throttled(cfs_rq))</a>
<a name="5703"><span class="lineNum">    5703 </span>            :                         goto enqueue_throttle;</a>
<a name="5704"><span class="lineNum">    5704 </span>            : </a>
<a name="5705"><span class="lineNum">    5705 </span>            :                /*</a>
<a name="5706"><span class="lineNum">    5706 </span>            :                 * One parent has been throttled and cfs_rq removed from the</a>
<a name="5707"><span class="lineNum">    5707 </span>            :                 * list. Add it back to not break the leaf list.</a>
<a name="5708"><span class="lineNum">    5708 </span>            :                 */</a>
<a name="5709"><span class="lineNum">    5709 </span>            :                if (throttled_hierarchy(cfs_rq))</a>
<a name="5710"><span class="lineNum">    5710 </span>            :                        list_add_leaf_cfs_rq(cfs_rq);</a>
<a name="5711"><span class="lineNum">    5711 </span>            :         }</a>
<a name="5712"><span class="lineNum">    5712 </span>            : </a>
<a name="5713"><span class="lineNum">    5713 </span>            :         /* At this point se is NULL and we are at root level*/</a>
<a name="5714"><span class="lineNum">    5714 </span><span class="lineCov">       1236 :         add_nr_running(rq, 1);</span></a>
<a name="5715"><span class="lineNum">    5715 </span>            : </a>
<a name="5716"><span class="lineNum">    5716 </span>            :         /*</a>
<a name="5717"><span class="lineNum">    5717 </span>            :          * Since new tasks are assigned an initial util_avg equal to</a>
<a name="5718"><span class="lineNum">    5718 </span>            :          * half of the spare capacity of their CPU, tiny tasks have the</a>
<a name="5719"><span class="lineNum">    5719 </span>            :          * ability to cross the overutilized threshold, which will</a>
<a name="5720"><span class="lineNum">    5720 </span>            :          * result in the load balancer ruining all the task placement</a>
<a name="5721"><span class="lineNum">    5721 </span>            :          * done by EAS. As a way to mitigate that effect, do not account</a>
<a name="5722"><span class="lineNum">    5722 </span>            :          * for the first enqueue operation of new tasks during the</a>
<a name="5723"><span class="lineNum">    5723 </span>            :          * overutilized flag detection.</a>
<a name="5724"><span class="lineNum">    5724 </span>            :          *</a>
<a name="5725"><span class="lineNum">    5725 </span>            :          * A better way of solving this problem would be to wait for</a>
<a name="5726"><span class="lineNum">    5726 </span>            :          * the PELT signals of tasks to converge before taking them</a>
<a name="5727"><span class="lineNum">    5727 </span>            :          * into account, but that is not straightforward to implement,</a>
<a name="5728"><span class="lineNum">    5728 </span>            :          * and the following generally works well enough in practice.</a>
<a name="5729"><span class="lineNum">    5729 </span>            :          */</a>
<a name="5730"><span class="lineNum">    5730 </span>            :         if (!task_new)</a>
<a name="5731"><span class="lineNum">    5731 </span>            :                 update_overutilized_status(rq);</a>
<a name="5732"><span class="lineNum">    5732 </span>            : </a>
<a name="5733"><span class="lineNum">    5733 </span>            : enqueue_throttle:</a>
<a name="5734"><span class="lineNum">    5734 </span>            :         if (cfs_bandwidth_used()) {</a>
<a name="5735"><span class="lineNum">    5735 </span>            :                 /*</a>
<a name="5736"><span class="lineNum">    5736 </span>            :                  * When bandwidth control is enabled; the cfs_rq_throttled()</a>
<a name="5737"><span class="lineNum">    5737 </span>            :                  * breaks in the above iteration can result in incomplete</a>
<a name="5738"><span class="lineNum">    5738 </span>            :                  * leaf list maintenance, resulting in triggering the assertion</a>
<a name="5739"><span class="lineNum">    5739 </span>            :                  * below.</a>
<a name="5740"><span class="lineNum">    5740 </span>            :                  */</a>
<a name="5741"><span class="lineNum">    5741 </span>            :                 for_each_sched_entity(se) {</a>
<a name="5742"><span class="lineNum">    5742 </span>            :                         cfs_rq = cfs_rq_of(se);</a>
<a name="5743"><span class="lineNum">    5743 </span>            : </a>
<a name="5744"><span class="lineNum">    5744 </span>            :                         if (list_add_leaf_cfs_rq(cfs_rq))</a>
<a name="5745"><span class="lineNum">    5745 </span>            :                                 break;</a>
<a name="5746"><span class="lineNum">    5746 </span>            :                 }</a>
<a name="5747"><span class="lineNum">    5747 </span>            :         }</a>
<a name="5748"><span class="lineNum">    5748 </span>            : </a>
<a name="5749"><span class="lineNum">    5749 </span><span class="lineCov">        618 :         assert_list_leaf_cfs_rq(rq);</span></a>
<a name="5750"><span class="lineNum">    5750 </span>            : </a>
<a name="5751"><span class="lineNum">    5751 </span><span class="lineCov">        618 :         hrtick_update(rq);</span></a>
<a name="5752"><span class="lineNum">    5752 </span><span class="lineCov">        618 : }</span></a>
<a name="5753"><span class="lineNum">    5753 </span>            : </a>
<a name="5754"><span class="lineNum">    5754 </span>            : static void set_next_buddy(struct sched_entity *se);</a>
<a name="5755"><span class="lineNum">    5755 </span>            : </a>
<a name="5756"><span class="lineNum">    5756 </span>            : /*</a>
<a name="5757"><span class="lineNum">    5757 </span>            :  * The dequeue_task method is called before nr_running is</a>
<a name="5758"><span class="lineNum">    5758 </span>            :  * decreased. We remove the task from the rbtree and</a>
<a name="5759"><span class="lineNum">    5759 </span>            :  * update the fair scheduling stats:</a>
<a name="5760"><span class="lineNum">    5760 </span>            :  */</a>
<a name="5761"><span class="lineNum">    5761 </span><span class="lineCov">        616 : static void dequeue_task_fair(struct rq *rq, struct task_struct *p, int flags)</span></a>
<a name="5762"><span class="lineNum">    5762 </span>            : {</a>
<a name="5763"><span class="lineNum">    5763 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="5764"><span class="lineNum">    5764 </span><span class="lineCov">        616 :         struct sched_entity *se = &amp;p-&gt;se;</span></a>
<a name="5765"><span class="lineNum">    5765 </span><span class="lineCov">        616 :         int task_sleep = flags &amp; DEQUEUE_SLEEP;</span></a>
<a name="5766"><span class="lineNum">    5766 </span><span class="lineCov">       1232 :         int idle_h_nr_running = task_has_idle_policy(p);</span></a>
<a name="5767"><span class="lineNum">    5767 </span><span class="lineCov">       1232 :         bool was_sched_idle = sched_idle_rq(rq);</span></a>
<a name="5768"><span class="lineNum">    5768 </span>            : </a>
<a name="5769"><span class="lineNum">    5769 </span><span class="lineCov">        616 :         util_est_dequeue(&amp;rq-&gt;cfs, p);</span></a>
<a name="5770"><span class="lineNum">    5770 </span>            : </a>
<a name="5771"><span class="lineNum">    5771 </span><span class="lineCov">          1 :         for_each_sched_entity(se) {</span></a>
<a name="5772"><span class="lineNum">    5772 </span><span class="lineCov">       1232 :                 cfs_rq = cfs_rq_of(se);</span></a>
<a name="5773"><span class="lineNum">    5773 </span><span class="lineCov">        616 :                 dequeue_entity(cfs_rq, se, flags);</span></a>
<a name="5774"><span class="lineNum">    5774 </span>            : </a>
<a name="5775"><span class="lineNum">    5775 </span><span class="lineCov">        616 :                 cfs_rq-&gt;h_nr_running--;</span></a>
<a name="5776"><span class="lineNum">    5776 </span><span class="lineCov">        616 :                 cfs_rq-&gt;idle_h_nr_running -= idle_h_nr_running;</span></a>
<a name="5777"><span class="lineNum">    5777 </span>            : </a>
<a name="5778"><span class="lineNum">    5778 </span>            :                 if (cfs_rq_is_idle(cfs_rq))</a>
<a name="5779"><span class="lineNum">    5779 </span>            :                         idle_h_nr_running = 1;</a>
<a name="5780"><span class="lineNum">    5780 </span>            : </a>
<a name="5781"><span class="lineNum">    5781 </span>            :                 /* end evaluation on encountering a throttled cfs_rq */</a>
<a name="5782"><span class="lineNum">    5782 </span>            :                 if (cfs_rq_throttled(cfs_rq))</a>
<a name="5783"><span class="lineNum">    5783 </span>            :                         goto dequeue_throttle;</a>
<a name="5784"><span class="lineNum">    5784 </span>            : </a>
<a name="5785"><span class="lineNum">    5785 </span>            :                 /* Don't dequeue parent if it has other entities besides us */</a>
<a name="5786"><span class="lineNum">    5786 </span><span class="lineCov">        616 :                 if (cfs_rq-&gt;load.weight) {</span></a>
<a name="5787"><span class="lineNum">    5787 </span>            :                         /* Avoid re-evaluating load for this entity: */</a>
<a name="5788"><span class="lineNum">    5788 </span>            :                         se = parent_entity(se);</a>
<a name="5789"><span class="lineNum">    5789 </span>            :                         /*</a>
<a name="5790"><span class="lineNum">    5790 </span>            :                          * Bias pick_next to pick a task from this cfs_rq, as</a>
<a name="5791"><span class="lineNum">    5791 </span>            :                          * p is sleeping when it is within its sched_slice.</a>
<a name="5792"><span class="lineNum">    5792 </span>            :                          */</a>
<a name="5793"><span class="lineNum">    5793 </span>            :                         if (task_sleep &amp;&amp; se &amp;&amp; !throttled_hierarchy(cfs_rq))</a>
<a name="5794"><span class="lineNum">    5794 </span>            :                                 set_next_buddy(se);</a>
<a name="5795"><span class="lineNum">    5795 </span>            :                         break;</a>
<a name="5796"><span class="lineNum">    5796 </span>            :                 }</a>
<a name="5797"><span class="lineNum">    5797 </span><span class="lineCov">          1 :                 flags |= DEQUEUE_SLEEP;</span></a>
<a name="5798"><span class="lineNum">    5798 </span>            :         }</a>
<a name="5799"><span class="lineNum">    5799 </span>            : </a>
<a name="5800"><span class="lineNum">    5800 </span><span class="lineCov">        616 :         for_each_sched_entity(se) {</span></a>
<a name="5801"><span class="lineNum">    5801 </span><span class="lineNoCov">          0 :                 cfs_rq = cfs_rq_of(se);</span></a>
<a name="5802"><span class="lineNum">    5802 </span>            : </a>
<a name="5803"><span class="lineNum">    5803 </span><span class="lineNoCov">          0 :                 update_load_avg(cfs_rq, se, UPDATE_TG);</span></a>
<a name="5804"><span class="lineNum">    5804 </span><span class="lineNoCov">          0 :                 se_update_runnable(se);</span></a>
<a name="5805"><span class="lineNum">    5805 </span><span class="lineNoCov">          0 :                 update_cfs_group(se);</span></a>
<a name="5806"><span class="lineNum">    5806 </span>            : </a>
<a name="5807"><span class="lineNum">    5807 </span><span class="lineNoCov">          0 :                 cfs_rq-&gt;h_nr_running--;</span></a>
<a name="5808"><span class="lineNum">    5808 </span><span class="lineNoCov">          0 :                 cfs_rq-&gt;idle_h_nr_running -= idle_h_nr_running;</span></a>
<a name="5809"><span class="lineNum">    5809 </span>            : </a>
<a name="5810"><span class="lineNum">    5810 </span>            :                 if (cfs_rq_is_idle(cfs_rq))</a>
<a name="5811"><span class="lineNum">    5811 </span>            :                         idle_h_nr_running = 1;</a>
<a name="5812"><span class="lineNum">    5812 </span>            : </a>
<a name="5813"><span class="lineNum">    5813 </span>            :                 /* end evaluation on encountering a throttled cfs_rq */</a>
<a name="5814"><span class="lineNum">    5814 </span>            :                 if (cfs_rq_throttled(cfs_rq))</a>
<a name="5815"><span class="lineNum">    5815 </span>            :                         goto dequeue_throttle;</a>
<a name="5816"><span class="lineNum">    5816 </span>            : </a>
<a name="5817"><span class="lineNum">    5817 </span>            :         }</a>
<a name="5818"><span class="lineNum">    5818 </span>            : </a>
<a name="5819"><span class="lineNum">    5819 </span>            :         /* At this point se is NULL and we are at root level*/</a>
<a name="5820"><span class="lineNum">    5820 </span><span class="lineCov">       1232 :         sub_nr_running(rq, 1);</span></a>
<a name="5821"><span class="lineNum">    5821 </span>            : </a>
<a name="5822"><span class="lineNum">    5822 </span>            :         /* balance early to pull high priority tasks */</a>
<a name="5823"><span class="lineNum">    5823 </span><span class="lineCov">       1232 :         if (unlikely(!was_sched_idle &amp;&amp; sched_idle_rq(rq)))</span></a>
<a name="5824"><span class="lineNum">    5824 </span><span class="lineNoCov">          0 :                 rq-&gt;next_balance = jiffies;</span></a>
<a name="5825"><span class="lineNum">    5825 </span>            : </a>
<a name="5826"><span class="lineNum">    5826 </span>            : dequeue_throttle:</a>
<a name="5827"><span class="lineNum">    5827 </span><span class="lineCov">        616 :         util_est_update(&amp;rq-&gt;cfs, p, task_sleep);</span></a>
<a name="5828"><span class="lineNum">    5828 </span><span class="lineCov">        616 :         hrtick_update(rq);</span></a>
<a name="5829"><span class="lineNum">    5829 </span><span class="lineCov">        616 : }</span></a>
<a name="5830"><span class="lineNum">    5830 </span>            : </a>
<a name="5831"><span class="lineNum">    5831 </span>            : #ifdef CONFIG_SMP</a>
<a name="5832"><span class="lineNum">    5832 </span>            : </a>
<a name="5833"><span class="lineNum">    5833 </span>            : /* Working cpumask for: load_balance, load_balance_newidle. */</a>
<a name="5834"><span class="lineNum">    5834 </span>            : DEFINE_PER_CPU(cpumask_var_t, load_balance_mask);</a>
<a name="5835"><span class="lineNum">    5835 </span>            : DEFINE_PER_CPU(cpumask_var_t, select_idle_mask);</a>
<a name="5836"><span class="lineNum">    5836 </span>            : </a>
<a name="5837"><span class="lineNum">    5837 </span>            : #ifdef CONFIG_NO_HZ_COMMON</a>
<a name="5838"><span class="lineNum">    5838 </span>            : </a>
<a name="5839"><span class="lineNum">    5839 </span>            : static struct {</a>
<a name="5840"><span class="lineNum">    5840 </span>            :         cpumask_var_t idle_cpus_mask;</a>
<a name="5841"><span class="lineNum">    5841 </span>            :         atomic_t nr_cpus;</a>
<a name="5842"><span class="lineNum">    5842 </span>            :         int has_blocked;                /* Idle CPUS has blocked load */</a>
<a name="5843"><span class="lineNum">    5843 </span>            :         int needs_update;               /* Newly idle CPUs need their next_balance collated */</a>
<a name="5844"><span class="lineNum">    5844 </span>            :         unsigned long next_balance;     /* in jiffy units */</a>
<a name="5845"><span class="lineNum">    5845 </span>            :         unsigned long next_blocked;     /* Next update of blocked load in jiffies */</a>
<a name="5846"><span class="lineNum">    5846 </span>            : } nohz ____cacheline_aligned;</a>
<a name="5847"><span class="lineNum">    5847 </span>            : </a>
<a name="5848"><span class="lineNum">    5848 </span>            : #endif /* CONFIG_NO_HZ_COMMON */</a>
<a name="5849"><span class="lineNum">    5849 </span>            : </a>
<a name="5850"><span class="lineNum">    5850 </span>            : static unsigned long cpu_load(struct rq *rq)</a>
<a name="5851"><span class="lineNum">    5851 </span>            : {</a>
<a name="5852"><span class="lineNum">    5852 </span>            :         return cfs_rq_load_avg(&amp;rq-&gt;cfs);</a>
<a name="5853"><span class="lineNum">    5853 </span>            : }</a>
<a name="5854"><span class="lineNum">    5854 </span>            : </a>
<a name="5855"><span class="lineNum">    5855 </span>            : /*</a>
<a name="5856"><span class="lineNum">    5856 </span>            :  * cpu_load_without - compute CPU load without any contributions from *p</a>
<a name="5857"><span class="lineNum">    5857 </span>            :  * @cpu: the CPU which load is requested</a>
<a name="5858"><span class="lineNum">    5858 </span>            :  * @p: the task which load should be discounted</a>
<a name="5859"><span class="lineNum">    5859 </span>            :  *</a>
<a name="5860"><span class="lineNum">    5860 </span>            :  * The load of a CPU is defined by the load of tasks currently enqueued on that</a>
<a name="5861"><span class="lineNum">    5861 </span>            :  * CPU as well as tasks which are currently sleeping after an execution on that</a>
<a name="5862"><span class="lineNum">    5862 </span>            :  * CPU.</a>
<a name="5863"><span class="lineNum">    5863 </span>            :  *</a>
<a name="5864"><span class="lineNum">    5864 </span>            :  * This method returns the load of the specified CPU by discounting the load of</a>
<a name="5865"><span class="lineNum">    5865 </span>            :  * the specified task, whenever the task is currently contributing to the CPU</a>
<a name="5866"><span class="lineNum">    5866 </span>            :  * load.</a>
<a name="5867"><span class="lineNum">    5867 </span>            :  */</a>
<a name="5868"><span class="lineNum">    5868 </span>            : static unsigned long cpu_load_without(struct rq *rq, struct task_struct *p)</a>
<a name="5869"><span class="lineNum">    5869 </span>            : {</a>
<a name="5870"><span class="lineNum">    5870 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="5871"><span class="lineNum">    5871 </span>            :         unsigned int load;</a>
<a name="5872"><span class="lineNum">    5872 </span>            : </a>
<a name="5873"><span class="lineNum">    5873 </span>            :         /* Task has no contribution or is new */</a>
<a name="5874"><span class="lineNum">    5874 </span>            :         if (cpu_of(rq) != task_cpu(p) || !READ_ONCE(p-&gt;se.avg.last_update_time))</a>
<a name="5875"><span class="lineNum">    5875 </span>            :                 return cpu_load(rq);</a>
<a name="5876"><span class="lineNum">    5876 </span>            : </a>
<a name="5877"><span class="lineNum">    5877 </span>            :         cfs_rq = &amp;rq-&gt;cfs;</a>
<a name="5878"><span class="lineNum">    5878 </span>            :         load = READ_ONCE(cfs_rq-&gt;avg.load_avg);</a>
<a name="5879"><span class="lineNum">    5879 </span>            : </a>
<a name="5880"><span class="lineNum">    5880 </span>            :         /* Discount task's util from CPU's util */</a>
<a name="5881"><span class="lineNum">    5881 </span>            :         lsub_positive(&amp;load, task_h_load(p));</a>
<a name="5882"><span class="lineNum">    5882 </span>            : </a>
<a name="5883"><span class="lineNum">    5883 </span>            :         return load;</a>
<a name="5884"><span class="lineNum">    5884 </span>            : }</a>
<a name="5885"><span class="lineNum">    5885 </span>            : </a>
<a name="5886"><span class="lineNum">    5886 </span>            : static unsigned long cpu_runnable(struct rq *rq)</a>
<a name="5887"><span class="lineNum">    5887 </span>            : {</a>
<a name="5888"><span class="lineNum">    5888 </span>            :         return cfs_rq_runnable_avg(&amp;rq-&gt;cfs);</a>
<a name="5889"><span class="lineNum">    5889 </span>            : }</a>
<a name="5890"><span class="lineNum">    5890 </span>            : </a>
<a name="5891"><span class="lineNum">    5891 </span>            : static unsigned long cpu_runnable_without(struct rq *rq, struct task_struct *p)</a>
<a name="5892"><span class="lineNum">    5892 </span>            : {</a>
<a name="5893"><span class="lineNum">    5893 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="5894"><span class="lineNum">    5894 </span>            :         unsigned int runnable;</a>
<a name="5895"><span class="lineNum">    5895 </span>            : </a>
<a name="5896"><span class="lineNum">    5896 </span>            :         /* Task has no contribution or is new */</a>
<a name="5897"><span class="lineNum">    5897 </span>            :         if (cpu_of(rq) != task_cpu(p) || !READ_ONCE(p-&gt;se.avg.last_update_time))</a>
<a name="5898"><span class="lineNum">    5898 </span>            :                 return cpu_runnable(rq);</a>
<a name="5899"><span class="lineNum">    5899 </span>            : </a>
<a name="5900"><span class="lineNum">    5900 </span>            :         cfs_rq = &amp;rq-&gt;cfs;</a>
<a name="5901"><span class="lineNum">    5901 </span>            :         runnable = READ_ONCE(cfs_rq-&gt;avg.runnable_avg);</a>
<a name="5902"><span class="lineNum">    5902 </span>            : </a>
<a name="5903"><span class="lineNum">    5903 </span>            :         /* Discount task's runnable from CPU's runnable */</a>
<a name="5904"><span class="lineNum">    5904 </span>            :         lsub_positive(&amp;runnable, p-&gt;se.avg.runnable_avg);</a>
<a name="5905"><span class="lineNum">    5905 </span>            : </a>
<a name="5906"><span class="lineNum">    5906 </span>            :         return runnable;</a>
<a name="5907"><span class="lineNum">    5907 </span>            : }</a>
<a name="5908"><span class="lineNum">    5908 </span>            : </a>
<a name="5909"><span class="lineNum">    5909 </span>            : static unsigned long capacity_of(int cpu)</a>
<a name="5910"><span class="lineNum">    5910 </span>            : {</a>
<a name="5911"><span class="lineNum">    5911 </span>            :         return cpu_rq(cpu)-&gt;cpu_capacity;</a>
<a name="5912"><span class="lineNum">    5912 </span>            : }</a>
<a name="5913"><span class="lineNum">    5913 </span>            : </a>
<a name="5914"><span class="lineNum">    5914 </span>            : static void record_wakee(struct task_struct *p)</a>
<a name="5915"><span class="lineNum">    5915 </span>            : {</a>
<a name="5916"><span class="lineNum">    5916 </span>            :         /*</a>
<a name="5917"><span class="lineNum">    5917 </span>            :          * Only decay a single time; tasks that have less then 1 wakeup per</a>
<a name="5918"><span class="lineNum">    5918 </span>            :          * jiffy will not have built up many flips.</a>
<a name="5919"><span class="lineNum">    5919 </span>            :          */</a>
<a name="5920"><span class="lineNum">    5920 </span>            :         if (time_after(jiffies, current-&gt;wakee_flip_decay_ts + HZ)) {</a>
<a name="5921"><span class="lineNum">    5921 </span>            :                 current-&gt;wakee_flips &gt;&gt;= 1;</a>
<a name="5922"><span class="lineNum">    5922 </span>            :                 current-&gt;wakee_flip_decay_ts = jiffies;</a>
<a name="5923"><span class="lineNum">    5923 </span>            :         }</a>
<a name="5924"><span class="lineNum">    5924 </span>            : </a>
<a name="5925"><span class="lineNum">    5925 </span>            :         if (current-&gt;last_wakee != p) {</a>
<a name="5926"><span class="lineNum">    5926 </span>            :                 current-&gt;last_wakee = p;</a>
<a name="5927"><span class="lineNum">    5927 </span>            :                 current-&gt;wakee_flips++;</a>
<a name="5928"><span class="lineNum">    5928 </span>            :         }</a>
<a name="5929"><span class="lineNum">    5929 </span>            : }</a>
<a name="5930"><span class="lineNum">    5930 </span>            : </a>
<a name="5931"><span class="lineNum">    5931 </span>            : /*</a>
<a name="5932"><span class="lineNum">    5932 </span>            :  * Detect M:N waker/wakee relationships via a switching-frequency heuristic.</a>
<a name="5933"><span class="lineNum">    5933 </span>            :  *</a>
<a name="5934"><span class="lineNum">    5934 </span>            :  * A waker of many should wake a different task than the one last awakened</a>
<a name="5935"><span class="lineNum">    5935 </span>            :  * at a frequency roughly N times higher than one of its wakees.</a>
<a name="5936"><span class="lineNum">    5936 </span>            :  *</a>
<a name="5937"><span class="lineNum">    5937 </span>            :  * In order to determine whether we should let the load spread vs consolidating</a>
<a name="5938"><span class="lineNum">    5938 </span>            :  * to shared cache, we look for a minimum 'flip' frequency of llc_size in one</a>
<a name="5939"><span class="lineNum">    5939 </span>            :  * partner, and a factor of lls_size higher frequency in the other.</a>
<a name="5940"><span class="lineNum">    5940 </span>            :  *</a>
<a name="5941"><span class="lineNum">    5941 </span>            :  * With both conditions met, we can be relatively sure that the relationship is</a>
<a name="5942"><span class="lineNum">    5942 </span>            :  * non-monogamous, with partner count exceeding socket size.</a>
<a name="5943"><span class="lineNum">    5943 </span>            :  *</a>
<a name="5944"><span class="lineNum">    5944 </span>            :  * Waker/wakee being client/server, worker/dispatcher, interrupt source or</a>
<a name="5945"><span class="lineNum">    5945 </span>            :  * whatever is irrelevant, spread criteria is apparent partner count exceeds</a>
<a name="5946"><span class="lineNum">    5946 </span>            :  * socket size.</a>
<a name="5947"><span class="lineNum">    5947 </span>            :  */</a>
<a name="5948"><span class="lineNum">    5948 </span>            : static int wake_wide(struct task_struct *p)</a>
<a name="5949"><span class="lineNum">    5949 </span>            : {</a>
<a name="5950"><span class="lineNum">    5950 </span>            :         unsigned int master = current-&gt;wakee_flips;</a>
<a name="5951"><span class="lineNum">    5951 </span>            :         unsigned int slave = p-&gt;wakee_flips;</a>
<a name="5952"><span class="lineNum">    5952 </span>            :         int factor = __this_cpu_read(sd_llc_size);</a>
<a name="5953"><span class="lineNum">    5953 </span>            : </a>
<a name="5954"><span class="lineNum">    5954 </span>            :         if (master &lt; slave)</a>
<a name="5955"><span class="lineNum">    5955 </span>            :                 swap(master, slave);</a>
<a name="5956"><span class="lineNum">    5956 </span>            :         if (slave &lt; factor || master &lt; slave * factor)</a>
<a name="5957"><span class="lineNum">    5957 </span>            :                 return 0;</a>
<a name="5958"><span class="lineNum">    5958 </span>            :         return 1;</a>
<a name="5959"><span class="lineNum">    5959 </span>            : }</a>
<a name="5960"><span class="lineNum">    5960 </span>            : </a>
<a name="5961"><span class="lineNum">    5961 </span>            : /*</a>
<a name="5962"><span class="lineNum">    5962 </span>            :  * The purpose of wake_affine() is to quickly determine on which CPU we can run</a>
<a name="5963"><span class="lineNum">    5963 </span>            :  * soonest. For the purpose of speed we only consider the waking and previous</a>
<a name="5964"><span class="lineNum">    5964 </span>            :  * CPU.</a>
<a name="5965"><span class="lineNum">    5965 </span>            :  *</a>
<a name="5966"><span class="lineNum">    5966 </span>            :  * wake_affine_idle() - only considers 'now', it check if the waking CPU is</a>
<a name="5967"><span class="lineNum">    5967 </span>            :  *                      cache-affine and is (or will be) idle.</a>
<a name="5968"><span class="lineNum">    5968 </span>            :  *</a>
<a name="5969"><span class="lineNum">    5969 </span>            :  * wake_affine_weight() - considers the weight to reflect the average</a>
<a name="5970"><span class="lineNum">    5970 </span>            :  *                        scheduling latency of the CPUs. This seems to work</a>
<a name="5971"><span class="lineNum">    5971 </span>            :  *                        for the overloaded case.</a>
<a name="5972"><span class="lineNum">    5972 </span>            :  */</a>
<a name="5973"><span class="lineNum">    5973 </span>            : static int</a>
<a name="5974"><span class="lineNum">    5974 </span>            : wake_affine_idle(int this_cpu, int prev_cpu, int sync)</a>
<a name="5975"><span class="lineNum">    5975 </span>            : {</a>
<a name="5976"><span class="lineNum">    5976 </span>            :         /*</a>
<a name="5977"><span class="lineNum">    5977 </span>            :          * If this_cpu is idle, it implies the wakeup is from interrupt</a>
<a name="5978"><span class="lineNum">    5978 </span>            :          * context. Only allow the move if cache is shared. Otherwise an</a>
<a name="5979"><span class="lineNum">    5979 </span>            :          * interrupt intensive workload could force all tasks onto one</a>
<a name="5980"><span class="lineNum">    5980 </span>            :          * node depending on the IO topology or IRQ affinity settings.</a>
<a name="5981"><span class="lineNum">    5981 </span>            :          *</a>
<a name="5982"><span class="lineNum">    5982 </span>            :          * If the prev_cpu is idle and cache affine then avoid a migration.</a>
<a name="5983"><span class="lineNum">    5983 </span>            :          * There is no guarantee that the cache hot data from an interrupt</a>
<a name="5984"><span class="lineNum">    5984 </span>            :          * is more important than cache hot data on the prev_cpu and from</a>
<a name="5985"><span class="lineNum">    5985 </span>            :          * a cpufreq perspective, it's better to have higher utilisation</a>
<a name="5986"><span class="lineNum">    5986 </span>            :          * on one CPU.</a>
<a name="5987"><span class="lineNum">    5987 </span>            :          */</a>
<a name="5988"><span class="lineNum">    5988 </span>            :         if (available_idle_cpu(this_cpu) &amp;&amp; cpus_share_cache(this_cpu, prev_cpu))</a>
<a name="5989"><span class="lineNum">    5989 </span>            :                 return available_idle_cpu(prev_cpu) ? prev_cpu : this_cpu;</a>
<a name="5990"><span class="lineNum">    5990 </span>            : </a>
<a name="5991"><span class="lineNum">    5991 </span>            :         if (sync &amp;&amp; cpu_rq(this_cpu)-&gt;nr_running == 1)</a>
<a name="5992"><span class="lineNum">    5992 </span>            :                 return this_cpu;</a>
<a name="5993"><span class="lineNum">    5993 </span>            : </a>
<a name="5994"><span class="lineNum">    5994 </span>            :         if (available_idle_cpu(prev_cpu))</a>
<a name="5995"><span class="lineNum">    5995 </span>            :                 return prev_cpu;</a>
<a name="5996"><span class="lineNum">    5996 </span>            : </a>
<a name="5997"><span class="lineNum">    5997 </span>            :         return nr_cpumask_bits;</a>
<a name="5998"><span class="lineNum">    5998 </span>            : }</a>
<a name="5999"><span class="lineNum">    5999 </span>            : </a>
<a name="6000"><span class="lineNum">    6000 </span>            : static int</a>
<a name="6001"><span class="lineNum">    6001 </span>            : wake_affine_weight(struct sched_domain *sd, struct task_struct *p,</a>
<a name="6002"><span class="lineNum">    6002 </span>            :                    int this_cpu, int prev_cpu, int sync)</a>
<a name="6003"><span class="lineNum">    6003 </span>            : {</a>
<a name="6004"><span class="lineNum">    6004 </span>            :         s64 this_eff_load, prev_eff_load;</a>
<a name="6005"><span class="lineNum">    6005 </span>            :         unsigned long task_load;</a>
<a name="6006"><span class="lineNum">    6006 </span>            : </a>
<a name="6007"><span class="lineNum">    6007 </span>            :         this_eff_load = cpu_load(cpu_rq(this_cpu));</a>
<a name="6008"><span class="lineNum">    6008 </span>            : </a>
<a name="6009"><span class="lineNum">    6009 </span>            :         if (sync) {</a>
<a name="6010"><span class="lineNum">    6010 </span>            :                 unsigned long current_load = task_h_load(current);</a>
<a name="6011"><span class="lineNum">    6011 </span>            : </a>
<a name="6012"><span class="lineNum">    6012 </span>            :                 if (current_load &gt; this_eff_load)</a>
<a name="6013"><span class="lineNum">    6013 </span>            :                         return this_cpu;</a>
<a name="6014"><span class="lineNum">    6014 </span>            : </a>
<a name="6015"><span class="lineNum">    6015 </span>            :                 this_eff_load -= current_load;</a>
<a name="6016"><span class="lineNum">    6016 </span>            :         }</a>
<a name="6017"><span class="lineNum">    6017 </span>            : </a>
<a name="6018"><span class="lineNum">    6018 </span>            :         task_load = task_h_load(p);</a>
<a name="6019"><span class="lineNum">    6019 </span>            : </a>
<a name="6020"><span class="lineNum">    6020 </span>            :         this_eff_load += task_load;</a>
<a name="6021"><span class="lineNum">    6021 </span>            :         if (sched_feat(WA_BIAS))</a>
<a name="6022"><span class="lineNum">    6022 </span>            :                 this_eff_load *= 100;</a>
<a name="6023"><span class="lineNum">    6023 </span>            :         this_eff_load *= capacity_of(prev_cpu);</a>
<a name="6024"><span class="lineNum">    6024 </span>            : </a>
<a name="6025"><span class="lineNum">    6025 </span>            :         prev_eff_load = cpu_load(cpu_rq(prev_cpu));</a>
<a name="6026"><span class="lineNum">    6026 </span>            :         prev_eff_load -= task_load;</a>
<a name="6027"><span class="lineNum">    6027 </span>            :         if (sched_feat(WA_BIAS))</a>
<a name="6028"><span class="lineNum">    6028 </span>            :                 prev_eff_load *= 100 + (sd-&gt;imbalance_pct - 100) / 2;</a>
<a name="6029"><span class="lineNum">    6029 </span>            :         prev_eff_load *= capacity_of(this_cpu);</a>
<a name="6030"><span class="lineNum">    6030 </span>            : </a>
<a name="6031"><span class="lineNum">    6031 </span>            :         /*</a>
<a name="6032"><span class="lineNum">    6032 </span>            :          * If sync, adjust the weight of prev_eff_load such that if</a>
<a name="6033"><span class="lineNum">    6033 </span>            :          * prev_eff == this_eff that select_idle_sibling() will consider</a>
<a name="6034"><span class="lineNum">    6034 </span>            :          * stacking the wakee on top of the waker if no other CPU is</a>
<a name="6035"><span class="lineNum">    6035 </span>            :          * idle.</a>
<a name="6036"><span class="lineNum">    6036 </span>            :          */</a>
<a name="6037"><span class="lineNum">    6037 </span>            :         if (sync)</a>
<a name="6038"><span class="lineNum">    6038 </span>            :                 prev_eff_load += 1;</a>
<a name="6039"><span class="lineNum">    6039 </span>            : </a>
<a name="6040"><span class="lineNum">    6040 </span>            :         return this_eff_load &lt; prev_eff_load ? this_cpu : nr_cpumask_bits;</a>
<a name="6041"><span class="lineNum">    6041 </span>            : }</a>
<a name="6042"><span class="lineNum">    6042 </span>            : </a>
<a name="6043"><span class="lineNum">    6043 </span>            : static int wake_affine(struct sched_domain *sd, struct task_struct *p,</a>
<a name="6044"><span class="lineNum">    6044 </span>            :                        int this_cpu, int prev_cpu, int sync)</a>
<a name="6045"><span class="lineNum">    6045 </span>            : {</a>
<a name="6046"><span class="lineNum">    6046 </span>            :         int target = nr_cpumask_bits;</a>
<a name="6047"><span class="lineNum">    6047 </span>            : </a>
<a name="6048"><span class="lineNum">    6048 </span>            :         if (sched_feat(WA_IDLE))</a>
<a name="6049"><span class="lineNum">    6049 </span>            :                 target = wake_affine_idle(this_cpu, prev_cpu, sync);</a>
<a name="6050"><span class="lineNum">    6050 </span>            : </a>
<a name="6051"><span class="lineNum">    6051 </span>            :         if (sched_feat(WA_WEIGHT) &amp;&amp; target == nr_cpumask_bits)</a>
<a name="6052"><span class="lineNum">    6052 </span>            :                 target = wake_affine_weight(sd, p, this_cpu, prev_cpu, sync);</a>
<a name="6053"><span class="lineNum">    6053 </span>            : </a>
<a name="6054"><span class="lineNum">    6054 </span>            :         schedstat_inc(p-&gt;stats.nr_wakeups_affine_attempts);</a>
<a name="6055"><span class="lineNum">    6055 </span>            :         if (target == nr_cpumask_bits)</a>
<a name="6056"><span class="lineNum">    6056 </span>            :                 return prev_cpu;</a>
<a name="6057"><span class="lineNum">    6057 </span>            : </a>
<a name="6058"><span class="lineNum">    6058 </span>            :         schedstat_inc(sd-&gt;ttwu_move_affine);</a>
<a name="6059"><span class="lineNum">    6059 </span>            :         schedstat_inc(p-&gt;stats.nr_wakeups_affine);</a>
<a name="6060"><span class="lineNum">    6060 </span>            :         return target;</a>
<a name="6061"><span class="lineNum">    6061 </span>            : }</a>
<a name="6062"><span class="lineNum">    6062 </span>            : </a>
<a name="6063"><span class="lineNum">    6063 </span>            : static struct sched_group *</a>
<a name="6064"><span class="lineNum">    6064 </span>            : find_idlest_group(struct sched_domain *sd, struct task_struct *p, int this_cpu);</a>
<a name="6065"><span class="lineNum">    6065 </span>            : </a>
<a name="6066"><span class="lineNum">    6066 </span>            : /*</a>
<a name="6067"><span class="lineNum">    6067 </span>            :  * find_idlest_group_cpu - find the idlest CPU among the CPUs in the group.</a>
<a name="6068"><span class="lineNum">    6068 </span>            :  */</a>
<a name="6069"><span class="lineNum">    6069 </span>            : static int</a>
<a name="6070"><span class="lineNum">    6070 </span>            : find_idlest_group_cpu(struct sched_group *group, struct task_struct *p, int this_cpu)</a>
<a name="6071"><span class="lineNum">    6071 </span>            : {</a>
<a name="6072"><span class="lineNum">    6072 </span>            :         unsigned long load, min_load = ULONG_MAX;</a>
<a name="6073"><span class="lineNum">    6073 </span>            :         unsigned int min_exit_latency = UINT_MAX;</a>
<a name="6074"><span class="lineNum">    6074 </span>            :         u64 latest_idle_timestamp = 0;</a>
<a name="6075"><span class="lineNum">    6075 </span>            :         int least_loaded_cpu = this_cpu;</a>
<a name="6076"><span class="lineNum">    6076 </span>            :         int shallowest_idle_cpu = -1;</a>
<a name="6077"><span class="lineNum">    6077 </span>            :         int i;</a>
<a name="6078"><span class="lineNum">    6078 </span>            : </a>
<a name="6079"><span class="lineNum">    6079 </span>            :         /* Check if we have any choice: */</a>
<a name="6080"><span class="lineNum">    6080 </span>            :         if (group-&gt;group_weight == 1)</a>
<a name="6081"><span class="lineNum">    6081 </span>            :                 return cpumask_first(sched_group_span(group));</a>
<a name="6082"><span class="lineNum">    6082 </span>            : </a>
<a name="6083"><span class="lineNum">    6083 </span>            :         /* Traverse only the allowed CPUs */</a>
<a name="6084"><span class="lineNum">    6084 </span>            :         for_each_cpu_and(i, sched_group_span(group), p-&gt;cpus_ptr) {</a>
<a name="6085"><span class="lineNum">    6085 </span>            :                 struct rq *rq = cpu_rq(i);</a>
<a name="6086"><span class="lineNum">    6086 </span>            : </a>
<a name="6087"><span class="lineNum">    6087 </span>            :                 if (!sched_core_cookie_match(rq, p))</a>
<a name="6088"><span class="lineNum">    6088 </span>            :                         continue;</a>
<a name="6089"><span class="lineNum">    6089 </span>            : </a>
<a name="6090"><span class="lineNum">    6090 </span>            :                 if (sched_idle_cpu(i))</a>
<a name="6091"><span class="lineNum">    6091 </span>            :                         return i;</a>
<a name="6092"><span class="lineNum">    6092 </span>            : </a>
<a name="6093"><span class="lineNum">    6093 </span>            :                 if (available_idle_cpu(i)) {</a>
<a name="6094"><span class="lineNum">    6094 </span>            :                         struct cpuidle_state *idle = idle_get_state(rq);</a>
<a name="6095"><span class="lineNum">    6095 </span>            :                         if (idle &amp;&amp; idle-&gt;exit_latency &lt; min_exit_latency) {</a>
<a name="6096"><span class="lineNum">    6096 </span>            :                                 /*</a>
<a name="6097"><span class="lineNum">    6097 </span>            :                                  * We give priority to a CPU whose idle state</a>
<a name="6098"><span class="lineNum">    6098 </span>            :                                  * has the smallest exit latency irrespective</a>
<a name="6099"><span class="lineNum">    6099 </span>            :                                  * of any idle timestamp.</a>
<a name="6100"><span class="lineNum">    6100 </span>            :                                  */</a>
<a name="6101"><span class="lineNum">    6101 </span>            :                                 min_exit_latency = idle-&gt;exit_latency;</a>
<a name="6102"><span class="lineNum">    6102 </span>            :                                 latest_idle_timestamp = rq-&gt;idle_stamp;</a>
<a name="6103"><span class="lineNum">    6103 </span>            :                                 shallowest_idle_cpu = i;</a>
<a name="6104"><span class="lineNum">    6104 </span>            :                         } else if ((!idle || idle-&gt;exit_latency == min_exit_latency) &amp;&amp;</a>
<a name="6105"><span class="lineNum">    6105 </span>            :                                    rq-&gt;idle_stamp &gt; latest_idle_timestamp) {</a>
<a name="6106"><span class="lineNum">    6106 </span>            :                                 /*</a>
<a name="6107"><span class="lineNum">    6107 </span>            :                                  * If equal or no active idle state, then</a>
<a name="6108"><span class="lineNum">    6108 </span>            :                                  * the most recently idled CPU might have</a>
<a name="6109"><span class="lineNum">    6109 </span>            :                                  * a warmer cache.</a>
<a name="6110"><span class="lineNum">    6110 </span>            :                                  */</a>
<a name="6111"><span class="lineNum">    6111 </span>            :                                 latest_idle_timestamp = rq-&gt;idle_stamp;</a>
<a name="6112"><span class="lineNum">    6112 </span>            :                                 shallowest_idle_cpu = i;</a>
<a name="6113"><span class="lineNum">    6113 </span>            :                         }</a>
<a name="6114"><span class="lineNum">    6114 </span>            :                 } else if (shallowest_idle_cpu == -1) {</a>
<a name="6115"><span class="lineNum">    6115 </span>            :                         load = cpu_load(cpu_rq(i));</a>
<a name="6116"><span class="lineNum">    6116 </span>            :                         if (load &lt; min_load) {</a>
<a name="6117"><span class="lineNum">    6117 </span>            :                                 min_load = load;</a>
<a name="6118"><span class="lineNum">    6118 </span>            :                                 least_loaded_cpu = i;</a>
<a name="6119"><span class="lineNum">    6119 </span>            :                         }</a>
<a name="6120"><span class="lineNum">    6120 </span>            :                 }</a>
<a name="6121"><span class="lineNum">    6121 </span>            :         }</a>
<a name="6122"><span class="lineNum">    6122 </span>            : </a>
<a name="6123"><span class="lineNum">    6123 </span>            :         return shallowest_idle_cpu != -1 ? shallowest_idle_cpu : least_loaded_cpu;</a>
<a name="6124"><span class="lineNum">    6124 </span>            : }</a>
<a name="6125"><span class="lineNum">    6125 </span>            : </a>
<a name="6126"><span class="lineNum">    6126 </span>            : static inline int find_idlest_cpu(struct sched_domain *sd, struct task_struct *p,</a>
<a name="6127"><span class="lineNum">    6127 </span>            :                                   int cpu, int prev_cpu, int sd_flag)</a>
<a name="6128"><span class="lineNum">    6128 </span>            : {</a>
<a name="6129"><span class="lineNum">    6129 </span>            :         int new_cpu = cpu;</a>
<a name="6130"><span class="lineNum">    6130 </span>            : </a>
<a name="6131"><span class="lineNum">    6131 </span>            :         if (!cpumask_intersects(sched_domain_span(sd), p-&gt;cpus_ptr))</a>
<a name="6132"><span class="lineNum">    6132 </span>            :                 return prev_cpu;</a>
<a name="6133"><span class="lineNum">    6133 </span>            : </a>
<a name="6134"><span class="lineNum">    6134 </span>            :         /*</a>
<a name="6135"><span class="lineNum">    6135 </span>            :          * We need task's util for cpu_util_without, sync it up to</a>
<a name="6136"><span class="lineNum">    6136 </span>            :          * prev_cpu's last_update_time.</a>
<a name="6137"><span class="lineNum">    6137 </span>            :          */</a>
<a name="6138"><span class="lineNum">    6138 </span>            :         if (!(sd_flag &amp; SD_BALANCE_FORK))</a>
<a name="6139"><span class="lineNum">    6139 </span>            :                 sync_entity_load_avg(&amp;p-&gt;se);</a>
<a name="6140"><span class="lineNum">    6140 </span>            : </a>
<a name="6141"><span class="lineNum">    6141 </span>            :         while (sd) {</a>
<a name="6142"><span class="lineNum">    6142 </span>            :                 struct sched_group *group;</a>
<a name="6143"><span class="lineNum">    6143 </span>            :                 struct sched_domain *tmp;</a>
<a name="6144"><span class="lineNum">    6144 </span>            :                 int weight;</a>
<a name="6145"><span class="lineNum">    6145 </span>            : </a>
<a name="6146"><span class="lineNum">    6146 </span>            :                 if (!(sd-&gt;flags &amp; sd_flag)) {</a>
<a name="6147"><span class="lineNum">    6147 </span>            :                         sd = sd-&gt;child;</a>
<a name="6148"><span class="lineNum">    6148 </span>            :                         continue;</a>
<a name="6149"><span class="lineNum">    6149 </span>            :                 }</a>
<a name="6150"><span class="lineNum">    6150 </span>            : </a>
<a name="6151"><span class="lineNum">    6151 </span>            :                 group = find_idlest_group(sd, p, cpu);</a>
<a name="6152"><span class="lineNum">    6152 </span>            :                 if (!group) {</a>
<a name="6153"><span class="lineNum">    6153 </span>            :                         sd = sd-&gt;child;</a>
<a name="6154"><span class="lineNum">    6154 </span>            :                         continue;</a>
<a name="6155"><span class="lineNum">    6155 </span>            :                 }</a>
<a name="6156"><span class="lineNum">    6156 </span>            : </a>
<a name="6157"><span class="lineNum">    6157 </span>            :                 new_cpu = find_idlest_group_cpu(group, p, cpu);</a>
<a name="6158"><span class="lineNum">    6158 </span>            :                 if (new_cpu == cpu) {</a>
<a name="6159"><span class="lineNum">    6159 </span>            :                         /* Now try balancing at a lower domain level of 'cpu': */</a>
<a name="6160"><span class="lineNum">    6160 </span>            :                         sd = sd-&gt;child;</a>
<a name="6161"><span class="lineNum">    6161 </span>            :                         continue;</a>
<a name="6162"><span class="lineNum">    6162 </span>            :                 }</a>
<a name="6163"><span class="lineNum">    6163 </span>            : </a>
<a name="6164"><span class="lineNum">    6164 </span>            :                 /* Now try balancing at a lower domain level of 'new_cpu': */</a>
<a name="6165"><span class="lineNum">    6165 </span>            :                 cpu = new_cpu;</a>
<a name="6166"><span class="lineNum">    6166 </span>            :                 weight = sd-&gt;span_weight;</a>
<a name="6167"><span class="lineNum">    6167 </span>            :                 sd = NULL;</a>
<a name="6168"><span class="lineNum">    6168 </span>            :                 for_each_domain(cpu, tmp) {</a>
<a name="6169"><span class="lineNum">    6169 </span>            :                         if (weight &lt;= tmp-&gt;span_weight)</a>
<a name="6170"><span class="lineNum">    6170 </span>            :                                 break;</a>
<a name="6171"><span class="lineNum">    6171 </span>            :                         if (tmp-&gt;flags &amp; sd_flag)</a>
<a name="6172"><span class="lineNum">    6172 </span>            :                                 sd = tmp;</a>
<a name="6173"><span class="lineNum">    6173 </span>            :                 }</a>
<a name="6174"><span class="lineNum">    6174 </span>            :         }</a>
<a name="6175"><span class="lineNum">    6175 </span>            : </a>
<a name="6176"><span class="lineNum">    6176 </span>            :         return new_cpu;</a>
<a name="6177"><span class="lineNum">    6177 </span>            : }</a>
<a name="6178"><span class="lineNum">    6178 </span>            : </a>
<a name="6179"><span class="lineNum">    6179 </span>            : static inline int __select_idle_cpu(int cpu, struct task_struct *p)</a>
<a name="6180"><span class="lineNum">    6180 </span>            : {</a>
<a name="6181"><span class="lineNum">    6181 </span>            :         if ((available_idle_cpu(cpu) || sched_idle_cpu(cpu)) &amp;&amp;</a>
<a name="6182"><span class="lineNum">    6182 </span>            :             sched_cpu_cookie_match(cpu_rq(cpu), p))</a>
<a name="6183"><span class="lineNum">    6183 </span>            :                 return cpu;</a>
<a name="6184"><span class="lineNum">    6184 </span>            : </a>
<a name="6185"><span class="lineNum">    6185 </span>            :         return -1;</a>
<a name="6186"><span class="lineNum">    6186 </span>            : }</a>
<a name="6187"><span class="lineNum">    6187 </span>            : </a>
<a name="6188"><span class="lineNum">    6188 </span>            : #ifdef CONFIG_SCHED_SMT</a>
<a name="6189"><span class="lineNum">    6189 </span>            : DEFINE_STATIC_KEY_FALSE(sched_smt_present);</a>
<a name="6190"><span class="lineNum">    6190 </span>            : EXPORT_SYMBOL_GPL(sched_smt_present);</a>
<a name="6191"><span class="lineNum">    6191 </span>            : </a>
<a name="6192"><span class="lineNum">    6192 </span>            : static inline void set_idle_cores(int cpu, int val)</a>
<a name="6193"><span class="lineNum">    6193 </span>            : {</a>
<a name="6194"><span class="lineNum">    6194 </span>            :         struct sched_domain_shared *sds;</a>
<a name="6195"><span class="lineNum">    6195 </span>            : </a>
<a name="6196"><span class="lineNum">    6196 </span>            :         sds = rcu_dereference(per_cpu(sd_llc_shared, cpu));</a>
<a name="6197"><span class="lineNum">    6197 </span>            :         if (sds)</a>
<a name="6198"><span class="lineNum">    6198 </span>            :                 WRITE_ONCE(sds-&gt;has_idle_cores, val);</a>
<a name="6199"><span class="lineNum">    6199 </span>            : }</a>
<a name="6200"><span class="lineNum">    6200 </span>            : </a>
<a name="6201"><span class="lineNum">    6201 </span>            : static inline bool test_idle_cores(int cpu, bool def)</a>
<a name="6202"><span class="lineNum">    6202 </span>            : {</a>
<a name="6203"><span class="lineNum">    6203 </span>            :         struct sched_domain_shared *sds;</a>
<a name="6204"><span class="lineNum">    6204 </span>            : </a>
<a name="6205"><span class="lineNum">    6205 </span>            :         sds = rcu_dereference(per_cpu(sd_llc_shared, cpu));</a>
<a name="6206"><span class="lineNum">    6206 </span>            :         if (sds)</a>
<a name="6207"><span class="lineNum">    6207 </span>            :                 return READ_ONCE(sds-&gt;has_idle_cores);</a>
<a name="6208"><span class="lineNum">    6208 </span>            : </a>
<a name="6209"><span class="lineNum">    6209 </span>            :         return def;</a>
<a name="6210"><span class="lineNum">    6210 </span>            : }</a>
<a name="6211"><span class="lineNum">    6211 </span>            : </a>
<a name="6212"><span class="lineNum">    6212 </span>            : /*</a>
<a name="6213"><span class="lineNum">    6213 </span>            :  * Scans the local SMT mask to see if the entire core is idle, and records this</a>
<a name="6214"><span class="lineNum">    6214 </span>            :  * information in sd_llc_shared-&gt;has_idle_cores.</a>
<a name="6215"><span class="lineNum">    6215 </span>            :  *</a>
<a name="6216"><span class="lineNum">    6216 </span>            :  * Since SMT siblings share all cache levels, inspecting this limited remote</a>
<a name="6217"><span class="lineNum">    6217 </span>            :  * state should be fairly cheap.</a>
<a name="6218"><span class="lineNum">    6218 </span>            :  */</a>
<a name="6219"><span class="lineNum">    6219 </span>            : void __update_idle_core(struct rq *rq)</a>
<a name="6220"><span class="lineNum">    6220 </span>            : {</a>
<a name="6221"><span class="lineNum">    6221 </span>            :         int core = cpu_of(rq);</a>
<a name="6222"><span class="lineNum">    6222 </span>            :         int cpu;</a>
<a name="6223"><span class="lineNum">    6223 </span>            : </a>
<a name="6224"><span class="lineNum">    6224 </span>            :         rcu_read_lock();</a>
<a name="6225"><span class="lineNum">    6225 </span>            :         if (test_idle_cores(core, true))</a>
<a name="6226"><span class="lineNum">    6226 </span>            :                 goto unlock;</a>
<a name="6227"><span class="lineNum">    6227 </span>            : </a>
<a name="6228"><span class="lineNum">    6228 </span>            :         for_each_cpu(cpu, cpu_smt_mask(core)) {</a>
<a name="6229"><span class="lineNum">    6229 </span>            :                 if (cpu == core)</a>
<a name="6230"><span class="lineNum">    6230 </span>            :                         continue;</a>
<a name="6231"><span class="lineNum">    6231 </span>            : </a>
<a name="6232"><span class="lineNum">    6232 </span>            :                 if (!available_idle_cpu(cpu))</a>
<a name="6233"><span class="lineNum">    6233 </span>            :                         goto unlock;</a>
<a name="6234"><span class="lineNum">    6234 </span>            :         }</a>
<a name="6235"><span class="lineNum">    6235 </span>            : </a>
<a name="6236"><span class="lineNum">    6236 </span>            :         set_idle_cores(core, 1);</a>
<a name="6237"><span class="lineNum">    6237 </span>            : unlock:</a>
<a name="6238"><span class="lineNum">    6238 </span>            :         rcu_read_unlock();</a>
<a name="6239"><span class="lineNum">    6239 </span>            : }</a>
<a name="6240"><span class="lineNum">    6240 </span>            : </a>
<a name="6241"><span class="lineNum">    6241 </span>            : /*</a>
<a name="6242"><span class="lineNum">    6242 </span>            :  * Scan the entire LLC domain for idle cores; this dynamically switches off if</a>
<a name="6243"><span class="lineNum">    6243 </span>            :  * there are no idle cores left in the system; tracked through</a>
<a name="6244"><span class="lineNum">    6244 </span>            :  * sd_llc-&gt;shared-&gt;has_idle_cores and enabled through update_idle_core() above.</a>
<a name="6245"><span class="lineNum">    6245 </span>            :  */</a>
<a name="6246"><span class="lineNum">    6246 </span>            : static int select_idle_core(struct task_struct *p, int core, struct cpumask *cpus, int *idle_cpu)</a>
<a name="6247"><span class="lineNum">    6247 </span>            : {</a>
<a name="6248"><span class="lineNum">    6248 </span>            :         bool idle = true;</a>
<a name="6249"><span class="lineNum">    6249 </span>            :         int cpu;</a>
<a name="6250"><span class="lineNum">    6250 </span>            : </a>
<a name="6251"><span class="lineNum">    6251 </span>            :         if (!static_branch_likely(&amp;sched_smt_present))</a>
<a name="6252"><span class="lineNum">    6252 </span>            :                 return __select_idle_cpu(core, p);</a>
<a name="6253"><span class="lineNum">    6253 </span>            : </a>
<a name="6254"><span class="lineNum">    6254 </span>            :         for_each_cpu(cpu, cpu_smt_mask(core)) {</a>
<a name="6255"><span class="lineNum">    6255 </span>            :                 if (!available_idle_cpu(cpu)) {</a>
<a name="6256"><span class="lineNum">    6256 </span>            :                         idle = false;</a>
<a name="6257"><span class="lineNum">    6257 </span>            :                         if (*idle_cpu == -1) {</a>
<a name="6258"><span class="lineNum">    6258 </span>            :                                 if (sched_idle_cpu(cpu) &amp;&amp; cpumask_test_cpu(cpu, p-&gt;cpus_ptr)) {</a>
<a name="6259"><span class="lineNum">    6259 </span>            :                                         *idle_cpu = cpu;</a>
<a name="6260"><span class="lineNum">    6260 </span>            :                                         break;</a>
<a name="6261"><span class="lineNum">    6261 </span>            :                                 }</a>
<a name="6262"><span class="lineNum">    6262 </span>            :                                 continue;</a>
<a name="6263"><span class="lineNum">    6263 </span>            :                         }</a>
<a name="6264"><span class="lineNum">    6264 </span>            :                         break;</a>
<a name="6265"><span class="lineNum">    6265 </span>            :                 }</a>
<a name="6266"><span class="lineNum">    6266 </span>            :                 if (*idle_cpu == -1 &amp;&amp; cpumask_test_cpu(cpu, p-&gt;cpus_ptr))</a>
<a name="6267"><span class="lineNum">    6267 </span>            :                         *idle_cpu = cpu;</a>
<a name="6268"><span class="lineNum">    6268 </span>            :         }</a>
<a name="6269"><span class="lineNum">    6269 </span>            : </a>
<a name="6270"><span class="lineNum">    6270 </span>            :         if (idle)</a>
<a name="6271"><span class="lineNum">    6271 </span>            :                 return core;</a>
<a name="6272"><span class="lineNum">    6272 </span>            : </a>
<a name="6273"><span class="lineNum">    6273 </span>            :         cpumask_andnot(cpus, cpus, cpu_smt_mask(core));</a>
<a name="6274"><span class="lineNum">    6274 </span>            :         return -1;</a>
<a name="6275"><span class="lineNum">    6275 </span>            : }</a>
<a name="6276"><span class="lineNum">    6276 </span>            : </a>
<a name="6277"><span class="lineNum">    6277 </span>            : /*</a>
<a name="6278"><span class="lineNum">    6278 </span>            :  * Scan the local SMT mask for idle CPUs.</a>
<a name="6279"><span class="lineNum">    6279 </span>            :  */</a>
<a name="6280"><span class="lineNum">    6280 </span>            : static int select_idle_smt(struct task_struct *p, struct sched_domain *sd, int target)</a>
<a name="6281"><span class="lineNum">    6281 </span>            : {</a>
<a name="6282"><span class="lineNum">    6282 </span>            :         int cpu;</a>
<a name="6283"><span class="lineNum">    6283 </span>            : </a>
<a name="6284"><span class="lineNum">    6284 </span>            :         for_each_cpu(cpu, cpu_smt_mask(target)) {</a>
<a name="6285"><span class="lineNum">    6285 </span>            :                 if (!cpumask_test_cpu(cpu, p-&gt;cpus_ptr) ||</a>
<a name="6286"><span class="lineNum">    6286 </span>            :                     !cpumask_test_cpu(cpu, sched_domain_span(sd)))</a>
<a name="6287"><span class="lineNum">    6287 </span>            :                         continue;</a>
<a name="6288"><span class="lineNum">    6288 </span>            :                 if (available_idle_cpu(cpu) || sched_idle_cpu(cpu))</a>
<a name="6289"><span class="lineNum">    6289 </span>            :                         return cpu;</a>
<a name="6290"><span class="lineNum">    6290 </span>            :         }</a>
<a name="6291"><span class="lineNum">    6291 </span>            : </a>
<a name="6292"><span class="lineNum">    6292 </span>            :         return -1;</a>
<a name="6293"><span class="lineNum">    6293 </span>            : }</a>
<a name="6294"><span class="lineNum">    6294 </span>            : </a>
<a name="6295"><span class="lineNum">    6295 </span>            : #else /* CONFIG_SCHED_SMT */</a>
<a name="6296"><span class="lineNum">    6296 </span>            : </a>
<a name="6297"><span class="lineNum">    6297 </span>            : static inline void set_idle_cores(int cpu, int val)</a>
<a name="6298"><span class="lineNum">    6298 </span>            : {</a>
<a name="6299"><span class="lineNum">    6299 </span>            : }</a>
<a name="6300"><span class="lineNum">    6300 </span>            : </a>
<a name="6301"><span class="lineNum">    6301 </span>            : static inline bool test_idle_cores(int cpu, bool def)</a>
<a name="6302"><span class="lineNum">    6302 </span>            : {</a>
<a name="6303"><span class="lineNum">    6303 </span>            :         return def;</a>
<a name="6304"><span class="lineNum">    6304 </span>            : }</a>
<a name="6305"><span class="lineNum">    6305 </span>            : </a>
<a name="6306"><span class="lineNum">    6306 </span>            : static inline int select_idle_core(struct task_struct *p, int core, struct cpumask *cpus, int *idle_cpu)</a>
<a name="6307"><span class="lineNum">    6307 </span>            : {</a>
<a name="6308"><span class="lineNum">    6308 </span>            :         return __select_idle_cpu(core, p);</a>
<a name="6309"><span class="lineNum">    6309 </span>            : }</a>
<a name="6310"><span class="lineNum">    6310 </span>            : </a>
<a name="6311"><span class="lineNum">    6311 </span>            : static inline int select_idle_smt(struct task_struct *p, struct sched_domain *sd, int target)</a>
<a name="6312"><span class="lineNum">    6312 </span>            : {</a>
<a name="6313"><span class="lineNum">    6313 </span>            :         return -1;</a>
<a name="6314"><span class="lineNum">    6314 </span>            : }</a>
<a name="6315"><span class="lineNum">    6315 </span>            : </a>
<a name="6316"><span class="lineNum">    6316 </span>            : #endif /* CONFIG_SCHED_SMT */</a>
<a name="6317"><span class="lineNum">    6317 </span>            : </a>
<a name="6318"><span class="lineNum">    6318 </span>            : /*</a>
<a name="6319"><span class="lineNum">    6319 </span>            :  * Scan the LLC domain for idle CPUs; this is dynamically regulated by</a>
<a name="6320"><span class="lineNum">    6320 </span>            :  * comparing the average scan cost (tracked in sd-&gt;avg_scan_cost) against the</a>
<a name="6321"><span class="lineNum">    6321 </span>            :  * average idle time for this rq (as found in rq-&gt;avg_idle).</a>
<a name="6322"><span class="lineNum">    6322 </span>            :  */</a>
<a name="6323"><span class="lineNum">    6323 </span>            : static int select_idle_cpu(struct task_struct *p, struct sched_domain *sd, bool has_idle_core, int target)</a>
<a name="6324"><span class="lineNum">    6324 </span>            : {</a>
<a name="6325"><span class="lineNum">    6325 </span>            :         struct cpumask *cpus = this_cpu_cpumask_var_ptr(select_idle_mask);</a>
<a name="6326"><span class="lineNum">    6326 </span>            :         int i, cpu, idle_cpu = -1, nr = INT_MAX;</a>
<a name="6327"><span class="lineNum">    6327 </span>            :         struct rq *this_rq = this_rq();</a>
<a name="6328"><span class="lineNum">    6328 </span>            :         int this = smp_processor_id();</a>
<a name="6329"><span class="lineNum">    6329 </span>            :         struct sched_domain *this_sd;</a>
<a name="6330"><span class="lineNum">    6330 </span>            :         u64 time = 0;</a>
<a name="6331"><span class="lineNum">    6331 </span>            : </a>
<a name="6332"><span class="lineNum">    6332 </span>            :         this_sd = rcu_dereference(*this_cpu_ptr(&amp;sd_llc));</a>
<a name="6333"><span class="lineNum">    6333 </span>            :         if (!this_sd)</a>
<a name="6334"><span class="lineNum">    6334 </span>            :                 return -1;</a>
<a name="6335"><span class="lineNum">    6335 </span>            : </a>
<a name="6336"><span class="lineNum">    6336 </span>            :         cpumask_and(cpus, sched_domain_span(sd), p-&gt;cpus_ptr);</a>
<a name="6337"><span class="lineNum">    6337 </span>            : </a>
<a name="6338"><span class="lineNum">    6338 </span>            :         if (sched_feat(SIS_PROP) &amp;&amp; !has_idle_core) {</a>
<a name="6339"><span class="lineNum">    6339 </span>            :                 u64 avg_cost, avg_idle, span_avg;</a>
<a name="6340"><span class="lineNum">    6340 </span>            :                 unsigned long now = jiffies;</a>
<a name="6341"><span class="lineNum">    6341 </span>            : </a>
<a name="6342"><span class="lineNum">    6342 </span>            :                 /*</a>
<a name="6343"><span class="lineNum">    6343 </span>            :                  * If we're busy, the assumption that the last idle period</a>
<a name="6344"><span class="lineNum">    6344 </span>            :                  * predicts the future is flawed; age away the remaining</a>
<a name="6345"><span class="lineNum">    6345 </span>            :                  * predicted idle time.</a>
<a name="6346"><span class="lineNum">    6346 </span>            :                  */</a>
<a name="6347"><span class="lineNum">    6347 </span>            :                 if (unlikely(this_rq-&gt;wake_stamp &lt; now)) {</a>
<a name="6348"><span class="lineNum">    6348 </span>            :                         while (this_rq-&gt;wake_stamp &lt; now &amp;&amp; this_rq-&gt;wake_avg_idle) {</a>
<a name="6349"><span class="lineNum">    6349 </span>            :                                 this_rq-&gt;wake_stamp++;</a>
<a name="6350"><span class="lineNum">    6350 </span>            :                                 this_rq-&gt;wake_avg_idle &gt;&gt;= 1;</a>
<a name="6351"><span class="lineNum">    6351 </span>            :                         }</a>
<a name="6352"><span class="lineNum">    6352 </span>            :                 }</a>
<a name="6353"><span class="lineNum">    6353 </span>            : </a>
<a name="6354"><span class="lineNum">    6354 </span>            :                 avg_idle = this_rq-&gt;wake_avg_idle;</a>
<a name="6355"><span class="lineNum">    6355 </span>            :                 avg_cost = this_sd-&gt;avg_scan_cost + 1;</a>
<a name="6356"><span class="lineNum">    6356 </span>            : </a>
<a name="6357"><span class="lineNum">    6357 </span>            :                 span_avg = sd-&gt;span_weight * avg_idle;</a>
<a name="6358"><span class="lineNum">    6358 </span>            :                 if (span_avg &gt; 4*avg_cost)</a>
<a name="6359"><span class="lineNum">    6359 </span>            :                         nr = div_u64(span_avg, avg_cost);</a>
<a name="6360"><span class="lineNum">    6360 </span>            :                 else</a>
<a name="6361"><span class="lineNum">    6361 </span>            :                         nr = 4;</a>
<a name="6362"><span class="lineNum">    6362 </span>            : </a>
<a name="6363"><span class="lineNum">    6363 </span>            :                 time = cpu_clock(this);</a>
<a name="6364"><span class="lineNum">    6364 </span>            :         }</a>
<a name="6365"><span class="lineNum">    6365 </span>            : </a>
<a name="6366"><span class="lineNum">    6366 </span>            :         for_each_cpu_wrap(cpu, cpus, target + 1) {</a>
<a name="6367"><span class="lineNum">    6367 </span>            :                 if (has_idle_core) {</a>
<a name="6368"><span class="lineNum">    6368 </span>            :                         i = select_idle_core(p, cpu, cpus, &amp;idle_cpu);</a>
<a name="6369"><span class="lineNum">    6369 </span>            :                         if ((unsigned int)i &lt; nr_cpumask_bits)</a>
<a name="6370"><span class="lineNum">    6370 </span>            :                                 return i;</a>
<a name="6371"><span class="lineNum">    6371 </span>            : </a>
<a name="6372"><span class="lineNum">    6372 </span>            :                 } else {</a>
<a name="6373"><span class="lineNum">    6373 </span>            :                         if (!--nr)</a>
<a name="6374"><span class="lineNum">    6374 </span>            :                                 return -1;</a>
<a name="6375"><span class="lineNum">    6375 </span>            :                         idle_cpu = __select_idle_cpu(cpu, p);</a>
<a name="6376"><span class="lineNum">    6376 </span>            :                         if ((unsigned int)idle_cpu &lt; nr_cpumask_bits)</a>
<a name="6377"><span class="lineNum">    6377 </span>            :                                 break;</a>
<a name="6378"><span class="lineNum">    6378 </span>            :                 }</a>
<a name="6379"><span class="lineNum">    6379 </span>            :         }</a>
<a name="6380"><span class="lineNum">    6380 </span>            : </a>
<a name="6381"><span class="lineNum">    6381 </span>            :         if (has_idle_core)</a>
<a name="6382"><span class="lineNum">    6382 </span>            :                 set_idle_cores(target, false);</a>
<a name="6383"><span class="lineNum">    6383 </span>            : </a>
<a name="6384"><span class="lineNum">    6384 </span>            :         if (sched_feat(SIS_PROP) &amp;&amp; !has_idle_core) {</a>
<a name="6385"><span class="lineNum">    6385 </span>            :                 time = cpu_clock(this) - time;</a>
<a name="6386"><span class="lineNum">    6386 </span>            : </a>
<a name="6387"><span class="lineNum">    6387 </span>            :                 /*</a>
<a name="6388"><span class="lineNum">    6388 </span>            :                  * Account for the scan cost of wakeups against the average</a>
<a name="6389"><span class="lineNum">    6389 </span>            :                  * idle time.</a>
<a name="6390"><span class="lineNum">    6390 </span>            :                  */</a>
<a name="6391"><span class="lineNum">    6391 </span>            :                 this_rq-&gt;wake_avg_idle -= min(this_rq-&gt;wake_avg_idle, time);</a>
<a name="6392"><span class="lineNum">    6392 </span>            : </a>
<a name="6393"><span class="lineNum">    6393 </span>            :                 update_avg(&amp;this_sd-&gt;avg_scan_cost, time);</a>
<a name="6394"><span class="lineNum">    6394 </span>            :         }</a>
<a name="6395"><span class="lineNum">    6395 </span>            : </a>
<a name="6396"><span class="lineNum">    6396 </span>            :         return idle_cpu;</a>
<a name="6397"><span class="lineNum">    6397 </span>            : }</a>
<a name="6398"><span class="lineNum">    6398 </span>            : </a>
<a name="6399"><span class="lineNum">    6399 </span>            : /*</a>
<a name="6400"><span class="lineNum">    6400 </span>            :  * Scan the asym_capacity domain for idle CPUs; pick the first idle one on which</a>
<a name="6401"><span class="lineNum">    6401 </span>            :  * the task fits. If no CPU is big enough, but there are idle ones, try to</a>
<a name="6402"><span class="lineNum">    6402 </span>            :  * maximize capacity.</a>
<a name="6403"><span class="lineNum">    6403 </span>            :  */</a>
<a name="6404"><span class="lineNum">    6404 </span>            : static int</a>
<a name="6405"><span class="lineNum">    6405 </span>            : select_idle_capacity(struct task_struct *p, struct sched_domain *sd, int target)</a>
<a name="6406"><span class="lineNum">    6406 </span>            : {</a>
<a name="6407"><span class="lineNum">    6407 </span>            :         unsigned long task_util, best_cap = 0;</a>
<a name="6408"><span class="lineNum">    6408 </span>            :         int cpu, best_cpu = -1;</a>
<a name="6409"><span class="lineNum">    6409 </span>            :         struct cpumask *cpus;</a>
<a name="6410"><span class="lineNum">    6410 </span>            : </a>
<a name="6411"><span class="lineNum">    6411 </span>            :         cpus = this_cpu_cpumask_var_ptr(select_idle_mask);</a>
<a name="6412"><span class="lineNum">    6412 </span>            :         cpumask_and(cpus, sched_domain_span(sd), p-&gt;cpus_ptr);</a>
<a name="6413"><span class="lineNum">    6413 </span>            : </a>
<a name="6414"><span class="lineNum">    6414 </span>            :         task_util = uclamp_task_util(p);</a>
<a name="6415"><span class="lineNum">    6415 </span>            : </a>
<a name="6416"><span class="lineNum">    6416 </span>            :         for_each_cpu_wrap(cpu, cpus, target) {</a>
<a name="6417"><span class="lineNum">    6417 </span>            :                 unsigned long cpu_cap = capacity_of(cpu);</a>
<a name="6418"><span class="lineNum">    6418 </span>            : </a>
<a name="6419"><span class="lineNum">    6419 </span>            :                 if (!available_idle_cpu(cpu) &amp;&amp; !sched_idle_cpu(cpu))</a>
<a name="6420"><span class="lineNum">    6420 </span>            :                         continue;</a>
<a name="6421"><span class="lineNum">    6421 </span>            :                 if (fits_capacity(task_util, cpu_cap))</a>
<a name="6422"><span class="lineNum">    6422 </span>            :                         return cpu;</a>
<a name="6423"><span class="lineNum">    6423 </span>            : </a>
<a name="6424"><span class="lineNum">    6424 </span>            :                 if (cpu_cap &gt; best_cap) {</a>
<a name="6425"><span class="lineNum">    6425 </span>            :                         best_cap = cpu_cap;</a>
<a name="6426"><span class="lineNum">    6426 </span>            :                         best_cpu = cpu;</a>
<a name="6427"><span class="lineNum">    6427 </span>            :                 }</a>
<a name="6428"><span class="lineNum">    6428 </span>            :         }</a>
<a name="6429"><span class="lineNum">    6429 </span>            : </a>
<a name="6430"><span class="lineNum">    6430 </span>            :         return best_cpu;</a>
<a name="6431"><span class="lineNum">    6431 </span>            : }</a>
<a name="6432"><span class="lineNum">    6432 </span>            : </a>
<a name="6433"><span class="lineNum">    6433 </span>            : static inline bool asym_fits_capacity(unsigned long task_util, int cpu)</a>
<a name="6434"><span class="lineNum">    6434 </span>            : {</a>
<a name="6435"><span class="lineNum">    6435 </span>            :         if (static_branch_unlikely(&amp;sched_asym_cpucapacity))</a>
<a name="6436"><span class="lineNum">    6436 </span>            :                 return fits_capacity(task_util, capacity_of(cpu));</a>
<a name="6437"><span class="lineNum">    6437 </span>            : </a>
<a name="6438"><span class="lineNum">    6438 </span>            :         return true;</a>
<a name="6439"><span class="lineNum">    6439 </span>            : }</a>
<a name="6440"><span class="lineNum">    6440 </span>            : </a>
<a name="6441"><span class="lineNum">    6441 </span>            : /*</a>
<a name="6442"><span class="lineNum">    6442 </span>            :  * Try and locate an idle core/thread in the LLC cache domain.</a>
<a name="6443"><span class="lineNum">    6443 </span>            :  */</a>
<a name="6444"><span class="lineNum">    6444 </span>            : static int select_idle_sibling(struct task_struct *p, int prev, int target)</a>
<a name="6445"><span class="lineNum">    6445 </span>            : {</a>
<a name="6446"><span class="lineNum">    6446 </span>            :         bool has_idle_core = false;</a>
<a name="6447"><span class="lineNum">    6447 </span>            :         struct sched_domain *sd;</a>
<a name="6448"><span class="lineNum">    6448 </span>            :         unsigned long task_util;</a>
<a name="6449"><span class="lineNum">    6449 </span>            :         int i, recent_used_cpu;</a>
<a name="6450"><span class="lineNum">    6450 </span>            : </a>
<a name="6451"><span class="lineNum">    6451 </span>            :         /*</a>
<a name="6452"><span class="lineNum">    6452 </span>            :          * On asymmetric system, update task utilization because we will check</a>
<a name="6453"><span class="lineNum">    6453 </span>            :          * that the task fits with cpu's capacity.</a>
<a name="6454"><span class="lineNum">    6454 </span>            :          */</a>
<a name="6455"><span class="lineNum">    6455 </span>            :         if (static_branch_unlikely(&amp;sched_asym_cpucapacity)) {</a>
<a name="6456"><span class="lineNum">    6456 </span>            :                 sync_entity_load_avg(&amp;p-&gt;se);</a>
<a name="6457"><span class="lineNum">    6457 </span>            :                 task_util = uclamp_task_util(p);</a>
<a name="6458"><span class="lineNum">    6458 </span>            :         }</a>
<a name="6459"><span class="lineNum">    6459 </span>            : </a>
<a name="6460"><span class="lineNum">    6460 </span>            :         /*</a>
<a name="6461"><span class="lineNum">    6461 </span>            :          * per-cpu select_idle_mask usage</a>
<a name="6462"><span class="lineNum">    6462 </span>            :          */</a>
<a name="6463"><span class="lineNum">    6463 </span>            :         lockdep_assert_irqs_disabled();</a>
<a name="6464"><span class="lineNum">    6464 </span>            : </a>
<a name="6465"><span class="lineNum">    6465 </span>            :         if ((available_idle_cpu(target) || sched_idle_cpu(target)) &amp;&amp;</a>
<a name="6466"><span class="lineNum">    6466 </span>            :             asym_fits_capacity(task_util, target))</a>
<a name="6467"><span class="lineNum">    6467 </span>            :                 return target;</a>
<a name="6468"><span class="lineNum">    6468 </span>            : </a>
<a name="6469"><span class="lineNum">    6469 </span>            :         /*</a>
<a name="6470"><span class="lineNum">    6470 </span>            :          * If the previous CPU is cache affine and idle, don't be stupid:</a>
<a name="6471"><span class="lineNum">    6471 </span>            :          */</a>
<a name="6472"><span class="lineNum">    6472 </span>            :         if (prev != target &amp;&amp; cpus_share_cache(prev, target) &amp;&amp;</a>
<a name="6473"><span class="lineNum">    6473 </span>            :             (available_idle_cpu(prev) || sched_idle_cpu(prev)) &amp;&amp;</a>
<a name="6474"><span class="lineNum">    6474 </span>            :             asym_fits_capacity(task_util, prev))</a>
<a name="6475"><span class="lineNum">    6475 </span>            :                 return prev;</a>
<a name="6476"><span class="lineNum">    6476 </span>            : </a>
<a name="6477"><span class="lineNum">    6477 </span>            :         /*</a>
<a name="6478"><span class="lineNum">    6478 </span>            :          * Allow a per-cpu kthread to stack with the wakee if the</a>
<a name="6479"><span class="lineNum">    6479 </span>            :          * kworker thread and the tasks previous CPUs are the same.</a>
<a name="6480"><span class="lineNum">    6480 </span>            :          * The assumption is that the wakee queued work for the</a>
<a name="6481"><span class="lineNum">    6481 </span>            :          * per-cpu kthread that is now complete and the wakeup is</a>
<a name="6482"><span class="lineNum">    6482 </span>            :          * essentially a sync wakeup. An obvious example of this</a>
<a name="6483"><span class="lineNum">    6483 </span>            :          * pattern is IO completions.</a>
<a name="6484"><span class="lineNum">    6484 </span>            :          */</a>
<a name="6485"><span class="lineNum">    6485 </span>            :         if (is_per_cpu_kthread(current) &amp;&amp;</a>
<a name="6486"><span class="lineNum">    6486 </span>            :             in_task() &amp;&amp;</a>
<a name="6487"><span class="lineNum">    6487 </span>            :             prev == smp_processor_id() &amp;&amp;</a>
<a name="6488"><span class="lineNum">    6488 </span>            :             this_rq()-&gt;nr_running &lt;= 1 &amp;&amp;</a>
<a name="6489"><span class="lineNum">    6489 </span>            :             asym_fits_capacity(task_util, prev)) {</a>
<a name="6490"><span class="lineNum">    6490 </span>            :                 return prev;</a>
<a name="6491"><span class="lineNum">    6491 </span>            :         }</a>
<a name="6492"><span class="lineNum">    6492 </span>            : </a>
<a name="6493"><span class="lineNum">    6493 </span>            :         /* Check a recently used CPU as a potential idle candidate: */</a>
<a name="6494"><span class="lineNum">    6494 </span>            :         recent_used_cpu = p-&gt;recent_used_cpu;</a>
<a name="6495"><span class="lineNum">    6495 </span>            :         p-&gt;recent_used_cpu = prev;</a>
<a name="6496"><span class="lineNum">    6496 </span>            :         if (recent_used_cpu != prev &amp;&amp;</a>
<a name="6497"><span class="lineNum">    6497 </span>            :             recent_used_cpu != target &amp;&amp;</a>
<a name="6498"><span class="lineNum">    6498 </span>            :             cpus_share_cache(recent_used_cpu, target) &amp;&amp;</a>
<a name="6499"><span class="lineNum">    6499 </span>            :             (available_idle_cpu(recent_used_cpu) || sched_idle_cpu(recent_used_cpu)) &amp;&amp;</a>
<a name="6500"><span class="lineNum">    6500 </span>            :             cpumask_test_cpu(p-&gt;recent_used_cpu, p-&gt;cpus_ptr) &amp;&amp;</a>
<a name="6501"><span class="lineNum">    6501 </span>            :             asym_fits_capacity(task_util, recent_used_cpu)) {</a>
<a name="6502"><span class="lineNum">    6502 </span>            :                 return recent_used_cpu;</a>
<a name="6503"><span class="lineNum">    6503 </span>            :         }</a>
<a name="6504"><span class="lineNum">    6504 </span>            : </a>
<a name="6505"><span class="lineNum">    6505 </span>            :         /*</a>
<a name="6506"><span class="lineNum">    6506 </span>            :          * For asymmetric CPU capacity systems, our domain of interest is</a>
<a name="6507"><span class="lineNum">    6507 </span>            :          * sd_asym_cpucapacity rather than sd_llc.</a>
<a name="6508"><span class="lineNum">    6508 </span>            :          */</a>
<a name="6509"><span class="lineNum">    6509 </span>            :         if (static_branch_unlikely(&amp;sched_asym_cpucapacity)) {</a>
<a name="6510"><span class="lineNum">    6510 </span>            :                 sd = rcu_dereference(per_cpu(sd_asym_cpucapacity, target));</a>
<a name="6511"><span class="lineNum">    6511 </span>            :                 /*</a>
<a name="6512"><span class="lineNum">    6512 </span>            :                  * On an asymmetric CPU capacity system where an exclusive</a>
<a name="6513"><span class="lineNum">    6513 </span>            :                  * cpuset defines a symmetric island (i.e. one unique</a>
<a name="6514"><span class="lineNum">    6514 </span>            :                  * capacity_orig value through the cpuset), the key will be set</a>
<a name="6515"><span class="lineNum">    6515 </span>            :                  * but the CPUs within that cpuset will not have a domain with</a>
<a name="6516"><span class="lineNum">    6516 </span>            :                  * SD_ASYM_CPUCAPACITY. These should follow the usual symmetric</a>
<a name="6517"><span class="lineNum">    6517 </span>            :                  * capacity path.</a>
<a name="6518"><span class="lineNum">    6518 </span>            :                  */</a>
<a name="6519"><span class="lineNum">    6519 </span>            :                 if (sd) {</a>
<a name="6520"><span class="lineNum">    6520 </span>            :                         i = select_idle_capacity(p, sd, target);</a>
<a name="6521"><span class="lineNum">    6521 </span>            :                         return ((unsigned)i &lt; nr_cpumask_bits) ? i : target;</a>
<a name="6522"><span class="lineNum">    6522 </span>            :                 }</a>
<a name="6523"><span class="lineNum">    6523 </span>            :         }</a>
<a name="6524"><span class="lineNum">    6524 </span>            : </a>
<a name="6525"><span class="lineNum">    6525 </span>            :         sd = rcu_dereference(per_cpu(sd_llc, target));</a>
<a name="6526"><span class="lineNum">    6526 </span>            :         if (!sd)</a>
<a name="6527"><span class="lineNum">    6527 </span>            :                 return target;</a>
<a name="6528"><span class="lineNum">    6528 </span>            : </a>
<a name="6529"><span class="lineNum">    6529 </span>            :         if (sched_smt_active()) {</a>
<a name="6530"><span class="lineNum">    6530 </span>            :                 has_idle_core = test_idle_cores(target, false);</a>
<a name="6531"><span class="lineNum">    6531 </span>            : </a>
<a name="6532"><span class="lineNum">    6532 </span>            :                 if (!has_idle_core &amp;&amp; cpus_share_cache(prev, target)) {</a>
<a name="6533"><span class="lineNum">    6533 </span>            :                         i = select_idle_smt(p, sd, prev);</a>
<a name="6534"><span class="lineNum">    6534 </span>            :                         if ((unsigned int)i &lt; nr_cpumask_bits)</a>
<a name="6535"><span class="lineNum">    6535 </span>            :                                 return i;</a>
<a name="6536"><span class="lineNum">    6536 </span>            :                 }</a>
<a name="6537"><span class="lineNum">    6537 </span>            :         }</a>
<a name="6538"><span class="lineNum">    6538 </span>            : </a>
<a name="6539"><span class="lineNum">    6539 </span>            :         i = select_idle_cpu(p, sd, has_idle_core, target);</a>
<a name="6540"><span class="lineNum">    6540 </span>            :         if ((unsigned)i &lt; nr_cpumask_bits)</a>
<a name="6541"><span class="lineNum">    6541 </span>            :                 return i;</a>
<a name="6542"><span class="lineNum">    6542 </span>            : </a>
<a name="6543"><span class="lineNum">    6543 </span>            :         return target;</a>
<a name="6544"><span class="lineNum">    6544 </span>            : }</a>
<a name="6545"><span class="lineNum">    6545 </span>            : </a>
<a name="6546"><span class="lineNum">    6546 </span>            : /*</a>
<a name="6547"><span class="lineNum">    6547 </span>            :  * cpu_util_without: compute cpu utilization without any contributions from *p</a>
<a name="6548"><span class="lineNum">    6548 </span>            :  * @cpu: the CPU which utilization is requested</a>
<a name="6549"><span class="lineNum">    6549 </span>            :  * @p: the task which utilization should be discounted</a>
<a name="6550"><span class="lineNum">    6550 </span>            :  *</a>
<a name="6551"><span class="lineNum">    6551 </span>            :  * The utilization of a CPU is defined by the utilization of tasks currently</a>
<a name="6552"><span class="lineNum">    6552 </span>            :  * enqueued on that CPU as well as tasks which are currently sleeping after an</a>
<a name="6553"><span class="lineNum">    6553 </span>            :  * execution on that CPU.</a>
<a name="6554"><span class="lineNum">    6554 </span>            :  *</a>
<a name="6555"><span class="lineNum">    6555 </span>            :  * This method returns the utilization of the specified CPU by discounting the</a>
<a name="6556"><span class="lineNum">    6556 </span>            :  * utilization of the specified task, whenever the task is currently</a>
<a name="6557"><span class="lineNum">    6557 </span>            :  * contributing to the CPU utilization.</a>
<a name="6558"><span class="lineNum">    6558 </span>            :  */</a>
<a name="6559"><span class="lineNum">    6559 </span>            : static unsigned long cpu_util_without(int cpu, struct task_struct *p)</a>
<a name="6560"><span class="lineNum">    6560 </span>            : {</a>
<a name="6561"><span class="lineNum">    6561 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="6562"><span class="lineNum">    6562 </span>            :         unsigned int util;</a>
<a name="6563"><span class="lineNum">    6563 </span>            : </a>
<a name="6564"><span class="lineNum">    6564 </span>            :         /* Task has no contribution or is new */</a>
<a name="6565"><span class="lineNum">    6565 </span>            :         if (cpu != task_cpu(p) || !READ_ONCE(p-&gt;se.avg.last_update_time))</a>
<a name="6566"><span class="lineNum">    6566 </span>            :                 return cpu_util_cfs(cpu);</a>
<a name="6567"><span class="lineNum">    6567 </span>            : </a>
<a name="6568"><span class="lineNum">    6568 </span>            :         cfs_rq = &amp;cpu_rq(cpu)-&gt;cfs;</a>
<a name="6569"><span class="lineNum">    6569 </span>            :         util = READ_ONCE(cfs_rq-&gt;avg.util_avg);</a>
<a name="6570"><span class="lineNum">    6570 </span>            : </a>
<a name="6571"><span class="lineNum">    6571 </span>            :         /* Discount task's util from CPU's util */</a>
<a name="6572"><span class="lineNum">    6572 </span>            :         lsub_positive(&amp;util, task_util(p));</a>
<a name="6573"><span class="lineNum">    6573 </span>            : </a>
<a name="6574"><span class="lineNum">    6574 </span>            :         /*</a>
<a name="6575"><span class="lineNum">    6575 </span>            :          * Covered cases:</a>
<a name="6576"><span class="lineNum">    6576 </span>            :          *</a>
<a name="6577"><span class="lineNum">    6577 </span>            :          * a) if *p is the only task sleeping on this CPU, then:</a>
<a name="6578"><span class="lineNum">    6578 </span>            :          *      cpu_util (== task_util) &gt; util_est (== 0)</a>
<a name="6579"><span class="lineNum">    6579 </span>            :          *    and thus we return:</a>
<a name="6580"><span class="lineNum">    6580 </span>            :          *      cpu_util_without = (cpu_util - task_util) = 0</a>
<a name="6581"><span class="lineNum">    6581 </span>            :          *</a>
<a name="6582"><span class="lineNum">    6582 </span>            :          * b) if other tasks are SLEEPING on this CPU, which is now exiting</a>
<a name="6583"><span class="lineNum">    6583 </span>            :          *    IDLE, then:</a>
<a name="6584"><span class="lineNum">    6584 </span>            :          *      cpu_util &gt;= task_util</a>
<a name="6585"><span class="lineNum">    6585 </span>            :          *      cpu_util &gt; util_est (== 0)</a>
<a name="6586"><span class="lineNum">    6586 </span>            :          *    and thus we discount *p's blocked utilization to return:</a>
<a name="6587"><span class="lineNum">    6587 </span>            :          *      cpu_util_without = (cpu_util - task_util) &gt;= 0</a>
<a name="6588"><span class="lineNum">    6588 </span>            :          *</a>
<a name="6589"><span class="lineNum">    6589 </span>            :          * c) if other tasks are RUNNABLE on that CPU and</a>
<a name="6590"><span class="lineNum">    6590 </span>            :          *      util_est &gt; cpu_util</a>
<a name="6591"><span class="lineNum">    6591 </span>            :          *    then we use util_est since it returns a more restrictive</a>
<a name="6592"><span class="lineNum">    6592 </span>            :          *    estimation of the spare capacity on that CPU, by just</a>
<a name="6593"><span class="lineNum">    6593 </span>            :          *    considering the expected utilization of tasks already</a>
<a name="6594"><span class="lineNum">    6594 </span>            :          *    runnable on that CPU.</a>
<a name="6595"><span class="lineNum">    6595 </span>            :          *</a>
<a name="6596"><span class="lineNum">    6596 </span>            :          * Cases a) and b) are covered by the above code, while case c) is</a>
<a name="6597"><span class="lineNum">    6597 </span>            :          * covered by the following code when estimated utilization is</a>
<a name="6598"><span class="lineNum">    6598 </span>            :          * enabled.</a>
<a name="6599"><span class="lineNum">    6599 </span>            :          */</a>
<a name="6600"><span class="lineNum">    6600 </span>            :         if (sched_feat(UTIL_EST)) {</a>
<a name="6601"><span class="lineNum">    6601 </span>            :                 unsigned int estimated =</a>
<a name="6602"><span class="lineNum">    6602 </span>            :                         READ_ONCE(cfs_rq-&gt;avg.util_est.enqueued);</a>
<a name="6603"><span class="lineNum">    6603 </span>            : </a>
<a name="6604"><span class="lineNum">    6604 </span>            :                 /*</a>
<a name="6605"><span class="lineNum">    6605 </span>            :                  * Despite the following checks we still have a small window</a>
<a name="6606"><span class="lineNum">    6606 </span>            :                  * for a possible race, when an execl's select_task_rq_fair()</a>
<a name="6607"><span class="lineNum">    6607 </span>            :                  * races with LB's detach_task():</a>
<a name="6608"><span class="lineNum">    6608 </span>            :                  *</a>
<a name="6609"><span class="lineNum">    6609 </span>            :                  *   detach_task()</a>
<a name="6610"><span class="lineNum">    6610 </span>            :                  *     p-&gt;on_rq = TASK_ON_RQ_MIGRATING;</a>
<a name="6611"><span class="lineNum">    6611 </span>            :                  *     ---------------------------------- A</a>
<a name="6612"><span class="lineNum">    6612 </span>            :                  *     deactivate_task()                   \</a>
<a name="6613"><span class="lineNum">    6613 </span>            :                  *       dequeue_task()                     + RaceTime</a>
<a name="6614"><span class="lineNum">    6614 </span>            :                  *         util_est_dequeue()              /</a>
<a name="6615"><span class="lineNum">    6615 </span>            :                  *     ---------------------------------- B</a>
<a name="6616"><span class="lineNum">    6616 </span>            :                  *</a>
<a name="6617"><span class="lineNum">    6617 </span>            :                  * The additional check on &quot;current == p&quot; it's required to</a>
<a name="6618"><span class="lineNum">    6618 </span>            :                  * properly fix the execl regression and it helps in further</a>
<a name="6619"><span class="lineNum">    6619 </span>            :                  * reducing the chances for the above race.</a>
<a name="6620"><span class="lineNum">    6620 </span>            :                  */</a>
<a name="6621"><span class="lineNum">    6621 </span>            :                 if (unlikely(task_on_rq_queued(p) || current == p))</a>
<a name="6622"><span class="lineNum">    6622 </span>            :                         lsub_positive(&amp;estimated, _task_util_est(p));</a>
<a name="6623"><span class="lineNum">    6623 </span>            : </a>
<a name="6624"><span class="lineNum">    6624 </span>            :                 util = max(util, estimated);</a>
<a name="6625"><span class="lineNum">    6625 </span>            :         }</a>
<a name="6626"><span class="lineNum">    6626 </span>            : </a>
<a name="6627"><span class="lineNum">    6627 </span>            :         /*</a>
<a name="6628"><span class="lineNum">    6628 </span>            :          * Utilization (estimated) can exceed the CPU capacity, thus let's</a>
<a name="6629"><span class="lineNum">    6629 </span>            :          * clamp to the maximum CPU capacity to ensure consistency with</a>
<a name="6630"><span class="lineNum">    6630 </span>            :          * cpu_util.</a>
<a name="6631"><span class="lineNum">    6631 </span>            :          */</a>
<a name="6632"><span class="lineNum">    6632 </span>            :         return min_t(unsigned long, util, capacity_orig_of(cpu));</a>
<a name="6633"><span class="lineNum">    6633 </span>            : }</a>
<a name="6634"><span class="lineNum">    6634 </span>            : </a>
<a name="6635"><span class="lineNum">    6635 </span>            : /*</a>
<a name="6636"><span class="lineNum">    6636 </span>            :  * Predicts what cpu_util(@cpu) would return if @p was migrated (and enqueued)</a>
<a name="6637"><span class="lineNum">    6637 </span>            :  * to @dst_cpu.</a>
<a name="6638"><span class="lineNum">    6638 </span>            :  */</a>
<a name="6639"><span class="lineNum">    6639 </span>            : static unsigned long cpu_util_next(int cpu, struct task_struct *p, int dst_cpu)</a>
<a name="6640"><span class="lineNum">    6640 </span>            : {</a>
<a name="6641"><span class="lineNum">    6641 </span>            :         struct cfs_rq *cfs_rq = &amp;cpu_rq(cpu)-&gt;cfs;</a>
<a name="6642"><span class="lineNum">    6642 </span>            :         unsigned long util_est, util = READ_ONCE(cfs_rq-&gt;avg.util_avg);</a>
<a name="6643"><span class="lineNum">    6643 </span>            : </a>
<a name="6644"><span class="lineNum">    6644 </span>            :         /*</a>
<a name="6645"><span class="lineNum">    6645 </span>            :          * If @p migrates from @cpu to another, remove its contribution. Or,</a>
<a name="6646"><span class="lineNum">    6646 </span>            :          * if @p migrates from another CPU to @cpu, add its contribution. In</a>
<a name="6647"><span class="lineNum">    6647 </span>            :          * the other cases, @cpu is not impacted by the migration, so the</a>
<a name="6648"><span class="lineNum">    6648 </span>            :          * util_avg should already be correct.</a>
<a name="6649"><span class="lineNum">    6649 </span>            :          */</a>
<a name="6650"><span class="lineNum">    6650 </span>            :         if (task_cpu(p) == cpu &amp;&amp; dst_cpu != cpu)</a>
<a name="6651"><span class="lineNum">    6651 </span>            :                 lsub_positive(&amp;util, task_util(p));</a>
<a name="6652"><span class="lineNum">    6652 </span>            :         else if (task_cpu(p) != cpu &amp;&amp; dst_cpu == cpu)</a>
<a name="6653"><span class="lineNum">    6653 </span>            :                 util += task_util(p);</a>
<a name="6654"><span class="lineNum">    6654 </span>            : </a>
<a name="6655"><span class="lineNum">    6655 </span>            :         if (sched_feat(UTIL_EST)) {</a>
<a name="6656"><span class="lineNum">    6656 </span>            :                 util_est = READ_ONCE(cfs_rq-&gt;avg.util_est.enqueued);</a>
<a name="6657"><span class="lineNum">    6657 </span>            : </a>
<a name="6658"><span class="lineNum">    6658 </span>            :                 /*</a>
<a name="6659"><span class="lineNum">    6659 </span>            :                  * During wake-up, the task isn't enqueued yet and doesn't</a>
<a name="6660"><span class="lineNum">    6660 </span>            :                  * appear in the cfs_rq-&gt;avg.util_est.enqueued of any rq,</a>
<a name="6661"><span class="lineNum">    6661 </span>            :                  * so just add it (if needed) to &quot;simulate&quot; what will be</a>
<a name="6662"><span class="lineNum">    6662 </span>            :                  * cpu_util after the task has been enqueued.</a>
<a name="6663"><span class="lineNum">    6663 </span>            :                  */</a>
<a name="6664"><span class="lineNum">    6664 </span>            :                 if (dst_cpu == cpu)</a>
<a name="6665"><span class="lineNum">    6665 </span>            :                         util_est += _task_util_est(p);</a>
<a name="6666"><span class="lineNum">    6666 </span>            : </a>
<a name="6667"><span class="lineNum">    6667 </span>            :                 util = max(util, util_est);</a>
<a name="6668"><span class="lineNum">    6668 </span>            :         }</a>
<a name="6669"><span class="lineNum">    6669 </span>            : </a>
<a name="6670"><span class="lineNum">    6670 </span>            :         return min(util, capacity_orig_of(cpu));</a>
<a name="6671"><span class="lineNum">    6671 </span>            : }</a>
<a name="6672"><span class="lineNum">    6672 </span>            : </a>
<a name="6673"><span class="lineNum">    6673 </span>            : /*</a>
<a name="6674"><span class="lineNum">    6674 </span>            :  * compute_energy(): Estimates the energy that @pd would consume if @p was</a>
<a name="6675"><span class="lineNum">    6675 </span>            :  * migrated to @dst_cpu. compute_energy() predicts what will be the utilization</a>
<a name="6676"><span class="lineNum">    6676 </span>            :  * landscape of @pd's CPUs after the task migration, and uses the Energy Model</a>
<a name="6677"><span class="lineNum">    6677 </span>            :  * to compute what would be the energy if we decided to actually migrate that</a>
<a name="6678"><span class="lineNum">    6678 </span>            :  * task.</a>
<a name="6679"><span class="lineNum">    6679 </span>            :  */</a>
<a name="6680"><span class="lineNum">    6680 </span>            : static long</a>
<a name="6681"><span class="lineNum">    6681 </span>            : compute_energy(struct task_struct *p, int dst_cpu, struct perf_domain *pd)</a>
<a name="6682"><span class="lineNum">    6682 </span>            : {</a>
<a name="6683"><span class="lineNum">    6683 </span>            :         struct cpumask *pd_mask = perf_domain_span(pd);</a>
<a name="6684"><span class="lineNum">    6684 </span>            :         unsigned long cpu_cap = arch_scale_cpu_capacity(cpumask_first(pd_mask));</a>
<a name="6685"><span class="lineNum">    6685 </span>            :         unsigned long max_util = 0, sum_util = 0;</a>
<a name="6686"><span class="lineNum">    6686 </span>            :         unsigned long _cpu_cap = cpu_cap;</a>
<a name="6687"><span class="lineNum">    6687 </span>            :         int cpu;</a>
<a name="6688"><span class="lineNum">    6688 </span>            : </a>
<a name="6689"><span class="lineNum">    6689 </span>            :         _cpu_cap -= arch_scale_thermal_pressure(cpumask_first(pd_mask));</a>
<a name="6690"><span class="lineNum">    6690 </span>            : </a>
<a name="6691"><span class="lineNum">    6691 </span>            :         /*</a>
<a name="6692"><span class="lineNum">    6692 </span>            :          * The capacity state of CPUs of the current rd can be driven by CPUs</a>
<a name="6693"><span class="lineNum">    6693 </span>            :          * of another rd if they belong to the same pd. So, account for the</a>
<a name="6694"><span class="lineNum">    6694 </span>            :          * utilization of these CPUs too by masking pd with cpu_online_mask</a>
<a name="6695"><span class="lineNum">    6695 </span>            :          * instead of the rd span.</a>
<a name="6696"><span class="lineNum">    6696 </span>            :          *</a>
<a name="6697"><span class="lineNum">    6697 </span>            :          * If an entire pd is outside of the current rd, it will not appear in</a>
<a name="6698"><span class="lineNum">    6698 </span>            :          * its pd list and will not be accounted by compute_energy().</a>
<a name="6699"><span class="lineNum">    6699 </span>            :          */</a>
<a name="6700"><span class="lineNum">    6700 </span>            :         for_each_cpu_and(cpu, pd_mask, cpu_online_mask) {</a>
<a name="6701"><span class="lineNum">    6701 </span>            :                 unsigned long util_freq = cpu_util_next(cpu, p, dst_cpu);</a>
<a name="6702"><span class="lineNum">    6702 </span>            :                 unsigned long cpu_util, util_running = util_freq;</a>
<a name="6703"><span class="lineNum">    6703 </span>            :                 struct task_struct *tsk = NULL;</a>
<a name="6704"><span class="lineNum">    6704 </span>            : </a>
<a name="6705"><span class="lineNum">    6705 </span>            :                 /*</a>
<a name="6706"><span class="lineNum">    6706 </span>            :                  * When @p is placed on @cpu:</a>
<a name="6707"><span class="lineNum">    6707 </span>            :                  *</a>
<a name="6708"><span class="lineNum">    6708 </span>            :                  * util_running = max(cpu_util, cpu_util_est) +</a>
<a name="6709"><span class="lineNum">    6709 </span>            :                  *                max(task_util, _task_util_est)</a>
<a name="6710"><span class="lineNum">    6710 </span>            :                  *</a>
<a name="6711"><span class="lineNum">    6711 </span>            :                  * while cpu_util_next is: max(cpu_util + task_util,</a>
<a name="6712"><span class="lineNum">    6712 </span>            :                  *                             cpu_util_est + _task_util_est)</a>
<a name="6713"><span class="lineNum">    6713 </span>            :                  */</a>
<a name="6714"><span class="lineNum">    6714 </span>            :                 if (cpu == dst_cpu) {</a>
<a name="6715"><span class="lineNum">    6715 </span>            :                         tsk = p;</a>
<a name="6716"><span class="lineNum">    6716 </span>            :                         util_running =</a>
<a name="6717"><span class="lineNum">    6717 </span>            :                                 cpu_util_next(cpu, p, -1) + task_util_est(p);</a>
<a name="6718"><span class="lineNum">    6718 </span>            :                 }</a>
<a name="6719"><span class="lineNum">    6719 </span>            : </a>
<a name="6720"><span class="lineNum">    6720 </span>            :                 /*</a>
<a name="6721"><span class="lineNum">    6721 </span>            :                  * Busy time computation: utilization clamping is not</a>
<a name="6722"><span class="lineNum">    6722 </span>            :                  * required since the ratio (sum_util / cpu_capacity)</a>
<a name="6723"><span class="lineNum">    6723 </span>            :                  * is already enough to scale the EM reported power</a>
<a name="6724"><span class="lineNum">    6724 </span>            :                  * consumption at the (eventually clamped) cpu_capacity.</a>
<a name="6725"><span class="lineNum">    6725 </span>            :                  */</a>
<a name="6726"><span class="lineNum">    6726 </span>            :                 cpu_util = effective_cpu_util(cpu, util_running, cpu_cap,</a>
<a name="6727"><span class="lineNum">    6727 </span>            :                                               ENERGY_UTIL, NULL);</a>
<a name="6728"><span class="lineNum">    6728 </span>            : </a>
<a name="6729"><span class="lineNum">    6729 </span>            :                 sum_util += min(cpu_util, _cpu_cap);</a>
<a name="6730"><span class="lineNum">    6730 </span>            : </a>
<a name="6731"><span class="lineNum">    6731 </span>            :                 /*</a>
<a name="6732"><span class="lineNum">    6732 </span>            :                  * Performance domain frequency: utilization clamping</a>
<a name="6733"><span class="lineNum">    6733 </span>            :                  * must be considered since it affects the selection</a>
<a name="6734"><span class="lineNum">    6734 </span>            :                  * of the performance domain frequency.</a>
<a name="6735"><span class="lineNum">    6735 </span>            :                  * NOTE: in case RT tasks are running, by default the</a>
<a name="6736"><span class="lineNum">    6736 </span>            :                  * FREQUENCY_UTIL's utilization can be max OPP.</a>
<a name="6737"><span class="lineNum">    6737 </span>            :                  */</a>
<a name="6738"><span class="lineNum">    6738 </span>            :                 cpu_util = effective_cpu_util(cpu, util_freq, cpu_cap,</a>
<a name="6739"><span class="lineNum">    6739 </span>            :                                               FREQUENCY_UTIL, tsk);</a>
<a name="6740"><span class="lineNum">    6740 </span>            :                 max_util = max(max_util, min(cpu_util, _cpu_cap));</a>
<a name="6741"><span class="lineNum">    6741 </span>            :         }</a>
<a name="6742"><span class="lineNum">    6742 </span>            : </a>
<a name="6743"><span class="lineNum">    6743 </span>            :         return em_cpu_energy(pd-&gt;em_pd, max_util, sum_util, _cpu_cap);</a>
<a name="6744"><span class="lineNum">    6744 </span>            : }</a>
<a name="6745"><span class="lineNum">    6745 </span>            : </a>
<a name="6746"><span class="lineNum">    6746 </span>            : /*</a>
<a name="6747"><span class="lineNum">    6747 </span>            :  * find_energy_efficient_cpu(): Find most energy-efficient target CPU for the</a>
<a name="6748"><span class="lineNum">    6748 </span>            :  * waking task. find_energy_efficient_cpu() looks for the CPU with maximum</a>
<a name="6749"><span class="lineNum">    6749 </span>            :  * spare capacity in each performance domain and uses it as a potential</a>
<a name="6750"><span class="lineNum">    6750 </span>            :  * candidate to execute the task. Then, it uses the Energy Model to figure</a>
<a name="6751"><span class="lineNum">    6751 </span>            :  * out which of the CPU candidates is the most energy-efficient.</a>
<a name="6752"><span class="lineNum">    6752 </span>            :  *</a>
<a name="6753"><span class="lineNum">    6753 </span>            :  * The rationale for this heuristic is as follows. In a performance domain,</a>
<a name="6754"><span class="lineNum">    6754 </span>            :  * all the most energy efficient CPU candidates (according to the Energy</a>
<a name="6755"><span class="lineNum">    6755 </span>            :  * Model) are those for which we'll request a low frequency. When there are</a>
<a name="6756"><span class="lineNum">    6756 </span>            :  * several CPUs for which the frequency request will be the same, we don't</a>
<a name="6757"><span class="lineNum">    6757 </span>            :  * have enough data to break the tie between them, because the Energy Model</a>
<a name="6758"><span class="lineNum">    6758 </span>            :  * only includes active power costs. With this model, if we assume that</a>
<a name="6759"><span class="lineNum">    6759 </span>            :  * frequency requests follow utilization (e.g. using schedutil), the CPU with</a>
<a name="6760"><span class="lineNum">    6760 </span>            :  * the maximum spare capacity in a performance domain is guaranteed to be among</a>
<a name="6761"><span class="lineNum">    6761 </span>            :  * the best candidates of the performance domain.</a>
<a name="6762"><span class="lineNum">    6762 </span>            :  *</a>
<a name="6763"><span class="lineNum">    6763 </span>            :  * In practice, it could be preferable from an energy standpoint to pack</a>
<a name="6764"><span class="lineNum">    6764 </span>            :  * small tasks on a CPU in order to let other CPUs go in deeper idle states,</a>
<a name="6765"><span class="lineNum">    6765 </span>            :  * but that could also hurt our chances to go cluster idle, and we have no</a>
<a name="6766"><span class="lineNum">    6766 </span>            :  * ways to tell with the current Energy Model if this is actually a good</a>
<a name="6767"><span class="lineNum">    6767 </span>            :  * idea or not. So, find_energy_efficient_cpu() basically favors</a>
<a name="6768"><span class="lineNum">    6768 </span>            :  * cluster-packing, and spreading inside a cluster. That should at least be</a>
<a name="6769"><span class="lineNum">    6769 </span>            :  * a good thing for latency, and this is consistent with the idea that most</a>
<a name="6770"><span class="lineNum">    6770 </span>            :  * of the energy savings of EAS come from the asymmetry of the system, and</a>
<a name="6771"><span class="lineNum">    6771 </span>            :  * not so much from breaking the tie between identical CPUs. That's also the</a>
<a name="6772"><span class="lineNum">    6772 </span>            :  * reason why EAS is enabled in the topology code only for systems where</a>
<a name="6773"><span class="lineNum">    6773 </span>            :  * SD_ASYM_CPUCAPACITY is set.</a>
<a name="6774"><span class="lineNum">    6774 </span>            :  *</a>
<a name="6775"><span class="lineNum">    6775 </span>            :  * NOTE: Forkees are not accepted in the energy-aware wake-up path because</a>
<a name="6776"><span class="lineNum">    6776 </span>            :  * they don't have any useful utilization data yet and it's not possible to</a>
<a name="6777"><span class="lineNum">    6777 </span>            :  * forecast their impact on energy consumption. Consequently, they will be</a>
<a name="6778"><span class="lineNum">    6778 </span>            :  * placed by find_idlest_cpu() on the least loaded CPU, which might turn out</a>
<a name="6779"><span class="lineNum">    6779 </span>            :  * to be energy-inefficient in some use-cases. The alternative would be to</a>
<a name="6780"><span class="lineNum">    6780 </span>            :  * bias new tasks towards specific types of CPUs first, or to try to infer</a>
<a name="6781"><span class="lineNum">    6781 </span>            :  * their util_avg from the parent task, but those heuristics could hurt</a>
<a name="6782"><span class="lineNum">    6782 </span>            :  * other use-cases too. So, until someone finds a better way to solve this,</a>
<a name="6783"><span class="lineNum">    6783 </span>            :  * let's keep things simple by re-using the existing slow path.</a>
<a name="6784"><span class="lineNum">    6784 </span>            :  */</a>
<a name="6785"><span class="lineNum">    6785 </span>            : static int find_energy_efficient_cpu(struct task_struct *p, int prev_cpu)</a>
<a name="6786"><span class="lineNum">    6786 </span>            : {</a>
<a name="6787"><span class="lineNum">    6787 </span>            :         unsigned long prev_delta = ULONG_MAX, best_delta = ULONG_MAX;</a>
<a name="6788"><span class="lineNum">    6788 </span>            :         struct root_domain *rd = cpu_rq(smp_processor_id())-&gt;rd;</a>
<a name="6789"><span class="lineNum">    6789 </span>            :         int cpu, best_energy_cpu = prev_cpu, target = -1;</a>
<a name="6790"><span class="lineNum">    6790 </span>            :         unsigned long cpu_cap, util, base_energy = 0;</a>
<a name="6791"><span class="lineNum">    6791 </span>            :         struct sched_domain *sd;</a>
<a name="6792"><span class="lineNum">    6792 </span>            :         struct perf_domain *pd;</a>
<a name="6793"><span class="lineNum">    6793 </span>            : </a>
<a name="6794"><span class="lineNum">    6794 </span>            :         rcu_read_lock();</a>
<a name="6795"><span class="lineNum">    6795 </span>            :         pd = rcu_dereference(rd-&gt;pd);</a>
<a name="6796"><span class="lineNum">    6796 </span>            :         if (!pd || READ_ONCE(rd-&gt;overutilized))</a>
<a name="6797"><span class="lineNum">    6797 </span>            :                 goto unlock;</a>
<a name="6798"><span class="lineNum">    6798 </span>            : </a>
<a name="6799"><span class="lineNum">    6799 </span>            :         /*</a>
<a name="6800"><span class="lineNum">    6800 </span>            :          * Energy-aware wake-up happens on the lowest sched_domain starting</a>
<a name="6801"><span class="lineNum">    6801 </span>            :          * from sd_asym_cpucapacity spanning over this_cpu and prev_cpu.</a>
<a name="6802"><span class="lineNum">    6802 </span>            :          */</a>
<a name="6803"><span class="lineNum">    6803 </span>            :         sd = rcu_dereference(*this_cpu_ptr(&amp;sd_asym_cpucapacity));</a>
<a name="6804"><span class="lineNum">    6804 </span>            :         while (sd &amp;&amp; !cpumask_test_cpu(prev_cpu, sched_domain_span(sd)))</a>
<a name="6805"><span class="lineNum">    6805 </span>            :                 sd = sd-&gt;parent;</a>
<a name="6806"><span class="lineNum">    6806 </span>            :         if (!sd)</a>
<a name="6807"><span class="lineNum">    6807 </span>            :                 goto unlock;</a>
<a name="6808"><span class="lineNum">    6808 </span>            : </a>
<a name="6809"><span class="lineNum">    6809 </span>            :         target = prev_cpu;</a>
<a name="6810"><span class="lineNum">    6810 </span>            : </a>
<a name="6811"><span class="lineNum">    6811 </span>            :         sync_entity_load_avg(&amp;p-&gt;se);</a>
<a name="6812"><span class="lineNum">    6812 </span>            :         if (!task_util_est(p))</a>
<a name="6813"><span class="lineNum">    6813 </span>            :                 goto unlock;</a>
<a name="6814"><span class="lineNum">    6814 </span>            : </a>
<a name="6815"><span class="lineNum">    6815 </span>            :         for (; pd; pd = pd-&gt;next) {</a>
<a name="6816"><span class="lineNum">    6816 </span>            :                 unsigned long cur_delta, spare_cap, max_spare_cap = 0;</a>
<a name="6817"><span class="lineNum">    6817 </span>            :                 bool compute_prev_delta = false;</a>
<a name="6818"><span class="lineNum">    6818 </span>            :                 unsigned long base_energy_pd;</a>
<a name="6819"><span class="lineNum">    6819 </span>            :                 int max_spare_cap_cpu = -1;</a>
<a name="6820"><span class="lineNum">    6820 </span>            : </a>
<a name="6821"><span class="lineNum">    6821 </span>            :                 for_each_cpu_and(cpu, perf_domain_span(pd), sched_domain_span(sd)) {</a>
<a name="6822"><span class="lineNum">    6822 </span>            :                         if (!cpumask_test_cpu(cpu, p-&gt;cpus_ptr))</a>
<a name="6823"><span class="lineNum">    6823 </span>            :                                 continue;</a>
<a name="6824"><span class="lineNum">    6824 </span>            : </a>
<a name="6825"><span class="lineNum">    6825 </span>            :                         util = cpu_util_next(cpu, p, cpu);</a>
<a name="6826"><span class="lineNum">    6826 </span>            :                         cpu_cap = capacity_of(cpu);</a>
<a name="6827"><span class="lineNum">    6827 </span>            :                         spare_cap = cpu_cap;</a>
<a name="6828"><span class="lineNum">    6828 </span>            :                         lsub_positive(&amp;spare_cap, util);</a>
<a name="6829"><span class="lineNum">    6829 </span>            : </a>
<a name="6830"><span class="lineNum">    6830 </span>            :                         /*</a>
<a name="6831"><span class="lineNum">    6831 </span>            :                          * Skip CPUs that cannot satisfy the capacity request.</a>
<a name="6832"><span class="lineNum">    6832 </span>            :                          * IOW, placing the task there would make the CPU</a>
<a name="6833"><span class="lineNum">    6833 </span>            :                          * overutilized. Take uclamp into account to see how</a>
<a name="6834"><span class="lineNum">    6834 </span>            :                          * much capacity we can get out of the CPU; this is</a>
<a name="6835"><span class="lineNum">    6835 </span>            :                          * aligned with sched_cpu_util().</a>
<a name="6836"><span class="lineNum">    6836 </span>            :                          */</a>
<a name="6837"><span class="lineNum">    6837 </span>            :                         util = uclamp_rq_util_with(cpu_rq(cpu), util, p);</a>
<a name="6838"><span class="lineNum">    6838 </span>            :                         if (!fits_capacity(util, cpu_cap))</a>
<a name="6839"><span class="lineNum">    6839 </span>            :                                 continue;</a>
<a name="6840"><span class="lineNum">    6840 </span>            : </a>
<a name="6841"><span class="lineNum">    6841 </span>            :                         if (cpu == prev_cpu) {</a>
<a name="6842"><span class="lineNum">    6842 </span>            :                                 /* Always use prev_cpu as a candidate. */</a>
<a name="6843"><span class="lineNum">    6843 </span>            :                                 compute_prev_delta = true;</a>
<a name="6844"><span class="lineNum">    6844 </span>            :                         } else if (spare_cap &gt; max_spare_cap) {</a>
<a name="6845"><span class="lineNum">    6845 </span>            :                                 /*</a>
<a name="6846"><span class="lineNum">    6846 </span>            :                                  * Find the CPU with the maximum spare capacity</a>
<a name="6847"><span class="lineNum">    6847 </span>            :                                  * in the performance domain.</a>
<a name="6848"><span class="lineNum">    6848 </span>            :                                  */</a>
<a name="6849"><span class="lineNum">    6849 </span>            :                                 max_spare_cap = spare_cap;</a>
<a name="6850"><span class="lineNum">    6850 </span>            :                                 max_spare_cap_cpu = cpu;</a>
<a name="6851"><span class="lineNum">    6851 </span>            :                         }</a>
<a name="6852"><span class="lineNum">    6852 </span>            :                 }</a>
<a name="6853"><span class="lineNum">    6853 </span>            : </a>
<a name="6854"><span class="lineNum">    6854 </span>            :                 if (max_spare_cap_cpu &lt; 0 &amp;&amp; !compute_prev_delta)</a>
<a name="6855"><span class="lineNum">    6855 </span>            :                         continue;</a>
<a name="6856"><span class="lineNum">    6856 </span>            : </a>
<a name="6857"><span class="lineNum">    6857 </span>            :                 /* Compute the 'base' energy of the pd, without @p */</a>
<a name="6858"><span class="lineNum">    6858 </span>            :                 base_energy_pd = compute_energy(p, -1, pd);</a>
<a name="6859"><span class="lineNum">    6859 </span>            :                 base_energy += base_energy_pd;</a>
<a name="6860"><span class="lineNum">    6860 </span>            : </a>
<a name="6861"><span class="lineNum">    6861 </span>            :                 /* Evaluate the energy impact of using prev_cpu. */</a>
<a name="6862"><span class="lineNum">    6862 </span>            :                 if (compute_prev_delta) {</a>
<a name="6863"><span class="lineNum">    6863 </span>            :                         prev_delta = compute_energy(p, prev_cpu, pd);</a>
<a name="6864"><span class="lineNum">    6864 </span>            :                         if (prev_delta &lt; base_energy_pd)</a>
<a name="6865"><span class="lineNum">    6865 </span>            :                                 goto unlock;</a>
<a name="6866"><span class="lineNum">    6866 </span>            :                         prev_delta -= base_energy_pd;</a>
<a name="6867"><span class="lineNum">    6867 </span>            :                         best_delta = min(best_delta, prev_delta);</a>
<a name="6868"><span class="lineNum">    6868 </span>            :                 }</a>
<a name="6869"><span class="lineNum">    6869 </span>            : </a>
<a name="6870"><span class="lineNum">    6870 </span>            :                 /* Evaluate the energy impact of using max_spare_cap_cpu. */</a>
<a name="6871"><span class="lineNum">    6871 </span>            :                 if (max_spare_cap_cpu &gt;= 0) {</a>
<a name="6872"><span class="lineNum">    6872 </span>            :                         cur_delta = compute_energy(p, max_spare_cap_cpu, pd);</a>
<a name="6873"><span class="lineNum">    6873 </span>            :                         if (cur_delta &lt; base_energy_pd)</a>
<a name="6874"><span class="lineNum">    6874 </span>            :                                 goto unlock;</a>
<a name="6875"><span class="lineNum">    6875 </span>            :                         cur_delta -= base_energy_pd;</a>
<a name="6876"><span class="lineNum">    6876 </span>            :                         if (cur_delta &lt; best_delta) {</a>
<a name="6877"><span class="lineNum">    6877 </span>            :                                 best_delta = cur_delta;</a>
<a name="6878"><span class="lineNum">    6878 </span>            :                                 best_energy_cpu = max_spare_cap_cpu;</a>
<a name="6879"><span class="lineNum">    6879 </span>            :                         }</a>
<a name="6880"><span class="lineNum">    6880 </span>            :                 }</a>
<a name="6881"><span class="lineNum">    6881 </span>            :         }</a>
<a name="6882"><span class="lineNum">    6882 </span>            :         rcu_read_unlock();</a>
<a name="6883"><span class="lineNum">    6883 </span>            : </a>
<a name="6884"><span class="lineNum">    6884 </span>            :         /*</a>
<a name="6885"><span class="lineNum">    6885 </span>            :          * Pick the best CPU if prev_cpu cannot be used, or if it saves at</a>
<a name="6886"><span class="lineNum">    6886 </span>            :          * least 6% of the energy used by prev_cpu.</a>
<a name="6887"><span class="lineNum">    6887 </span>            :          */</a>
<a name="6888"><span class="lineNum">    6888 </span>            :         if ((prev_delta == ULONG_MAX) ||</a>
<a name="6889"><span class="lineNum">    6889 </span>            :             (prev_delta - best_delta) &gt; ((prev_delta + base_energy) &gt;&gt; 4))</a>
<a name="6890"><span class="lineNum">    6890 </span>            :                 target = best_energy_cpu;</a>
<a name="6891"><span class="lineNum">    6891 </span>            : </a>
<a name="6892"><span class="lineNum">    6892 </span>            :         return target;</a>
<a name="6893"><span class="lineNum">    6893 </span>            : </a>
<a name="6894"><span class="lineNum">    6894 </span>            : unlock:</a>
<a name="6895"><span class="lineNum">    6895 </span>            :         rcu_read_unlock();</a>
<a name="6896"><span class="lineNum">    6896 </span>            : </a>
<a name="6897"><span class="lineNum">    6897 </span>            :         return target;</a>
<a name="6898"><span class="lineNum">    6898 </span>            : }</a>
<a name="6899"><span class="lineNum">    6899 </span>            : </a>
<a name="6900"><span class="lineNum">    6900 </span>            : /*</a>
<a name="6901"><span class="lineNum">    6901 </span>            :  * select_task_rq_fair: Select target runqueue for the waking task in domains</a>
<a name="6902"><span class="lineNum">    6902 </span>            :  * that have the relevant SD flag set. In practice, this is SD_BALANCE_WAKE,</a>
<a name="6903"><span class="lineNum">    6903 </span>            :  * SD_BALANCE_FORK, or SD_BALANCE_EXEC.</a>
<a name="6904"><span class="lineNum">    6904 </span>            :  *</a>
<a name="6905"><span class="lineNum">    6905 </span>            :  * Balances load by selecting the idlest CPU in the idlest group, or under</a>
<a name="6906"><span class="lineNum">    6906 </span>            :  * certain conditions an idle sibling CPU if the domain has SD_WAKE_AFFINE set.</a>
<a name="6907"><span class="lineNum">    6907 </span>            :  *</a>
<a name="6908"><span class="lineNum">    6908 </span>            :  * Returns the target CPU number.</a>
<a name="6909"><span class="lineNum">    6909 </span>            :  */</a>
<a name="6910"><span class="lineNum">    6910 </span>            : static int</a>
<a name="6911"><span class="lineNum">    6911 </span>            : select_task_rq_fair(struct task_struct *p, int prev_cpu, int wake_flags)</a>
<a name="6912"><span class="lineNum">    6912 </span>            : {</a>
<a name="6913"><span class="lineNum">    6913 </span>            :         int sync = (wake_flags &amp; WF_SYNC) &amp;&amp; !(current-&gt;flags &amp; PF_EXITING);</a>
<a name="6914"><span class="lineNum">    6914 </span>            :         struct sched_domain *tmp, *sd = NULL;</a>
<a name="6915"><span class="lineNum">    6915 </span>            :         int cpu = smp_processor_id();</a>
<a name="6916"><span class="lineNum">    6916 </span>            :         int new_cpu = prev_cpu;</a>
<a name="6917"><span class="lineNum">    6917 </span>            :         int want_affine = 0;</a>
<a name="6918"><span class="lineNum">    6918 </span>            :         /* SD_flags and WF_flags share the first nibble */</a>
<a name="6919"><span class="lineNum">    6919 </span>            :         int sd_flag = wake_flags &amp; 0xF;</a>
<a name="6920"><span class="lineNum">    6920 </span>            : </a>
<a name="6921"><span class="lineNum">    6921 </span>            :         /*</a>
<a name="6922"><span class="lineNum">    6922 </span>            :          * required for stable -&gt;cpus_allowed</a>
<a name="6923"><span class="lineNum">    6923 </span>            :          */</a>
<a name="6924"><span class="lineNum">    6924 </span>            :         lockdep_assert_held(&amp;p-&gt;pi_lock);</a>
<a name="6925"><span class="lineNum">    6925 </span>            :         if (wake_flags &amp; WF_TTWU) {</a>
<a name="6926"><span class="lineNum">    6926 </span>            :                 record_wakee(p);</a>
<a name="6927"><span class="lineNum">    6927 </span>            : </a>
<a name="6928"><span class="lineNum">    6928 </span>            :                 if (sched_energy_enabled()) {</a>
<a name="6929"><span class="lineNum">    6929 </span>            :                         new_cpu = find_energy_efficient_cpu(p, prev_cpu);</a>
<a name="6930"><span class="lineNum">    6930 </span>            :                         if (new_cpu &gt;= 0)</a>
<a name="6931"><span class="lineNum">    6931 </span>            :                                 return new_cpu;</a>
<a name="6932"><span class="lineNum">    6932 </span>            :                         new_cpu = prev_cpu;</a>
<a name="6933"><span class="lineNum">    6933 </span>            :                 }</a>
<a name="6934"><span class="lineNum">    6934 </span>            : </a>
<a name="6935"><span class="lineNum">    6935 </span>            :                 want_affine = !wake_wide(p) &amp;&amp; cpumask_test_cpu(cpu, p-&gt;cpus_ptr);</a>
<a name="6936"><span class="lineNum">    6936 </span>            :         }</a>
<a name="6937"><span class="lineNum">    6937 </span>            : </a>
<a name="6938"><span class="lineNum">    6938 </span>            :         rcu_read_lock();</a>
<a name="6939"><span class="lineNum">    6939 </span>            :         for_each_domain(cpu, tmp) {</a>
<a name="6940"><span class="lineNum">    6940 </span>            :                 /*</a>
<a name="6941"><span class="lineNum">    6941 </span>            :                  * If both 'cpu' and 'prev_cpu' are part of this domain,</a>
<a name="6942"><span class="lineNum">    6942 </span>            :                  * cpu is a valid SD_WAKE_AFFINE target.</a>
<a name="6943"><span class="lineNum">    6943 </span>            :                  */</a>
<a name="6944"><span class="lineNum">    6944 </span>            :                 if (want_affine &amp;&amp; (tmp-&gt;flags &amp; SD_WAKE_AFFINE) &amp;&amp;</a>
<a name="6945"><span class="lineNum">    6945 </span>            :                     cpumask_test_cpu(prev_cpu, sched_domain_span(tmp))) {</a>
<a name="6946"><span class="lineNum">    6946 </span>            :                         if (cpu != prev_cpu)</a>
<a name="6947"><span class="lineNum">    6947 </span>            :                                 new_cpu = wake_affine(tmp, p, cpu, prev_cpu, sync);</a>
<a name="6948"><span class="lineNum">    6948 </span>            : </a>
<a name="6949"><span class="lineNum">    6949 </span>            :                         sd = NULL; /* Prefer wake_affine over balance flags */</a>
<a name="6950"><span class="lineNum">    6950 </span>            :                         break;</a>
<a name="6951"><span class="lineNum">    6951 </span>            :                 }</a>
<a name="6952"><span class="lineNum">    6952 </span>            : </a>
<a name="6953"><span class="lineNum">    6953 </span>            :                 /*</a>
<a name="6954"><span class="lineNum">    6954 </span>            :                  * Usually only true for WF_EXEC and WF_FORK, as sched_domains</a>
<a name="6955"><span class="lineNum">    6955 </span>            :                  * usually do not have SD_BALANCE_WAKE set. That means wakeup</a>
<a name="6956"><span class="lineNum">    6956 </span>            :                  * will usually go to the fast path.</a>
<a name="6957"><span class="lineNum">    6957 </span>            :                  */</a>
<a name="6958"><span class="lineNum">    6958 </span>            :                 if (tmp-&gt;flags &amp; sd_flag)</a>
<a name="6959"><span class="lineNum">    6959 </span>            :                         sd = tmp;</a>
<a name="6960"><span class="lineNum">    6960 </span>            :                 else if (!want_affine)</a>
<a name="6961"><span class="lineNum">    6961 </span>            :                         break;</a>
<a name="6962"><span class="lineNum">    6962 </span>            :         }</a>
<a name="6963"><span class="lineNum">    6963 </span>            : </a>
<a name="6964"><span class="lineNum">    6964 </span>            :         if (unlikely(sd)) {</a>
<a name="6965"><span class="lineNum">    6965 </span>            :                 /* Slow path */</a>
<a name="6966"><span class="lineNum">    6966 </span>            :                 new_cpu = find_idlest_cpu(sd, p, cpu, prev_cpu, sd_flag);</a>
<a name="6967"><span class="lineNum">    6967 </span>            :         } else if (wake_flags &amp; WF_TTWU) { /* XXX always ? */</a>
<a name="6968"><span class="lineNum">    6968 </span>            :                 /* Fast path */</a>
<a name="6969"><span class="lineNum">    6969 </span>            :                 new_cpu = select_idle_sibling(p, prev_cpu, new_cpu);</a>
<a name="6970"><span class="lineNum">    6970 </span>            :         }</a>
<a name="6971"><span class="lineNum">    6971 </span>            :         rcu_read_unlock();</a>
<a name="6972"><span class="lineNum">    6972 </span>            : </a>
<a name="6973"><span class="lineNum">    6973 </span>            :         return new_cpu;</a>
<a name="6974"><span class="lineNum">    6974 </span>            : }</a>
<a name="6975"><span class="lineNum">    6975 </span>            : </a>
<a name="6976"><span class="lineNum">    6976 </span>            : static void detach_entity_cfs_rq(struct sched_entity *se);</a>
<a name="6977"><span class="lineNum">    6977 </span>            : </a>
<a name="6978"><span class="lineNum">    6978 </span>            : /*</a>
<a name="6979"><span class="lineNum">    6979 </span>            :  * Called immediately before a task is migrated to a new CPU; task_cpu(p) and</a>
<a name="6980"><span class="lineNum">    6980 </span>            :  * cfs_rq_of(p) references at time of call are still valid and identify the</a>
<a name="6981"><span class="lineNum">    6981 </span>            :  * previous CPU. The caller guarantees p-&gt;pi_lock or task_rq(p)-&gt;lock is held.</a>
<a name="6982"><span class="lineNum">    6982 </span>            :  */</a>
<a name="6983"><span class="lineNum">    6983 </span>            : static void migrate_task_rq_fair(struct task_struct *p, int new_cpu)</a>
<a name="6984"><span class="lineNum">    6984 </span>            : {</a>
<a name="6985"><span class="lineNum">    6985 </span>            :         /*</a>
<a name="6986"><span class="lineNum">    6986 </span>            :          * As blocked tasks retain absolute vruntime the migration needs to</a>
<a name="6987"><span class="lineNum">    6987 </span>            :          * deal with this by subtracting the old and adding the new</a>
<a name="6988"><span class="lineNum">    6988 </span>            :          * min_vruntime -- the latter is done by enqueue_entity() when placing</a>
<a name="6989"><span class="lineNum">    6989 </span>            :          * the task on the new runqueue.</a>
<a name="6990"><span class="lineNum">    6990 </span>            :          */</a>
<a name="6991"><span class="lineNum">    6991 </span>            :         if (READ_ONCE(p-&gt;__state) == TASK_WAKING) {</a>
<a name="6992"><span class="lineNum">    6992 </span>            :                 struct sched_entity *se = &amp;p-&gt;se;</a>
<a name="6993"><span class="lineNum">    6993 </span>            :                 struct cfs_rq *cfs_rq = cfs_rq_of(se);</a>
<a name="6994"><span class="lineNum">    6994 </span>            :                 u64 min_vruntime;</a>
<a name="6995"><span class="lineNum">    6995 </span>            : </a>
<a name="6996"><span class="lineNum">    6996 </span>            : #ifndef CONFIG_64BIT</a>
<a name="6997"><span class="lineNum">    6997 </span>            :                 u64 min_vruntime_copy;</a>
<a name="6998"><span class="lineNum">    6998 </span>            : </a>
<a name="6999"><span class="lineNum">    6999 </span>            :                 do {</a>
<a name="7000"><span class="lineNum">    7000 </span>            :                         min_vruntime_copy = cfs_rq-&gt;min_vruntime_copy;</a>
<a name="7001"><span class="lineNum">    7001 </span>            :                         smp_rmb();</a>
<a name="7002"><span class="lineNum">    7002 </span>            :                         min_vruntime = cfs_rq-&gt;min_vruntime;</a>
<a name="7003"><span class="lineNum">    7003 </span>            :                 } while (min_vruntime != min_vruntime_copy);</a>
<a name="7004"><span class="lineNum">    7004 </span>            : #else</a>
<a name="7005"><span class="lineNum">    7005 </span>            :                 min_vruntime = cfs_rq-&gt;min_vruntime;</a>
<a name="7006"><span class="lineNum">    7006 </span>            : #endif</a>
<a name="7007"><span class="lineNum">    7007 </span>            : </a>
<a name="7008"><span class="lineNum">    7008 </span>            :                 se-&gt;vruntime -= min_vruntime;</a>
<a name="7009"><span class="lineNum">    7009 </span>            :         }</a>
<a name="7010"><span class="lineNum">    7010 </span>            : </a>
<a name="7011"><span class="lineNum">    7011 </span>            :         if (p-&gt;on_rq == TASK_ON_RQ_MIGRATING) {</a>
<a name="7012"><span class="lineNum">    7012 </span>            :                 /*</a>
<a name="7013"><span class="lineNum">    7013 </span>            :                  * In case of TASK_ON_RQ_MIGRATING we in fact hold the 'old'</a>
<a name="7014"><span class="lineNum">    7014 </span>            :                  * rq-&gt;lock and can modify state directly.</a>
<a name="7015"><span class="lineNum">    7015 </span>            :                  */</a>
<a name="7016"><span class="lineNum">    7016 </span>            :                 lockdep_assert_rq_held(task_rq(p));</a>
<a name="7017"><span class="lineNum">    7017 </span>            :                 detach_entity_cfs_rq(&amp;p-&gt;se);</a>
<a name="7018"><span class="lineNum">    7018 </span>            : </a>
<a name="7019"><span class="lineNum">    7019 </span>            :         } else {</a>
<a name="7020"><span class="lineNum">    7020 </span>            :                 /*</a>
<a name="7021"><span class="lineNum">    7021 </span>            :                  * We are supposed to update the task to &quot;current&quot; time, then</a>
<a name="7022"><span class="lineNum">    7022 </span>            :                  * its up to date and ready to go to new CPU/cfs_rq. But we</a>
<a name="7023"><span class="lineNum">    7023 </span>            :                  * have difficulty in getting what current time is, so simply</a>
<a name="7024"><span class="lineNum">    7024 </span>            :                  * throw away the out-of-date time. This will result in the</a>
<a name="7025"><span class="lineNum">    7025 </span>            :                  * wakee task is less decayed, but giving the wakee more load</a>
<a name="7026"><span class="lineNum">    7026 </span>            :                  * sounds not bad.</a>
<a name="7027"><span class="lineNum">    7027 </span>            :                  */</a>
<a name="7028"><span class="lineNum">    7028 </span>            :                 remove_entity_load_avg(&amp;p-&gt;se);</a>
<a name="7029"><span class="lineNum">    7029 </span>            :         }</a>
<a name="7030"><span class="lineNum">    7030 </span>            : </a>
<a name="7031"><span class="lineNum">    7031 </span>            :         /* Tell new CPU we are migrated */</a>
<a name="7032"><span class="lineNum">    7032 </span>            :         p-&gt;se.avg.last_update_time = 0;</a>
<a name="7033"><span class="lineNum">    7033 </span>            : </a>
<a name="7034"><span class="lineNum">    7034 </span>            :         /* We have migrated, no longer consider this task hot */</a>
<a name="7035"><span class="lineNum">    7035 </span>            :         p-&gt;se.exec_start = 0;</a>
<a name="7036"><span class="lineNum">    7036 </span>            : </a>
<a name="7037"><span class="lineNum">    7037 </span>            :         update_scan_period(p, new_cpu);</a>
<a name="7038"><span class="lineNum">    7038 </span>            : }</a>
<a name="7039"><span class="lineNum">    7039 </span>            : </a>
<a name="7040"><span class="lineNum">    7040 </span>            : static void task_dead_fair(struct task_struct *p)</a>
<a name="7041"><span class="lineNum">    7041 </span>            : {</a>
<a name="7042"><span class="lineNum">    7042 </span>            :         remove_entity_load_avg(&amp;p-&gt;se);</a>
<a name="7043"><span class="lineNum">    7043 </span>            : }</a>
<a name="7044"><span class="lineNum">    7044 </span>            : </a>
<a name="7045"><span class="lineNum">    7045 </span>            : static int</a>
<a name="7046"><span class="lineNum">    7046 </span>            : balance_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)</a>
<a name="7047"><span class="lineNum">    7047 </span>            : {</a>
<a name="7048"><span class="lineNum">    7048 </span>            :         if (rq-&gt;nr_running)</a>
<a name="7049"><span class="lineNum">    7049 </span>            :                 return 1;</a>
<a name="7050"><span class="lineNum">    7050 </span>            : </a>
<a name="7051"><span class="lineNum">    7051 </span>            :         return newidle_balance(rq, rf) != 0;</a>
<a name="7052"><span class="lineNum">    7052 </span>            : }</a>
<a name="7053"><span class="lineNum">    7053 </span>            : #endif /* CONFIG_SMP */</a>
<a name="7054"><span class="lineNum">    7054 </span>            : </a>
<a name="7055"><span class="lineNum">    7055 </span>            : static unsigned long wakeup_gran(struct sched_entity *se)</a>
<a name="7056"><span class="lineNum">    7056 </span>            : {</a>
<a name="7057"><span class="lineNum">    7057 </span><span class="lineCov">        199 :         unsigned long gran = sysctl_sched_wakeup_granularity;</span></a>
<a name="7058"><span class="lineNum">    7058 </span>            : </a>
<a name="7059"><span class="lineNum">    7059 </span>            :         /*</a>
<a name="7060"><span class="lineNum">    7060 </span>            :          * Since its curr running now, convert the gran from real-time</a>
<a name="7061"><span class="lineNum">    7061 </span>            :          * to virtual-time in his units.</a>
<a name="7062"><span class="lineNum">    7062 </span>            :          *</a>
<a name="7063"><span class="lineNum">    7063 </span>            :          * By using 'se' instead of 'curr' we penalize light tasks, so</a>
<a name="7064"><span class="lineNum">    7064 </span>            :          * they get preempted easier. That is, if 'se' &lt; 'curr' then</a>
<a name="7065"><span class="lineNum">    7065 </span>            :          * the resulting gran will be larger, therefore penalizing the</a>
<a name="7066"><span class="lineNum">    7066 </span>            :          * lighter, if otoh 'se' &gt; 'curr' then the resulting gran will</a>
<a name="7067"><span class="lineNum">    7067 </span>            :          * be smaller, again penalizing the lighter task.</a>
<a name="7068"><span class="lineNum">    7068 </span>            :          *</a>
<a name="7069"><span class="lineNum">    7069 </span>            :          * This is especially important for buddies when the leftmost</a>
<a name="7070"><span class="lineNum">    7070 </span>            :          * task is higher priority than the buddy.</a>
<a name="7071"><span class="lineNum">    7071 </span>            :          */</a>
<a name="7072"><span class="lineNum">    7072 </span><span class="lineCov">        199 :         return calc_delta_fair(gran, se);</span></a>
<a name="7073"><span class="lineNum">    7073 </span>            : }</a>
<a name="7074"><span class="lineNum">    7074 </span>            : </a>
<a name="7075"><span class="lineNum">    7075 </span>            : /*</a>
<a name="7076"><span class="lineNum">    7076 </span>            :  * Should 'se' preempt 'curr'.</a>
<a name="7077"><span class="lineNum">    7077 </span>            :  *</a>
<a name="7078"><span class="lineNum">    7078 </span>            :  *             |s1</a>
<a name="7079"><span class="lineNum">    7079 </span>            :  *        |s2</a>
<a name="7080"><span class="lineNum">    7080 </span>            :  *   |s3</a>
<a name="7081"><span class="lineNum">    7081 </span>            :  *         g</a>
<a name="7082"><span class="lineNum">    7082 </span>            :  *      |&lt;---&gt;|c</a>
<a name="7083"><span class="lineNum">    7083 </span>            :  *</a>
<a name="7084"><span class="lineNum">    7084 </span>            :  *  w(c, s1) = -1</a>
<a name="7085"><span class="lineNum">    7085 </span>            :  *  w(c, s2) =  0</a>
<a name="7086"><span class="lineNum">    7086 </span>            :  *  w(c, s3) =  1</a>
<a name="7087"><span class="lineNum">    7087 </span>            :  *</a>
<a name="7088"><span class="lineNum">    7088 </span>            :  */</a>
<a name="7089"><span class="lineNum">    7089 </span>            : static int</a>
<a name="7090"><span class="lineNum">    7090 </span><span class="lineCov">        718 : wakeup_preempt_entity(struct sched_entity *curr, struct sched_entity *se)</span></a>
<a name="7091"><span class="lineNum">    7091 </span>            : {</a>
<a name="7092"><span class="lineNum">    7092 </span><span class="lineCov">        718 :         s64 gran, vdiff = curr-&gt;vruntime - se-&gt;vruntime;</span></a>
<a name="7093"><span class="lineNum">    7093 </span>            : </a>
<a name="7094"><span class="lineNum">    7094 </span><span class="lineCov">        718 :         if (vdiff &lt;= 0)</span></a>
<a name="7095"><span class="lineNum">    7095 </span>            :                 return -1;</a>
<a name="7096"><span class="lineNum">    7096 </span>            : </a>
<a name="7097"><span class="lineNum">    7097 </span><span class="lineCov">        199 :         gran = wakeup_gran(se);</span></a>
<a name="7098"><span class="lineNum">    7098 </span><span class="lineCov">        199 :         if (vdiff &gt; gran)</span></a>
<a name="7099"><span class="lineNum">    7099 </span>            :                 return 1;</a>
<a name="7100"><span class="lineNum">    7100 </span>            : </a>
<a name="7101"><span class="lineNum">    7101 </span>            :         return 0;</a>
<a name="7102"><span class="lineNum">    7102 </span>            : }</a>
<a name="7103"><span class="lineNum">    7103 </span>            : </a>
<a name="7104"><span class="lineNum">    7104 </span><span class="lineNoCov">          0 : static void set_last_buddy(struct sched_entity *se)</span></a>
<a name="7105"><span class="lineNum">    7105 </span>            : {</a>
<a name="7106"><span class="lineNum">    7106 </span><span class="lineNoCov">          0 :         for_each_sched_entity(se) {</span></a>
<a name="7107"><span class="lineNum">    7107 </span><span class="lineNoCov">          0 :                 if (SCHED_WARN_ON(!se-&gt;on_rq))</span></a>
<a name="7108"><span class="lineNum">    7108 </span>            :                         return;</a>
<a name="7109"><span class="lineNum">    7109 </span><span class="lineNoCov">          0 :                 if (se_is_idle(se))</span></a>
<a name="7110"><span class="lineNum">    7110 </span>            :                         return;</a>
<a name="7111"><span class="lineNum">    7111 </span><span class="lineNoCov">          0 :                 cfs_rq_of(se)-&gt;last = se;</span></a>
<a name="7112"><span class="lineNum">    7112 </span>            :         }</a>
<a name="7113"><span class="lineNum">    7113 </span>            : }</a>
<a name="7114"><span class="lineNum">    7114 </span>            : </a>
<a name="7115"><span class="lineNum">    7115 </span><span class="lineCov">        199 : static void set_next_buddy(struct sched_entity *se)</span></a>
<a name="7116"><span class="lineNum">    7116 </span>            : {</a>
<a name="7117"><span class="lineNum">    7117 </span><span class="lineCov">        398 :         for_each_sched_entity(se) {</span></a>
<a name="7118"><span class="lineNum">    7118 </span><span class="lineCov">        199 :                 if (SCHED_WARN_ON(!se-&gt;on_rq))</span></a>
<a name="7119"><span class="lineNum">    7119 </span>            :                         return;</a>
<a name="7120"><span class="lineNum">    7120 </span><span class="lineCov">        199 :                 if (se_is_idle(se))</span></a>
<a name="7121"><span class="lineNum">    7121 </span>            :                         return;</a>
<a name="7122"><span class="lineNum">    7122 </span><span class="lineCov">        398 :                 cfs_rq_of(se)-&gt;next = se;</span></a>
<a name="7123"><span class="lineNum">    7123 </span>            :         }</a>
<a name="7124"><span class="lineNum">    7124 </span>            : }</a>
<a name="7125"><span class="lineNum">    7125 </span>            : </a>
<a name="7126"><span class="lineNum">    7126 </span>            : static void set_skip_buddy(struct sched_entity *se)</a>
<a name="7127"><span class="lineNum">    7127 </span>            : {</a>
<a name="7128"><span class="lineNum">    7128 </span><span class="lineNoCov">          0 :         for_each_sched_entity(se)</span></a>
<a name="7129"><span class="lineNum">    7129 </span><span class="lineNoCov">          0 :                 cfs_rq_of(se)-&gt;skip = se;</span></a>
<a name="7130"><span class="lineNum">    7130 </span>            : }</a>
<a name="7131"><span class="lineNum">    7131 </span>            : </a>
<a name="7132"><span class="lineNum">    7132 </span>            : /*</a>
<a name="7133"><span class="lineNum">    7133 </span>            :  * Preempt the current task with a newly woken task if needed:</a>
<a name="7134"><span class="lineNum">    7134 </span>            :  */</a>
<a name="7135"><span class="lineNum">    7135 </span><span class="lineCov">        612 : static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_flags)</span></a>
<a name="7136"><span class="lineNum">    7136 </span>            : {</a>
<a name="7137"><span class="lineNum">    7137 </span><span class="lineCov">        612 :         struct task_struct *curr = rq-&gt;curr;</span></a>
<a name="7138"><span class="lineNum">    7138 </span><span class="lineCov">        612 :         struct sched_entity *se = &amp;curr-&gt;se, *pse = &amp;p-&gt;se;</span></a>
<a name="7139"><span class="lineNum">    7139 </span><span class="lineCov">       1224 :         struct cfs_rq *cfs_rq = task_cfs_rq(curr);</span></a>
<a name="7140"><span class="lineNum">    7140 </span><span class="lineCov">        612 :         int scale = cfs_rq-&gt;nr_running &gt;= sched_nr_latency;</span></a>
<a name="7141"><span class="lineNum">    7141 </span><span class="lineCov">        612 :         int next_buddy_marked = 0;</span></a>
<a name="7142"><span class="lineNum">    7142 </span>            :         int cse_is_idle, pse_is_idle;</a>
<a name="7143"><span class="lineNum">    7143 </span>            : </a>
<a name="7144"><span class="lineNum">    7144 </span><span class="lineCov">        612 :         if (unlikely(se == pse))</span></a>
<a name="7145"><span class="lineNum">    7145 </span>            :                 return;</a>
<a name="7146"><span class="lineNum">    7146 </span>            : </a>
<a name="7147"><span class="lineNum">    7147 </span>            :         /*</a>
<a name="7148"><span class="lineNum">    7148 </span>            :          * This is possible from callers such as attach_tasks(), in which we</a>
<a name="7149"><span class="lineNum">    7149 </span>            :          * unconditionally check_preempt_curr() after an enqueue (which may have</a>
<a name="7150"><span class="lineNum">    7150 </span>            :          * lead to a throttle).  This both saves work and prevents false</a>
<a name="7151"><span class="lineNum">    7151 </span>            :          * next-buddy nomination below.</a>
<a name="7152"><span class="lineNum">    7152 </span>            :          */</a>
<a name="7153"><span class="lineNum">    7153 </span><span class="lineCov">        612 :         if (unlikely(throttled_hierarchy(cfs_rq_of(pse))))</span></a>
<a name="7154"><span class="lineNum">    7154 </span>            :                 return;</a>
<a name="7155"><span class="lineNum">    7155 </span>            : </a>
<a name="7156"><span class="lineNum">    7156 </span><span class="lineCov">        612 :         if (sched_feat(NEXT_BUDDY) &amp;&amp; scale &amp;&amp; !(wake_flags &amp; WF_FORK)) {</span></a>
<a name="7157"><span class="lineNum">    7157 </span><span class="lineNoCov">          0 :                 set_next_buddy(pse);</span></a>
<a name="7158"><span class="lineNum">    7158 </span><span class="lineNoCov">          0 :                 next_buddy_marked = 1;</span></a>
<a name="7159"><span class="lineNum">    7159 </span>            :         }</a>
<a name="7160"><span class="lineNum">    7160 </span>            : </a>
<a name="7161"><span class="lineNum">    7161 </span>            :         /*</a>
<a name="7162"><span class="lineNum">    7162 </span>            :          * We can come here with TIF_NEED_RESCHED already set from new task</a>
<a name="7163"><span class="lineNum">    7163 </span>            :          * wake up path.</a>
<a name="7164"><span class="lineNum">    7164 </span>            :          *</a>
<a name="7165"><span class="lineNum">    7165 </span>            :          * Note: this also catches the edge-case of curr being in a throttled</a>
<a name="7166"><span class="lineNum">    7166 </span>            :          * group (e.g. via set_curr_task), since update_curr() (in the</a>
<a name="7167"><span class="lineNum">    7167 </span>            :          * enqueue of curr) will have resulted in resched being set.  This</a>
<a name="7168"><span class="lineNum">    7168 </span>            :          * prevents us from potentially nominating it as a false LAST_BUDDY</a>
<a name="7169"><span class="lineNum">    7169 </span>            :          * below.</a>
<a name="7170"><span class="lineNum">    7170 </span>            :          */</a>
<a name="7171"><span class="lineNum">    7171 </span><span class="lineCov">        612 :         if (test_tsk_need_resched(curr))</span></a>
<a name="7172"><span class="lineNum">    7172 </span>            :                 return;</a>
<a name="7173"><span class="lineNum">    7173 </span>            : </a>
<a name="7174"><span class="lineNum">    7174 </span>            :         /* Idle tasks are by definition preempted by non-idle tasks. */</a>
<a name="7175"><span class="lineNum">    7175 </span><span class="lineCov">       1038 :         if (unlikely(task_has_idle_policy(curr)) &amp;&amp;</span></a>
<a name="7176"><span class="lineNum">    7176 </span><span class="lineNoCov">          0 :             likely(!task_has_idle_policy(p)))</span></a>
<a name="7177"><span class="lineNum">    7177 </span>            :                 goto preempt;</a>
<a name="7178"><span class="lineNum">    7178 </span>            : </a>
<a name="7179"><span class="lineNum">    7179 </span>            :         /*</a>
<a name="7180"><span class="lineNum">    7180 </span>            :          * Batch and idle tasks do not preempt non-idle tasks (their preemption</a>
<a name="7181"><span class="lineNum">    7181 </span>            :          * is driven by the tick):</a>
<a name="7182"><span class="lineNum">    7182 </span>            :          */</a>
<a name="7183"><span class="lineNum">    7183 </span><span class="lineCov">        519 :         if (unlikely(p-&gt;policy != SCHED_NORMAL) || !sched_feat(WAKEUP_PREEMPTION))</span></a>
<a name="7184"><span class="lineNum">    7184 </span>            :                 return;</a>
<a name="7185"><span class="lineNum">    7185 </span>            : </a>
<a name="7186"><span class="lineNum">    7186 </span><span class="lineCov">        519 :         find_matching_se(&amp;se, &amp;pse);</span></a>
<a name="7187"><span class="lineNum">    7187 </span><span class="lineCov">        519 :         BUG_ON(!pse);</span></a>
<a name="7188"><span class="lineNum">    7188 </span>            : </a>
<a name="7189"><span class="lineNum">    7189 </span><span class="lineCov">        519 :         cse_is_idle = se_is_idle(se);</span></a>
<a name="7190"><span class="lineNum">    7190 </span><span class="lineCov">        519 :         pse_is_idle = se_is_idle(pse);</span></a>
<a name="7191"><span class="lineNum">    7191 </span>            : </a>
<a name="7192"><span class="lineNum">    7192 </span>            :         /*</a>
<a name="7193"><span class="lineNum">    7193 </span>            :          * Preempt an idle group in favor of a non-idle group (and don't preempt</a>
<a name="7194"><span class="lineNum">    7194 </span>            :          * in the inverse case).</a>
<a name="7195"><span class="lineNum">    7195 </span>            :          */</a>
<a name="7196"><span class="lineNum">    7196 </span>            :         if (cse_is_idle &amp;&amp; !pse_is_idle)</a>
<a name="7197"><span class="lineNum">    7197 </span>            :                 goto preempt;</a>
<a name="7198"><span class="lineNum">    7198 </span>            :         if (cse_is_idle != pse_is_idle)</a>
<a name="7199"><span class="lineNum">    7199 </span>            :                 return;</a>
<a name="7200"><span class="lineNum">    7200 </span>            : </a>
<a name="7201"><span class="lineNum">    7201 </span><span class="lineCov">       1038 :         update_curr(cfs_rq_of(se));</span></a>
<a name="7202"><span class="lineNum">    7202 </span><span class="lineCov">        519 :         if (wakeup_preempt_entity(se, pse) == 1) {</span></a>
<a name="7203"><span class="lineNum">    7203 </span>            :                 /*</a>
<a name="7204"><span class="lineNum">    7204 </span>            :                  * Bias pick_next to pick the sched entity that is</a>
<a name="7205"><span class="lineNum">    7205 </span>            :                  * triggering this preemption.</a>
<a name="7206"><span class="lineNum">    7206 </span>            :                  */</a>
<a name="7207"><span class="lineNum">    7207 </span><span class="lineCov">        199 :                 if (!next_buddy_marked)</span></a>
<a name="7208"><span class="lineNum">    7208 </span><span class="lineCov">        199 :                         set_next_buddy(pse);</span></a>
<a name="7209"><span class="lineNum">    7209 </span>            :                 goto preempt;</a>
<a name="7210"><span class="lineNum">    7210 </span>            :         }</a>
<a name="7211"><span class="lineNum">    7211 </span>            : </a>
<a name="7212"><span class="lineNum">    7212 </span>            :         return;</a>
<a name="7213"><span class="lineNum">    7213 </span>            : </a>
<a name="7214"><span class="lineNum">    7214 </span>            : preempt:</a>
<a name="7215"><span class="lineNum">    7215 </span><span class="lineCov">        199 :         resched_curr(rq);</span></a>
<a name="7216"><span class="lineNum">    7216 </span>            :         /*</a>
<a name="7217"><span class="lineNum">    7217 </span>            :          * Only set the backward buddy when the current task is still</a>
<a name="7218"><span class="lineNum">    7218 </span>            :          * on the rq. This can happen when a wakeup gets interleaved</a>
<a name="7219"><span class="lineNum">    7219 </span>            :          * with schedule on the -&gt;pre_schedule() or idle_balance()</a>
<a name="7220"><span class="lineNum">    7220 </span>            :          * point, either of which can * drop the rq lock.</a>
<a name="7221"><span class="lineNum">    7221 </span>            :          *</a>
<a name="7222"><span class="lineNum">    7222 </span>            :          * Also, during early boot the idle thread is in the fair class,</a>
<a name="7223"><span class="lineNum">    7223 </span>            :          * for obvious reasons its a bad idea to schedule back to it.</a>
<a name="7224"><span class="lineNum">    7224 </span>            :          */</a>
<a name="7225"><span class="lineNum">    7225 </span><span class="lineCov">        199 :         if (unlikely(!se-&gt;on_rq || curr == rq-&gt;idle))</span></a>
<a name="7226"><span class="lineNum">    7226 </span>            :                 return;</a>
<a name="7227"><span class="lineNum">    7227 </span>            : </a>
<a name="7228"><span class="lineNum">    7228 </span><span class="lineCov">        199 :         if (sched_feat(LAST_BUDDY) &amp;&amp; scale &amp;&amp; entity_is_task(se))</span></a>
<a name="7229"><span class="lineNum">    7229 </span><span class="lineNoCov">          0 :                 set_last_buddy(se);</span></a>
<a name="7230"><span class="lineNum">    7230 </span>            : }</a>
<a name="7231"><span class="lineNum">    7231 </span>            : </a>
<a name="7232"><span class="lineNum">    7232 </span>            : #ifdef CONFIG_SMP</a>
<a name="7233"><span class="lineNum">    7233 </span>            : static struct task_struct *pick_task_fair(struct rq *rq)</a>
<a name="7234"><span class="lineNum">    7234 </span>            : {</a>
<a name="7235"><span class="lineNum">    7235 </span>            :         struct sched_entity *se;</a>
<a name="7236"><span class="lineNum">    7236 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="7237"><span class="lineNum">    7237 </span>            : </a>
<a name="7238"><span class="lineNum">    7238 </span>            : again:</a>
<a name="7239"><span class="lineNum">    7239 </span>            :         cfs_rq = &amp;rq-&gt;cfs;</a>
<a name="7240"><span class="lineNum">    7240 </span>            :         if (!cfs_rq-&gt;nr_running)</a>
<a name="7241"><span class="lineNum">    7241 </span>            :                 return NULL;</a>
<a name="7242"><span class="lineNum">    7242 </span>            : </a>
<a name="7243"><span class="lineNum">    7243 </span>            :         do {</a>
<a name="7244"><span class="lineNum">    7244 </span>            :                 struct sched_entity *curr = cfs_rq-&gt;curr;</a>
<a name="7245"><span class="lineNum">    7245 </span>            : </a>
<a name="7246"><span class="lineNum">    7246 </span>            :                 /* When we pick for a remote RQ, we'll not have done put_prev_entity() */</a>
<a name="7247"><span class="lineNum">    7247 </span>            :                 if (curr) {</a>
<a name="7248"><span class="lineNum">    7248 </span>            :                         if (curr-&gt;on_rq)</a>
<a name="7249"><span class="lineNum">    7249 </span>            :                                 update_curr(cfs_rq);</a>
<a name="7250"><span class="lineNum">    7250 </span>            :                         else</a>
<a name="7251"><span class="lineNum">    7251 </span>            :                                 curr = NULL;</a>
<a name="7252"><span class="lineNum">    7252 </span>            : </a>
<a name="7253"><span class="lineNum">    7253 </span>            :                         if (unlikely(check_cfs_rq_runtime(cfs_rq)))</a>
<a name="7254"><span class="lineNum">    7254 </span>            :                                 goto again;</a>
<a name="7255"><span class="lineNum">    7255 </span>            :                 }</a>
<a name="7256"><span class="lineNum">    7256 </span>            : </a>
<a name="7257"><span class="lineNum">    7257 </span>            :                 se = pick_next_entity(cfs_rq, curr);</a>
<a name="7258"><span class="lineNum">    7258 </span>            :                 cfs_rq = group_cfs_rq(se);</a>
<a name="7259"><span class="lineNum">    7259 </span>            :         } while (cfs_rq);</a>
<a name="7260"><span class="lineNum">    7260 </span>            : </a>
<a name="7261"><span class="lineNum">    7261 </span>            :         return task_of(se);</a>
<a name="7262"><span class="lineNum">    7262 </span>            : }</a>
<a name="7263"><span class="lineNum">    7263 </span>            : #endif</a>
<a name="7264"><span class="lineNum">    7264 </span>            : </a>
<a name="7265"><span class="lineNum">    7265 </span>            : struct task_struct *</a>
<a name="7266"><span class="lineNum">    7266 </span><span class="lineCov">        616 : pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)</span></a>
<a name="7267"><span class="lineNum">    7267 </span>            : {</a>
<a name="7268"><span class="lineNum">    7268 </span><span class="lineCov">        616 :         struct cfs_rq *cfs_rq = &amp;rq-&gt;cfs;</span></a>
<a name="7269"><span class="lineNum">    7269 </span>            :         struct sched_entity *se;</a>
<a name="7270"><span class="lineNum">    7270 </span>            :         struct task_struct *p;</a>
<a name="7271"><span class="lineNum">    7271 </span>            :         int new_tasks;</a>
<a name="7272"><span class="lineNum">    7272 </span>            : </a>
<a name="7273"><span class="lineNum">    7273 </span>            : again:</a>
<a name="7274"><span class="lineNum">    7274 </span><span class="lineCov">        616 :         if (!sched_fair_runnable(rq))</span></a>
<a name="7275"><span class="lineNum">    7275 </span>            :                 goto idle;</a>
<a name="7276"><span class="lineNum">    7276 </span>            : </a>
<a name="7277"><span class="lineNum">    7277 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="7278"><span class="lineNum">    7278 </span>            :         if (!prev || prev-&gt;sched_class != &amp;fair_sched_class)</a>
<a name="7279"><span class="lineNum">    7279 </span>            :                 goto simple;</a>
<a name="7280"><span class="lineNum">    7280 </span>            : </a>
<a name="7281"><span class="lineNum">    7281 </span>            :         /*</a>
<a name="7282"><span class="lineNum">    7282 </span>            :          * Because of the set_next_buddy() in dequeue_task_fair() it is rather</a>
<a name="7283"><span class="lineNum">    7283 </span>            :          * likely that a next task is from the same cgroup as the current.</a>
<a name="7284"><span class="lineNum">    7284 </span>            :          *</a>
<a name="7285"><span class="lineNum">    7285 </span>            :          * Therefore attempt to avoid putting and setting the entire cgroup</a>
<a name="7286"><span class="lineNum">    7286 </span>            :          * hierarchy, only change the part that actually changes.</a>
<a name="7287"><span class="lineNum">    7287 </span>            :          */</a>
<a name="7288"><span class="lineNum">    7288 </span>            : </a>
<a name="7289"><span class="lineNum">    7289 </span>            :         do {</a>
<a name="7290"><span class="lineNum">    7290 </span>            :                 struct sched_entity *curr = cfs_rq-&gt;curr;</a>
<a name="7291"><span class="lineNum">    7291 </span>            : </a>
<a name="7292"><span class="lineNum">    7292 </span>            :                 /*</a>
<a name="7293"><span class="lineNum">    7293 </span>            :                  * Since we got here without doing put_prev_entity() we also</a>
<a name="7294"><span class="lineNum">    7294 </span>            :                  * have to consider cfs_rq-&gt;curr. If it is still a runnable</a>
<a name="7295"><span class="lineNum">    7295 </span>            :                  * entity, update_curr() will update its vruntime, otherwise</a>
<a name="7296"><span class="lineNum">    7296 </span>            :                  * forget we've ever seen it.</a>
<a name="7297"><span class="lineNum">    7297 </span>            :                  */</a>
<a name="7298"><span class="lineNum">    7298 </span>            :                 if (curr) {</a>
<a name="7299"><span class="lineNum">    7299 </span>            :                         if (curr-&gt;on_rq)</a>
<a name="7300"><span class="lineNum">    7300 </span>            :                                 update_curr(cfs_rq);</a>
<a name="7301"><span class="lineNum">    7301 </span>            :                         else</a>
<a name="7302"><span class="lineNum">    7302 </span>            :                                 curr = NULL;</a>
<a name="7303"><span class="lineNum">    7303 </span>            : </a>
<a name="7304"><span class="lineNum">    7304 </span>            :                         /*</a>
<a name="7305"><span class="lineNum">    7305 </span>            :                          * This call to check_cfs_rq_runtime() will do the</a>
<a name="7306"><span class="lineNum">    7306 </span>            :                          * throttle and dequeue its entity in the parent(s).</a>
<a name="7307"><span class="lineNum">    7307 </span>            :                          * Therefore the nr_running test will indeed</a>
<a name="7308"><span class="lineNum">    7308 </span>            :                          * be correct.</a>
<a name="7309"><span class="lineNum">    7309 </span>            :                          */</a>
<a name="7310"><span class="lineNum">    7310 </span>            :                         if (unlikely(check_cfs_rq_runtime(cfs_rq))) {</a>
<a name="7311"><span class="lineNum">    7311 </span>            :                                 cfs_rq = &amp;rq-&gt;cfs;</a>
<a name="7312"><span class="lineNum">    7312 </span>            : </a>
<a name="7313"><span class="lineNum">    7313 </span>            :                                 if (!cfs_rq-&gt;nr_running)</a>
<a name="7314"><span class="lineNum">    7314 </span>            :                                         goto idle;</a>
<a name="7315"><span class="lineNum">    7315 </span>            : </a>
<a name="7316"><span class="lineNum">    7316 </span>            :                                 goto simple;</a>
<a name="7317"><span class="lineNum">    7317 </span>            :                         }</a>
<a name="7318"><span class="lineNum">    7318 </span>            :                 }</a>
<a name="7319"><span class="lineNum">    7319 </span>            : </a>
<a name="7320"><span class="lineNum">    7320 </span>            :                 se = pick_next_entity(cfs_rq, curr);</a>
<a name="7321"><span class="lineNum">    7321 </span>            :                 cfs_rq = group_cfs_rq(se);</a>
<a name="7322"><span class="lineNum">    7322 </span>            :         } while (cfs_rq);</a>
<a name="7323"><span class="lineNum">    7323 </span>            : </a>
<a name="7324"><span class="lineNum">    7324 </span>            :         p = task_of(se);</a>
<a name="7325"><span class="lineNum">    7325 </span>            : </a>
<a name="7326"><span class="lineNum">    7326 </span>            :         /*</a>
<a name="7327"><span class="lineNum">    7327 </span>            :          * Since we haven't yet done put_prev_entity and if the selected task</a>
<a name="7328"><span class="lineNum">    7328 </span>            :          * is a different task than we started out with, try and touch the</a>
<a name="7329"><span class="lineNum">    7329 </span>            :          * least amount of cfs_rqs.</a>
<a name="7330"><span class="lineNum">    7330 </span>            :          */</a>
<a name="7331"><span class="lineNum">    7331 </span>            :         if (prev != p) {</a>
<a name="7332"><span class="lineNum">    7332 </span>            :                 struct sched_entity *pse = &amp;prev-&gt;se;</a>
<a name="7333"><span class="lineNum">    7333 </span>            : </a>
<a name="7334"><span class="lineNum">    7334 </span>            :                 while (!(cfs_rq = is_same_group(se, pse))) {</a>
<a name="7335"><span class="lineNum">    7335 </span>            :                         int se_depth = se-&gt;depth;</a>
<a name="7336"><span class="lineNum">    7336 </span>            :                         int pse_depth = pse-&gt;depth;</a>
<a name="7337"><span class="lineNum">    7337 </span>            : </a>
<a name="7338"><span class="lineNum">    7338 </span>            :                         if (se_depth &lt;= pse_depth) {</a>
<a name="7339"><span class="lineNum">    7339 </span>            :                                 put_prev_entity(cfs_rq_of(pse), pse);</a>
<a name="7340"><span class="lineNum">    7340 </span>            :                                 pse = parent_entity(pse);</a>
<a name="7341"><span class="lineNum">    7341 </span>            :                         }</a>
<a name="7342"><span class="lineNum">    7342 </span>            :                         if (se_depth &gt;= pse_depth) {</a>
<a name="7343"><span class="lineNum">    7343 </span>            :                                 set_next_entity(cfs_rq_of(se), se);</a>
<a name="7344"><span class="lineNum">    7344 </span>            :                                 se = parent_entity(se);</a>
<a name="7345"><span class="lineNum">    7345 </span>            :                         }</a>
<a name="7346"><span class="lineNum">    7346 </span>            :                 }</a>
<a name="7347"><span class="lineNum">    7347 </span>            : </a>
<a name="7348"><span class="lineNum">    7348 </span>            :                 put_prev_entity(cfs_rq, pse);</a>
<a name="7349"><span class="lineNum">    7349 </span>            :                 set_next_entity(cfs_rq, se);</a>
<a name="7350"><span class="lineNum">    7350 </span>            :         }</a>
<a name="7351"><span class="lineNum">    7351 </span>            : </a>
<a name="7352"><span class="lineNum">    7352 </span>            :         goto done;</a>
<a name="7353"><span class="lineNum">    7353 </span>            : simple:</a>
<a name="7354"><span class="lineNum">    7354 </span>            : #endif</a>
<a name="7355"><span class="lineNum">    7355 </span><span class="lineCov">        615 :         if (prev)</span></a>
<a name="7356"><span class="lineNum">    7356 </span><span class="lineCov">        615 :                 put_prev_task(rq, prev);</span></a>
<a name="7357"><span class="lineNum">    7357 </span>            : </a>
<a name="7358"><span class="lineNum">    7358 </span>            :         do {</a>
<a name="7359"><span class="lineNum">    7359 </span><span class="lineCov">        615 :                 se = pick_next_entity(cfs_rq, NULL);</span></a>
<a name="7360"><span class="lineNum">    7360 </span><span class="lineCov">        615 :                 set_next_entity(cfs_rq, se);</span></a>
<a name="7361"><span class="lineNum">    7361 </span><span class="lineCov">        615 :                 cfs_rq = group_cfs_rq(se);</span></a>
<a name="7362"><span class="lineNum">    7362 </span>            :         } while (cfs_rq);</a>
<a name="7363"><span class="lineNum">    7363 </span>            : </a>
<a name="7364"><span class="lineNum">    7364 </span><span class="lineCov">        615 :         p = task_of(se);</span></a>
<a name="7365"><span class="lineNum">    7365 </span>            : </a>
<a name="7366"><span class="lineNum">    7366 </span>            : done: __maybe_unused;</a>
<a name="7367"><span class="lineNum">    7367 </span>            : #ifdef CONFIG_SMP</a>
<a name="7368"><span class="lineNum">    7368 </span>            :         /*</a>
<a name="7369"><span class="lineNum">    7369 </span>            :          * Move the next running task to the front of</a>
<a name="7370"><span class="lineNum">    7370 </span>            :          * the list, so our cfs_tasks list becomes MRU</a>
<a name="7371"><span class="lineNum">    7371 </span>            :          * one.</a>
<a name="7372"><span class="lineNum">    7372 </span>            :          */</a>
<a name="7373"><span class="lineNum">    7373 </span>            :         list_move(&amp;p-&gt;se.group_node, &amp;rq-&gt;cfs_tasks);</a>
<a name="7374"><span class="lineNum">    7374 </span>            : #endif</a>
<a name="7375"><span class="lineNum">    7375 </span>            : </a>
<a name="7376"><span class="lineNum">    7376 </span><span class="lineCov">        615 :         if (hrtick_enabled_fair(rq))</span></a>
<a name="7377"><span class="lineNum">    7377 </span>            :                 hrtick_start_fair(rq, p);</a>
<a name="7378"><span class="lineNum">    7378 </span>            : </a>
<a name="7379"><span class="lineNum">    7379 </span><span class="lineCov">        615 :         update_misfit_status(p, rq);</span></a>
<a name="7380"><span class="lineNum">    7380 </span>            : </a>
<a name="7381"><span class="lineNum">    7381 </span><span class="lineCov">        615 :         return p;</span></a>
<a name="7382"><span class="lineNum">    7382 </span>            : </a>
<a name="7383"><span class="lineNum">    7383 </span>            : idle:</a>
<a name="7384"><span class="lineNum">    7384 </span>            :         if (!rf)</a>
<a name="7385"><span class="lineNum">    7385 </span>            :                 return NULL;</a>
<a name="7386"><span class="lineNum">    7386 </span>            : </a>
<a name="7387"><span class="lineNum">    7387 </span>            :         new_tasks = newidle_balance(rq, rf);</a>
<a name="7388"><span class="lineNum">    7388 </span>            : </a>
<a name="7389"><span class="lineNum">    7389 </span>            :         /*</a>
<a name="7390"><span class="lineNum">    7390 </span>            :          * Because newidle_balance() releases (and re-acquires) rq-&gt;lock, it is</a>
<a name="7391"><span class="lineNum">    7391 </span>            :          * possible for any higher priority task to appear. In that case we</a>
<a name="7392"><span class="lineNum">    7392 </span>            :          * must re-start the pick_next_entity() loop.</a>
<a name="7393"><span class="lineNum">    7393 </span>            :          */</a>
<a name="7394"><span class="lineNum">    7394 </span>            :         if (new_tasks &lt; 0)</a>
<a name="7395"><span class="lineNum">    7395 </span>            :                 return RETRY_TASK;</a>
<a name="7396"><span class="lineNum">    7396 </span>            : </a>
<a name="7397"><span class="lineNum">    7397 </span>            :         if (new_tasks &gt; 0)</a>
<a name="7398"><span class="lineNum">    7398 </span>            :                 goto again;</a>
<a name="7399"><span class="lineNum">    7399 </span>            : </a>
<a name="7400"><span class="lineNum">    7400 </span>            :         /*</a>
<a name="7401"><span class="lineNum">    7401 </span>            :          * rq is about to be idle, check if we need to update the</a>
<a name="7402"><span class="lineNum">    7402 </span>            :          * lost_idle_time of clock_pelt</a>
<a name="7403"><span class="lineNum">    7403 </span>            :          */</a>
<a name="7404"><span class="lineNum">    7404 </span>            :         update_idle_rq_clock_pelt(rq);</a>
<a name="7405"><span class="lineNum">    7405 </span>            : </a>
<a name="7406"><span class="lineNum">    7406 </span>            :         return NULL;</a>
<a name="7407"><span class="lineNum">    7407 </span>            : }</a>
<a name="7408"><span class="lineNum">    7408 </span>            : </a>
<a name="7409"><span class="lineNum">    7409 </span><span class="lineNoCov">          0 : static struct task_struct *__pick_next_task_fair(struct rq *rq)</span></a>
<a name="7410"><span class="lineNum">    7410 </span>            : {</a>
<a name="7411"><span class="lineNum">    7411 </span><span class="lineNoCov">          0 :         return pick_next_task_fair(rq, NULL, NULL);</span></a>
<a name="7412"><span class="lineNum">    7412 </span>            : }</a>
<a name="7413"><span class="lineNum">    7413 </span>            : </a>
<a name="7414"><span class="lineNum">    7414 </span>            : /*</a>
<a name="7415"><span class="lineNum">    7415 </span>            :  * Account for a descheduled task:</a>
<a name="7416"><span class="lineNum">    7416 </span>            :  */</a>
<a name="7417"><span class="lineNum">    7417 </span><span class="lineCov">        617 : static void put_prev_task_fair(struct rq *rq, struct task_struct *prev)</span></a>
<a name="7418"><span class="lineNum">    7418 </span>            : {</a>
<a name="7419"><span class="lineNum">    7419 </span><span class="lineCov">        617 :         struct sched_entity *se = &amp;prev-&gt;se;</span></a>
<a name="7420"><span class="lineNum">    7420 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="7421"><span class="lineNum">    7421 </span>            : </a>
<a name="7422"><span class="lineNum">    7422 </span><span class="lineCov">       1234 :         for_each_sched_entity(se) {</span></a>
<a name="7423"><span class="lineNum">    7423 </span><span class="lineCov">       1234 :                 cfs_rq = cfs_rq_of(se);</span></a>
<a name="7424"><span class="lineNum">    7424 </span><span class="lineCov">        617 :                 put_prev_entity(cfs_rq, se);</span></a>
<a name="7425"><span class="lineNum">    7425 </span>            :         }</a>
<a name="7426"><span class="lineNum">    7426 </span><span class="lineCov">        617 : }</span></a>
<a name="7427"><span class="lineNum">    7427 </span>            : </a>
<a name="7428"><span class="lineNum">    7428 </span>            : /*</a>
<a name="7429"><span class="lineNum">    7429 </span>            :  * sched_yield() is very simple</a>
<a name="7430"><span class="lineNum">    7430 </span>            :  *</a>
<a name="7431"><span class="lineNum">    7431 </span>            :  * The magic of dealing with the -&gt;skip buddy is in pick_next_entity.</a>
<a name="7432"><span class="lineNum">    7432 </span>            :  */</a>
<a name="7433"><span class="lineNum">    7433 </span><span class="lineNoCov">          0 : static void yield_task_fair(struct rq *rq)</span></a>
<a name="7434"><span class="lineNum">    7434 </span>            : {</a>
<a name="7435"><span class="lineNum">    7435 </span><span class="lineNoCov">          0 :         struct task_struct *curr = rq-&gt;curr;</span></a>
<a name="7436"><span class="lineNum">    7436 </span><span class="lineNoCov">          0 :         struct cfs_rq *cfs_rq = task_cfs_rq(curr);</span></a>
<a name="7437"><span class="lineNum">    7437 </span><span class="lineNoCov">          0 :         struct sched_entity *se = &amp;curr-&gt;se;</span></a>
<a name="7438"><span class="lineNum">    7438 </span>            : </a>
<a name="7439"><span class="lineNum">    7439 </span>            :         /*</a>
<a name="7440"><span class="lineNum">    7440 </span>            :          * Are we the only task in the tree?</a>
<a name="7441"><span class="lineNum">    7441 </span>            :          */</a>
<a name="7442"><span class="lineNum">    7442 </span><span class="lineNoCov">          0 :         if (unlikely(rq-&gt;nr_running == 1))</span></a>
<a name="7443"><span class="lineNum">    7443 </span>            :                 return;</a>
<a name="7444"><span class="lineNum">    7444 </span>            : </a>
<a name="7445"><span class="lineNum">    7445 </span><span class="lineNoCov">          0 :         clear_buddies(cfs_rq, se);</span></a>
<a name="7446"><span class="lineNum">    7446 </span>            : </a>
<a name="7447"><span class="lineNum">    7447 </span><span class="lineNoCov">          0 :         if (curr-&gt;policy != SCHED_BATCH) {</span></a>
<a name="7448"><span class="lineNum">    7448 </span><span class="lineNoCov">          0 :                 update_rq_clock(rq);</span></a>
<a name="7449"><span class="lineNum">    7449 </span>            :                 /*</a>
<a name="7450"><span class="lineNum">    7450 </span>            :                  * Update run-time statistics of the 'current'.</a>
<a name="7451"><span class="lineNum">    7451 </span>            :                  */</a>
<a name="7452"><span class="lineNum">    7452 </span><span class="lineNoCov">          0 :                 update_curr(cfs_rq);</span></a>
<a name="7453"><span class="lineNum">    7453 </span>            :                 /*</a>
<a name="7454"><span class="lineNum">    7454 </span>            :                  * Tell update_rq_clock() that we've just updated,</a>
<a name="7455"><span class="lineNum">    7455 </span>            :                  * so we don't do microscopic update in schedule()</a>
<a name="7456"><span class="lineNum">    7456 </span>            :                  * and double the fastpath cost.</a>
<a name="7457"><span class="lineNum">    7457 </span>            :                  */</a>
<a name="7458"><span class="lineNum">    7458 </span><span class="lineNoCov">          0 :                 rq_clock_skip_update(rq);</span></a>
<a name="7459"><span class="lineNum">    7459 </span>            :         }</a>
<a name="7460"><span class="lineNum">    7460 </span>            : </a>
<a name="7461"><span class="lineNum">    7461 </span>            :         set_skip_buddy(se);</a>
<a name="7462"><span class="lineNum">    7462 </span>            : }</a>
<a name="7463"><span class="lineNum">    7463 </span>            : </a>
<a name="7464"><span class="lineNum">    7464 </span><span class="lineNoCov">          0 : static bool yield_to_task_fair(struct rq *rq, struct task_struct *p)</span></a>
<a name="7465"><span class="lineNum">    7465 </span>            : {</a>
<a name="7466"><span class="lineNum">    7466 </span><span class="lineNoCov">          0 :         struct sched_entity *se = &amp;p-&gt;se;</span></a>
<a name="7467"><span class="lineNum">    7467 </span>            : </a>
<a name="7468"><span class="lineNum">    7468 </span>            :         /* throttled hierarchies are not runnable */</a>
<a name="7469"><span class="lineNum">    7469 </span><span class="lineNoCov">          0 :         if (!se-&gt;on_rq || throttled_hierarchy(cfs_rq_of(se)))</span></a>
<a name="7470"><span class="lineNum">    7470 </span>            :                 return false;</a>
<a name="7471"><span class="lineNum">    7471 </span>            : </a>
<a name="7472"><span class="lineNum">    7472 </span>            :         /* Tell the scheduler that we'd really like pse to run next. */</a>
<a name="7473"><span class="lineNum">    7473 </span><span class="lineNoCov">          0 :         set_next_buddy(se);</span></a>
<a name="7474"><span class="lineNum">    7474 </span>            : </a>
<a name="7475"><span class="lineNum">    7475 </span><span class="lineNoCov">          0 :         yield_task_fair(rq);</span></a>
<a name="7476"><span class="lineNum">    7476 </span>            : </a>
<a name="7477"><span class="lineNum">    7477 </span><span class="lineNoCov">          0 :         return true;</span></a>
<a name="7478"><span class="lineNum">    7478 </span>            : }</a>
<a name="7479"><span class="lineNum">    7479 </span>            : </a>
<a name="7480"><span class="lineNum">    7480 </span>            : #ifdef CONFIG_SMP</a>
<a name="7481"><span class="lineNum">    7481 </span>            : /**************************************************</a>
<a name="7482"><span class="lineNum">    7482 </span>            :  * Fair scheduling class load-balancing methods.</a>
<a name="7483"><span class="lineNum">    7483 </span>            :  *</a>
<a name="7484"><span class="lineNum">    7484 </span>            :  * BASICS</a>
<a name="7485"><span class="lineNum">    7485 </span>            :  *</a>
<a name="7486"><span class="lineNum">    7486 </span>            :  * The purpose of load-balancing is to achieve the same basic fairness the</a>
<a name="7487"><span class="lineNum">    7487 </span>            :  * per-CPU scheduler provides, namely provide a proportional amount of compute</a>
<a name="7488"><span class="lineNum">    7488 </span>            :  * time to each task. This is expressed in the following equation:</a>
<a name="7489"><span class="lineNum">    7489 </span>            :  *</a>
<a name="7490"><span class="lineNum">    7490 </span>            :  *   W_i,n/P_i == W_j,n/P_j for all i,j                               (1)</a>
<a name="7491"><span class="lineNum">    7491 </span>            :  *</a>
<a name="7492"><span class="lineNum">    7492 </span>            :  * Where W_i,n is the n-th weight average for CPU i. The instantaneous weight</a>
<a name="7493"><span class="lineNum">    7493 </span>            :  * W_i,0 is defined as:</a>
<a name="7494"><span class="lineNum">    7494 </span>            :  *</a>
<a name="7495"><span class="lineNum">    7495 </span>            :  *   W_i,0 = \Sum_j w_i,j                                             (2)</a>
<a name="7496"><span class="lineNum">    7496 </span>            :  *</a>
<a name="7497"><span class="lineNum">    7497 </span>            :  * Where w_i,j is the weight of the j-th runnable task on CPU i. This weight</a>
<a name="7498"><span class="lineNum">    7498 </span>            :  * is derived from the nice value as per sched_prio_to_weight[].</a>
<a name="7499"><span class="lineNum">    7499 </span>            :  *</a>
<a name="7500"><span class="lineNum">    7500 </span>            :  * The weight average is an exponential decay average of the instantaneous</a>
<a name="7501"><span class="lineNum">    7501 </span>            :  * weight:</a>
<a name="7502"><span class="lineNum">    7502 </span>            :  *</a>
<a name="7503"><span class="lineNum">    7503 </span>            :  *   W'_i,n = (2^n - 1) / 2^n * W_i,n + 1 / 2^n * W_i,0               (3)</a>
<a name="7504"><span class="lineNum">    7504 </span>            :  *</a>
<a name="7505"><span class="lineNum">    7505 </span>            :  * C_i is the compute capacity of CPU i, typically it is the</a>
<a name="7506"><span class="lineNum">    7506 </span>            :  * fraction of 'recent' time available for SCHED_OTHER task execution. But it</a>
<a name="7507"><span class="lineNum">    7507 </span>            :  * can also include other factors [XXX].</a>
<a name="7508"><span class="lineNum">    7508 </span>            :  *</a>
<a name="7509"><span class="lineNum">    7509 </span>            :  * To achieve this balance we define a measure of imbalance which follows</a>
<a name="7510"><span class="lineNum">    7510 </span>            :  * directly from (1):</a>
<a name="7511"><span class="lineNum">    7511 </span>            :  *</a>
<a name="7512"><span class="lineNum">    7512 </span>            :  *   imb_i,j = max{ avg(W/C), W_i/C_i } - min{ avg(W/C), W_j/C_j }    (4)</a>
<a name="7513"><span class="lineNum">    7513 </span>            :  *</a>
<a name="7514"><span class="lineNum">    7514 </span>            :  * We them move tasks around to minimize the imbalance. In the continuous</a>
<a name="7515"><span class="lineNum">    7515 </span>            :  * function space it is obvious this converges, in the discrete case we get</a>
<a name="7516"><span class="lineNum">    7516 </span>            :  * a few fun cases generally called infeasible weight scenarios.</a>
<a name="7517"><span class="lineNum">    7517 </span>            :  *</a>
<a name="7518"><span class="lineNum">    7518 </span>            :  * [XXX expand on:</a>
<a name="7519"><span class="lineNum">    7519 </span>            :  *     - infeasible weights;</a>
<a name="7520"><span class="lineNum">    7520 </span>            :  *     - local vs global optima in the discrete case. ]</a>
<a name="7521"><span class="lineNum">    7521 </span>            :  *</a>
<a name="7522"><span class="lineNum">    7522 </span>            :  *</a>
<a name="7523"><span class="lineNum">    7523 </span>            :  * SCHED DOMAINS</a>
<a name="7524"><span class="lineNum">    7524 </span>            :  *</a>
<a name="7525"><span class="lineNum">    7525 </span>            :  * In order to solve the imbalance equation (4), and avoid the obvious O(n^2)</a>
<a name="7526"><span class="lineNum">    7526 </span>            :  * for all i,j solution, we create a tree of CPUs that follows the hardware</a>
<a name="7527"><span class="lineNum">    7527 </span>            :  * topology where each level pairs two lower groups (or better). This results</a>
<a name="7528"><span class="lineNum">    7528 </span>            :  * in O(log n) layers. Furthermore we reduce the number of CPUs going up the</a>
<a name="7529"><span class="lineNum">    7529 </span>            :  * tree to only the first of the previous level and we decrease the frequency</a>
<a name="7530"><span class="lineNum">    7530 </span>            :  * of load-balance at each level inv. proportional to the number of CPUs in</a>
<a name="7531"><span class="lineNum">    7531 </span>            :  * the groups.</a>
<a name="7532"><span class="lineNum">    7532 </span>            :  *</a>
<a name="7533"><span class="lineNum">    7533 </span>            :  * This yields:</a>
<a name="7534"><span class="lineNum">    7534 </span>            :  *</a>
<a name="7535"><span class="lineNum">    7535 </span>            :  *     log_2 n     1     n</a>
<a name="7536"><span class="lineNum">    7536 </span>            :  *   \Sum       { --- * --- * 2^i } = O(n)                            (5)</a>
<a name="7537"><span class="lineNum">    7537 </span>            :  *     i = 0      2^i   2^i</a>
<a name="7538"><span class="lineNum">    7538 </span>            :  *                               `- size of each group</a>
<a name="7539"><span class="lineNum">    7539 </span>            :  *         |         |     `- number of CPUs doing load-balance</a>
<a name="7540"><span class="lineNum">    7540 </span>            :  *         |         `- freq</a>
<a name="7541"><span class="lineNum">    7541 </span>            :  *         `- sum over all levels</a>
<a name="7542"><span class="lineNum">    7542 </span>            :  *</a>
<a name="7543"><span class="lineNum">    7543 </span>            :  * Coupled with a limit on how many tasks we can migrate every balance pass,</a>
<a name="7544"><span class="lineNum">    7544 </span>            :  * this makes (5) the runtime complexity of the balancer.</a>
<a name="7545"><span class="lineNum">    7545 </span>            :  *</a>
<a name="7546"><span class="lineNum">    7546 </span>            :  * An important property here is that each CPU is still (indirectly) connected</a>
<a name="7547"><span class="lineNum">    7547 </span>            :  * to every other CPU in at most O(log n) steps:</a>
<a name="7548"><span class="lineNum">    7548 </span>            :  *</a>
<a name="7549"><span class="lineNum">    7549 </span>            :  * The adjacency matrix of the resulting graph is given by:</a>
<a name="7550"><span class="lineNum">    7550 </span>            :  *</a>
<a name="7551"><span class="lineNum">    7551 </span>            :  *             log_2 n</a>
<a name="7552"><span class="lineNum">    7552 </span>            :  *   A_i,j = \Union     (i % 2^k == 0) &amp;&amp; i / 2^(k+1) == j / 2^(k+1)  (6)</a>
<a name="7553"><span class="lineNum">    7553 </span>            :  *             k = 0</a>
<a name="7554"><span class="lineNum">    7554 </span>            :  *</a>
<a name="7555"><span class="lineNum">    7555 </span>            :  * And you'll find that:</a>
<a name="7556"><span class="lineNum">    7556 </span>            :  *</a>
<a name="7557"><span class="lineNum">    7557 </span>            :  *   A^(log_2 n)_i,j != 0  for all i,j                                (7)</a>
<a name="7558"><span class="lineNum">    7558 </span>            :  *</a>
<a name="7559"><span class="lineNum">    7559 </span>            :  * Showing there's indeed a path between every CPU in at most O(log n) steps.</a>
<a name="7560"><span class="lineNum">    7560 </span>            :  * The task movement gives a factor of O(m), giving a convergence complexity</a>
<a name="7561"><span class="lineNum">    7561 </span>            :  * of:</a>
<a name="7562"><span class="lineNum">    7562 </span>            :  *</a>
<a name="7563"><span class="lineNum">    7563 </span>            :  *   O(nm log n),  n := nr_cpus, m := nr_tasks                        (8)</a>
<a name="7564"><span class="lineNum">    7564 </span>            :  *</a>
<a name="7565"><span class="lineNum">    7565 </span>            :  *</a>
<a name="7566"><span class="lineNum">    7566 </span>            :  * WORK CONSERVING</a>
<a name="7567"><span class="lineNum">    7567 </span>            :  *</a>
<a name="7568"><span class="lineNum">    7568 </span>            :  * In order to avoid CPUs going idle while there's still work to do, new idle</a>
<a name="7569"><span class="lineNum">    7569 </span>            :  * balancing is more aggressive and has the newly idle CPU iterate up the domain</a>
<a name="7570"><span class="lineNum">    7570 </span>            :  * tree itself instead of relying on other CPUs to bring it work.</a>
<a name="7571"><span class="lineNum">    7571 </span>            :  *</a>
<a name="7572"><span class="lineNum">    7572 </span>            :  * This adds some complexity to both (5) and (8) but it reduces the total idle</a>
<a name="7573"><span class="lineNum">    7573 </span>            :  * time.</a>
<a name="7574"><span class="lineNum">    7574 </span>            :  *</a>
<a name="7575"><span class="lineNum">    7575 </span>            :  * [XXX more?]</a>
<a name="7576"><span class="lineNum">    7576 </span>            :  *</a>
<a name="7577"><span class="lineNum">    7577 </span>            :  *</a>
<a name="7578"><span class="lineNum">    7578 </span>            :  * CGROUPS</a>
<a name="7579"><span class="lineNum">    7579 </span>            :  *</a>
<a name="7580"><span class="lineNum">    7580 </span>            :  * Cgroups make a horror show out of (2), instead of a simple sum we get:</a>
<a name="7581"><span class="lineNum">    7581 </span>            :  *</a>
<a name="7582"><span class="lineNum">    7582 </span>            :  *                                s_k,i</a>
<a name="7583"><span class="lineNum">    7583 </span>            :  *   W_i,0 = \Sum_j \Prod_k w_k * -----                               (9)</a>
<a name="7584"><span class="lineNum">    7584 </span>            :  *                                 S_k</a>
<a name="7585"><span class="lineNum">    7585 </span>            :  *</a>
<a name="7586"><span class="lineNum">    7586 </span>            :  * Where</a>
<a name="7587"><span class="lineNum">    7587 </span>            :  *</a>
<a name="7588"><span class="lineNum">    7588 </span>            :  *   s_k,i = \Sum_j w_i,j,k  and  S_k = \Sum_i s_k,i                 (10)</a>
<a name="7589"><span class="lineNum">    7589 </span>            :  *</a>
<a name="7590"><span class="lineNum">    7590 </span>            :  * w_i,j,k is the weight of the j-th runnable task in the k-th cgroup on CPU i.</a>
<a name="7591"><span class="lineNum">    7591 </span>            :  *</a>
<a name="7592"><span class="lineNum">    7592 </span>            :  * The big problem is S_k, its a global sum needed to compute a local (W_i)</a>
<a name="7593"><span class="lineNum">    7593 </span>            :  * property.</a>
<a name="7594"><span class="lineNum">    7594 </span>            :  *</a>
<a name="7595"><span class="lineNum">    7595 </span>            :  * [XXX write more on how we solve this.. _after_ merging pjt's patches that</a>
<a name="7596"><span class="lineNum">    7596 </span>            :  *      rewrite all of this once again.]</a>
<a name="7597"><span class="lineNum">    7597 </span>            :  */</a>
<a name="7598"><span class="lineNum">    7598 </span>            : </a>
<a name="7599"><span class="lineNum">    7599 </span>            : static unsigned long __read_mostly max_load_balance_interval = HZ/10;</a>
<a name="7600"><span class="lineNum">    7600 </span>            : </a>
<a name="7601"><span class="lineNum">    7601 </span>            : enum fbq_type { regular, remote, all };</a>
<a name="7602"><span class="lineNum">    7602 </span>            : </a>
<a name="7603"><span class="lineNum">    7603 </span>            : /*</a>
<a name="7604"><span class="lineNum">    7604 </span>            :  * 'group_type' describes the group of CPUs at the moment of load balancing.</a>
<a name="7605"><span class="lineNum">    7605 </span>            :  *</a>
<a name="7606"><span class="lineNum">    7606 </span>            :  * The enum is ordered by pulling priority, with the group with lowest priority</a>
<a name="7607"><span class="lineNum">    7607 </span>            :  * first so the group_type can simply be compared when selecting the busiest</a>
<a name="7608"><span class="lineNum">    7608 </span>            :  * group. See update_sd_pick_busiest().</a>
<a name="7609"><span class="lineNum">    7609 </span>            :  */</a>
<a name="7610"><span class="lineNum">    7610 </span>            : enum group_type {</a>
<a name="7611"><span class="lineNum">    7611 </span>            :         /* The group has spare capacity that can be used to run more tasks.  */</a>
<a name="7612"><span class="lineNum">    7612 </span>            :         group_has_spare = 0,</a>
<a name="7613"><span class="lineNum">    7613 </span>            :         /*</a>
<a name="7614"><span class="lineNum">    7614 </span>            :          * The group is fully used and the tasks don't compete for more CPU</a>
<a name="7615"><span class="lineNum">    7615 </span>            :          * cycles. Nevertheless, some tasks might wait before running.</a>
<a name="7616"><span class="lineNum">    7616 </span>            :          */</a>
<a name="7617"><span class="lineNum">    7617 </span>            :         group_fully_busy,</a>
<a name="7618"><span class="lineNum">    7618 </span>            :         /*</a>
<a name="7619"><span class="lineNum">    7619 </span>            :          * SD_ASYM_CPUCAPACITY only: One task doesn't fit with CPU's capacity</a>
<a name="7620"><span class="lineNum">    7620 </span>            :          * and must be migrated to a more powerful CPU.</a>
<a name="7621"><span class="lineNum">    7621 </span>            :          */</a>
<a name="7622"><span class="lineNum">    7622 </span>            :         group_misfit_task,</a>
<a name="7623"><span class="lineNum">    7623 </span>            :         /*</a>
<a name="7624"><span class="lineNum">    7624 </span>            :          * SD_ASYM_PACKING only: One local CPU with higher capacity is available,</a>
<a name="7625"><span class="lineNum">    7625 </span>            :          * and the task should be migrated to it instead of running on the</a>
<a name="7626"><span class="lineNum">    7626 </span>            :          * current CPU.</a>
<a name="7627"><span class="lineNum">    7627 </span>            :          */</a>
<a name="7628"><span class="lineNum">    7628 </span>            :         group_asym_packing,</a>
<a name="7629"><span class="lineNum">    7629 </span>            :         /*</a>
<a name="7630"><span class="lineNum">    7630 </span>            :          * The tasks' affinity constraints previously prevented the scheduler</a>
<a name="7631"><span class="lineNum">    7631 </span>            :          * from balancing the load across the system.</a>
<a name="7632"><span class="lineNum">    7632 </span>            :          */</a>
<a name="7633"><span class="lineNum">    7633 </span>            :         group_imbalanced,</a>
<a name="7634"><span class="lineNum">    7634 </span>            :         /*</a>
<a name="7635"><span class="lineNum">    7635 </span>            :          * The CPU is overloaded and can't provide expected CPU cycles to all</a>
<a name="7636"><span class="lineNum">    7636 </span>            :          * tasks.</a>
<a name="7637"><span class="lineNum">    7637 </span>            :          */</a>
<a name="7638"><span class="lineNum">    7638 </span>            :         group_overloaded</a>
<a name="7639"><span class="lineNum">    7639 </span>            : };</a>
<a name="7640"><span class="lineNum">    7640 </span>            : </a>
<a name="7641"><span class="lineNum">    7641 </span>            : enum migration_type {</a>
<a name="7642"><span class="lineNum">    7642 </span>            :         migrate_load = 0,</a>
<a name="7643"><span class="lineNum">    7643 </span>            :         migrate_util,</a>
<a name="7644"><span class="lineNum">    7644 </span>            :         migrate_task,</a>
<a name="7645"><span class="lineNum">    7645 </span>            :         migrate_misfit</a>
<a name="7646"><span class="lineNum">    7646 </span>            : };</a>
<a name="7647"><span class="lineNum">    7647 </span>            : </a>
<a name="7648"><span class="lineNum">    7648 </span>            : #define LBF_ALL_PINNED  0x01</a>
<a name="7649"><span class="lineNum">    7649 </span>            : #define LBF_NEED_BREAK  0x02</a>
<a name="7650"><span class="lineNum">    7650 </span>            : #define LBF_DST_PINNED  0x04</a>
<a name="7651"><span class="lineNum">    7651 </span>            : #define LBF_SOME_PINNED 0x08</a>
<a name="7652"><span class="lineNum">    7652 </span>            : #define LBF_ACTIVE_LB   0x10</a>
<a name="7653"><span class="lineNum">    7653 </span>            : </a>
<a name="7654"><span class="lineNum">    7654 </span>            : struct lb_env {</a>
<a name="7655"><span class="lineNum">    7655 </span>            :         struct sched_domain     *sd;</a>
<a name="7656"><span class="lineNum">    7656 </span>            : </a>
<a name="7657"><span class="lineNum">    7657 </span>            :         struct rq               *src_rq;</a>
<a name="7658"><span class="lineNum">    7658 </span>            :         int                     src_cpu;</a>
<a name="7659"><span class="lineNum">    7659 </span>            : </a>
<a name="7660"><span class="lineNum">    7660 </span>            :         int                     dst_cpu;</a>
<a name="7661"><span class="lineNum">    7661 </span>            :         struct rq               *dst_rq;</a>
<a name="7662"><span class="lineNum">    7662 </span>            : </a>
<a name="7663"><span class="lineNum">    7663 </span>            :         struct cpumask          *dst_grpmask;</a>
<a name="7664"><span class="lineNum">    7664 </span>            :         int                     new_dst_cpu;</a>
<a name="7665"><span class="lineNum">    7665 </span>            :         enum cpu_idle_type      idle;</a>
<a name="7666"><span class="lineNum">    7666 </span>            :         long                    imbalance;</a>
<a name="7667"><span class="lineNum">    7667 </span>            :         /* The set of CPUs under consideration for load-balancing */</a>
<a name="7668"><span class="lineNum">    7668 </span>            :         struct cpumask          *cpus;</a>
<a name="7669"><span class="lineNum">    7669 </span>            : </a>
<a name="7670"><span class="lineNum">    7670 </span>            :         unsigned int            flags;</a>
<a name="7671"><span class="lineNum">    7671 </span>            : </a>
<a name="7672"><span class="lineNum">    7672 </span>            :         unsigned int            loop;</a>
<a name="7673"><span class="lineNum">    7673 </span>            :         unsigned int            loop_break;</a>
<a name="7674"><span class="lineNum">    7674 </span>            :         unsigned int            loop_max;</a>
<a name="7675"><span class="lineNum">    7675 </span>            : </a>
<a name="7676"><span class="lineNum">    7676 </span>            :         enum fbq_type           fbq_type;</a>
<a name="7677"><span class="lineNum">    7677 </span>            :         enum migration_type     migration_type;</a>
<a name="7678"><span class="lineNum">    7678 </span>            :         struct list_head        tasks;</a>
<a name="7679"><span class="lineNum">    7679 </span>            : };</a>
<a name="7680"><span class="lineNum">    7680 </span>            : </a>
<a name="7681"><span class="lineNum">    7681 </span>            : /*</a>
<a name="7682"><span class="lineNum">    7682 </span>            :  * Is this task likely cache-hot:</a>
<a name="7683"><span class="lineNum">    7683 </span>            :  */</a>
<a name="7684"><span class="lineNum">    7684 </span>            : static int task_hot(struct task_struct *p, struct lb_env *env)</a>
<a name="7685"><span class="lineNum">    7685 </span>            : {</a>
<a name="7686"><span class="lineNum">    7686 </span>            :         s64 delta;</a>
<a name="7687"><span class="lineNum">    7687 </span>            : </a>
<a name="7688"><span class="lineNum">    7688 </span>            :         lockdep_assert_rq_held(env-&gt;src_rq);</a>
<a name="7689"><span class="lineNum">    7689 </span>            : </a>
<a name="7690"><span class="lineNum">    7690 </span>            :         if (p-&gt;sched_class != &amp;fair_sched_class)</a>
<a name="7691"><span class="lineNum">    7691 </span>            :                 return 0;</a>
<a name="7692"><span class="lineNum">    7692 </span>            : </a>
<a name="7693"><span class="lineNum">    7693 </span>            :         if (unlikely(task_has_idle_policy(p)))</a>
<a name="7694"><span class="lineNum">    7694 </span>            :                 return 0;</a>
<a name="7695"><span class="lineNum">    7695 </span>            : </a>
<a name="7696"><span class="lineNum">    7696 </span>            :         /* SMT siblings share cache */</a>
<a name="7697"><span class="lineNum">    7697 </span>            :         if (env-&gt;sd-&gt;flags &amp; SD_SHARE_CPUCAPACITY)</a>
<a name="7698"><span class="lineNum">    7698 </span>            :                 return 0;</a>
<a name="7699"><span class="lineNum">    7699 </span>            : </a>
<a name="7700"><span class="lineNum">    7700 </span>            :         /*</a>
<a name="7701"><span class="lineNum">    7701 </span>            :          * Buddy candidates are cache hot:</a>
<a name="7702"><span class="lineNum">    7702 </span>            :          */</a>
<a name="7703"><span class="lineNum">    7703 </span>            :         if (sched_feat(CACHE_HOT_BUDDY) &amp;&amp; env-&gt;dst_rq-&gt;nr_running &amp;&amp;</a>
<a name="7704"><span class="lineNum">    7704 </span>            :                         (&amp;p-&gt;se == cfs_rq_of(&amp;p-&gt;se)-&gt;next ||</a>
<a name="7705"><span class="lineNum">    7705 </span>            :                          &amp;p-&gt;se == cfs_rq_of(&amp;p-&gt;se)-&gt;last))</a>
<a name="7706"><span class="lineNum">    7706 </span>            :                 return 1;</a>
<a name="7707"><span class="lineNum">    7707 </span>            : </a>
<a name="7708"><span class="lineNum">    7708 </span>            :         if (sysctl_sched_migration_cost == -1)</a>
<a name="7709"><span class="lineNum">    7709 </span>            :                 return 1;</a>
<a name="7710"><span class="lineNum">    7710 </span>            : </a>
<a name="7711"><span class="lineNum">    7711 </span>            :         /*</a>
<a name="7712"><span class="lineNum">    7712 </span>            :          * Don't migrate task if the task's cookie does not match</a>
<a name="7713"><span class="lineNum">    7713 </span>            :          * with the destination CPU's core cookie.</a>
<a name="7714"><span class="lineNum">    7714 </span>            :          */</a>
<a name="7715"><span class="lineNum">    7715 </span>            :         if (!sched_core_cookie_match(cpu_rq(env-&gt;dst_cpu), p))</a>
<a name="7716"><span class="lineNum">    7716 </span>            :                 return 1;</a>
<a name="7717"><span class="lineNum">    7717 </span>            : </a>
<a name="7718"><span class="lineNum">    7718 </span>            :         if (sysctl_sched_migration_cost == 0)</a>
<a name="7719"><span class="lineNum">    7719 </span>            :                 return 0;</a>
<a name="7720"><span class="lineNum">    7720 </span>            : </a>
<a name="7721"><span class="lineNum">    7721 </span>            :         delta = rq_clock_task(env-&gt;src_rq) - p-&gt;se.exec_start;</a>
<a name="7722"><span class="lineNum">    7722 </span>            : </a>
<a name="7723"><span class="lineNum">    7723 </span>            :         return delta &lt; (s64)sysctl_sched_migration_cost;</a>
<a name="7724"><span class="lineNum">    7724 </span>            : }</a>
<a name="7725"><span class="lineNum">    7725 </span>            : </a>
<a name="7726"><span class="lineNum">    7726 </span>            : #ifdef CONFIG_NUMA_BALANCING</a>
<a name="7727"><span class="lineNum">    7727 </span>            : /*</a>
<a name="7728"><span class="lineNum">    7728 </span>            :  * Returns 1, if task migration degrades locality</a>
<a name="7729"><span class="lineNum">    7729 </span>            :  * Returns 0, if task migration improves locality i.e migration preferred.</a>
<a name="7730"><span class="lineNum">    7730 </span>            :  * Returns -1, if task migration is not affected by locality.</a>
<a name="7731"><span class="lineNum">    7731 </span>            :  */</a>
<a name="7732"><span class="lineNum">    7732 </span>            : static int migrate_degrades_locality(struct task_struct *p, struct lb_env *env)</a>
<a name="7733"><span class="lineNum">    7733 </span>            : {</a>
<a name="7734"><span class="lineNum">    7734 </span>            :         struct numa_group *numa_group = rcu_dereference(p-&gt;numa_group);</a>
<a name="7735"><span class="lineNum">    7735 </span>            :         unsigned long src_weight, dst_weight;</a>
<a name="7736"><span class="lineNum">    7736 </span>            :         int src_nid, dst_nid, dist;</a>
<a name="7737"><span class="lineNum">    7737 </span>            : </a>
<a name="7738"><span class="lineNum">    7738 </span>            :         if (!static_branch_likely(&amp;sched_numa_balancing))</a>
<a name="7739"><span class="lineNum">    7739 </span>            :                 return -1;</a>
<a name="7740"><span class="lineNum">    7740 </span>            : </a>
<a name="7741"><span class="lineNum">    7741 </span>            :         if (!p-&gt;numa_faults || !(env-&gt;sd-&gt;flags &amp; SD_NUMA))</a>
<a name="7742"><span class="lineNum">    7742 </span>            :                 return -1;</a>
<a name="7743"><span class="lineNum">    7743 </span>            : </a>
<a name="7744"><span class="lineNum">    7744 </span>            :         src_nid = cpu_to_node(env-&gt;src_cpu);</a>
<a name="7745"><span class="lineNum">    7745 </span>            :         dst_nid = cpu_to_node(env-&gt;dst_cpu);</a>
<a name="7746"><span class="lineNum">    7746 </span>            : </a>
<a name="7747"><span class="lineNum">    7747 </span>            :         if (src_nid == dst_nid)</a>
<a name="7748"><span class="lineNum">    7748 </span>            :                 return -1;</a>
<a name="7749"><span class="lineNum">    7749 </span>            : </a>
<a name="7750"><span class="lineNum">    7750 </span>            :         /* Migrating away from the preferred node is always bad. */</a>
<a name="7751"><span class="lineNum">    7751 </span>            :         if (src_nid == p-&gt;numa_preferred_nid) {</a>
<a name="7752"><span class="lineNum">    7752 </span>            :                 if (env-&gt;src_rq-&gt;nr_running &gt; env-&gt;src_rq-&gt;nr_preferred_running)</a>
<a name="7753"><span class="lineNum">    7753 </span>            :                         return 1;</a>
<a name="7754"><span class="lineNum">    7754 </span>            :                 else</a>
<a name="7755"><span class="lineNum">    7755 </span>            :                         return -1;</a>
<a name="7756"><span class="lineNum">    7756 </span>            :         }</a>
<a name="7757"><span class="lineNum">    7757 </span>            : </a>
<a name="7758"><span class="lineNum">    7758 </span>            :         /* Encourage migration to the preferred node. */</a>
<a name="7759"><span class="lineNum">    7759 </span>            :         if (dst_nid == p-&gt;numa_preferred_nid)</a>
<a name="7760"><span class="lineNum">    7760 </span>            :                 return 0;</a>
<a name="7761"><span class="lineNum">    7761 </span>            : </a>
<a name="7762"><span class="lineNum">    7762 </span>            :         /* Leaving a core idle is often worse than degrading locality. */</a>
<a name="7763"><span class="lineNum">    7763 </span>            :         if (env-&gt;idle == CPU_IDLE)</a>
<a name="7764"><span class="lineNum">    7764 </span>            :                 return -1;</a>
<a name="7765"><span class="lineNum">    7765 </span>            : </a>
<a name="7766"><span class="lineNum">    7766 </span>            :         dist = node_distance(src_nid, dst_nid);</a>
<a name="7767"><span class="lineNum">    7767 </span>            :         if (numa_group) {</a>
<a name="7768"><span class="lineNum">    7768 </span>            :                 src_weight = group_weight(p, src_nid, dist);</a>
<a name="7769"><span class="lineNum">    7769 </span>            :                 dst_weight = group_weight(p, dst_nid, dist);</a>
<a name="7770"><span class="lineNum">    7770 </span>            :         } else {</a>
<a name="7771"><span class="lineNum">    7771 </span>            :                 src_weight = task_weight(p, src_nid, dist);</a>
<a name="7772"><span class="lineNum">    7772 </span>            :                 dst_weight = task_weight(p, dst_nid, dist);</a>
<a name="7773"><span class="lineNum">    7773 </span>            :         }</a>
<a name="7774"><span class="lineNum">    7774 </span>            : </a>
<a name="7775"><span class="lineNum">    7775 </span>            :         return dst_weight &lt; src_weight;</a>
<a name="7776"><span class="lineNum">    7776 </span>            : }</a>
<a name="7777"><span class="lineNum">    7777 </span>            : </a>
<a name="7778"><span class="lineNum">    7778 </span>            : #else</a>
<a name="7779"><span class="lineNum">    7779 </span>            : static inline int migrate_degrades_locality(struct task_struct *p,</a>
<a name="7780"><span class="lineNum">    7780 </span>            :                                              struct lb_env *env)</a>
<a name="7781"><span class="lineNum">    7781 </span>            : {</a>
<a name="7782"><span class="lineNum">    7782 </span>            :         return -1;</a>
<a name="7783"><span class="lineNum">    7783 </span>            : }</a>
<a name="7784"><span class="lineNum">    7784 </span>            : #endif</a>
<a name="7785"><span class="lineNum">    7785 </span>            : </a>
<a name="7786"><span class="lineNum">    7786 </span>            : /*</a>
<a name="7787"><span class="lineNum">    7787 </span>            :  * can_migrate_task - may task p from runqueue rq be migrated to this_cpu?</a>
<a name="7788"><span class="lineNum">    7788 </span>            :  */</a>
<a name="7789"><span class="lineNum">    7789 </span>            : static</a>
<a name="7790"><span class="lineNum">    7790 </span>            : int can_migrate_task(struct task_struct *p, struct lb_env *env)</a>
<a name="7791"><span class="lineNum">    7791 </span>            : {</a>
<a name="7792"><span class="lineNum">    7792 </span>            :         int tsk_cache_hot;</a>
<a name="7793"><span class="lineNum">    7793 </span>            : </a>
<a name="7794"><span class="lineNum">    7794 </span>            :         lockdep_assert_rq_held(env-&gt;src_rq);</a>
<a name="7795"><span class="lineNum">    7795 </span>            : </a>
<a name="7796"><span class="lineNum">    7796 </span>            :         /*</a>
<a name="7797"><span class="lineNum">    7797 </span>            :          * We do not migrate tasks that are:</a>
<a name="7798"><span class="lineNum">    7798 </span>            :          * 1) throttled_lb_pair, or</a>
<a name="7799"><span class="lineNum">    7799 </span>            :          * 2) cannot be migrated to this CPU due to cpus_ptr, or</a>
<a name="7800"><span class="lineNum">    7800 </span>            :          * 3) running (obviously), or</a>
<a name="7801"><span class="lineNum">    7801 </span>            :          * 4) are cache-hot on their current CPU.</a>
<a name="7802"><span class="lineNum">    7802 </span>            :          */</a>
<a name="7803"><span class="lineNum">    7803 </span>            :         if (throttled_lb_pair(task_group(p), env-&gt;src_cpu, env-&gt;dst_cpu))</a>
<a name="7804"><span class="lineNum">    7804 </span>            :                 return 0;</a>
<a name="7805"><span class="lineNum">    7805 </span>            : </a>
<a name="7806"><span class="lineNum">    7806 </span>            :         /* Disregard pcpu kthreads; they are where they need to be. */</a>
<a name="7807"><span class="lineNum">    7807 </span>            :         if (kthread_is_per_cpu(p))</a>
<a name="7808"><span class="lineNum">    7808 </span>            :                 return 0;</a>
<a name="7809"><span class="lineNum">    7809 </span>            : </a>
<a name="7810"><span class="lineNum">    7810 </span>            :         if (!cpumask_test_cpu(env-&gt;dst_cpu, p-&gt;cpus_ptr)) {</a>
<a name="7811"><span class="lineNum">    7811 </span>            :                 int cpu;</a>
<a name="7812"><span class="lineNum">    7812 </span>            : </a>
<a name="7813"><span class="lineNum">    7813 </span>            :                 schedstat_inc(p-&gt;stats.nr_failed_migrations_affine);</a>
<a name="7814"><span class="lineNum">    7814 </span>            : </a>
<a name="7815"><span class="lineNum">    7815 </span>            :                 env-&gt;flags |= LBF_SOME_PINNED;</a>
<a name="7816"><span class="lineNum">    7816 </span>            : </a>
<a name="7817"><span class="lineNum">    7817 </span>            :                 /*</a>
<a name="7818"><span class="lineNum">    7818 </span>            :                  * Remember if this task can be migrated to any other CPU in</a>
<a name="7819"><span class="lineNum">    7819 </span>            :                  * our sched_group. We may want to revisit it if we couldn't</a>
<a name="7820"><span class="lineNum">    7820 </span>            :                  * meet load balance goals by pulling other tasks on src_cpu.</a>
<a name="7821"><span class="lineNum">    7821 </span>            :                  *</a>
<a name="7822"><span class="lineNum">    7822 </span>            :                  * Avoid computing new_dst_cpu</a>
<a name="7823"><span class="lineNum">    7823 </span>            :                  * - for NEWLY_IDLE</a>
<a name="7824"><span class="lineNum">    7824 </span>            :                  * - if we have already computed one in current iteration</a>
<a name="7825"><span class="lineNum">    7825 </span>            :                  * - if it's an active balance</a>
<a name="7826"><span class="lineNum">    7826 </span>            :                  */</a>
<a name="7827"><span class="lineNum">    7827 </span>            :                 if (env-&gt;idle == CPU_NEWLY_IDLE ||</a>
<a name="7828"><span class="lineNum">    7828 </span>            :                     env-&gt;flags &amp; (LBF_DST_PINNED | LBF_ACTIVE_LB))</a>
<a name="7829"><span class="lineNum">    7829 </span>            :                         return 0;</a>
<a name="7830"><span class="lineNum">    7830 </span>            : </a>
<a name="7831"><span class="lineNum">    7831 </span>            :                 /* Prevent to re-select dst_cpu via env's CPUs: */</a>
<a name="7832"><span class="lineNum">    7832 </span>            :                 for_each_cpu_and(cpu, env-&gt;dst_grpmask, env-&gt;cpus) {</a>
<a name="7833"><span class="lineNum">    7833 </span>            :                         if (cpumask_test_cpu(cpu, p-&gt;cpus_ptr)) {</a>
<a name="7834"><span class="lineNum">    7834 </span>            :                                 env-&gt;flags |= LBF_DST_PINNED;</a>
<a name="7835"><span class="lineNum">    7835 </span>            :                                 env-&gt;new_dst_cpu = cpu;</a>
<a name="7836"><span class="lineNum">    7836 </span>            :                                 break;</a>
<a name="7837"><span class="lineNum">    7837 </span>            :                         }</a>
<a name="7838"><span class="lineNum">    7838 </span>            :                 }</a>
<a name="7839"><span class="lineNum">    7839 </span>            : </a>
<a name="7840"><span class="lineNum">    7840 </span>            :                 return 0;</a>
<a name="7841"><span class="lineNum">    7841 </span>            :         }</a>
<a name="7842"><span class="lineNum">    7842 </span>            : </a>
<a name="7843"><span class="lineNum">    7843 </span>            :         /* Record that we found at least one task that could run on dst_cpu */</a>
<a name="7844"><span class="lineNum">    7844 </span>            :         env-&gt;flags &amp;= ~LBF_ALL_PINNED;</a>
<a name="7845"><span class="lineNum">    7845 </span>            : </a>
<a name="7846"><span class="lineNum">    7846 </span>            :         if (task_running(env-&gt;src_rq, p)) {</a>
<a name="7847"><span class="lineNum">    7847 </span>            :                 schedstat_inc(p-&gt;stats.nr_failed_migrations_running);</a>
<a name="7848"><span class="lineNum">    7848 </span>            :                 return 0;</a>
<a name="7849"><span class="lineNum">    7849 </span>            :         }</a>
<a name="7850"><span class="lineNum">    7850 </span>            : </a>
<a name="7851"><span class="lineNum">    7851 </span>            :         /*</a>
<a name="7852"><span class="lineNum">    7852 </span>            :          * Aggressive migration if:</a>
<a name="7853"><span class="lineNum">    7853 </span>            :          * 1) active balance</a>
<a name="7854"><span class="lineNum">    7854 </span>            :          * 2) destination numa is preferred</a>
<a name="7855"><span class="lineNum">    7855 </span>            :          * 3) task is cache cold, or</a>
<a name="7856"><span class="lineNum">    7856 </span>            :          * 4) too many balance attempts have failed.</a>
<a name="7857"><span class="lineNum">    7857 </span>            :          */</a>
<a name="7858"><span class="lineNum">    7858 </span>            :         if (env-&gt;flags &amp; LBF_ACTIVE_LB)</a>
<a name="7859"><span class="lineNum">    7859 </span>            :                 return 1;</a>
<a name="7860"><span class="lineNum">    7860 </span>            : </a>
<a name="7861"><span class="lineNum">    7861 </span>            :         tsk_cache_hot = migrate_degrades_locality(p, env);</a>
<a name="7862"><span class="lineNum">    7862 </span>            :         if (tsk_cache_hot == -1)</a>
<a name="7863"><span class="lineNum">    7863 </span>            :                 tsk_cache_hot = task_hot(p, env);</a>
<a name="7864"><span class="lineNum">    7864 </span>            : </a>
<a name="7865"><span class="lineNum">    7865 </span>            :         if (tsk_cache_hot &lt;= 0 ||</a>
<a name="7866"><span class="lineNum">    7866 </span>            :             env-&gt;sd-&gt;nr_balance_failed &gt; env-&gt;sd-&gt;cache_nice_tries) {</a>
<a name="7867"><span class="lineNum">    7867 </span>            :                 if (tsk_cache_hot == 1) {</a>
<a name="7868"><span class="lineNum">    7868 </span>            :                         schedstat_inc(env-&gt;sd-&gt;lb_hot_gained[env-&gt;idle]);</a>
<a name="7869"><span class="lineNum">    7869 </span>            :                         schedstat_inc(p-&gt;stats.nr_forced_migrations);</a>
<a name="7870"><span class="lineNum">    7870 </span>            :                 }</a>
<a name="7871"><span class="lineNum">    7871 </span>            :                 return 1;</a>
<a name="7872"><span class="lineNum">    7872 </span>            :         }</a>
<a name="7873"><span class="lineNum">    7873 </span>            : </a>
<a name="7874"><span class="lineNum">    7874 </span>            :         schedstat_inc(p-&gt;stats.nr_failed_migrations_hot);</a>
<a name="7875"><span class="lineNum">    7875 </span>            :         return 0;</a>
<a name="7876"><span class="lineNum">    7876 </span>            : }</a>
<a name="7877"><span class="lineNum">    7877 </span>            : </a>
<a name="7878"><span class="lineNum">    7878 </span>            : /*</a>
<a name="7879"><span class="lineNum">    7879 </span>            :  * detach_task() -- detach the task for the migration specified in env</a>
<a name="7880"><span class="lineNum">    7880 </span>            :  */</a>
<a name="7881"><span class="lineNum">    7881 </span>            : static void detach_task(struct task_struct *p, struct lb_env *env)</a>
<a name="7882"><span class="lineNum">    7882 </span>            : {</a>
<a name="7883"><span class="lineNum">    7883 </span>            :         lockdep_assert_rq_held(env-&gt;src_rq);</a>
<a name="7884"><span class="lineNum">    7884 </span>            : </a>
<a name="7885"><span class="lineNum">    7885 </span>            :         deactivate_task(env-&gt;src_rq, p, DEQUEUE_NOCLOCK);</a>
<a name="7886"><span class="lineNum">    7886 </span>            :         set_task_cpu(p, env-&gt;dst_cpu);</a>
<a name="7887"><span class="lineNum">    7887 </span>            : }</a>
<a name="7888"><span class="lineNum">    7888 </span>            : </a>
<a name="7889"><span class="lineNum">    7889 </span>            : /*</a>
<a name="7890"><span class="lineNum">    7890 </span>            :  * detach_one_task() -- tries to dequeue exactly one task from env-&gt;src_rq, as</a>
<a name="7891"><span class="lineNum">    7891 </span>            :  * part of active balancing operations within &quot;domain&quot;.</a>
<a name="7892"><span class="lineNum">    7892 </span>            :  *</a>
<a name="7893"><span class="lineNum">    7893 </span>            :  * Returns a task if successful and NULL otherwise.</a>
<a name="7894"><span class="lineNum">    7894 </span>            :  */</a>
<a name="7895"><span class="lineNum">    7895 </span>            : static struct task_struct *detach_one_task(struct lb_env *env)</a>
<a name="7896"><span class="lineNum">    7896 </span>            : {</a>
<a name="7897"><span class="lineNum">    7897 </span>            :         struct task_struct *p;</a>
<a name="7898"><span class="lineNum">    7898 </span>            : </a>
<a name="7899"><span class="lineNum">    7899 </span>            :         lockdep_assert_rq_held(env-&gt;src_rq);</a>
<a name="7900"><span class="lineNum">    7900 </span>            : </a>
<a name="7901"><span class="lineNum">    7901 </span>            :         list_for_each_entry_reverse(p,</a>
<a name="7902"><span class="lineNum">    7902 </span>            :                         &amp;env-&gt;src_rq-&gt;cfs_tasks, se.group_node) {</a>
<a name="7903"><span class="lineNum">    7903 </span>            :                 if (!can_migrate_task(p, env))</a>
<a name="7904"><span class="lineNum">    7904 </span>            :                         continue;</a>
<a name="7905"><span class="lineNum">    7905 </span>            : </a>
<a name="7906"><span class="lineNum">    7906 </span>            :                 detach_task(p, env);</a>
<a name="7907"><span class="lineNum">    7907 </span>            : </a>
<a name="7908"><span class="lineNum">    7908 </span>            :                 /*</a>
<a name="7909"><span class="lineNum">    7909 </span>            :                  * Right now, this is only the second place where</a>
<a name="7910"><span class="lineNum">    7910 </span>            :                  * lb_gained[env-&gt;idle] is updated (other is detach_tasks)</a>
<a name="7911"><span class="lineNum">    7911 </span>            :                  * so we can safely collect stats here rather than</a>
<a name="7912"><span class="lineNum">    7912 </span>            :                  * inside detach_tasks().</a>
<a name="7913"><span class="lineNum">    7913 </span>            :                  */</a>
<a name="7914"><span class="lineNum">    7914 </span>            :                 schedstat_inc(env-&gt;sd-&gt;lb_gained[env-&gt;idle]);</a>
<a name="7915"><span class="lineNum">    7915 </span>            :                 return p;</a>
<a name="7916"><span class="lineNum">    7916 </span>            :         }</a>
<a name="7917"><span class="lineNum">    7917 </span>            :         return NULL;</a>
<a name="7918"><span class="lineNum">    7918 </span>            : }</a>
<a name="7919"><span class="lineNum">    7919 </span>            : </a>
<a name="7920"><span class="lineNum">    7920 </span>            : static const unsigned int sched_nr_migrate_break = 32;</a>
<a name="7921"><span class="lineNum">    7921 </span>            : </a>
<a name="7922"><span class="lineNum">    7922 </span>            : /*</a>
<a name="7923"><span class="lineNum">    7923 </span>            :  * detach_tasks() -- tries to detach up to imbalance load/util/tasks from</a>
<a name="7924"><span class="lineNum">    7924 </span>            :  * busiest_rq, as part of a balancing operation within domain &quot;sd&quot;.</a>
<a name="7925"><span class="lineNum">    7925 </span>            :  *</a>
<a name="7926"><span class="lineNum">    7926 </span>            :  * Returns number of detached tasks if successful and 0 otherwise.</a>
<a name="7927"><span class="lineNum">    7927 </span>            :  */</a>
<a name="7928"><span class="lineNum">    7928 </span>            : static int detach_tasks(struct lb_env *env)</a>
<a name="7929"><span class="lineNum">    7929 </span>            : {</a>
<a name="7930"><span class="lineNum">    7930 </span>            :         struct list_head *tasks = &amp;env-&gt;src_rq-&gt;cfs_tasks;</a>
<a name="7931"><span class="lineNum">    7931 </span>            :         unsigned long util, load;</a>
<a name="7932"><span class="lineNum">    7932 </span>            :         struct task_struct *p;</a>
<a name="7933"><span class="lineNum">    7933 </span>            :         int detached = 0;</a>
<a name="7934"><span class="lineNum">    7934 </span>            : </a>
<a name="7935"><span class="lineNum">    7935 </span>            :         lockdep_assert_rq_held(env-&gt;src_rq);</a>
<a name="7936"><span class="lineNum">    7936 </span>            : </a>
<a name="7937"><span class="lineNum">    7937 </span>            :         /*</a>
<a name="7938"><span class="lineNum">    7938 </span>            :          * Source run queue has been emptied by another CPU, clear</a>
<a name="7939"><span class="lineNum">    7939 </span>            :          * LBF_ALL_PINNED flag as we will not test any task.</a>
<a name="7940"><span class="lineNum">    7940 </span>            :          */</a>
<a name="7941"><span class="lineNum">    7941 </span>            :         if (env-&gt;src_rq-&gt;nr_running &lt;= 1) {</a>
<a name="7942"><span class="lineNum">    7942 </span>            :                 env-&gt;flags &amp;= ~LBF_ALL_PINNED;</a>
<a name="7943"><span class="lineNum">    7943 </span>            :                 return 0;</a>
<a name="7944"><span class="lineNum">    7944 </span>            :         }</a>
<a name="7945"><span class="lineNum">    7945 </span>            : </a>
<a name="7946"><span class="lineNum">    7946 </span>            :         if (env-&gt;imbalance &lt;= 0)</a>
<a name="7947"><span class="lineNum">    7947 </span>            :                 return 0;</a>
<a name="7948"><span class="lineNum">    7948 </span>            : </a>
<a name="7949"><span class="lineNum">    7949 </span>            :         while (!list_empty(tasks)) {</a>
<a name="7950"><span class="lineNum">    7950 </span>            :                 /*</a>
<a name="7951"><span class="lineNum">    7951 </span>            :                  * We don't want to steal all, otherwise we may be treated likewise,</a>
<a name="7952"><span class="lineNum">    7952 </span>            :                  * which could at worst lead to a livelock crash.</a>
<a name="7953"><span class="lineNum">    7953 </span>            :                  */</a>
<a name="7954"><span class="lineNum">    7954 </span>            :                 if (env-&gt;idle != CPU_NOT_IDLE &amp;&amp; env-&gt;src_rq-&gt;nr_running &lt;= 1)</a>
<a name="7955"><span class="lineNum">    7955 </span>            :                         break;</a>
<a name="7956"><span class="lineNum">    7956 </span>            : </a>
<a name="7957"><span class="lineNum">    7957 </span>            :                 p = list_last_entry(tasks, struct task_struct, se.group_node);</a>
<a name="7958"><span class="lineNum">    7958 </span>            : </a>
<a name="7959"><span class="lineNum">    7959 </span>            :                 env-&gt;loop++;</a>
<a name="7960"><span class="lineNum">    7960 </span>            :                 /* We've more or less seen every task there is, call it quits */</a>
<a name="7961"><span class="lineNum">    7961 </span>            :                 if (env-&gt;loop &gt; env-&gt;loop_max)</a>
<a name="7962"><span class="lineNum">    7962 </span>            :                         break;</a>
<a name="7963"><span class="lineNum">    7963 </span>            : </a>
<a name="7964"><span class="lineNum">    7964 </span>            :                 /* take a breather every nr_migrate tasks */</a>
<a name="7965"><span class="lineNum">    7965 </span>            :                 if (env-&gt;loop &gt; env-&gt;loop_break) {</a>
<a name="7966"><span class="lineNum">    7966 </span>            :                         env-&gt;loop_break += sched_nr_migrate_break;</a>
<a name="7967"><span class="lineNum">    7967 </span>            :                         env-&gt;flags |= LBF_NEED_BREAK;</a>
<a name="7968"><span class="lineNum">    7968 </span>            :                         break;</a>
<a name="7969"><span class="lineNum">    7969 </span>            :                 }</a>
<a name="7970"><span class="lineNum">    7970 </span>            : </a>
<a name="7971"><span class="lineNum">    7971 </span>            :                 if (!can_migrate_task(p, env))</a>
<a name="7972"><span class="lineNum">    7972 </span>            :                         goto next;</a>
<a name="7973"><span class="lineNum">    7973 </span>            : </a>
<a name="7974"><span class="lineNum">    7974 </span>            :                 switch (env-&gt;migration_type) {</a>
<a name="7975"><span class="lineNum">    7975 </span>            :                 case migrate_load:</a>
<a name="7976"><span class="lineNum">    7976 </span>            :                         /*</a>
<a name="7977"><span class="lineNum">    7977 </span>            :                          * Depending of the number of CPUs and tasks and the</a>
<a name="7978"><span class="lineNum">    7978 </span>            :                          * cgroup hierarchy, task_h_load() can return a null</a>
<a name="7979"><span class="lineNum">    7979 </span>            :                          * value. Make sure that env-&gt;imbalance decreases</a>
<a name="7980"><span class="lineNum">    7980 </span>            :                          * otherwise detach_tasks() will stop only after</a>
<a name="7981"><span class="lineNum">    7981 </span>            :                          * detaching up to loop_max tasks.</a>
<a name="7982"><span class="lineNum">    7982 </span>            :                          */</a>
<a name="7983"><span class="lineNum">    7983 </span>            :                         load = max_t(unsigned long, task_h_load(p), 1);</a>
<a name="7984"><span class="lineNum">    7984 </span>            : </a>
<a name="7985"><span class="lineNum">    7985 </span>            :                         if (sched_feat(LB_MIN) &amp;&amp;</a>
<a name="7986"><span class="lineNum">    7986 </span>            :                             load &lt; 16 &amp;&amp; !env-&gt;sd-&gt;nr_balance_failed)</a>
<a name="7987"><span class="lineNum">    7987 </span>            :                                 goto next;</a>
<a name="7988"><span class="lineNum">    7988 </span>            : </a>
<a name="7989"><span class="lineNum">    7989 </span>            :                         /*</a>
<a name="7990"><span class="lineNum">    7990 </span>            :                          * Make sure that we don't migrate too much load.</a>
<a name="7991"><span class="lineNum">    7991 </span>            :                          * Nevertheless, let relax the constraint if</a>
<a name="7992"><span class="lineNum">    7992 </span>            :                          * scheduler fails to find a good waiting task to</a>
<a name="7993"><span class="lineNum">    7993 </span>            :                          * migrate.</a>
<a name="7994"><span class="lineNum">    7994 </span>            :                          */</a>
<a name="7995"><span class="lineNum">    7995 </span>            :                         if (shr_bound(load, env-&gt;sd-&gt;nr_balance_failed) &gt; env-&gt;imbalance)</a>
<a name="7996"><span class="lineNum">    7996 </span>            :                                 goto next;</a>
<a name="7997"><span class="lineNum">    7997 </span>            : </a>
<a name="7998"><span class="lineNum">    7998 </span>            :                         env-&gt;imbalance -= load;</a>
<a name="7999"><span class="lineNum">    7999 </span>            :                         break;</a>
<a name="8000"><span class="lineNum">    8000 </span>            : </a>
<a name="8001"><span class="lineNum">    8001 </span>            :                 case migrate_util:</a>
<a name="8002"><span class="lineNum">    8002 </span>            :                         util = task_util_est(p);</a>
<a name="8003"><span class="lineNum">    8003 </span>            : </a>
<a name="8004"><span class="lineNum">    8004 </span>            :                         if (util &gt; env-&gt;imbalance)</a>
<a name="8005"><span class="lineNum">    8005 </span>            :                                 goto next;</a>
<a name="8006"><span class="lineNum">    8006 </span>            : </a>
<a name="8007"><span class="lineNum">    8007 </span>            :                         env-&gt;imbalance -= util;</a>
<a name="8008"><span class="lineNum">    8008 </span>            :                         break;</a>
<a name="8009"><span class="lineNum">    8009 </span>            : </a>
<a name="8010"><span class="lineNum">    8010 </span>            :                 case migrate_task:</a>
<a name="8011"><span class="lineNum">    8011 </span>            :                         env-&gt;imbalance--;</a>
<a name="8012"><span class="lineNum">    8012 </span>            :                         break;</a>
<a name="8013"><span class="lineNum">    8013 </span>            : </a>
<a name="8014"><span class="lineNum">    8014 </span>            :                 case migrate_misfit:</a>
<a name="8015"><span class="lineNum">    8015 </span>            :                         /* This is not a misfit task */</a>
<a name="8016"><span class="lineNum">    8016 </span>            :                         if (task_fits_capacity(p, capacity_of(env-&gt;src_cpu)))</a>
<a name="8017"><span class="lineNum">    8017 </span>            :                                 goto next;</a>
<a name="8018"><span class="lineNum">    8018 </span>            : </a>
<a name="8019"><span class="lineNum">    8019 </span>            :                         env-&gt;imbalance = 0;</a>
<a name="8020"><span class="lineNum">    8020 </span>            :                         break;</a>
<a name="8021"><span class="lineNum">    8021 </span>            :                 }</a>
<a name="8022"><span class="lineNum">    8022 </span>            : </a>
<a name="8023"><span class="lineNum">    8023 </span>            :                 detach_task(p, env);</a>
<a name="8024"><span class="lineNum">    8024 </span>            :                 list_add(&amp;p-&gt;se.group_node, &amp;env-&gt;tasks);</a>
<a name="8025"><span class="lineNum">    8025 </span>            : </a>
<a name="8026"><span class="lineNum">    8026 </span>            :                 detached++;</a>
<a name="8027"><span class="lineNum">    8027 </span>            : </a>
<a name="8028"><span class="lineNum">    8028 </span>            : #ifdef CONFIG_PREEMPTION</a>
<a name="8029"><span class="lineNum">    8029 </span>            :                 /*</a>
<a name="8030"><span class="lineNum">    8030 </span>            :                  * NEWIDLE balancing is a source of latency, so preemptible</a>
<a name="8031"><span class="lineNum">    8031 </span>            :                  * kernels will stop after the first task is detached to minimize</a>
<a name="8032"><span class="lineNum">    8032 </span>            :                  * the critical section.</a>
<a name="8033"><span class="lineNum">    8033 </span>            :                  */</a>
<a name="8034"><span class="lineNum">    8034 </span>            :                 if (env-&gt;idle == CPU_NEWLY_IDLE)</a>
<a name="8035"><span class="lineNum">    8035 </span>            :                         break;</a>
<a name="8036"><span class="lineNum">    8036 </span>            : #endif</a>
<a name="8037"><span class="lineNum">    8037 </span>            : </a>
<a name="8038"><span class="lineNum">    8038 </span>            :                 /*</a>
<a name="8039"><span class="lineNum">    8039 </span>            :                  * We only want to steal up to the prescribed amount of</a>
<a name="8040"><span class="lineNum">    8040 </span>            :                  * load/util/tasks.</a>
<a name="8041"><span class="lineNum">    8041 </span>            :                  */</a>
<a name="8042"><span class="lineNum">    8042 </span>            :                 if (env-&gt;imbalance &lt;= 0)</a>
<a name="8043"><span class="lineNum">    8043 </span>            :                         break;</a>
<a name="8044"><span class="lineNum">    8044 </span>            : </a>
<a name="8045"><span class="lineNum">    8045 </span>            :                 continue;</a>
<a name="8046"><span class="lineNum">    8046 </span>            : next:</a>
<a name="8047"><span class="lineNum">    8047 </span>            :                 list_move(&amp;p-&gt;se.group_node, tasks);</a>
<a name="8048"><span class="lineNum">    8048 </span>            :         }</a>
<a name="8049"><span class="lineNum">    8049 </span>            : </a>
<a name="8050"><span class="lineNum">    8050 </span>            :         /*</a>
<a name="8051"><span class="lineNum">    8051 </span>            :          * Right now, this is one of only two places we collect this stat</a>
<a name="8052"><span class="lineNum">    8052 </span>            :          * so we can safely collect detach_one_task() stats here rather</a>
<a name="8053"><span class="lineNum">    8053 </span>            :          * than inside detach_one_task().</a>
<a name="8054"><span class="lineNum">    8054 </span>            :          */</a>
<a name="8055"><span class="lineNum">    8055 </span>            :         schedstat_add(env-&gt;sd-&gt;lb_gained[env-&gt;idle], detached);</a>
<a name="8056"><span class="lineNum">    8056 </span>            : </a>
<a name="8057"><span class="lineNum">    8057 </span>            :         return detached;</a>
<a name="8058"><span class="lineNum">    8058 </span>            : }</a>
<a name="8059"><span class="lineNum">    8059 </span>            : </a>
<a name="8060"><span class="lineNum">    8060 </span>            : /*</a>
<a name="8061"><span class="lineNum">    8061 </span>            :  * attach_task() -- attach the task detached by detach_task() to its new rq.</a>
<a name="8062"><span class="lineNum">    8062 </span>            :  */</a>
<a name="8063"><span class="lineNum">    8063 </span>            : static void attach_task(struct rq *rq, struct task_struct *p)</a>
<a name="8064"><span class="lineNum">    8064 </span>            : {</a>
<a name="8065"><span class="lineNum">    8065 </span>            :         lockdep_assert_rq_held(rq);</a>
<a name="8066"><span class="lineNum">    8066 </span>            : </a>
<a name="8067"><span class="lineNum">    8067 </span>            :         BUG_ON(task_rq(p) != rq);</a>
<a name="8068"><span class="lineNum">    8068 </span>            :         activate_task(rq, p, ENQUEUE_NOCLOCK);</a>
<a name="8069"><span class="lineNum">    8069 </span>            :         check_preempt_curr(rq, p, 0);</a>
<a name="8070"><span class="lineNum">    8070 </span>            : }</a>
<a name="8071"><span class="lineNum">    8071 </span>            : </a>
<a name="8072"><span class="lineNum">    8072 </span>            : /*</a>
<a name="8073"><span class="lineNum">    8073 </span>            :  * attach_one_task() -- attaches the task returned from detach_one_task() to</a>
<a name="8074"><span class="lineNum">    8074 </span>            :  * its new rq.</a>
<a name="8075"><span class="lineNum">    8075 </span>            :  */</a>
<a name="8076"><span class="lineNum">    8076 </span>            : static void attach_one_task(struct rq *rq, struct task_struct *p)</a>
<a name="8077"><span class="lineNum">    8077 </span>            : {</a>
<a name="8078"><span class="lineNum">    8078 </span>            :         struct rq_flags rf;</a>
<a name="8079"><span class="lineNum">    8079 </span>            : </a>
<a name="8080"><span class="lineNum">    8080 </span>            :         rq_lock(rq, &amp;rf);</a>
<a name="8081"><span class="lineNum">    8081 </span>            :         update_rq_clock(rq);</a>
<a name="8082"><span class="lineNum">    8082 </span>            :         attach_task(rq, p);</a>
<a name="8083"><span class="lineNum">    8083 </span>            :         rq_unlock(rq, &amp;rf);</a>
<a name="8084"><span class="lineNum">    8084 </span>            : }</a>
<a name="8085"><span class="lineNum">    8085 </span>            : </a>
<a name="8086"><span class="lineNum">    8086 </span>            : /*</a>
<a name="8087"><span class="lineNum">    8087 </span>            :  * attach_tasks() -- attaches all tasks detached by detach_tasks() to their</a>
<a name="8088"><span class="lineNum">    8088 </span>            :  * new rq.</a>
<a name="8089"><span class="lineNum">    8089 </span>            :  */</a>
<a name="8090"><span class="lineNum">    8090 </span>            : static void attach_tasks(struct lb_env *env)</a>
<a name="8091"><span class="lineNum">    8091 </span>            : {</a>
<a name="8092"><span class="lineNum">    8092 </span>            :         struct list_head *tasks = &amp;env-&gt;tasks;</a>
<a name="8093"><span class="lineNum">    8093 </span>            :         struct task_struct *p;</a>
<a name="8094"><span class="lineNum">    8094 </span>            :         struct rq_flags rf;</a>
<a name="8095"><span class="lineNum">    8095 </span>            : </a>
<a name="8096"><span class="lineNum">    8096 </span>            :         rq_lock(env-&gt;dst_rq, &amp;rf);</a>
<a name="8097"><span class="lineNum">    8097 </span>            :         update_rq_clock(env-&gt;dst_rq);</a>
<a name="8098"><span class="lineNum">    8098 </span>            : </a>
<a name="8099"><span class="lineNum">    8099 </span>            :         while (!list_empty(tasks)) {</a>
<a name="8100"><span class="lineNum">    8100 </span>            :                 p = list_first_entry(tasks, struct task_struct, se.group_node);</a>
<a name="8101"><span class="lineNum">    8101 </span>            :                 list_del_init(&amp;p-&gt;se.group_node);</a>
<a name="8102"><span class="lineNum">    8102 </span>            : </a>
<a name="8103"><span class="lineNum">    8103 </span>            :                 attach_task(env-&gt;dst_rq, p);</a>
<a name="8104"><span class="lineNum">    8104 </span>            :         }</a>
<a name="8105"><span class="lineNum">    8105 </span>            : </a>
<a name="8106"><span class="lineNum">    8106 </span>            :         rq_unlock(env-&gt;dst_rq, &amp;rf);</a>
<a name="8107"><span class="lineNum">    8107 </span>            : }</a>
<a name="8108"><span class="lineNum">    8108 </span>            : </a>
<a name="8109"><span class="lineNum">    8109 </span>            : #ifdef CONFIG_NO_HZ_COMMON</a>
<a name="8110"><span class="lineNum">    8110 </span>            : static inline bool cfs_rq_has_blocked(struct cfs_rq *cfs_rq)</a>
<a name="8111"><span class="lineNum">    8111 </span>            : {</a>
<a name="8112"><span class="lineNum">    8112 </span>            :         if (cfs_rq-&gt;avg.load_avg)</a>
<a name="8113"><span class="lineNum">    8113 </span>            :                 return true;</a>
<a name="8114"><span class="lineNum">    8114 </span>            : </a>
<a name="8115"><span class="lineNum">    8115 </span>            :         if (cfs_rq-&gt;avg.util_avg)</a>
<a name="8116"><span class="lineNum">    8116 </span>            :                 return true;</a>
<a name="8117"><span class="lineNum">    8117 </span>            : </a>
<a name="8118"><span class="lineNum">    8118 </span>            :         return false;</a>
<a name="8119"><span class="lineNum">    8119 </span>            : }</a>
<a name="8120"><span class="lineNum">    8120 </span>            : </a>
<a name="8121"><span class="lineNum">    8121 </span>            : static inline bool others_have_blocked(struct rq *rq)</a>
<a name="8122"><span class="lineNum">    8122 </span>            : {</a>
<a name="8123"><span class="lineNum">    8123 </span>            :         if (READ_ONCE(rq-&gt;avg_rt.util_avg))</a>
<a name="8124"><span class="lineNum">    8124 </span>            :                 return true;</a>
<a name="8125"><span class="lineNum">    8125 </span>            : </a>
<a name="8126"><span class="lineNum">    8126 </span>            :         if (READ_ONCE(rq-&gt;avg_dl.util_avg))</a>
<a name="8127"><span class="lineNum">    8127 </span>            :                 return true;</a>
<a name="8128"><span class="lineNum">    8128 </span>            : </a>
<a name="8129"><span class="lineNum">    8129 </span>            :         if (thermal_load_avg(rq))</a>
<a name="8130"><span class="lineNum">    8130 </span>            :                 return true;</a>
<a name="8131"><span class="lineNum">    8131 </span>            : </a>
<a name="8132"><span class="lineNum">    8132 </span>            : #ifdef CONFIG_HAVE_SCHED_AVG_IRQ</a>
<a name="8133"><span class="lineNum">    8133 </span>            :         if (READ_ONCE(rq-&gt;avg_irq.util_avg))</a>
<a name="8134"><span class="lineNum">    8134 </span>            :                 return true;</a>
<a name="8135"><span class="lineNum">    8135 </span>            : #endif</a>
<a name="8136"><span class="lineNum">    8136 </span>            : </a>
<a name="8137"><span class="lineNum">    8137 </span>            :         return false;</a>
<a name="8138"><span class="lineNum">    8138 </span>            : }</a>
<a name="8139"><span class="lineNum">    8139 </span>            : </a>
<a name="8140"><span class="lineNum">    8140 </span>            : static inline void update_blocked_load_tick(struct rq *rq)</a>
<a name="8141"><span class="lineNum">    8141 </span>            : {</a>
<a name="8142"><span class="lineNum">    8142 </span>            :         WRITE_ONCE(rq-&gt;last_blocked_load_update_tick, jiffies);</a>
<a name="8143"><span class="lineNum">    8143 </span>            : }</a>
<a name="8144"><span class="lineNum">    8144 </span>            : </a>
<a name="8145"><span class="lineNum">    8145 </span>            : static inline void update_blocked_load_status(struct rq *rq, bool has_blocked)</a>
<a name="8146"><span class="lineNum">    8146 </span>            : {</a>
<a name="8147"><span class="lineNum">    8147 </span>            :         if (!has_blocked)</a>
<a name="8148"><span class="lineNum">    8148 </span>            :                 rq-&gt;has_blocked_load = 0;</a>
<a name="8149"><span class="lineNum">    8149 </span>            : }</a>
<a name="8150"><span class="lineNum">    8150 </span>            : #else</a>
<a name="8151"><span class="lineNum">    8151 </span>            : static inline bool cfs_rq_has_blocked(struct cfs_rq *cfs_rq) { return false; }</a>
<a name="8152"><span class="lineNum">    8152 </span>            : static inline bool others_have_blocked(struct rq *rq) { return false; }</a>
<a name="8153"><span class="lineNum">    8153 </span>            : static inline void update_blocked_load_tick(struct rq *rq) {}</a>
<a name="8154"><span class="lineNum">    8154 </span>            : static inline void update_blocked_load_status(struct rq *rq, bool has_blocked) {}</a>
<a name="8155"><span class="lineNum">    8155 </span>            : #endif</a>
<a name="8156"><span class="lineNum">    8156 </span>            : </a>
<a name="8157"><span class="lineNum">    8157 </span>            : static bool __update_blocked_others(struct rq *rq, bool *done)</a>
<a name="8158"><span class="lineNum">    8158 </span>            : {</a>
<a name="8159"><span class="lineNum">    8159 </span>            :         const struct sched_class *curr_class;</a>
<a name="8160"><span class="lineNum">    8160 </span>            :         u64 now = rq_clock_pelt(rq);</a>
<a name="8161"><span class="lineNum">    8161 </span>            :         unsigned long thermal_pressure;</a>
<a name="8162"><span class="lineNum">    8162 </span>            :         bool decayed;</a>
<a name="8163"><span class="lineNum">    8163 </span>            : </a>
<a name="8164"><span class="lineNum">    8164 </span>            :         /*</a>
<a name="8165"><span class="lineNum">    8165 </span>            :          * update_load_avg() can call cpufreq_update_util(). Make sure that RT,</a>
<a name="8166"><span class="lineNum">    8166 </span>            :          * DL and IRQ signals have been updated before updating CFS.</a>
<a name="8167"><span class="lineNum">    8167 </span>            :          */</a>
<a name="8168"><span class="lineNum">    8168 </span>            :         curr_class = rq-&gt;curr-&gt;sched_class;</a>
<a name="8169"><span class="lineNum">    8169 </span>            : </a>
<a name="8170"><span class="lineNum">    8170 </span>            :         thermal_pressure = arch_scale_thermal_pressure(cpu_of(rq));</a>
<a name="8171"><span class="lineNum">    8171 </span>            : </a>
<a name="8172"><span class="lineNum">    8172 </span>            :         decayed = update_rt_rq_load_avg(now, rq, curr_class == &amp;rt_sched_class) |</a>
<a name="8173"><span class="lineNum">    8173 </span>            :                   update_dl_rq_load_avg(now, rq, curr_class == &amp;dl_sched_class) |</a>
<a name="8174"><span class="lineNum">    8174 </span>            :                   update_thermal_load_avg(rq_clock_thermal(rq), rq, thermal_pressure) |</a>
<a name="8175"><span class="lineNum">    8175 </span>            :                   update_irq_load_avg(rq, 0);</a>
<a name="8176"><span class="lineNum">    8176 </span>            : </a>
<a name="8177"><span class="lineNum">    8177 </span>            :         if (others_have_blocked(rq))</a>
<a name="8178"><span class="lineNum">    8178 </span>            :                 *done = false;</a>
<a name="8179"><span class="lineNum">    8179 </span>            : </a>
<a name="8180"><span class="lineNum">    8180 </span>            :         return decayed;</a>
<a name="8181"><span class="lineNum">    8181 </span>            : }</a>
<a name="8182"><span class="lineNum">    8182 </span>            : </a>
<a name="8183"><span class="lineNum">    8183 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="8184"><span class="lineNum">    8184 </span>            : </a>
<a name="8185"><span class="lineNum">    8185 </span>            : static bool __update_blocked_fair(struct rq *rq, bool *done)</a>
<a name="8186"><span class="lineNum">    8186 </span>            : {</a>
<a name="8187"><span class="lineNum">    8187 </span>            :         struct cfs_rq *cfs_rq, *pos;</a>
<a name="8188"><span class="lineNum">    8188 </span>            :         bool decayed = false;</a>
<a name="8189"><span class="lineNum">    8189 </span>            :         int cpu = cpu_of(rq);</a>
<a name="8190"><span class="lineNum">    8190 </span>            : </a>
<a name="8191"><span class="lineNum">    8191 </span>            :         /*</a>
<a name="8192"><span class="lineNum">    8192 </span>            :          * Iterates the task_group tree in a bottom up fashion, see</a>
<a name="8193"><span class="lineNum">    8193 </span>            :          * list_add_leaf_cfs_rq() for details.</a>
<a name="8194"><span class="lineNum">    8194 </span>            :          */</a>
<a name="8195"><span class="lineNum">    8195 </span>            :         for_each_leaf_cfs_rq_safe(rq, cfs_rq, pos) {</a>
<a name="8196"><span class="lineNum">    8196 </span>            :                 struct sched_entity *se;</a>
<a name="8197"><span class="lineNum">    8197 </span>            : </a>
<a name="8198"><span class="lineNum">    8198 </span>            :                 if (update_cfs_rq_load_avg(cfs_rq_clock_pelt(cfs_rq), cfs_rq)) {</a>
<a name="8199"><span class="lineNum">    8199 </span>            :                         update_tg_load_avg(cfs_rq);</a>
<a name="8200"><span class="lineNum">    8200 </span>            : </a>
<a name="8201"><span class="lineNum">    8201 </span>            :                         if (cfs_rq == &amp;rq-&gt;cfs)</a>
<a name="8202"><span class="lineNum">    8202 </span>            :                                 decayed = true;</a>
<a name="8203"><span class="lineNum">    8203 </span>            :                 }</a>
<a name="8204"><span class="lineNum">    8204 </span>            : </a>
<a name="8205"><span class="lineNum">    8205 </span>            :                 /* Propagate pending load changes to the parent, if any: */</a>
<a name="8206"><span class="lineNum">    8206 </span>            :                 se = cfs_rq-&gt;tg-&gt;se[cpu];</a>
<a name="8207"><span class="lineNum">    8207 </span>            :                 if (se &amp;&amp; !skip_blocked_update(se))</a>
<a name="8208"><span class="lineNum">    8208 </span>            :                         update_load_avg(cfs_rq_of(se), se, UPDATE_TG);</a>
<a name="8209"><span class="lineNum">    8209 </span>            : </a>
<a name="8210"><span class="lineNum">    8210 </span>            :                 /*</a>
<a name="8211"><span class="lineNum">    8211 </span>            :                  * There can be a lot of idle CPU cgroups.  Don't let fully</a>
<a name="8212"><span class="lineNum">    8212 </span>            :                  * decayed cfs_rqs linger on the list.</a>
<a name="8213"><span class="lineNum">    8213 </span>            :                  */</a>
<a name="8214"><span class="lineNum">    8214 </span>            :                 if (cfs_rq_is_decayed(cfs_rq))</a>
<a name="8215"><span class="lineNum">    8215 </span>            :                         list_del_leaf_cfs_rq(cfs_rq);</a>
<a name="8216"><span class="lineNum">    8216 </span>            : </a>
<a name="8217"><span class="lineNum">    8217 </span>            :                 /* Don't need periodic decay once load/util_avg are null */</a>
<a name="8218"><span class="lineNum">    8218 </span>            :                 if (cfs_rq_has_blocked(cfs_rq))</a>
<a name="8219"><span class="lineNum">    8219 </span>            :                         *done = false;</a>
<a name="8220"><span class="lineNum">    8220 </span>            :         }</a>
<a name="8221"><span class="lineNum">    8221 </span>            : </a>
<a name="8222"><span class="lineNum">    8222 </span>            :         return decayed;</a>
<a name="8223"><span class="lineNum">    8223 </span>            : }</a>
<a name="8224"><span class="lineNum">    8224 </span>            : </a>
<a name="8225"><span class="lineNum">    8225 </span>            : /*</a>
<a name="8226"><span class="lineNum">    8226 </span>            :  * Compute the hierarchical load factor for cfs_rq and all its ascendants.</a>
<a name="8227"><span class="lineNum">    8227 </span>            :  * This needs to be done in a top-down fashion because the load of a child</a>
<a name="8228"><span class="lineNum">    8228 </span>            :  * group is a fraction of its parents load.</a>
<a name="8229"><span class="lineNum">    8229 </span>            :  */</a>
<a name="8230"><span class="lineNum">    8230 </span>            : static void update_cfs_rq_h_load(struct cfs_rq *cfs_rq)</a>
<a name="8231"><span class="lineNum">    8231 </span>            : {</a>
<a name="8232"><span class="lineNum">    8232 </span>            :         struct rq *rq = rq_of(cfs_rq);</a>
<a name="8233"><span class="lineNum">    8233 </span>            :         struct sched_entity *se = cfs_rq-&gt;tg-&gt;se[cpu_of(rq)];</a>
<a name="8234"><span class="lineNum">    8234 </span>            :         unsigned long now = jiffies;</a>
<a name="8235"><span class="lineNum">    8235 </span>            :         unsigned long load;</a>
<a name="8236"><span class="lineNum">    8236 </span>            : </a>
<a name="8237"><span class="lineNum">    8237 </span>            :         if (cfs_rq-&gt;last_h_load_update == now)</a>
<a name="8238"><span class="lineNum">    8238 </span>            :                 return;</a>
<a name="8239"><span class="lineNum">    8239 </span>            : </a>
<a name="8240"><span class="lineNum">    8240 </span>            :         WRITE_ONCE(cfs_rq-&gt;h_load_next, NULL);</a>
<a name="8241"><span class="lineNum">    8241 </span>            :         for_each_sched_entity(se) {</a>
<a name="8242"><span class="lineNum">    8242 </span>            :                 cfs_rq = cfs_rq_of(se);</a>
<a name="8243"><span class="lineNum">    8243 </span>            :                 WRITE_ONCE(cfs_rq-&gt;h_load_next, se);</a>
<a name="8244"><span class="lineNum">    8244 </span>            :                 if (cfs_rq-&gt;last_h_load_update == now)</a>
<a name="8245"><span class="lineNum">    8245 </span>            :                         break;</a>
<a name="8246"><span class="lineNum">    8246 </span>            :         }</a>
<a name="8247"><span class="lineNum">    8247 </span>            : </a>
<a name="8248"><span class="lineNum">    8248 </span>            :         if (!se) {</a>
<a name="8249"><span class="lineNum">    8249 </span>            :                 cfs_rq-&gt;h_load = cfs_rq_load_avg(cfs_rq);</a>
<a name="8250"><span class="lineNum">    8250 </span>            :                 cfs_rq-&gt;last_h_load_update = now;</a>
<a name="8251"><span class="lineNum">    8251 </span>            :         }</a>
<a name="8252"><span class="lineNum">    8252 </span>            : </a>
<a name="8253"><span class="lineNum">    8253 </span>            :         while ((se = READ_ONCE(cfs_rq-&gt;h_load_next)) != NULL) {</a>
<a name="8254"><span class="lineNum">    8254 </span>            :                 load = cfs_rq-&gt;h_load;</a>
<a name="8255"><span class="lineNum">    8255 </span>            :                 load = div64_ul(load * se-&gt;avg.load_avg,</a>
<a name="8256"><span class="lineNum">    8256 </span>            :                         cfs_rq_load_avg(cfs_rq) + 1);</a>
<a name="8257"><span class="lineNum">    8257 </span>            :                 cfs_rq = group_cfs_rq(se);</a>
<a name="8258"><span class="lineNum">    8258 </span>            :                 cfs_rq-&gt;h_load = load;</a>
<a name="8259"><span class="lineNum">    8259 </span>            :                 cfs_rq-&gt;last_h_load_update = now;</a>
<a name="8260"><span class="lineNum">    8260 </span>            :         }</a>
<a name="8261"><span class="lineNum">    8261 </span>            : }</a>
<a name="8262"><span class="lineNum">    8262 </span>            : </a>
<a name="8263"><span class="lineNum">    8263 </span>            : static unsigned long task_h_load(struct task_struct *p)</a>
<a name="8264"><span class="lineNum">    8264 </span>            : {</a>
<a name="8265"><span class="lineNum">    8265 </span>            :         struct cfs_rq *cfs_rq = task_cfs_rq(p);</a>
<a name="8266"><span class="lineNum">    8266 </span>            : </a>
<a name="8267"><span class="lineNum">    8267 </span>            :         update_cfs_rq_h_load(cfs_rq);</a>
<a name="8268"><span class="lineNum">    8268 </span>            :         return div64_ul(p-&gt;se.avg.load_avg * cfs_rq-&gt;h_load,</a>
<a name="8269"><span class="lineNum">    8269 </span>            :                         cfs_rq_load_avg(cfs_rq) + 1);</a>
<a name="8270"><span class="lineNum">    8270 </span>            : }</a>
<a name="8271"><span class="lineNum">    8271 </span>            : #else</a>
<a name="8272"><span class="lineNum">    8272 </span>            : static bool __update_blocked_fair(struct rq *rq, bool *done)</a>
<a name="8273"><span class="lineNum">    8273 </span>            : {</a>
<a name="8274"><span class="lineNum">    8274 </span>            :         struct cfs_rq *cfs_rq = &amp;rq-&gt;cfs;</a>
<a name="8275"><span class="lineNum">    8275 </span>            :         bool decayed;</a>
<a name="8276"><span class="lineNum">    8276 </span>            : </a>
<a name="8277"><span class="lineNum">    8277 </span>            :         decayed = update_cfs_rq_load_avg(cfs_rq_clock_pelt(cfs_rq), cfs_rq);</a>
<a name="8278"><span class="lineNum">    8278 </span>            :         if (cfs_rq_has_blocked(cfs_rq))</a>
<a name="8279"><span class="lineNum">    8279 </span>            :                 *done = false;</a>
<a name="8280"><span class="lineNum">    8280 </span>            : </a>
<a name="8281"><span class="lineNum">    8281 </span>            :         return decayed;</a>
<a name="8282"><span class="lineNum">    8282 </span>            : }</a>
<a name="8283"><span class="lineNum">    8283 </span>            : </a>
<a name="8284"><span class="lineNum">    8284 </span>            : static unsigned long task_h_load(struct task_struct *p)</a>
<a name="8285"><span class="lineNum">    8285 </span>            : {</a>
<a name="8286"><span class="lineNum">    8286 </span>            :         return p-&gt;se.avg.load_avg;</a>
<a name="8287"><span class="lineNum">    8287 </span>            : }</a>
<a name="8288"><span class="lineNum">    8288 </span>            : #endif</a>
<a name="8289"><span class="lineNum">    8289 </span>            : </a>
<a name="8290"><span class="lineNum">    8290 </span>            : static void update_blocked_averages(int cpu)</a>
<a name="8291"><span class="lineNum">    8291 </span>            : {</a>
<a name="8292"><span class="lineNum">    8292 </span>            :         bool decayed = false, done = true;</a>
<a name="8293"><span class="lineNum">    8293 </span>            :         struct rq *rq = cpu_rq(cpu);</a>
<a name="8294"><span class="lineNum">    8294 </span>            :         struct rq_flags rf;</a>
<a name="8295"><span class="lineNum">    8295 </span>            : </a>
<a name="8296"><span class="lineNum">    8296 </span>            :         rq_lock_irqsave(rq, &amp;rf);</a>
<a name="8297"><span class="lineNum">    8297 </span>            :         update_blocked_load_tick(rq);</a>
<a name="8298"><span class="lineNum">    8298 </span>            :         update_rq_clock(rq);</a>
<a name="8299"><span class="lineNum">    8299 </span>            : </a>
<a name="8300"><span class="lineNum">    8300 </span>            :         decayed |= __update_blocked_others(rq, &amp;done);</a>
<a name="8301"><span class="lineNum">    8301 </span>            :         decayed |= __update_blocked_fair(rq, &amp;done);</a>
<a name="8302"><span class="lineNum">    8302 </span>            : </a>
<a name="8303"><span class="lineNum">    8303 </span>            :         update_blocked_load_status(rq, !done);</a>
<a name="8304"><span class="lineNum">    8304 </span>            :         if (decayed)</a>
<a name="8305"><span class="lineNum">    8305 </span>            :                 cpufreq_update_util(rq, 0);</a>
<a name="8306"><span class="lineNum">    8306 </span>            :         rq_unlock_irqrestore(rq, &amp;rf);</a>
<a name="8307"><span class="lineNum">    8307 </span>            : }</a>
<a name="8308"><span class="lineNum">    8308 </span>            : </a>
<a name="8309"><span class="lineNum">    8309 </span>            : /********** Helpers for find_busiest_group ************************/</a>
<a name="8310"><span class="lineNum">    8310 </span>            : </a>
<a name="8311"><span class="lineNum">    8311 </span>            : /*</a>
<a name="8312"><span class="lineNum">    8312 </span>            :  * sg_lb_stats - stats of a sched_group required for load_balancing</a>
<a name="8313"><span class="lineNum">    8313 </span>            :  */</a>
<a name="8314"><span class="lineNum">    8314 </span>            : struct sg_lb_stats {</a>
<a name="8315"><span class="lineNum">    8315 </span>            :         unsigned long avg_load; /*Avg load across the CPUs of the group */</a>
<a name="8316"><span class="lineNum">    8316 </span>            :         unsigned long group_load; /* Total load over the CPUs of the group */</a>
<a name="8317"><span class="lineNum">    8317 </span>            :         unsigned long group_capacity;</a>
<a name="8318"><span class="lineNum">    8318 </span>            :         unsigned long group_util; /* Total utilization over the CPUs of the group */</a>
<a name="8319"><span class="lineNum">    8319 </span>            :         unsigned long group_runnable; /* Total runnable time over the CPUs of the group */</a>
<a name="8320"><span class="lineNum">    8320 </span>            :         unsigned int sum_nr_running; /* Nr of tasks running in the group */</a>
<a name="8321"><span class="lineNum">    8321 </span>            :         unsigned int sum_h_nr_running; /* Nr of CFS tasks running in the group */</a>
<a name="8322"><span class="lineNum">    8322 </span>            :         unsigned int idle_cpus;</a>
<a name="8323"><span class="lineNum">    8323 </span>            :         unsigned int group_weight;</a>
<a name="8324"><span class="lineNum">    8324 </span>            :         enum group_type group_type;</a>
<a name="8325"><span class="lineNum">    8325 </span>            :         unsigned int group_asym_packing; /* Tasks should be moved to preferred CPU */</a>
<a name="8326"><span class="lineNum">    8326 </span>            :         unsigned long group_misfit_task_load; /* A CPU has a task too big for its capacity */</a>
<a name="8327"><span class="lineNum">    8327 </span>            : #ifdef CONFIG_NUMA_BALANCING</a>
<a name="8328"><span class="lineNum">    8328 </span>            :         unsigned int nr_numa_running;</a>
<a name="8329"><span class="lineNum">    8329 </span>            :         unsigned int nr_preferred_running;</a>
<a name="8330"><span class="lineNum">    8330 </span>            : #endif</a>
<a name="8331"><span class="lineNum">    8331 </span>            : };</a>
<a name="8332"><span class="lineNum">    8332 </span>            : </a>
<a name="8333"><span class="lineNum">    8333 </span>            : /*</a>
<a name="8334"><span class="lineNum">    8334 </span>            :  * sd_lb_stats - Structure to store the statistics of a sched_domain</a>
<a name="8335"><span class="lineNum">    8335 </span>            :  *               during load balancing.</a>
<a name="8336"><span class="lineNum">    8336 </span>            :  */</a>
<a name="8337"><span class="lineNum">    8337 </span>            : struct sd_lb_stats {</a>
<a name="8338"><span class="lineNum">    8338 </span>            :         struct sched_group *busiest;    /* Busiest group in this sd */</a>
<a name="8339"><span class="lineNum">    8339 </span>            :         struct sched_group *local;      /* Local group in this sd */</a>
<a name="8340"><span class="lineNum">    8340 </span>            :         unsigned long total_load;       /* Total load of all groups in sd */</a>
<a name="8341"><span class="lineNum">    8341 </span>            :         unsigned long total_capacity;   /* Total capacity of all groups in sd */</a>
<a name="8342"><span class="lineNum">    8342 </span>            :         unsigned long avg_load; /* Average load across all groups in sd */</a>
<a name="8343"><span class="lineNum">    8343 </span>            :         unsigned int prefer_sibling; /* tasks should go to sibling first */</a>
<a name="8344"><span class="lineNum">    8344 </span>            : </a>
<a name="8345"><span class="lineNum">    8345 </span>            :         struct sg_lb_stats busiest_stat;/* Statistics of the busiest group */</a>
<a name="8346"><span class="lineNum">    8346 </span>            :         struct sg_lb_stats local_stat;  /* Statistics of the local group */</a>
<a name="8347"><span class="lineNum">    8347 </span>            : };</a>
<a name="8348"><span class="lineNum">    8348 </span>            : </a>
<a name="8349"><span class="lineNum">    8349 </span>            : static inline void init_sd_lb_stats(struct sd_lb_stats *sds)</a>
<a name="8350"><span class="lineNum">    8350 </span>            : {</a>
<a name="8351"><span class="lineNum">    8351 </span>            :         /*</a>
<a name="8352"><span class="lineNum">    8352 </span>            :          * Skimp on the clearing to avoid duplicate work. We can avoid clearing</a>
<a name="8353"><span class="lineNum">    8353 </span>            :          * local_stat because update_sg_lb_stats() does a full clear/assignment.</a>
<a name="8354"><span class="lineNum">    8354 </span>            :          * We must however set busiest_stat::group_type and</a>
<a name="8355"><span class="lineNum">    8355 </span>            :          * busiest_stat::idle_cpus to the worst busiest group because</a>
<a name="8356"><span class="lineNum">    8356 </span>            :          * update_sd_pick_busiest() reads these before assignment.</a>
<a name="8357"><span class="lineNum">    8357 </span>            :          */</a>
<a name="8358"><span class="lineNum">    8358 </span>            :         *sds = (struct sd_lb_stats){</a>
<a name="8359"><span class="lineNum">    8359 </span>            :                 .busiest = NULL,</a>
<a name="8360"><span class="lineNum">    8360 </span>            :                 .local = NULL,</a>
<a name="8361"><span class="lineNum">    8361 </span>            :                 .total_load = 0UL,</a>
<a name="8362"><span class="lineNum">    8362 </span>            :                 .total_capacity = 0UL,</a>
<a name="8363"><span class="lineNum">    8363 </span>            :                 .busiest_stat = {</a>
<a name="8364"><span class="lineNum">    8364 </span>            :                         .idle_cpus = UINT_MAX,</a>
<a name="8365"><span class="lineNum">    8365 </span>            :                         .group_type = group_has_spare,</a>
<a name="8366"><span class="lineNum">    8366 </span>            :                 },</a>
<a name="8367"><span class="lineNum">    8367 </span>            :         };</a>
<a name="8368"><span class="lineNum">    8368 </span>            : }</a>
<a name="8369"><span class="lineNum">    8369 </span>            : </a>
<a name="8370"><span class="lineNum">    8370 </span>            : static unsigned long scale_rt_capacity(int cpu)</a>
<a name="8371"><span class="lineNum">    8371 </span>            : {</a>
<a name="8372"><span class="lineNum">    8372 </span>            :         struct rq *rq = cpu_rq(cpu);</a>
<a name="8373"><span class="lineNum">    8373 </span>            :         unsigned long max = arch_scale_cpu_capacity(cpu);</a>
<a name="8374"><span class="lineNum">    8374 </span>            :         unsigned long used, free;</a>
<a name="8375"><span class="lineNum">    8375 </span>            :         unsigned long irq;</a>
<a name="8376"><span class="lineNum">    8376 </span>            : </a>
<a name="8377"><span class="lineNum">    8377 </span>            :         irq = cpu_util_irq(rq);</a>
<a name="8378"><span class="lineNum">    8378 </span>            : </a>
<a name="8379"><span class="lineNum">    8379 </span>            :         if (unlikely(irq &gt;= max))</a>
<a name="8380"><span class="lineNum">    8380 </span>            :                 return 1;</a>
<a name="8381"><span class="lineNum">    8381 </span>            : </a>
<a name="8382"><span class="lineNum">    8382 </span>            :         /*</a>
<a name="8383"><span class="lineNum">    8383 </span>            :          * avg_rt.util_avg and avg_dl.util_avg track binary signals</a>
<a name="8384"><span class="lineNum">    8384 </span>            :          * (running and not running) with weights 0 and 1024 respectively.</a>
<a name="8385"><span class="lineNum">    8385 </span>            :          * avg_thermal.load_avg tracks thermal pressure and the weighted</a>
<a name="8386"><span class="lineNum">    8386 </span>            :          * average uses the actual delta max capacity(load).</a>
<a name="8387"><span class="lineNum">    8387 </span>            :          */</a>
<a name="8388"><span class="lineNum">    8388 </span>            :         used = READ_ONCE(rq-&gt;avg_rt.util_avg);</a>
<a name="8389"><span class="lineNum">    8389 </span>            :         used += READ_ONCE(rq-&gt;avg_dl.util_avg);</a>
<a name="8390"><span class="lineNum">    8390 </span>            :         used += thermal_load_avg(rq);</a>
<a name="8391"><span class="lineNum">    8391 </span>            : </a>
<a name="8392"><span class="lineNum">    8392 </span>            :         if (unlikely(used &gt;= max))</a>
<a name="8393"><span class="lineNum">    8393 </span>            :                 return 1;</a>
<a name="8394"><span class="lineNum">    8394 </span>            : </a>
<a name="8395"><span class="lineNum">    8395 </span>            :         free = max - used;</a>
<a name="8396"><span class="lineNum">    8396 </span>            : </a>
<a name="8397"><span class="lineNum">    8397 </span>            :         return scale_irq_capacity(free, irq, max);</a>
<a name="8398"><span class="lineNum">    8398 </span>            : }</a>
<a name="8399"><span class="lineNum">    8399 </span>            : </a>
<a name="8400"><span class="lineNum">    8400 </span>            : static void update_cpu_capacity(struct sched_domain *sd, int cpu)</a>
<a name="8401"><span class="lineNum">    8401 </span>            : {</a>
<a name="8402"><span class="lineNum">    8402 </span>            :         unsigned long capacity = scale_rt_capacity(cpu);</a>
<a name="8403"><span class="lineNum">    8403 </span>            :         struct sched_group *sdg = sd-&gt;groups;</a>
<a name="8404"><span class="lineNum">    8404 </span>            : </a>
<a name="8405"><span class="lineNum">    8405 </span>            :         cpu_rq(cpu)-&gt;cpu_capacity_orig = arch_scale_cpu_capacity(cpu);</a>
<a name="8406"><span class="lineNum">    8406 </span>            : </a>
<a name="8407"><span class="lineNum">    8407 </span>            :         if (!capacity)</a>
<a name="8408"><span class="lineNum">    8408 </span>            :                 capacity = 1;</a>
<a name="8409"><span class="lineNum">    8409 </span>            : </a>
<a name="8410"><span class="lineNum">    8410 </span>            :         cpu_rq(cpu)-&gt;cpu_capacity = capacity;</a>
<a name="8411"><span class="lineNum">    8411 </span>            :         trace_sched_cpu_capacity_tp(cpu_rq(cpu));</a>
<a name="8412"><span class="lineNum">    8412 </span>            : </a>
<a name="8413"><span class="lineNum">    8413 </span>            :         sdg-&gt;sgc-&gt;capacity = capacity;</a>
<a name="8414"><span class="lineNum">    8414 </span>            :         sdg-&gt;sgc-&gt;min_capacity = capacity;</a>
<a name="8415"><span class="lineNum">    8415 </span>            :         sdg-&gt;sgc-&gt;max_capacity = capacity;</a>
<a name="8416"><span class="lineNum">    8416 </span>            : }</a>
<a name="8417"><span class="lineNum">    8417 </span>            : </a>
<a name="8418"><span class="lineNum">    8418 </span>            : void update_group_capacity(struct sched_domain *sd, int cpu)</a>
<a name="8419"><span class="lineNum">    8419 </span>            : {</a>
<a name="8420"><span class="lineNum">    8420 </span>            :         struct sched_domain *child = sd-&gt;child;</a>
<a name="8421"><span class="lineNum">    8421 </span>            :         struct sched_group *group, *sdg = sd-&gt;groups;</a>
<a name="8422"><span class="lineNum">    8422 </span>            :         unsigned long capacity, min_capacity, max_capacity;</a>
<a name="8423"><span class="lineNum">    8423 </span>            :         unsigned long interval;</a>
<a name="8424"><span class="lineNum">    8424 </span>            : </a>
<a name="8425"><span class="lineNum">    8425 </span>            :         interval = msecs_to_jiffies(sd-&gt;balance_interval);</a>
<a name="8426"><span class="lineNum">    8426 </span>            :         interval = clamp(interval, 1UL, max_load_balance_interval);</a>
<a name="8427"><span class="lineNum">    8427 </span>            :         sdg-&gt;sgc-&gt;next_update = jiffies + interval;</a>
<a name="8428"><span class="lineNum">    8428 </span>            : </a>
<a name="8429"><span class="lineNum">    8429 </span>            :         if (!child) {</a>
<a name="8430"><span class="lineNum">    8430 </span>            :                 update_cpu_capacity(sd, cpu);</a>
<a name="8431"><span class="lineNum">    8431 </span>            :                 return;</a>
<a name="8432"><span class="lineNum">    8432 </span>            :         }</a>
<a name="8433"><span class="lineNum">    8433 </span>            : </a>
<a name="8434"><span class="lineNum">    8434 </span>            :         capacity = 0;</a>
<a name="8435"><span class="lineNum">    8435 </span>            :         min_capacity = ULONG_MAX;</a>
<a name="8436"><span class="lineNum">    8436 </span>            :         max_capacity = 0;</a>
<a name="8437"><span class="lineNum">    8437 </span>            : </a>
<a name="8438"><span class="lineNum">    8438 </span>            :         if (child-&gt;flags &amp; SD_OVERLAP) {</a>
<a name="8439"><span class="lineNum">    8439 </span>            :                 /*</a>
<a name="8440"><span class="lineNum">    8440 </span>            :                  * SD_OVERLAP domains cannot assume that child groups</a>
<a name="8441"><span class="lineNum">    8441 </span>            :                  * span the current group.</a>
<a name="8442"><span class="lineNum">    8442 </span>            :                  */</a>
<a name="8443"><span class="lineNum">    8443 </span>            : </a>
<a name="8444"><span class="lineNum">    8444 </span>            :                 for_each_cpu(cpu, sched_group_span(sdg)) {</a>
<a name="8445"><span class="lineNum">    8445 </span>            :                         unsigned long cpu_cap = capacity_of(cpu);</a>
<a name="8446"><span class="lineNum">    8446 </span>            : </a>
<a name="8447"><span class="lineNum">    8447 </span>            :                         capacity += cpu_cap;</a>
<a name="8448"><span class="lineNum">    8448 </span>            :                         min_capacity = min(cpu_cap, min_capacity);</a>
<a name="8449"><span class="lineNum">    8449 </span>            :                         max_capacity = max(cpu_cap, max_capacity);</a>
<a name="8450"><span class="lineNum">    8450 </span>            :                 }</a>
<a name="8451"><span class="lineNum">    8451 </span>            :         } else  {</a>
<a name="8452"><span class="lineNum">    8452 </span>            :                 /*</a>
<a name="8453"><span class="lineNum">    8453 </span>            :                  * !SD_OVERLAP domains can assume that child groups</a>
<a name="8454"><span class="lineNum">    8454 </span>            :                  * span the current group.</a>
<a name="8455"><span class="lineNum">    8455 </span>            :                  */</a>
<a name="8456"><span class="lineNum">    8456 </span>            : </a>
<a name="8457"><span class="lineNum">    8457 </span>            :                 group = child-&gt;groups;</a>
<a name="8458"><span class="lineNum">    8458 </span>            :                 do {</a>
<a name="8459"><span class="lineNum">    8459 </span>            :                         struct sched_group_capacity *sgc = group-&gt;sgc;</a>
<a name="8460"><span class="lineNum">    8460 </span>            : </a>
<a name="8461"><span class="lineNum">    8461 </span>            :                         capacity += sgc-&gt;capacity;</a>
<a name="8462"><span class="lineNum">    8462 </span>            :                         min_capacity = min(sgc-&gt;min_capacity, min_capacity);</a>
<a name="8463"><span class="lineNum">    8463 </span>            :                         max_capacity = max(sgc-&gt;max_capacity, max_capacity);</a>
<a name="8464"><span class="lineNum">    8464 </span>            :                         group = group-&gt;next;</a>
<a name="8465"><span class="lineNum">    8465 </span>            :                 } while (group != child-&gt;groups);</a>
<a name="8466"><span class="lineNum">    8466 </span>            :         }</a>
<a name="8467"><span class="lineNum">    8467 </span>            : </a>
<a name="8468"><span class="lineNum">    8468 </span>            :         sdg-&gt;sgc-&gt;capacity = capacity;</a>
<a name="8469"><span class="lineNum">    8469 </span>            :         sdg-&gt;sgc-&gt;min_capacity = min_capacity;</a>
<a name="8470"><span class="lineNum">    8470 </span>            :         sdg-&gt;sgc-&gt;max_capacity = max_capacity;</a>
<a name="8471"><span class="lineNum">    8471 </span>            : }</a>
<a name="8472"><span class="lineNum">    8472 </span>            : </a>
<a name="8473"><span class="lineNum">    8473 </span>            : /*</a>
<a name="8474"><span class="lineNum">    8474 </span>            :  * Check whether the capacity of the rq has been noticeably reduced by side</a>
<a name="8475"><span class="lineNum">    8475 </span>            :  * activity. The imbalance_pct is used for the threshold.</a>
<a name="8476"><span class="lineNum">    8476 </span>            :  * Return true is the capacity is reduced</a>
<a name="8477"><span class="lineNum">    8477 </span>            :  */</a>
<a name="8478"><span class="lineNum">    8478 </span>            : static inline int</a>
<a name="8479"><span class="lineNum">    8479 </span>            : check_cpu_capacity(struct rq *rq, struct sched_domain *sd)</a>
<a name="8480"><span class="lineNum">    8480 </span>            : {</a>
<a name="8481"><span class="lineNum">    8481 </span>            :         return ((rq-&gt;cpu_capacity * sd-&gt;imbalance_pct) &lt;</a>
<a name="8482"><span class="lineNum">    8482 </span>            :                                 (rq-&gt;cpu_capacity_orig * 100));</a>
<a name="8483"><span class="lineNum">    8483 </span>            : }</a>
<a name="8484"><span class="lineNum">    8484 </span>            : </a>
<a name="8485"><span class="lineNum">    8485 </span>            : /*</a>
<a name="8486"><span class="lineNum">    8486 </span>            :  * Check whether a rq has a misfit task and if it looks like we can actually</a>
<a name="8487"><span class="lineNum">    8487 </span>            :  * help that task: we can migrate the task to a CPU of higher capacity, or</a>
<a name="8488"><span class="lineNum">    8488 </span>            :  * the task's current CPU is heavily pressured.</a>
<a name="8489"><span class="lineNum">    8489 </span>            :  */</a>
<a name="8490"><span class="lineNum">    8490 </span>            : static inline int check_misfit_status(struct rq *rq, struct sched_domain *sd)</a>
<a name="8491"><span class="lineNum">    8491 </span>            : {</a>
<a name="8492"><span class="lineNum">    8492 </span>            :         return rq-&gt;misfit_task_load &amp;&amp;</a>
<a name="8493"><span class="lineNum">    8493 </span>            :                 (rq-&gt;cpu_capacity_orig &lt; rq-&gt;rd-&gt;max_cpu_capacity ||</a>
<a name="8494"><span class="lineNum">    8494 </span>            :                  check_cpu_capacity(rq, sd));</a>
<a name="8495"><span class="lineNum">    8495 </span>            : }</a>
<a name="8496"><span class="lineNum">    8496 </span>            : </a>
<a name="8497"><span class="lineNum">    8497 </span>            : /*</a>
<a name="8498"><span class="lineNum">    8498 </span>            :  * Group imbalance indicates (and tries to solve) the problem where balancing</a>
<a name="8499"><span class="lineNum">    8499 </span>            :  * groups is inadequate due to -&gt;cpus_ptr constraints.</a>
<a name="8500"><span class="lineNum">    8500 </span>            :  *</a>
<a name="8501"><span class="lineNum">    8501 </span>            :  * Imagine a situation of two groups of 4 CPUs each and 4 tasks each with a</a>
<a name="8502"><span class="lineNum">    8502 </span>            :  * cpumask covering 1 CPU of the first group and 3 CPUs of the second group.</a>
<a name="8503"><span class="lineNum">    8503 </span>            :  * Something like:</a>
<a name="8504"><span class="lineNum">    8504 </span>            :  *</a>
<a name="8505"><span class="lineNum">    8505 </span>            :  *      { 0 1 2 3 } { 4 5 6 7 }</a>
<a name="8506"><span class="lineNum">    8506 </span>            :  *              *     * * *</a>
<a name="8507"><span class="lineNum">    8507 </span>            :  *</a>
<a name="8508"><span class="lineNum">    8508 </span>            :  * If we were to balance group-wise we'd place two tasks in the first group and</a>
<a name="8509"><span class="lineNum">    8509 </span>            :  * two tasks in the second group. Clearly this is undesired as it will overload</a>
<a name="8510"><span class="lineNum">    8510 </span>            :  * cpu 3 and leave one of the CPUs in the second group unused.</a>
<a name="8511"><span class="lineNum">    8511 </span>            :  *</a>
<a name="8512"><span class="lineNum">    8512 </span>            :  * The current solution to this issue is detecting the skew in the first group</a>
<a name="8513"><span class="lineNum">    8513 </span>            :  * by noticing the lower domain failed to reach balance and had difficulty</a>
<a name="8514"><span class="lineNum">    8514 </span>            :  * moving tasks due to affinity constraints.</a>
<a name="8515"><span class="lineNum">    8515 </span>            :  *</a>
<a name="8516"><span class="lineNum">    8516 </span>            :  * When this is so detected; this group becomes a candidate for busiest; see</a>
<a name="8517"><span class="lineNum">    8517 </span>            :  * update_sd_pick_busiest(). And calculate_imbalance() and</a>
<a name="8518"><span class="lineNum">    8518 </span>            :  * find_busiest_group() avoid some of the usual balance conditions to allow it</a>
<a name="8519"><span class="lineNum">    8519 </span>            :  * to create an effective group imbalance.</a>
<a name="8520"><span class="lineNum">    8520 </span>            :  *</a>
<a name="8521"><span class="lineNum">    8521 </span>            :  * This is a somewhat tricky proposition since the next run might not find the</a>
<a name="8522"><span class="lineNum">    8522 </span>            :  * group imbalance and decide the groups need to be balanced again. A most</a>
<a name="8523"><span class="lineNum">    8523 </span>            :  * subtle and fragile situation.</a>
<a name="8524"><span class="lineNum">    8524 </span>            :  */</a>
<a name="8525"><span class="lineNum">    8525 </span>            : </a>
<a name="8526"><span class="lineNum">    8526 </span>            : static inline int sg_imbalanced(struct sched_group *group)</a>
<a name="8527"><span class="lineNum">    8527 </span>            : {</a>
<a name="8528"><span class="lineNum">    8528 </span>            :         return group-&gt;sgc-&gt;imbalance;</a>
<a name="8529"><span class="lineNum">    8529 </span>            : }</a>
<a name="8530"><span class="lineNum">    8530 </span>            : </a>
<a name="8531"><span class="lineNum">    8531 </span>            : /*</a>
<a name="8532"><span class="lineNum">    8532 </span>            :  * group_has_capacity returns true if the group has spare capacity that could</a>
<a name="8533"><span class="lineNum">    8533 </span>            :  * be used by some tasks.</a>
<a name="8534"><span class="lineNum">    8534 </span>            :  * We consider that a group has spare capacity if the  * number of task is</a>
<a name="8535"><span class="lineNum">    8535 </span>            :  * smaller than the number of CPUs or if the utilization is lower than the</a>
<a name="8536"><span class="lineNum">    8536 </span>            :  * available capacity for CFS tasks.</a>
<a name="8537"><span class="lineNum">    8537 </span>            :  * For the latter, we use a threshold to stabilize the state, to take into</a>
<a name="8538"><span class="lineNum">    8538 </span>            :  * account the variance of the tasks' load and to return true if the available</a>
<a name="8539"><span class="lineNum">    8539 </span>            :  * capacity in meaningful for the load balancer.</a>
<a name="8540"><span class="lineNum">    8540 </span>            :  * As an example, an available capacity of 1% can appear but it doesn't make</a>
<a name="8541"><span class="lineNum">    8541 </span>            :  * any benefit for the load balance.</a>
<a name="8542"><span class="lineNum">    8542 </span>            :  */</a>
<a name="8543"><span class="lineNum">    8543 </span>            : static inline bool</a>
<a name="8544"><span class="lineNum">    8544 </span>            : group_has_capacity(unsigned int imbalance_pct, struct sg_lb_stats *sgs)</a>
<a name="8545"><span class="lineNum">    8545 </span>            : {</a>
<a name="8546"><span class="lineNum">    8546 </span>            :         if (sgs-&gt;sum_nr_running &lt; sgs-&gt;group_weight)</a>
<a name="8547"><span class="lineNum">    8547 </span>            :                 return true;</a>
<a name="8548"><span class="lineNum">    8548 </span>            : </a>
<a name="8549"><span class="lineNum">    8549 </span>            :         if ((sgs-&gt;group_capacity * imbalance_pct) &lt;</a>
<a name="8550"><span class="lineNum">    8550 </span>            :                         (sgs-&gt;group_runnable * 100))</a>
<a name="8551"><span class="lineNum">    8551 </span>            :                 return false;</a>
<a name="8552"><span class="lineNum">    8552 </span>            : </a>
<a name="8553"><span class="lineNum">    8553 </span>            :         if ((sgs-&gt;group_capacity * 100) &gt;</a>
<a name="8554"><span class="lineNum">    8554 </span>            :                         (sgs-&gt;group_util * imbalance_pct))</a>
<a name="8555"><span class="lineNum">    8555 </span>            :                 return true;</a>
<a name="8556"><span class="lineNum">    8556 </span>            : </a>
<a name="8557"><span class="lineNum">    8557 </span>            :         return false;</a>
<a name="8558"><span class="lineNum">    8558 </span>            : }</a>
<a name="8559"><span class="lineNum">    8559 </span>            : </a>
<a name="8560"><span class="lineNum">    8560 </span>            : /*</a>
<a name="8561"><span class="lineNum">    8561 </span>            :  *  group_is_overloaded returns true if the group has more tasks than it can</a>
<a name="8562"><span class="lineNum">    8562 </span>            :  *  handle.</a>
<a name="8563"><span class="lineNum">    8563 </span>            :  *  group_is_overloaded is not equals to !group_has_capacity because a group</a>
<a name="8564"><span class="lineNum">    8564 </span>            :  *  with the exact right number of tasks, has no more spare capacity but is not</a>
<a name="8565"><span class="lineNum">    8565 </span>            :  *  overloaded so both group_has_capacity and group_is_overloaded return</a>
<a name="8566"><span class="lineNum">    8566 </span>            :  *  false.</a>
<a name="8567"><span class="lineNum">    8567 </span>            :  */</a>
<a name="8568"><span class="lineNum">    8568 </span>            : static inline bool</a>
<a name="8569"><span class="lineNum">    8569 </span>            : group_is_overloaded(unsigned int imbalance_pct, struct sg_lb_stats *sgs)</a>
<a name="8570"><span class="lineNum">    8570 </span>            : {</a>
<a name="8571"><span class="lineNum">    8571 </span>            :         if (sgs-&gt;sum_nr_running &lt;= sgs-&gt;group_weight)</a>
<a name="8572"><span class="lineNum">    8572 </span>            :                 return false;</a>
<a name="8573"><span class="lineNum">    8573 </span>            : </a>
<a name="8574"><span class="lineNum">    8574 </span>            :         if ((sgs-&gt;group_capacity * 100) &lt;</a>
<a name="8575"><span class="lineNum">    8575 </span>            :                         (sgs-&gt;group_util * imbalance_pct))</a>
<a name="8576"><span class="lineNum">    8576 </span>            :                 return true;</a>
<a name="8577"><span class="lineNum">    8577 </span>            : </a>
<a name="8578"><span class="lineNum">    8578 </span>            :         if ((sgs-&gt;group_capacity * imbalance_pct) &lt;</a>
<a name="8579"><span class="lineNum">    8579 </span>            :                         (sgs-&gt;group_runnable * 100))</a>
<a name="8580"><span class="lineNum">    8580 </span>            :                 return true;</a>
<a name="8581"><span class="lineNum">    8581 </span>            : </a>
<a name="8582"><span class="lineNum">    8582 </span>            :         return false;</a>
<a name="8583"><span class="lineNum">    8583 </span>            : }</a>
<a name="8584"><span class="lineNum">    8584 </span>            : </a>
<a name="8585"><span class="lineNum">    8585 </span>            : static inline enum</a>
<a name="8586"><span class="lineNum">    8586 </span>            : group_type group_classify(unsigned int imbalance_pct,</a>
<a name="8587"><span class="lineNum">    8587 </span>            :                           struct sched_group *group,</a>
<a name="8588"><span class="lineNum">    8588 </span>            :                           struct sg_lb_stats *sgs)</a>
<a name="8589"><span class="lineNum">    8589 </span>            : {</a>
<a name="8590"><span class="lineNum">    8590 </span>            :         if (group_is_overloaded(imbalance_pct, sgs))</a>
<a name="8591"><span class="lineNum">    8591 </span>            :                 return group_overloaded;</a>
<a name="8592"><span class="lineNum">    8592 </span>            : </a>
<a name="8593"><span class="lineNum">    8593 </span>            :         if (sg_imbalanced(group))</a>
<a name="8594"><span class="lineNum">    8594 </span>            :                 return group_imbalanced;</a>
<a name="8595"><span class="lineNum">    8595 </span>            : </a>
<a name="8596"><span class="lineNum">    8596 </span>            :         if (sgs-&gt;group_asym_packing)</a>
<a name="8597"><span class="lineNum">    8597 </span>            :                 return group_asym_packing;</a>
<a name="8598"><span class="lineNum">    8598 </span>            : </a>
<a name="8599"><span class="lineNum">    8599 </span>            :         if (sgs-&gt;group_misfit_task_load)</a>
<a name="8600"><span class="lineNum">    8600 </span>            :                 return group_misfit_task;</a>
<a name="8601"><span class="lineNum">    8601 </span>            : </a>
<a name="8602"><span class="lineNum">    8602 </span>            :         if (!group_has_capacity(imbalance_pct, sgs))</a>
<a name="8603"><span class="lineNum">    8603 </span>            :                 return group_fully_busy;</a>
<a name="8604"><span class="lineNum">    8604 </span>            : </a>
<a name="8605"><span class="lineNum">    8605 </span>            :         return group_has_spare;</a>
<a name="8606"><span class="lineNum">    8606 </span>            : }</a>
<a name="8607"><span class="lineNum">    8607 </span>            : </a>
<a name="8608"><span class="lineNum">    8608 </span>            : /**</a>
<a name="8609"><span class="lineNum">    8609 </span>            :  * asym_smt_can_pull_tasks - Check whether the load balancing CPU can pull tasks</a>
<a name="8610"><span class="lineNum">    8610 </span>            :  * @dst_cpu:    Destination CPU of the load balancing</a>
<a name="8611"><span class="lineNum">    8611 </span>            :  * @sds:        Load-balancing data with statistics of the local group</a>
<a name="8612"><span class="lineNum">    8612 </span>            :  * @sgs:        Load-balancing statistics of the candidate busiest group</a>
<a name="8613"><span class="lineNum">    8613 </span>            :  * @sg:         The candidate busiest group</a>
<a name="8614"><span class="lineNum">    8614 </span>            :  *</a>
<a name="8615"><span class="lineNum">    8615 </span>            :  * Check the state of the SMT siblings of both @sds::local and @sg and decide</a>
<a name="8616"><span class="lineNum">    8616 </span>            :  * if @dst_cpu can pull tasks.</a>
<a name="8617"><span class="lineNum">    8617 </span>            :  *</a>
<a name="8618"><span class="lineNum">    8618 </span>            :  * If @dst_cpu does not have SMT siblings, it can pull tasks if two or more of</a>
<a name="8619"><span class="lineNum">    8619 </span>            :  * the SMT siblings of @sg are busy. If only one CPU in @sg is busy, pull tasks</a>
<a name="8620"><span class="lineNum">    8620 </span>            :  * only if @dst_cpu has higher priority.</a>
<a name="8621"><span class="lineNum">    8621 </span>            :  *</a>
<a name="8622"><span class="lineNum">    8622 </span>            :  * If both @dst_cpu and @sg have SMT siblings, and @sg has exactly one more</a>
<a name="8623"><span class="lineNum">    8623 </span>            :  * busy CPU than @sds::local, let @dst_cpu pull tasks if it has higher priority.</a>
<a name="8624"><span class="lineNum">    8624 </span>            :  * Bigger imbalances in the number of busy CPUs will be dealt with in</a>
<a name="8625"><span class="lineNum">    8625 </span>            :  * update_sd_pick_busiest().</a>
<a name="8626"><span class="lineNum">    8626 </span>            :  *</a>
<a name="8627"><span class="lineNum">    8627 </span>            :  * If @sg does not have SMT siblings, only pull tasks if all of the SMT siblings</a>
<a name="8628"><span class="lineNum">    8628 </span>            :  * of @dst_cpu are idle and @sg has lower priority.</a>
<a name="8629"><span class="lineNum">    8629 </span>            :  *</a>
<a name="8630"><span class="lineNum">    8630 </span>            :  * Return: true if @dst_cpu can pull tasks, false otherwise.</a>
<a name="8631"><span class="lineNum">    8631 </span>            :  */</a>
<a name="8632"><span class="lineNum">    8632 </span>            : static bool asym_smt_can_pull_tasks(int dst_cpu, struct sd_lb_stats *sds,</a>
<a name="8633"><span class="lineNum">    8633 </span>            :                                     struct sg_lb_stats *sgs,</a>
<a name="8634"><span class="lineNum">    8634 </span>            :                                     struct sched_group *sg)</a>
<a name="8635"><span class="lineNum">    8635 </span>            : {</a>
<a name="8636"><span class="lineNum">    8636 </span>            : #ifdef CONFIG_SCHED_SMT</a>
<a name="8637"><span class="lineNum">    8637 </span>            :         bool local_is_smt, sg_is_smt;</a>
<a name="8638"><span class="lineNum">    8638 </span>            :         int sg_busy_cpus;</a>
<a name="8639"><span class="lineNum">    8639 </span>            : </a>
<a name="8640"><span class="lineNum">    8640 </span>            :         local_is_smt = sds-&gt;local-&gt;flags &amp; SD_SHARE_CPUCAPACITY;</a>
<a name="8641"><span class="lineNum">    8641 </span>            :         sg_is_smt = sg-&gt;flags &amp; SD_SHARE_CPUCAPACITY;</a>
<a name="8642"><span class="lineNum">    8642 </span>            : </a>
<a name="8643"><span class="lineNum">    8643 </span>            :         sg_busy_cpus = sgs-&gt;group_weight - sgs-&gt;idle_cpus;</a>
<a name="8644"><span class="lineNum">    8644 </span>            : </a>
<a name="8645"><span class="lineNum">    8645 </span>            :         if (!local_is_smt) {</a>
<a name="8646"><span class="lineNum">    8646 </span>            :                 /*</a>
<a name="8647"><span class="lineNum">    8647 </span>            :                  * If we are here, @dst_cpu is idle and does not have SMT</a>
<a name="8648"><span class="lineNum">    8648 </span>            :                  * siblings. Pull tasks if candidate group has two or more</a>
<a name="8649"><span class="lineNum">    8649 </span>            :                  * busy CPUs.</a>
<a name="8650"><span class="lineNum">    8650 </span>            :                  */</a>
<a name="8651"><span class="lineNum">    8651 </span>            :                 if (sg_busy_cpus &gt;= 2) /* implies sg_is_smt */</a>
<a name="8652"><span class="lineNum">    8652 </span>            :                         return true;</a>
<a name="8653"><span class="lineNum">    8653 </span>            : </a>
<a name="8654"><span class="lineNum">    8654 </span>            :                 /*</a>
<a name="8655"><span class="lineNum">    8655 </span>            :                  * @dst_cpu does not have SMT siblings. @sg may have SMT</a>
<a name="8656"><span class="lineNum">    8656 </span>            :                  * siblings and only one is busy. In such case, @dst_cpu</a>
<a name="8657"><span class="lineNum">    8657 </span>            :                  * can help if it has higher priority and is idle (i.e.,</a>
<a name="8658"><span class="lineNum">    8658 </span>            :                  * it has no running tasks).</a>
<a name="8659"><span class="lineNum">    8659 </span>            :                  */</a>
<a name="8660"><span class="lineNum">    8660 </span>            :                 return sched_asym_prefer(dst_cpu, sg-&gt;asym_prefer_cpu);</a>
<a name="8661"><span class="lineNum">    8661 </span>            :         }</a>
<a name="8662"><span class="lineNum">    8662 </span>            : </a>
<a name="8663"><span class="lineNum">    8663 </span>            :         /* @dst_cpu has SMT siblings. */</a>
<a name="8664"><span class="lineNum">    8664 </span>            : </a>
<a name="8665"><span class="lineNum">    8665 </span>            :         if (sg_is_smt) {</a>
<a name="8666"><span class="lineNum">    8666 </span>            :                 int local_busy_cpus = sds-&gt;local-&gt;group_weight -</a>
<a name="8667"><span class="lineNum">    8667 </span>            :                                       sds-&gt;local_stat.idle_cpus;</a>
<a name="8668"><span class="lineNum">    8668 </span>            :                 int busy_cpus_delta = sg_busy_cpus - local_busy_cpus;</a>
<a name="8669"><span class="lineNum">    8669 </span>            : </a>
<a name="8670"><span class="lineNum">    8670 </span>            :                 if (busy_cpus_delta == 1)</a>
<a name="8671"><span class="lineNum">    8671 </span>            :                         return sched_asym_prefer(dst_cpu, sg-&gt;asym_prefer_cpu);</a>
<a name="8672"><span class="lineNum">    8672 </span>            : </a>
<a name="8673"><span class="lineNum">    8673 </span>            :                 return false;</a>
<a name="8674"><span class="lineNum">    8674 </span>            :         }</a>
<a name="8675"><span class="lineNum">    8675 </span>            : </a>
<a name="8676"><span class="lineNum">    8676 </span>            :         /*</a>
<a name="8677"><span class="lineNum">    8677 </span>            :          * @sg does not have SMT siblings. Ensure that @sds::local does not end</a>
<a name="8678"><span class="lineNum">    8678 </span>            :          * up with more than one busy SMT sibling and only pull tasks if there</a>
<a name="8679"><span class="lineNum">    8679 </span>            :          * are not busy CPUs (i.e., no CPU has running tasks).</a>
<a name="8680"><span class="lineNum">    8680 </span>            :          */</a>
<a name="8681"><span class="lineNum">    8681 </span>            :         if (!sds-&gt;local_stat.sum_nr_running)</a>
<a name="8682"><span class="lineNum">    8682 </span>            :                 return sched_asym_prefer(dst_cpu, sg-&gt;asym_prefer_cpu);</a>
<a name="8683"><span class="lineNum">    8683 </span>            : </a>
<a name="8684"><span class="lineNum">    8684 </span>            :         return false;</a>
<a name="8685"><span class="lineNum">    8685 </span>            : #else</a>
<a name="8686"><span class="lineNum">    8686 </span>            :         /* Always return false so that callers deal with non-SMT cases. */</a>
<a name="8687"><span class="lineNum">    8687 </span>            :         return false;</a>
<a name="8688"><span class="lineNum">    8688 </span>            : #endif</a>
<a name="8689"><span class="lineNum">    8689 </span>            : }</a>
<a name="8690"><span class="lineNum">    8690 </span>            : </a>
<a name="8691"><span class="lineNum">    8691 </span>            : static inline bool</a>
<a name="8692"><span class="lineNum">    8692 </span>            : sched_asym(struct lb_env *env, struct sd_lb_stats *sds,  struct sg_lb_stats *sgs,</a>
<a name="8693"><span class="lineNum">    8693 </span>            :            struct sched_group *group)</a>
<a name="8694"><span class="lineNum">    8694 </span>            : {</a>
<a name="8695"><span class="lineNum">    8695 </span>            :         /* Only do SMT checks if either local or candidate have SMT siblings */</a>
<a name="8696"><span class="lineNum">    8696 </span>            :         if ((sds-&gt;local-&gt;flags &amp; SD_SHARE_CPUCAPACITY) ||</a>
<a name="8697"><span class="lineNum">    8697 </span>            :             (group-&gt;flags &amp; SD_SHARE_CPUCAPACITY))</a>
<a name="8698"><span class="lineNum">    8698 </span>            :                 return asym_smt_can_pull_tasks(env-&gt;dst_cpu, sds, sgs, group);</a>
<a name="8699"><span class="lineNum">    8699 </span>            : </a>
<a name="8700"><span class="lineNum">    8700 </span>            :         return sched_asym_prefer(env-&gt;dst_cpu, group-&gt;asym_prefer_cpu);</a>
<a name="8701"><span class="lineNum">    8701 </span>            : }</a>
<a name="8702"><span class="lineNum">    8702 </span>            : </a>
<a name="8703"><span class="lineNum">    8703 </span>            : /**</a>
<a name="8704"><span class="lineNum">    8704 </span>            :  * update_sg_lb_stats - Update sched_group's statistics for load balancing.</a>
<a name="8705"><span class="lineNum">    8705 </span>            :  * @env: The load balancing environment.</a>
<a name="8706"><span class="lineNum">    8706 </span>            :  * @sds: Load-balancing data with statistics of the local group.</a>
<a name="8707"><span class="lineNum">    8707 </span>            :  * @group: sched_group whose statistics are to be updated.</a>
<a name="8708"><span class="lineNum">    8708 </span>            :  * @sgs: variable to hold the statistics for this group.</a>
<a name="8709"><span class="lineNum">    8709 </span>            :  * @sg_status: Holds flag indicating the status of the sched_group</a>
<a name="8710"><span class="lineNum">    8710 </span>            :  */</a>
<a name="8711"><span class="lineNum">    8711 </span>            : static inline void update_sg_lb_stats(struct lb_env *env,</a>
<a name="8712"><span class="lineNum">    8712 </span>            :                                       struct sd_lb_stats *sds,</a>
<a name="8713"><span class="lineNum">    8713 </span>            :                                       struct sched_group *group,</a>
<a name="8714"><span class="lineNum">    8714 </span>            :                                       struct sg_lb_stats *sgs,</a>
<a name="8715"><span class="lineNum">    8715 </span>            :                                       int *sg_status)</a>
<a name="8716"><span class="lineNum">    8716 </span>            : {</a>
<a name="8717"><span class="lineNum">    8717 </span>            :         int i, nr_running, local_group;</a>
<a name="8718"><span class="lineNum">    8718 </span>            : </a>
<a name="8719"><span class="lineNum">    8719 </span>            :         memset(sgs, 0, sizeof(*sgs));</a>
<a name="8720"><span class="lineNum">    8720 </span>            : </a>
<a name="8721"><span class="lineNum">    8721 </span>            :         local_group = group == sds-&gt;local;</a>
<a name="8722"><span class="lineNum">    8722 </span>            : </a>
<a name="8723"><span class="lineNum">    8723 </span>            :         for_each_cpu_and(i, sched_group_span(group), env-&gt;cpus) {</a>
<a name="8724"><span class="lineNum">    8724 </span>            :                 struct rq *rq = cpu_rq(i);</a>
<a name="8725"><span class="lineNum">    8725 </span>            : </a>
<a name="8726"><span class="lineNum">    8726 </span>            :                 sgs-&gt;group_load += cpu_load(rq);</a>
<a name="8727"><span class="lineNum">    8727 </span>            :                 sgs-&gt;group_util += cpu_util_cfs(i);</a>
<a name="8728"><span class="lineNum">    8728 </span>            :                 sgs-&gt;group_runnable += cpu_runnable(rq);</a>
<a name="8729"><span class="lineNum">    8729 </span>            :                 sgs-&gt;sum_h_nr_running += rq-&gt;cfs.h_nr_running;</a>
<a name="8730"><span class="lineNum">    8730 </span>            : </a>
<a name="8731"><span class="lineNum">    8731 </span>            :                 nr_running = rq-&gt;nr_running;</a>
<a name="8732"><span class="lineNum">    8732 </span>            :                 sgs-&gt;sum_nr_running += nr_running;</a>
<a name="8733"><span class="lineNum">    8733 </span>            : </a>
<a name="8734"><span class="lineNum">    8734 </span>            :                 if (nr_running &gt; 1)</a>
<a name="8735"><span class="lineNum">    8735 </span>            :                         *sg_status |= SG_OVERLOAD;</a>
<a name="8736"><span class="lineNum">    8736 </span>            : </a>
<a name="8737"><span class="lineNum">    8737 </span>            :                 if (cpu_overutilized(i))</a>
<a name="8738"><span class="lineNum">    8738 </span>            :                         *sg_status |= SG_OVERUTILIZED;</a>
<a name="8739"><span class="lineNum">    8739 </span>            : </a>
<a name="8740"><span class="lineNum">    8740 </span>            : #ifdef CONFIG_NUMA_BALANCING</a>
<a name="8741"><span class="lineNum">    8741 </span>            :                 sgs-&gt;nr_numa_running += rq-&gt;nr_numa_running;</a>
<a name="8742"><span class="lineNum">    8742 </span>            :                 sgs-&gt;nr_preferred_running += rq-&gt;nr_preferred_running;</a>
<a name="8743"><span class="lineNum">    8743 </span>            : #endif</a>
<a name="8744"><span class="lineNum">    8744 </span>            :                 /*</a>
<a name="8745"><span class="lineNum">    8745 </span>            :                  * No need to call idle_cpu() if nr_running is not 0</a>
<a name="8746"><span class="lineNum">    8746 </span>            :                  */</a>
<a name="8747"><span class="lineNum">    8747 </span>            :                 if (!nr_running &amp;&amp; idle_cpu(i)) {</a>
<a name="8748"><span class="lineNum">    8748 </span>            :                         sgs-&gt;idle_cpus++;</a>
<a name="8749"><span class="lineNum">    8749 </span>            :                         /* Idle cpu can't have misfit task */</a>
<a name="8750"><span class="lineNum">    8750 </span>            :                         continue;</a>
<a name="8751"><span class="lineNum">    8751 </span>            :                 }</a>
<a name="8752"><span class="lineNum">    8752 </span>            : </a>
<a name="8753"><span class="lineNum">    8753 </span>            :                 if (local_group)</a>
<a name="8754"><span class="lineNum">    8754 </span>            :                         continue;</a>
<a name="8755"><span class="lineNum">    8755 </span>            : </a>
<a name="8756"><span class="lineNum">    8756 </span>            :                 /* Check for a misfit task on the cpu */</a>
<a name="8757"><span class="lineNum">    8757 </span>            :                 if (env-&gt;sd-&gt;flags &amp; SD_ASYM_CPUCAPACITY &amp;&amp;</a>
<a name="8758"><span class="lineNum">    8758 </span>            :                     sgs-&gt;group_misfit_task_load &lt; rq-&gt;misfit_task_load) {</a>
<a name="8759"><span class="lineNum">    8759 </span>            :                         sgs-&gt;group_misfit_task_load = rq-&gt;misfit_task_load;</a>
<a name="8760"><span class="lineNum">    8760 </span>            :                         *sg_status |= SG_OVERLOAD;</a>
<a name="8761"><span class="lineNum">    8761 </span>            :                 }</a>
<a name="8762"><span class="lineNum">    8762 </span>            :         }</a>
<a name="8763"><span class="lineNum">    8763 </span>            : </a>
<a name="8764"><span class="lineNum">    8764 </span>            :         sgs-&gt;group_capacity = group-&gt;sgc-&gt;capacity;</a>
<a name="8765"><span class="lineNum">    8765 </span>            : </a>
<a name="8766"><span class="lineNum">    8766 </span>            :         sgs-&gt;group_weight = group-&gt;group_weight;</a>
<a name="8767"><span class="lineNum">    8767 </span>            : </a>
<a name="8768"><span class="lineNum">    8768 </span>            :         /* Check if dst CPU is idle and preferred to this group */</a>
<a name="8769"><span class="lineNum">    8769 </span>            :         if (!local_group &amp;&amp; env-&gt;sd-&gt;flags &amp; SD_ASYM_PACKING &amp;&amp;</a>
<a name="8770"><span class="lineNum">    8770 </span>            :             env-&gt;idle != CPU_NOT_IDLE &amp;&amp; sgs-&gt;sum_h_nr_running &amp;&amp;</a>
<a name="8771"><span class="lineNum">    8771 </span>            :             sched_asym(env, sds, sgs, group)) {</a>
<a name="8772"><span class="lineNum">    8772 </span>            :                 sgs-&gt;group_asym_packing = 1;</a>
<a name="8773"><span class="lineNum">    8773 </span>            :         }</a>
<a name="8774"><span class="lineNum">    8774 </span>            : </a>
<a name="8775"><span class="lineNum">    8775 </span>            :         sgs-&gt;group_type = group_classify(env-&gt;sd-&gt;imbalance_pct, group, sgs);</a>
<a name="8776"><span class="lineNum">    8776 </span>            : </a>
<a name="8777"><span class="lineNum">    8777 </span>            :         /* Computing avg_load makes sense only when group is overloaded */</a>
<a name="8778"><span class="lineNum">    8778 </span>            :         if (sgs-&gt;group_type == group_overloaded)</a>
<a name="8779"><span class="lineNum">    8779 </span>            :                 sgs-&gt;avg_load = (sgs-&gt;group_load * SCHED_CAPACITY_SCALE) /</a>
<a name="8780"><span class="lineNum">    8780 </span>            :                                 sgs-&gt;group_capacity;</a>
<a name="8781"><span class="lineNum">    8781 </span>            : }</a>
<a name="8782"><span class="lineNum">    8782 </span>            : </a>
<a name="8783"><span class="lineNum">    8783 </span>            : /**</a>
<a name="8784"><span class="lineNum">    8784 </span>            :  * update_sd_pick_busiest - return 1 on busiest group</a>
<a name="8785"><span class="lineNum">    8785 </span>            :  * @env: The load balancing environment.</a>
<a name="8786"><span class="lineNum">    8786 </span>            :  * @sds: sched_domain statistics</a>
<a name="8787"><span class="lineNum">    8787 </span>            :  * @sg: sched_group candidate to be checked for being the busiest</a>
<a name="8788"><span class="lineNum">    8788 </span>            :  * @sgs: sched_group statistics</a>
<a name="8789"><span class="lineNum">    8789 </span>            :  *</a>
<a name="8790"><span class="lineNum">    8790 </span>            :  * Determine if @sg is a busier group than the previously selected</a>
<a name="8791"><span class="lineNum">    8791 </span>            :  * busiest group.</a>
<a name="8792"><span class="lineNum">    8792 </span>            :  *</a>
<a name="8793"><span class="lineNum">    8793 </span>            :  * Return: %true if @sg is a busier group than the previously selected</a>
<a name="8794"><span class="lineNum">    8794 </span>            :  * busiest group. %false otherwise.</a>
<a name="8795"><span class="lineNum">    8795 </span>            :  */</a>
<a name="8796"><span class="lineNum">    8796 </span>            : static bool update_sd_pick_busiest(struct lb_env *env,</a>
<a name="8797"><span class="lineNum">    8797 </span>            :                                    struct sd_lb_stats *sds,</a>
<a name="8798"><span class="lineNum">    8798 </span>            :                                    struct sched_group *sg,</a>
<a name="8799"><span class="lineNum">    8799 </span>            :                                    struct sg_lb_stats *sgs)</a>
<a name="8800"><span class="lineNum">    8800 </span>            : {</a>
<a name="8801"><span class="lineNum">    8801 </span>            :         struct sg_lb_stats *busiest = &amp;sds-&gt;busiest_stat;</a>
<a name="8802"><span class="lineNum">    8802 </span>            : </a>
<a name="8803"><span class="lineNum">    8803 </span>            :         /* Make sure that there is at least one task to pull */</a>
<a name="8804"><span class="lineNum">    8804 </span>            :         if (!sgs-&gt;sum_h_nr_running)</a>
<a name="8805"><span class="lineNum">    8805 </span>            :                 return false;</a>
<a name="8806"><span class="lineNum">    8806 </span>            : </a>
<a name="8807"><span class="lineNum">    8807 </span>            :         /*</a>
<a name="8808"><span class="lineNum">    8808 </span>            :          * Don't try to pull misfit tasks we can't help.</a>
<a name="8809"><span class="lineNum">    8809 </span>            :          * We can use max_capacity here as reduction in capacity on some</a>
<a name="8810"><span class="lineNum">    8810 </span>            :          * CPUs in the group should either be possible to resolve</a>
<a name="8811"><span class="lineNum">    8811 </span>            :          * internally or be covered by avg_load imbalance (eventually).</a>
<a name="8812"><span class="lineNum">    8812 </span>            :          */</a>
<a name="8813"><span class="lineNum">    8813 </span>            :         if (sgs-&gt;group_type == group_misfit_task &amp;&amp;</a>
<a name="8814"><span class="lineNum">    8814 </span>            :             (!capacity_greater(capacity_of(env-&gt;dst_cpu), sg-&gt;sgc-&gt;max_capacity) ||</a>
<a name="8815"><span class="lineNum">    8815 </span>            :              sds-&gt;local_stat.group_type != group_has_spare))</a>
<a name="8816"><span class="lineNum">    8816 </span>            :                 return false;</a>
<a name="8817"><span class="lineNum">    8817 </span>            : </a>
<a name="8818"><span class="lineNum">    8818 </span>            :         if (sgs-&gt;group_type &gt; busiest-&gt;group_type)</a>
<a name="8819"><span class="lineNum">    8819 </span>            :                 return true;</a>
<a name="8820"><span class="lineNum">    8820 </span>            : </a>
<a name="8821"><span class="lineNum">    8821 </span>            :         if (sgs-&gt;group_type &lt; busiest-&gt;group_type)</a>
<a name="8822"><span class="lineNum">    8822 </span>            :                 return false;</a>
<a name="8823"><span class="lineNum">    8823 </span>            : </a>
<a name="8824"><span class="lineNum">    8824 </span>            :         /*</a>
<a name="8825"><span class="lineNum">    8825 </span>            :          * The candidate and the current busiest group are the same type of</a>
<a name="8826"><span class="lineNum">    8826 </span>            :          * group. Let check which one is the busiest according to the type.</a>
<a name="8827"><span class="lineNum">    8827 </span>            :          */</a>
<a name="8828"><span class="lineNum">    8828 </span>            : </a>
<a name="8829"><span class="lineNum">    8829 </span>            :         switch (sgs-&gt;group_type) {</a>
<a name="8830"><span class="lineNum">    8830 </span>            :         case group_overloaded:</a>
<a name="8831"><span class="lineNum">    8831 </span>            :                 /* Select the overloaded group with highest avg_load. */</a>
<a name="8832"><span class="lineNum">    8832 </span>            :                 if (sgs-&gt;avg_load &lt;= busiest-&gt;avg_load)</a>
<a name="8833"><span class="lineNum">    8833 </span>            :                         return false;</a>
<a name="8834"><span class="lineNum">    8834 </span>            :                 break;</a>
<a name="8835"><span class="lineNum">    8835 </span>            : </a>
<a name="8836"><span class="lineNum">    8836 </span>            :         case group_imbalanced:</a>
<a name="8837"><span class="lineNum">    8837 </span>            :                 /*</a>
<a name="8838"><span class="lineNum">    8838 </span>            :                  * Select the 1st imbalanced group as we don't have any way to</a>
<a name="8839"><span class="lineNum">    8839 </span>            :                  * choose one more than another.</a>
<a name="8840"><span class="lineNum">    8840 </span>            :                  */</a>
<a name="8841"><span class="lineNum">    8841 </span>            :                 return false;</a>
<a name="8842"><span class="lineNum">    8842 </span>            : </a>
<a name="8843"><span class="lineNum">    8843 </span>            :         case group_asym_packing:</a>
<a name="8844"><span class="lineNum">    8844 </span>            :                 /* Prefer to move from lowest priority CPU's work */</a>
<a name="8845"><span class="lineNum">    8845 </span>            :                 if (sched_asym_prefer(sg-&gt;asym_prefer_cpu, sds-&gt;busiest-&gt;asym_prefer_cpu))</a>
<a name="8846"><span class="lineNum">    8846 </span>            :                         return false;</a>
<a name="8847"><span class="lineNum">    8847 </span>            :                 break;</a>
<a name="8848"><span class="lineNum">    8848 </span>            : </a>
<a name="8849"><span class="lineNum">    8849 </span>            :         case group_misfit_task:</a>
<a name="8850"><span class="lineNum">    8850 </span>            :                 /*</a>
<a name="8851"><span class="lineNum">    8851 </span>            :                  * If we have more than one misfit sg go with the biggest</a>
<a name="8852"><span class="lineNum">    8852 </span>            :                  * misfit.</a>
<a name="8853"><span class="lineNum">    8853 </span>            :                  */</a>
<a name="8854"><span class="lineNum">    8854 </span>            :                 if (sgs-&gt;group_misfit_task_load &lt; busiest-&gt;group_misfit_task_load)</a>
<a name="8855"><span class="lineNum">    8855 </span>            :                         return false;</a>
<a name="8856"><span class="lineNum">    8856 </span>            :                 break;</a>
<a name="8857"><span class="lineNum">    8857 </span>            : </a>
<a name="8858"><span class="lineNum">    8858 </span>            :         case group_fully_busy:</a>
<a name="8859"><span class="lineNum">    8859 </span>            :                 /*</a>
<a name="8860"><span class="lineNum">    8860 </span>            :                  * Select the fully busy group with highest avg_load. In</a>
<a name="8861"><span class="lineNum">    8861 </span>            :                  * theory, there is no need to pull task from such kind of</a>
<a name="8862"><span class="lineNum">    8862 </span>            :                  * group because tasks have all compute capacity that they need</a>
<a name="8863"><span class="lineNum">    8863 </span>            :                  * but we can still improve the overall throughput by reducing</a>
<a name="8864"><span class="lineNum">    8864 </span>            :                  * contention when accessing shared HW resources.</a>
<a name="8865"><span class="lineNum">    8865 </span>            :                  *</a>
<a name="8866"><span class="lineNum">    8866 </span>            :                  * XXX for now avg_load is not computed and always 0 so we</a>
<a name="8867"><span class="lineNum">    8867 </span>            :                  * select the 1st one.</a>
<a name="8868"><span class="lineNum">    8868 </span>            :                  */</a>
<a name="8869"><span class="lineNum">    8869 </span>            :                 if (sgs-&gt;avg_load &lt;= busiest-&gt;avg_load)</a>
<a name="8870"><span class="lineNum">    8870 </span>            :                         return false;</a>
<a name="8871"><span class="lineNum">    8871 </span>            :                 break;</a>
<a name="8872"><span class="lineNum">    8872 </span>            : </a>
<a name="8873"><span class="lineNum">    8873 </span>            :         case group_has_spare:</a>
<a name="8874"><span class="lineNum">    8874 </span>            :                 /*</a>
<a name="8875"><span class="lineNum">    8875 </span>            :                  * Select not overloaded group with lowest number of idle cpus</a>
<a name="8876"><span class="lineNum">    8876 </span>            :                  * and highest number of running tasks. We could also compare</a>
<a name="8877"><span class="lineNum">    8877 </span>            :                  * the spare capacity which is more stable but it can end up</a>
<a name="8878"><span class="lineNum">    8878 </span>            :                  * that the group has less spare capacity but finally more idle</a>
<a name="8879"><span class="lineNum">    8879 </span>            :                  * CPUs which means less opportunity to pull tasks.</a>
<a name="8880"><span class="lineNum">    8880 </span>            :                  */</a>
<a name="8881"><span class="lineNum">    8881 </span>            :                 if (sgs-&gt;idle_cpus &gt; busiest-&gt;idle_cpus)</a>
<a name="8882"><span class="lineNum">    8882 </span>            :                         return false;</a>
<a name="8883"><span class="lineNum">    8883 </span>            :                 else if ((sgs-&gt;idle_cpus == busiest-&gt;idle_cpus) &amp;&amp;</a>
<a name="8884"><span class="lineNum">    8884 </span>            :                          (sgs-&gt;sum_nr_running &lt;= busiest-&gt;sum_nr_running))</a>
<a name="8885"><span class="lineNum">    8885 </span>            :                         return false;</a>
<a name="8886"><span class="lineNum">    8886 </span>            : </a>
<a name="8887"><span class="lineNum">    8887 </span>            :                 break;</a>
<a name="8888"><span class="lineNum">    8888 </span>            :         }</a>
<a name="8889"><span class="lineNum">    8889 </span>            : </a>
<a name="8890"><span class="lineNum">    8890 </span>            :         /*</a>
<a name="8891"><span class="lineNum">    8891 </span>            :          * Candidate sg has no more than one task per CPU and has higher</a>
<a name="8892"><span class="lineNum">    8892 </span>            :          * per-CPU capacity. Migrating tasks to less capable CPUs may harm</a>
<a name="8893"><span class="lineNum">    8893 </span>            :          * throughput. Maximize throughput, power/energy consequences are not</a>
<a name="8894"><span class="lineNum">    8894 </span>            :          * considered.</a>
<a name="8895"><span class="lineNum">    8895 </span>            :          */</a>
<a name="8896"><span class="lineNum">    8896 </span>            :         if ((env-&gt;sd-&gt;flags &amp; SD_ASYM_CPUCAPACITY) &amp;&amp;</a>
<a name="8897"><span class="lineNum">    8897 </span>            :             (sgs-&gt;group_type &lt;= group_fully_busy) &amp;&amp;</a>
<a name="8898"><span class="lineNum">    8898 </span>            :             (capacity_greater(sg-&gt;sgc-&gt;min_capacity, capacity_of(env-&gt;dst_cpu))))</a>
<a name="8899"><span class="lineNum">    8899 </span>            :                 return false;</a>
<a name="8900"><span class="lineNum">    8900 </span>            : </a>
<a name="8901"><span class="lineNum">    8901 </span>            :         return true;</a>
<a name="8902"><span class="lineNum">    8902 </span>            : }</a>
<a name="8903"><span class="lineNum">    8903 </span>            : </a>
<a name="8904"><span class="lineNum">    8904 </span>            : #ifdef CONFIG_NUMA_BALANCING</a>
<a name="8905"><span class="lineNum">    8905 </span>            : static inline enum fbq_type fbq_classify_group(struct sg_lb_stats *sgs)</a>
<a name="8906"><span class="lineNum">    8906 </span>            : {</a>
<a name="8907"><span class="lineNum">    8907 </span>            :         if (sgs-&gt;sum_h_nr_running &gt; sgs-&gt;nr_numa_running)</a>
<a name="8908"><span class="lineNum">    8908 </span>            :                 return regular;</a>
<a name="8909"><span class="lineNum">    8909 </span>            :         if (sgs-&gt;sum_h_nr_running &gt; sgs-&gt;nr_preferred_running)</a>
<a name="8910"><span class="lineNum">    8910 </span>            :                 return remote;</a>
<a name="8911"><span class="lineNum">    8911 </span>            :         return all;</a>
<a name="8912"><span class="lineNum">    8912 </span>            : }</a>
<a name="8913"><span class="lineNum">    8913 </span>            : </a>
<a name="8914"><span class="lineNum">    8914 </span>            : static inline enum fbq_type fbq_classify_rq(struct rq *rq)</a>
<a name="8915"><span class="lineNum">    8915 </span>            : {</a>
<a name="8916"><span class="lineNum">    8916 </span>            :         if (rq-&gt;nr_running &gt; rq-&gt;nr_numa_running)</a>
<a name="8917"><span class="lineNum">    8917 </span>            :                 return regular;</a>
<a name="8918"><span class="lineNum">    8918 </span>            :         if (rq-&gt;nr_running &gt; rq-&gt;nr_preferred_running)</a>
<a name="8919"><span class="lineNum">    8919 </span>            :                 return remote;</a>
<a name="8920"><span class="lineNum">    8920 </span>            :         return all;</a>
<a name="8921"><span class="lineNum">    8921 </span>            : }</a>
<a name="8922"><span class="lineNum">    8922 </span>            : #else</a>
<a name="8923"><span class="lineNum">    8923 </span>            : static inline enum fbq_type fbq_classify_group(struct sg_lb_stats *sgs)</a>
<a name="8924"><span class="lineNum">    8924 </span>            : {</a>
<a name="8925"><span class="lineNum">    8925 </span>            :         return all;</a>
<a name="8926"><span class="lineNum">    8926 </span>            : }</a>
<a name="8927"><span class="lineNum">    8927 </span>            : </a>
<a name="8928"><span class="lineNum">    8928 </span>            : static inline enum fbq_type fbq_classify_rq(struct rq *rq)</a>
<a name="8929"><span class="lineNum">    8929 </span>            : {</a>
<a name="8930"><span class="lineNum">    8930 </span>            :         return regular;</a>
<a name="8931"><span class="lineNum">    8931 </span>            : }</a>
<a name="8932"><span class="lineNum">    8932 </span>            : #endif /* CONFIG_NUMA_BALANCING */</a>
<a name="8933"><span class="lineNum">    8933 </span>            : </a>
<a name="8934"><span class="lineNum">    8934 </span>            : </a>
<a name="8935"><span class="lineNum">    8935 </span>            : struct sg_lb_stats;</a>
<a name="8936"><span class="lineNum">    8936 </span>            : </a>
<a name="8937"><span class="lineNum">    8937 </span>            : /*</a>
<a name="8938"><span class="lineNum">    8938 </span>            :  * task_running_on_cpu - return 1 if @p is running on @cpu.</a>
<a name="8939"><span class="lineNum">    8939 </span>            :  */</a>
<a name="8940"><span class="lineNum">    8940 </span>            : </a>
<a name="8941"><span class="lineNum">    8941 </span>            : static unsigned int task_running_on_cpu(int cpu, struct task_struct *p)</a>
<a name="8942"><span class="lineNum">    8942 </span>            : {</a>
<a name="8943"><span class="lineNum">    8943 </span>            :         /* Task has no contribution or is new */</a>
<a name="8944"><span class="lineNum">    8944 </span>            :         if (cpu != task_cpu(p) || !READ_ONCE(p-&gt;se.avg.last_update_time))</a>
<a name="8945"><span class="lineNum">    8945 </span>            :                 return 0;</a>
<a name="8946"><span class="lineNum">    8946 </span>            : </a>
<a name="8947"><span class="lineNum">    8947 </span>            :         if (task_on_rq_queued(p))</a>
<a name="8948"><span class="lineNum">    8948 </span>            :                 return 1;</a>
<a name="8949"><span class="lineNum">    8949 </span>            : </a>
<a name="8950"><span class="lineNum">    8950 </span>            :         return 0;</a>
<a name="8951"><span class="lineNum">    8951 </span>            : }</a>
<a name="8952"><span class="lineNum">    8952 </span>            : </a>
<a name="8953"><span class="lineNum">    8953 </span>            : /**</a>
<a name="8954"><span class="lineNum">    8954 </span>            :  * idle_cpu_without - would a given CPU be idle without p ?</a>
<a name="8955"><span class="lineNum">    8955 </span>            :  * @cpu: the processor on which idleness is tested.</a>
<a name="8956"><span class="lineNum">    8956 </span>            :  * @p: task which should be ignored.</a>
<a name="8957"><span class="lineNum">    8957 </span>            :  *</a>
<a name="8958"><span class="lineNum">    8958 </span>            :  * Return: 1 if the CPU would be idle. 0 otherwise.</a>
<a name="8959"><span class="lineNum">    8959 </span>            :  */</a>
<a name="8960"><span class="lineNum">    8960 </span>            : static int idle_cpu_without(int cpu, struct task_struct *p)</a>
<a name="8961"><span class="lineNum">    8961 </span>            : {</a>
<a name="8962"><span class="lineNum">    8962 </span>            :         struct rq *rq = cpu_rq(cpu);</a>
<a name="8963"><span class="lineNum">    8963 </span>            : </a>
<a name="8964"><span class="lineNum">    8964 </span>            :         if (rq-&gt;curr != rq-&gt;idle &amp;&amp; rq-&gt;curr != p)</a>
<a name="8965"><span class="lineNum">    8965 </span>            :                 return 0;</a>
<a name="8966"><span class="lineNum">    8966 </span>            : </a>
<a name="8967"><span class="lineNum">    8967 </span>            :         /*</a>
<a name="8968"><span class="lineNum">    8968 </span>            :          * rq-&gt;nr_running can't be used but an updated version without the</a>
<a name="8969"><span class="lineNum">    8969 </span>            :          * impact of p on cpu must be used instead. The updated nr_running</a>
<a name="8970"><span class="lineNum">    8970 </span>            :          * be computed and tested before calling idle_cpu_without().</a>
<a name="8971"><span class="lineNum">    8971 </span>            :          */</a>
<a name="8972"><span class="lineNum">    8972 </span>            : </a>
<a name="8973"><span class="lineNum">    8973 </span>            : #ifdef CONFIG_SMP</a>
<a name="8974"><span class="lineNum">    8974 </span>            :         if (rq-&gt;ttwu_pending)</a>
<a name="8975"><span class="lineNum">    8975 </span>            :                 return 0;</a>
<a name="8976"><span class="lineNum">    8976 </span>            : #endif</a>
<a name="8977"><span class="lineNum">    8977 </span>            : </a>
<a name="8978"><span class="lineNum">    8978 </span>            :         return 1;</a>
<a name="8979"><span class="lineNum">    8979 </span>            : }</a>
<a name="8980"><span class="lineNum">    8980 </span>            : </a>
<a name="8981"><span class="lineNum">    8981 </span>            : /*</a>
<a name="8982"><span class="lineNum">    8982 </span>            :  * update_sg_wakeup_stats - Update sched_group's statistics for wakeup.</a>
<a name="8983"><span class="lineNum">    8983 </span>            :  * @sd: The sched_domain level to look for idlest group.</a>
<a name="8984"><span class="lineNum">    8984 </span>            :  * @group: sched_group whose statistics are to be updated.</a>
<a name="8985"><span class="lineNum">    8985 </span>            :  * @sgs: variable to hold the statistics for this group.</a>
<a name="8986"><span class="lineNum">    8986 </span>            :  * @p: The task for which we look for the idlest group/CPU.</a>
<a name="8987"><span class="lineNum">    8987 </span>            :  */</a>
<a name="8988"><span class="lineNum">    8988 </span>            : static inline void update_sg_wakeup_stats(struct sched_domain *sd,</a>
<a name="8989"><span class="lineNum">    8989 </span>            :                                           struct sched_group *group,</a>
<a name="8990"><span class="lineNum">    8990 </span>            :                                           struct sg_lb_stats *sgs,</a>
<a name="8991"><span class="lineNum">    8991 </span>            :                                           struct task_struct *p)</a>
<a name="8992"><span class="lineNum">    8992 </span>            : {</a>
<a name="8993"><span class="lineNum">    8993 </span>            :         int i, nr_running;</a>
<a name="8994"><span class="lineNum">    8994 </span>            : </a>
<a name="8995"><span class="lineNum">    8995 </span>            :         memset(sgs, 0, sizeof(*sgs));</a>
<a name="8996"><span class="lineNum">    8996 </span>            : </a>
<a name="8997"><span class="lineNum">    8997 </span>            :         for_each_cpu(i, sched_group_span(group)) {</a>
<a name="8998"><span class="lineNum">    8998 </span>            :                 struct rq *rq = cpu_rq(i);</a>
<a name="8999"><span class="lineNum">    8999 </span>            :                 unsigned int local;</a>
<a name="9000"><span class="lineNum">    9000 </span>            : </a>
<a name="9001"><span class="lineNum">    9001 </span>            :                 sgs-&gt;group_load += cpu_load_without(rq, p);</a>
<a name="9002"><span class="lineNum">    9002 </span>            :                 sgs-&gt;group_util += cpu_util_without(i, p);</a>
<a name="9003"><span class="lineNum">    9003 </span>            :                 sgs-&gt;group_runnable += cpu_runnable_without(rq, p);</a>
<a name="9004"><span class="lineNum">    9004 </span>            :                 local = task_running_on_cpu(i, p);</a>
<a name="9005"><span class="lineNum">    9005 </span>            :                 sgs-&gt;sum_h_nr_running += rq-&gt;cfs.h_nr_running - local;</a>
<a name="9006"><span class="lineNum">    9006 </span>            : </a>
<a name="9007"><span class="lineNum">    9007 </span>            :                 nr_running = rq-&gt;nr_running - local;</a>
<a name="9008"><span class="lineNum">    9008 </span>            :                 sgs-&gt;sum_nr_running += nr_running;</a>
<a name="9009"><span class="lineNum">    9009 </span>            : </a>
<a name="9010"><span class="lineNum">    9010 </span>            :                 /*</a>
<a name="9011"><span class="lineNum">    9011 </span>            :                  * No need to call idle_cpu_without() if nr_running is not 0</a>
<a name="9012"><span class="lineNum">    9012 </span>            :                  */</a>
<a name="9013"><span class="lineNum">    9013 </span>            :                 if (!nr_running &amp;&amp; idle_cpu_without(i, p))</a>
<a name="9014"><span class="lineNum">    9014 </span>            :                         sgs-&gt;idle_cpus++;</a>
<a name="9015"><span class="lineNum">    9015 </span>            : </a>
<a name="9016"><span class="lineNum">    9016 </span>            :         }</a>
<a name="9017"><span class="lineNum">    9017 </span>            : </a>
<a name="9018"><span class="lineNum">    9018 </span>            :         /* Check if task fits in the group */</a>
<a name="9019"><span class="lineNum">    9019 </span>            :         if (sd-&gt;flags &amp; SD_ASYM_CPUCAPACITY &amp;&amp;</a>
<a name="9020"><span class="lineNum">    9020 </span>            :             !task_fits_capacity(p, group-&gt;sgc-&gt;max_capacity)) {</a>
<a name="9021"><span class="lineNum">    9021 </span>            :                 sgs-&gt;group_misfit_task_load = 1;</a>
<a name="9022"><span class="lineNum">    9022 </span>            :         }</a>
<a name="9023"><span class="lineNum">    9023 </span>            : </a>
<a name="9024"><span class="lineNum">    9024 </span>            :         sgs-&gt;group_capacity = group-&gt;sgc-&gt;capacity;</a>
<a name="9025"><span class="lineNum">    9025 </span>            : </a>
<a name="9026"><span class="lineNum">    9026 </span>            :         sgs-&gt;group_weight = group-&gt;group_weight;</a>
<a name="9027"><span class="lineNum">    9027 </span>            : </a>
<a name="9028"><span class="lineNum">    9028 </span>            :         sgs-&gt;group_type = group_classify(sd-&gt;imbalance_pct, group, sgs);</a>
<a name="9029"><span class="lineNum">    9029 </span>            : </a>
<a name="9030"><span class="lineNum">    9030 </span>            :         /*</a>
<a name="9031"><span class="lineNum">    9031 </span>            :          * Computing avg_load makes sense only when group is fully busy or</a>
<a name="9032"><span class="lineNum">    9032 </span>            :          * overloaded</a>
<a name="9033"><span class="lineNum">    9033 </span>            :          */</a>
<a name="9034"><span class="lineNum">    9034 </span>            :         if (sgs-&gt;group_type == group_fully_busy ||</a>
<a name="9035"><span class="lineNum">    9035 </span>            :                 sgs-&gt;group_type == group_overloaded)</a>
<a name="9036"><span class="lineNum">    9036 </span>            :                 sgs-&gt;avg_load = (sgs-&gt;group_load * SCHED_CAPACITY_SCALE) /</a>
<a name="9037"><span class="lineNum">    9037 </span>            :                                 sgs-&gt;group_capacity;</a>
<a name="9038"><span class="lineNum">    9038 </span>            : }</a>
<a name="9039"><span class="lineNum">    9039 </span>            : </a>
<a name="9040"><span class="lineNum">    9040 </span>            : static bool update_pick_idlest(struct sched_group *idlest,</a>
<a name="9041"><span class="lineNum">    9041 </span>            :                                struct sg_lb_stats *idlest_sgs,</a>
<a name="9042"><span class="lineNum">    9042 </span>            :                                struct sched_group *group,</a>
<a name="9043"><span class="lineNum">    9043 </span>            :                                struct sg_lb_stats *sgs)</a>
<a name="9044"><span class="lineNum">    9044 </span>            : {</a>
<a name="9045"><span class="lineNum">    9045 </span>            :         if (sgs-&gt;group_type &lt; idlest_sgs-&gt;group_type)</a>
<a name="9046"><span class="lineNum">    9046 </span>            :                 return true;</a>
<a name="9047"><span class="lineNum">    9047 </span>            : </a>
<a name="9048"><span class="lineNum">    9048 </span>            :         if (sgs-&gt;group_type &gt; idlest_sgs-&gt;group_type)</a>
<a name="9049"><span class="lineNum">    9049 </span>            :                 return false;</a>
<a name="9050"><span class="lineNum">    9050 </span>            : </a>
<a name="9051"><span class="lineNum">    9051 </span>            :         /*</a>
<a name="9052"><span class="lineNum">    9052 </span>            :          * The candidate and the current idlest group are the same type of</a>
<a name="9053"><span class="lineNum">    9053 </span>            :          * group. Let check which one is the idlest according to the type.</a>
<a name="9054"><span class="lineNum">    9054 </span>            :          */</a>
<a name="9055"><span class="lineNum">    9055 </span>            : </a>
<a name="9056"><span class="lineNum">    9056 </span>            :         switch (sgs-&gt;group_type) {</a>
<a name="9057"><span class="lineNum">    9057 </span>            :         case group_overloaded:</a>
<a name="9058"><span class="lineNum">    9058 </span>            :         case group_fully_busy:</a>
<a name="9059"><span class="lineNum">    9059 </span>            :                 /* Select the group with lowest avg_load. */</a>
<a name="9060"><span class="lineNum">    9060 </span>            :                 if (idlest_sgs-&gt;avg_load &lt;= sgs-&gt;avg_load)</a>
<a name="9061"><span class="lineNum">    9061 </span>            :                         return false;</a>
<a name="9062"><span class="lineNum">    9062 </span>            :                 break;</a>
<a name="9063"><span class="lineNum">    9063 </span>            : </a>
<a name="9064"><span class="lineNum">    9064 </span>            :         case group_imbalanced:</a>
<a name="9065"><span class="lineNum">    9065 </span>            :         case group_asym_packing:</a>
<a name="9066"><span class="lineNum">    9066 </span>            :                 /* Those types are not used in the slow wakeup path */</a>
<a name="9067"><span class="lineNum">    9067 </span>            :                 return false;</a>
<a name="9068"><span class="lineNum">    9068 </span>            : </a>
<a name="9069"><span class="lineNum">    9069 </span>            :         case group_misfit_task:</a>
<a name="9070"><span class="lineNum">    9070 </span>            :                 /* Select group with the highest max capacity */</a>
<a name="9071"><span class="lineNum">    9071 </span>            :                 if (idlest-&gt;sgc-&gt;max_capacity &gt;= group-&gt;sgc-&gt;max_capacity)</a>
<a name="9072"><span class="lineNum">    9072 </span>            :                         return false;</a>
<a name="9073"><span class="lineNum">    9073 </span>            :                 break;</a>
<a name="9074"><span class="lineNum">    9074 </span>            : </a>
<a name="9075"><span class="lineNum">    9075 </span>            :         case group_has_spare:</a>
<a name="9076"><span class="lineNum">    9076 </span>            :                 /* Select group with most idle CPUs */</a>
<a name="9077"><span class="lineNum">    9077 </span>            :                 if (idlest_sgs-&gt;idle_cpus &gt; sgs-&gt;idle_cpus)</a>
<a name="9078"><span class="lineNum">    9078 </span>            :                         return false;</a>
<a name="9079"><span class="lineNum">    9079 </span>            : </a>
<a name="9080"><span class="lineNum">    9080 </span>            :                 /* Select group with lowest group_util */</a>
<a name="9081"><span class="lineNum">    9081 </span>            :                 if (idlest_sgs-&gt;idle_cpus == sgs-&gt;idle_cpus &amp;&amp;</a>
<a name="9082"><span class="lineNum">    9082 </span>            :                         idlest_sgs-&gt;group_util &lt;= sgs-&gt;group_util)</a>
<a name="9083"><span class="lineNum">    9083 </span>            :                         return false;</a>
<a name="9084"><span class="lineNum">    9084 </span>            : </a>
<a name="9085"><span class="lineNum">    9085 </span>            :                 break;</a>
<a name="9086"><span class="lineNum">    9086 </span>            :         }</a>
<a name="9087"><span class="lineNum">    9087 </span>            : </a>
<a name="9088"><span class="lineNum">    9088 </span>            :         return true;</a>
<a name="9089"><span class="lineNum">    9089 </span>            : }</a>
<a name="9090"><span class="lineNum">    9090 </span>            : </a>
<a name="9091"><span class="lineNum">    9091 </span>            : /*</a>
<a name="9092"><span class="lineNum">    9092 </span>            :  * Allow a NUMA imbalance if busy CPUs is less than 25% of the domain.</a>
<a name="9093"><span class="lineNum">    9093 </span>            :  * This is an approximation as the number of running tasks may not be</a>
<a name="9094"><span class="lineNum">    9094 </span>            :  * related to the number of busy CPUs due to sched_setaffinity.</a>
<a name="9095"><span class="lineNum">    9095 </span>            :  */</a>
<a name="9096"><span class="lineNum">    9096 </span>            : static inline bool allow_numa_imbalance(int running, int imb_numa_nr)</a>
<a name="9097"><span class="lineNum">    9097 </span>            : {</a>
<a name="9098"><span class="lineNum">    9098 </span>            :         return running &lt;= imb_numa_nr;</a>
<a name="9099"><span class="lineNum">    9099 </span>            : }</a>
<a name="9100"><span class="lineNum">    9100 </span>            : </a>
<a name="9101"><span class="lineNum">    9101 </span>            : /*</a>
<a name="9102"><span class="lineNum">    9102 </span>            :  * find_idlest_group() finds and returns the least busy CPU group within the</a>
<a name="9103"><span class="lineNum">    9103 </span>            :  * domain.</a>
<a name="9104"><span class="lineNum">    9104 </span>            :  *</a>
<a name="9105"><span class="lineNum">    9105 </span>            :  * Assumes p is allowed on at least one CPU in sd.</a>
<a name="9106"><span class="lineNum">    9106 </span>            :  */</a>
<a name="9107"><span class="lineNum">    9107 </span>            : static struct sched_group *</a>
<a name="9108"><span class="lineNum">    9108 </span>            : find_idlest_group(struct sched_domain *sd, struct task_struct *p, int this_cpu)</a>
<a name="9109"><span class="lineNum">    9109 </span>            : {</a>
<a name="9110"><span class="lineNum">    9110 </span>            :         struct sched_group *idlest = NULL, *local = NULL, *group = sd-&gt;groups;</a>
<a name="9111"><span class="lineNum">    9111 </span>            :         struct sg_lb_stats local_sgs, tmp_sgs;</a>
<a name="9112"><span class="lineNum">    9112 </span>            :         struct sg_lb_stats *sgs;</a>
<a name="9113"><span class="lineNum">    9113 </span>            :         unsigned long imbalance;</a>
<a name="9114"><span class="lineNum">    9114 </span>            :         struct sg_lb_stats idlest_sgs = {</a>
<a name="9115"><span class="lineNum">    9115 </span>            :                         .avg_load = UINT_MAX,</a>
<a name="9116"><span class="lineNum">    9116 </span>            :                         .group_type = group_overloaded,</a>
<a name="9117"><span class="lineNum">    9117 </span>            :         };</a>
<a name="9118"><span class="lineNum">    9118 </span>            : </a>
<a name="9119"><span class="lineNum">    9119 </span>            :         do {</a>
<a name="9120"><span class="lineNum">    9120 </span>            :                 int local_group;</a>
<a name="9121"><span class="lineNum">    9121 </span>            : </a>
<a name="9122"><span class="lineNum">    9122 </span>            :                 /* Skip over this group if it has no CPUs allowed */</a>
<a name="9123"><span class="lineNum">    9123 </span>            :                 if (!cpumask_intersects(sched_group_span(group),</a>
<a name="9124"><span class="lineNum">    9124 </span>            :                                         p-&gt;cpus_ptr))</a>
<a name="9125"><span class="lineNum">    9125 </span>            :                         continue;</a>
<a name="9126"><span class="lineNum">    9126 </span>            : </a>
<a name="9127"><span class="lineNum">    9127 </span>            :                 /* Skip over this group if no cookie matched */</a>
<a name="9128"><span class="lineNum">    9128 </span>            :                 if (!sched_group_cookie_match(cpu_rq(this_cpu), p, group))</a>
<a name="9129"><span class="lineNum">    9129 </span>            :                         continue;</a>
<a name="9130"><span class="lineNum">    9130 </span>            : </a>
<a name="9131"><span class="lineNum">    9131 </span>            :                 local_group = cpumask_test_cpu(this_cpu,</a>
<a name="9132"><span class="lineNum">    9132 </span>            :                                                sched_group_span(group));</a>
<a name="9133"><span class="lineNum">    9133 </span>            : </a>
<a name="9134"><span class="lineNum">    9134 </span>            :                 if (local_group) {</a>
<a name="9135"><span class="lineNum">    9135 </span>            :                         sgs = &amp;local_sgs;</a>
<a name="9136"><span class="lineNum">    9136 </span>            :                         local = group;</a>
<a name="9137"><span class="lineNum">    9137 </span>            :                 } else {</a>
<a name="9138"><span class="lineNum">    9138 </span>            :                         sgs = &amp;tmp_sgs;</a>
<a name="9139"><span class="lineNum">    9139 </span>            :                 }</a>
<a name="9140"><span class="lineNum">    9140 </span>            : </a>
<a name="9141"><span class="lineNum">    9141 </span>            :                 update_sg_wakeup_stats(sd, group, sgs, p);</a>
<a name="9142"><span class="lineNum">    9142 </span>            : </a>
<a name="9143"><span class="lineNum">    9143 </span>            :                 if (!local_group &amp;&amp; update_pick_idlest(idlest, &amp;idlest_sgs, group, sgs)) {</a>
<a name="9144"><span class="lineNum">    9144 </span>            :                         idlest = group;</a>
<a name="9145"><span class="lineNum">    9145 </span>            :                         idlest_sgs = *sgs;</a>
<a name="9146"><span class="lineNum">    9146 </span>            :                 }</a>
<a name="9147"><span class="lineNum">    9147 </span>            : </a>
<a name="9148"><span class="lineNum">    9148 </span>            :         } while (group = group-&gt;next, group != sd-&gt;groups);</a>
<a name="9149"><span class="lineNum">    9149 </span>            : </a>
<a name="9150"><span class="lineNum">    9150 </span>            : </a>
<a name="9151"><span class="lineNum">    9151 </span>            :         /* There is no idlest group to push tasks to */</a>
<a name="9152"><span class="lineNum">    9152 </span>            :         if (!idlest)</a>
<a name="9153"><span class="lineNum">    9153 </span>            :                 return NULL;</a>
<a name="9154"><span class="lineNum">    9154 </span>            : </a>
<a name="9155"><span class="lineNum">    9155 </span>            :         /* The local group has been skipped because of CPU affinity */</a>
<a name="9156"><span class="lineNum">    9156 </span>            :         if (!local)</a>
<a name="9157"><span class="lineNum">    9157 </span>            :                 return idlest;</a>
<a name="9158"><span class="lineNum">    9158 </span>            : </a>
<a name="9159"><span class="lineNum">    9159 </span>            :         /*</a>
<a name="9160"><span class="lineNum">    9160 </span>            :          * If the local group is idler than the selected idlest group</a>
<a name="9161"><span class="lineNum">    9161 </span>            :          * don't try and push the task.</a>
<a name="9162"><span class="lineNum">    9162 </span>            :          */</a>
<a name="9163"><span class="lineNum">    9163 </span>            :         if (local_sgs.group_type &lt; idlest_sgs.group_type)</a>
<a name="9164"><span class="lineNum">    9164 </span>            :                 return NULL;</a>
<a name="9165"><span class="lineNum">    9165 </span>            : </a>
<a name="9166"><span class="lineNum">    9166 </span>            :         /*</a>
<a name="9167"><span class="lineNum">    9167 </span>            :          * If the local group is busier than the selected idlest group</a>
<a name="9168"><span class="lineNum">    9168 </span>            :          * try and push the task.</a>
<a name="9169"><span class="lineNum">    9169 </span>            :          */</a>
<a name="9170"><span class="lineNum">    9170 </span>            :         if (local_sgs.group_type &gt; idlest_sgs.group_type)</a>
<a name="9171"><span class="lineNum">    9171 </span>            :                 return idlest;</a>
<a name="9172"><span class="lineNum">    9172 </span>            : </a>
<a name="9173"><span class="lineNum">    9173 </span>            :         switch (local_sgs.group_type) {</a>
<a name="9174"><span class="lineNum">    9174 </span>            :         case group_overloaded:</a>
<a name="9175"><span class="lineNum">    9175 </span>            :         case group_fully_busy:</a>
<a name="9176"><span class="lineNum">    9176 </span>            : </a>
<a name="9177"><span class="lineNum">    9177 </span>            :                 /* Calculate allowed imbalance based on load */</a>
<a name="9178"><span class="lineNum">    9178 </span>            :                 imbalance = scale_load_down(NICE_0_LOAD) *</a>
<a name="9179"><span class="lineNum">    9179 </span>            :                                 (sd-&gt;imbalance_pct-100) / 100;</a>
<a name="9180"><span class="lineNum">    9180 </span>            : </a>
<a name="9181"><span class="lineNum">    9181 </span>            :                 /*</a>
<a name="9182"><span class="lineNum">    9182 </span>            :                  * When comparing groups across NUMA domains, it's possible for</a>
<a name="9183"><span class="lineNum">    9183 </span>            :                  * the local domain to be very lightly loaded relative to the</a>
<a name="9184"><span class="lineNum">    9184 </span>            :                  * remote domains but &quot;imbalance&quot; skews the comparison making</a>
<a name="9185"><span class="lineNum">    9185 </span>            :                  * remote CPUs look much more favourable. When considering</a>
<a name="9186"><span class="lineNum">    9186 </span>            :                  * cross-domain, add imbalance to the load on the remote node</a>
<a name="9187"><span class="lineNum">    9187 </span>            :                  * and consider staying local.</a>
<a name="9188"><span class="lineNum">    9188 </span>            :                  */</a>
<a name="9189"><span class="lineNum">    9189 </span>            : </a>
<a name="9190"><span class="lineNum">    9190 </span>            :                 if ((sd-&gt;flags &amp; SD_NUMA) &amp;&amp;</a>
<a name="9191"><span class="lineNum">    9191 </span>            :                     ((idlest_sgs.avg_load + imbalance) &gt;= local_sgs.avg_load))</a>
<a name="9192"><span class="lineNum">    9192 </span>            :                         return NULL;</a>
<a name="9193"><span class="lineNum">    9193 </span>            : </a>
<a name="9194"><span class="lineNum">    9194 </span>            :                 /*</a>
<a name="9195"><span class="lineNum">    9195 </span>            :                  * If the local group is less loaded than the selected</a>
<a name="9196"><span class="lineNum">    9196 </span>            :                  * idlest group don't try and push any tasks.</a>
<a name="9197"><span class="lineNum">    9197 </span>            :                  */</a>
<a name="9198"><span class="lineNum">    9198 </span>            :                 if (idlest_sgs.avg_load &gt;= (local_sgs.avg_load + imbalance))</a>
<a name="9199"><span class="lineNum">    9199 </span>            :                         return NULL;</a>
<a name="9200"><span class="lineNum">    9200 </span>            : </a>
<a name="9201"><span class="lineNum">    9201 </span>            :                 if (100 * local_sgs.avg_load &lt;= sd-&gt;imbalance_pct * idlest_sgs.avg_load)</a>
<a name="9202"><span class="lineNum">    9202 </span>            :                         return NULL;</a>
<a name="9203"><span class="lineNum">    9203 </span>            :                 break;</a>
<a name="9204"><span class="lineNum">    9204 </span>            : </a>
<a name="9205"><span class="lineNum">    9205 </span>            :         case group_imbalanced:</a>
<a name="9206"><span class="lineNum">    9206 </span>            :         case group_asym_packing:</a>
<a name="9207"><span class="lineNum">    9207 </span>            :                 /* Those type are not used in the slow wakeup path */</a>
<a name="9208"><span class="lineNum">    9208 </span>            :                 return NULL;</a>
<a name="9209"><span class="lineNum">    9209 </span>            : </a>
<a name="9210"><span class="lineNum">    9210 </span>            :         case group_misfit_task:</a>
<a name="9211"><span class="lineNum">    9211 </span>            :                 /* Select group with the highest max capacity */</a>
<a name="9212"><span class="lineNum">    9212 </span>            :                 if (local-&gt;sgc-&gt;max_capacity &gt;= idlest-&gt;sgc-&gt;max_capacity)</a>
<a name="9213"><span class="lineNum">    9213 </span>            :                         return NULL;</a>
<a name="9214"><span class="lineNum">    9214 </span>            :                 break;</a>
<a name="9215"><span class="lineNum">    9215 </span>            : </a>
<a name="9216"><span class="lineNum">    9216 </span>            :         case group_has_spare:</a>
<a name="9217"><span class="lineNum">    9217 </span>            :                 if (sd-&gt;flags &amp; SD_NUMA) {</a>
<a name="9218"><span class="lineNum">    9218 </span>            : #ifdef CONFIG_NUMA_BALANCING</a>
<a name="9219"><span class="lineNum">    9219 </span>            :                         int idlest_cpu;</a>
<a name="9220"><span class="lineNum">    9220 </span>            :                         /*</a>
<a name="9221"><span class="lineNum">    9221 </span>            :                          * If there is spare capacity at NUMA, try to select</a>
<a name="9222"><span class="lineNum">    9222 </span>            :                          * the preferred node</a>
<a name="9223"><span class="lineNum">    9223 </span>            :                          */</a>
<a name="9224"><span class="lineNum">    9224 </span>            :                         if (cpu_to_node(this_cpu) == p-&gt;numa_preferred_nid)</a>
<a name="9225"><span class="lineNum">    9225 </span>            :                                 return NULL;</a>
<a name="9226"><span class="lineNum">    9226 </span>            : </a>
<a name="9227"><span class="lineNum">    9227 </span>            :                         idlest_cpu = cpumask_first(sched_group_span(idlest));</a>
<a name="9228"><span class="lineNum">    9228 </span>            :                         if (cpu_to_node(idlest_cpu) == p-&gt;numa_preferred_nid)</a>
<a name="9229"><span class="lineNum">    9229 </span>            :                                 return idlest;</a>
<a name="9230"><span class="lineNum">    9230 </span>            : #endif</a>
<a name="9231"><span class="lineNum">    9231 </span>            :                         /*</a>
<a name="9232"><span class="lineNum">    9232 </span>            :                          * Otherwise, keep the task close to the wakeup source</a>
<a name="9233"><span class="lineNum">    9233 </span>            :                          * and improve locality if the number of running tasks</a>
<a name="9234"><span class="lineNum">    9234 </span>            :                          * would remain below threshold where an imbalance is</a>
<a name="9235"><span class="lineNum">    9235 </span>            :                          * allowed. If there is a real need of migration,</a>
<a name="9236"><span class="lineNum">    9236 </span>            :                          * periodic load balance will take care of it.</a>
<a name="9237"><span class="lineNum">    9237 </span>            :                          */</a>
<a name="9238"><span class="lineNum">    9238 </span>            :                         if (allow_numa_imbalance(local_sgs.sum_nr_running + 1, sd-&gt;imb_numa_nr))</a>
<a name="9239"><span class="lineNum">    9239 </span>            :                                 return NULL;</a>
<a name="9240"><span class="lineNum">    9240 </span>            :                 }</a>
<a name="9241"><span class="lineNum">    9241 </span>            : </a>
<a name="9242"><span class="lineNum">    9242 </span>            :                 /*</a>
<a name="9243"><span class="lineNum">    9243 </span>            :                  * Select group with highest number of idle CPUs. We could also</a>
<a name="9244"><span class="lineNum">    9244 </span>            :                  * compare the utilization which is more stable but it can end</a>
<a name="9245"><span class="lineNum">    9245 </span>            :                  * up that the group has less spare capacity but finally more</a>
<a name="9246"><span class="lineNum">    9246 </span>            :                  * idle CPUs which means more opportunity to run task.</a>
<a name="9247"><span class="lineNum">    9247 </span>            :                  */</a>
<a name="9248"><span class="lineNum">    9248 </span>            :                 if (local_sgs.idle_cpus &gt;= idlest_sgs.idle_cpus)</a>
<a name="9249"><span class="lineNum">    9249 </span>            :                         return NULL;</a>
<a name="9250"><span class="lineNum">    9250 </span>            :                 break;</a>
<a name="9251"><span class="lineNum">    9251 </span>            :         }</a>
<a name="9252"><span class="lineNum">    9252 </span>            : </a>
<a name="9253"><span class="lineNum">    9253 </span>            :         return idlest;</a>
<a name="9254"><span class="lineNum">    9254 </span>            : }</a>
<a name="9255"><span class="lineNum">    9255 </span>            : </a>
<a name="9256"><span class="lineNum">    9256 </span>            : /**</a>
<a name="9257"><span class="lineNum">    9257 </span>            :  * update_sd_lb_stats - Update sched_domain's statistics for load balancing.</a>
<a name="9258"><span class="lineNum">    9258 </span>            :  * @env: The load balancing environment.</a>
<a name="9259"><span class="lineNum">    9259 </span>            :  * @sds: variable to hold the statistics for this sched_domain.</a>
<a name="9260"><span class="lineNum">    9260 </span>            :  */</a>
<a name="9261"><span class="lineNum">    9261 </span>            : </a>
<a name="9262"><span class="lineNum">    9262 </span>            : static inline void update_sd_lb_stats(struct lb_env *env, struct sd_lb_stats *sds)</a>
<a name="9263"><span class="lineNum">    9263 </span>            : {</a>
<a name="9264"><span class="lineNum">    9264 </span>            :         struct sched_domain *child = env-&gt;sd-&gt;child;</a>
<a name="9265"><span class="lineNum">    9265 </span>            :         struct sched_group *sg = env-&gt;sd-&gt;groups;</a>
<a name="9266"><span class="lineNum">    9266 </span>            :         struct sg_lb_stats *local = &amp;sds-&gt;local_stat;</a>
<a name="9267"><span class="lineNum">    9267 </span>            :         struct sg_lb_stats tmp_sgs;</a>
<a name="9268"><span class="lineNum">    9268 </span>            :         int sg_status = 0;</a>
<a name="9269"><span class="lineNum">    9269 </span>            : </a>
<a name="9270"><span class="lineNum">    9270 </span>            :         do {</a>
<a name="9271"><span class="lineNum">    9271 </span>            :                 struct sg_lb_stats *sgs = &amp;tmp_sgs;</a>
<a name="9272"><span class="lineNum">    9272 </span>            :                 int local_group;</a>
<a name="9273"><span class="lineNum">    9273 </span>            : </a>
<a name="9274"><span class="lineNum">    9274 </span>            :                 local_group = cpumask_test_cpu(env-&gt;dst_cpu, sched_group_span(sg));</a>
<a name="9275"><span class="lineNum">    9275 </span>            :                 if (local_group) {</a>
<a name="9276"><span class="lineNum">    9276 </span>            :                         sds-&gt;local = sg;</a>
<a name="9277"><span class="lineNum">    9277 </span>            :                         sgs = local;</a>
<a name="9278"><span class="lineNum">    9278 </span>            : </a>
<a name="9279"><span class="lineNum">    9279 </span>            :                         if (env-&gt;idle != CPU_NEWLY_IDLE ||</a>
<a name="9280"><span class="lineNum">    9280 </span>            :                             time_after_eq(jiffies, sg-&gt;sgc-&gt;next_update))</a>
<a name="9281"><span class="lineNum">    9281 </span>            :                                 update_group_capacity(env-&gt;sd, env-&gt;dst_cpu);</a>
<a name="9282"><span class="lineNum">    9282 </span>            :                 }</a>
<a name="9283"><span class="lineNum">    9283 </span>            : </a>
<a name="9284"><span class="lineNum">    9284 </span>            :                 update_sg_lb_stats(env, sds, sg, sgs, &amp;sg_status);</a>
<a name="9285"><span class="lineNum">    9285 </span>            : </a>
<a name="9286"><span class="lineNum">    9286 </span>            :                 if (local_group)</a>
<a name="9287"><span class="lineNum">    9287 </span>            :                         goto next_group;</a>
<a name="9288"><span class="lineNum">    9288 </span>            : </a>
<a name="9289"><span class="lineNum">    9289 </span>            : </a>
<a name="9290"><span class="lineNum">    9290 </span>            :                 if (update_sd_pick_busiest(env, sds, sg, sgs)) {</a>
<a name="9291"><span class="lineNum">    9291 </span>            :                         sds-&gt;busiest = sg;</a>
<a name="9292"><span class="lineNum">    9292 </span>            :                         sds-&gt;busiest_stat = *sgs;</a>
<a name="9293"><span class="lineNum">    9293 </span>            :                 }</a>
<a name="9294"><span class="lineNum">    9294 </span>            : </a>
<a name="9295"><span class="lineNum">    9295 </span>            : next_group:</a>
<a name="9296"><span class="lineNum">    9296 </span>            :                 /* Now, start updating sd_lb_stats */</a>
<a name="9297"><span class="lineNum">    9297 </span>            :                 sds-&gt;total_load += sgs-&gt;group_load;</a>
<a name="9298"><span class="lineNum">    9298 </span>            :                 sds-&gt;total_capacity += sgs-&gt;group_capacity;</a>
<a name="9299"><span class="lineNum">    9299 </span>            : </a>
<a name="9300"><span class="lineNum">    9300 </span>            :                 sg = sg-&gt;next;</a>
<a name="9301"><span class="lineNum">    9301 </span>            :         } while (sg != env-&gt;sd-&gt;groups);</a>
<a name="9302"><span class="lineNum">    9302 </span>            : </a>
<a name="9303"><span class="lineNum">    9303 </span>            :         /* Tag domain that child domain prefers tasks go to siblings first */</a>
<a name="9304"><span class="lineNum">    9304 </span>            :         sds-&gt;prefer_sibling = child &amp;&amp; child-&gt;flags &amp; SD_PREFER_SIBLING;</a>
<a name="9305"><span class="lineNum">    9305 </span>            : </a>
<a name="9306"><span class="lineNum">    9306 </span>            : </a>
<a name="9307"><span class="lineNum">    9307 </span>            :         if (env-&gt;sd-&gt;flags &amp; SD_NUMA)</a>
<a name="9308"><span class="lineNum">    9308 </span>            :                 env-&gt;fbq_type = fbq_classify_group(&amp;sds-&gt;busiest_stat);</a>
<a name="9309"><span class="lineNum">    9309 </span>            : </a>
<a name="9310"><span class="lineNum">    9310 </span>            :         if (!env-&gt;sd-&gt;parent) {</a>
<a name="9311"><span class="lineNum">    9311 </span>            :                 struct root_domain *rd = env-&gt;dst_rq-&gt;rd;</a>
<a name="9312"><span class="lineNum">    9312 </span>            : </a>
<a name="9313"><span class="lineNum">    9313 </span>            :                 /* update overload indicator if we are at root domain */</a>
<a name="9314"><span class="lineNum">    9314 </span>            :                 WRITE_ONCE(rd-&gt;overload, sg_status &amp; SG_OVERLOAD);</a>
<a name="9315"><span class="lineNum">    9315 </span>            : </a>
<a name="9316"><span class="lineNum">    9316 </span>            :                 /* Update over-utilization (tipping point, U &gt;= 0) indicator */</a>
<a name="9317"><span class="lineNum">    9317 </span>            :                 WRITE_ONCE(rd-&gt;overutilized, sg_status &amp; SG_OVERUTILIZED);</a>
<a name="9318"><span class="lineNum">    9318 </span>            :                 trace_sched_overutilized_tp(rd, sg_status &amp; SG_OVERUTILIZED);</a>
<a name="9319"><span class="lineNum">    9319 </span>            :         } else if (sg_status &amp; SG_OVERUTILIZED) {</a>
<a name="9320"><span class="lineNum">    9320 </span>            :                 struct root_domain *rd = env-&gt;dst_rq-&gt;rd;</a>
<a name="9321"><span class="lineNum">    9321 </span>            : </a>
<a name="9322"><span class="lineNum">    9322 </span>            :                 WRITE_ONCE(rd-&gt;overutilized, SG_OVERUTILIZED);</a>
<a name="9323"><span class="lineNum">    9323 </span>            :                 trace_sched_overutilized_tp(rd, SG_OVERUTILIZED);</a>
<a name="9324"><span class="lineNum">    9324 </span>            :         }</a>
<a name="9325"><span class="lineNum">    9325 </span>            : }</a>
<a name="9326"><span class="lineNum">    9326 </span>            : </a>
<a name="9327"><span class="lineNum">    9327 </span>            : #define NUMA_IMBALANCE_MIN 2</a>
<a name="9328"><span class="lineNum">    9328 </span>            : </a>
<a name="9329"><span class="lineNum">    9329 </span>            : static inline long adjust_numa_imbalance(int imbalance,</a>
<a name="9330"><span class="lineNum">    9330 </span>            :                                 int dst_running, int imb_numa_nr)</a>
<a name="9331"><span class="lineNum">    9331 </span>            : {</a>
<a name="9332"><span class="lineNum">    9332 </span>            :         if (!allow_numa_imbalance(dst_running, imb_numa_nr))</a>
<a name="9333"><span class="lineNum">    9333 </span>            :                 return imbalance;</a>
<a name="9334"><span class="lineNum">    9334 </span>            : </a>
<a name="9335"><span class="lineNum">    9335 </span>            :         /*</a>
<a name="9336"><span class="lineNum">    9336 </span>            :          * Allow a small imbalance based on a simple pair of communicating</a>
<a name="9337"><span class="lineNum">    9337 </span>            :          * tasks that remain local when the destination is lightly loaded.</a>
<a name="9338"><span class="lineNum">    9338 </span>            :          */</a>
<a name="9339"><span class="lineNum">    9339 </span>            :         if (imbalance &lt;= NUMA_IMBALANCE_MIN)</a>
<a name="9340"><span class="lineNum">    9340 </span>            :                 return 0;</a>
<a name="9341"><span class="lineNum">    9341 </span>            : </a>
<a name="9342"><span class="lineNum">    9342 </span>            :         return imbalance;</a>
<a name="9343"><span class="lineNum">    9343 </span>            : }</a>
<a name="9344"><span class="lineNum">    9344 </span>            : </a>
<a name="9345"><span class="lineNum">    9345 </span>            : /**</a>
<a name="9346"><span class="lineNum">    9346 </span>            :  * calculate_imbalance - Calculate the amount of imbalance present within the</a>
<a name="9347"><span class="lineNum">    9347 </span>            :  *                       groups of a given sched_domain during load balance.</a>
<a name="9348"><span class="lineNum">    9348 </span>            :  * @env: load balance environment</a>
<a name="9349"><span class="lineNum">    9349 </span>            :  * @sds: statistics of the sched_domain whose imbalance is to be calculated.</a>
<a name="9350"><span class="lineNum">    9350 </span>            :  */</a>
<a name="9351"><span class="lineNum">    9351 </span>            : static inline void calculate_imbalance(struct lb_env *env, struct sd_lb_stats *sds)</a>
<a name="9352"><span class="lineNum">    9352 </span>            : {</a>
<a name="9353"><span class="lineNum">    9353 </span>            :         struct sg_lb_stats *local, *busiest;</a>
<a name="9354"><span class="lineNum">    9354 </span>            : </a>
<a name="9355"><span class="lineNum">    9355 </span>            :         local = &amp;sds-&gt;local_stat;</a>
<a name="9356"><span class="lineNum">    9356 </span>            :         busiest = &amp;sds-&gt;busiest_stat;</a>
<a name="9357"><span class="lineNum">    9357 </span>            : </a>
<a name="9358"><span class="lineNum">    9358 </span>            :         if (busiest-&gt;group_type == group_misfit_task) {</a>
<a name="9359"><span class="lineNum">    9359 </span>            :                 /* Set imbalance to allow misfit tasks to be balanced. */</a>
<a name="9360"><span class="lineNum">    9360 </span>            :                 env-&gt;migration_type = migrate_misfit;</a>
<a name="9361"><span class="lineNum">    9361 </span>            :                 env-&gt;imbalance = 1;</a>
<a name="9362"><span class="lineNum">    9362 </span>            :                 return;</a>
<a name="9363"><span class="lineNum">    9363 </span>            :         }</a>
<a name="9364"><span class="lineNum">    9364 </span>            : </a>
<a name="9365"><span class="lineNum">    9365 </span>            :         if (busiest-&gt;group_type == group_asym_packing) {</a>
<a name="9366"><span class="lineNum">    9366 </span>            :                 /*</a>
<a name="9367"><span class="lineNum">    9367 </span>            :                  * In case of asym capacity, we will try to migrate all load to</a>
<a name="9368"><span class="lineNum">    9368 </span>            :                  * the preferred CPU.</a>
<a name="9369"><span class="lineNum">    9369 </span>            :                  */</a>
<a name="9370"><span class="lineNum">    9370 </span>            :                 env-&gt;migration_type = migrate_task;</a>
<a name="9371"><span class="lineNum">    9371 </span>            :                 env-&gt;imbalance = busiest-&gt;sum_h_nr_running;</a>
<a name="9372"><span class="lineNum">    9372 </span>            :                 return;</a>
<a name="9373"><span class="lineNum">    9373 </span>            :         }</a>
<a name="9374"><span class="lineNum">    9374 </span>            : </a>
<a name="9375"><span class="lineNum">    9375 </span>            :         if (busiest-&gt;group_type == group_imbalanced) {</a>
<a name="9376"><span class="lineNum">    9376 </span>            :                 /*</a>
<a name="9377"><span class="lineNum">    9377 </span>            :                  * In the group_imb case we cannot rely on group-wide averages</a>
<a name="9378"><span class="lineNum">    9378 </span>            :                  * to ensure CPU-load equilibrium, try to move any task to fix</a>
<a name="9379"><span class="lineNum">    9379 </span>            :                  * the imbalance. The next load balance will take care of</a>
<a name="9380"><span class="lineNum">    9380 </span>            :                  * balancing back the system.</a>
<a name="9381"><span class="lineNum">    9381 </span>            :                  */</a>
<a name="9382"><span class="lineNum">    9382 </span>            :                 env-&gt;migration_type = migrate_task;</a>
<a name="9383"><span class="lineNum">    9383 </span>            :                 env-&gt;imbalance = 1;</a>
<a name="9384"><span class="lineNum">    9384 </span>            :                 return;</a>
<a name="9385"><span class="lineNum">    9385 </span>            :         }</a>
<a name="9386"><span class="lineNum">    9386 </span>            : </a>
<a name="9387"><span class="lineNum">    9387 </span>            :         /*</a>
<a name="9388"><span class="lineNum">    9388 </span>            :          * Try to use spare capacity of local group without overloading it or</a>
<a name="9389"><span class="lineNum">    9389 </span>            :          * emptying busiest.</a>
<a name="9390"><span class="lineNum">    9390 </span>            :          */</a>
<a name="9391"><span class="lineNum">    9391 </span>            :         if (local-&gt;group_type == group_has_spare) {</a>
<a name="9392"><span class="lineNum">    9392 </span>            :                 if ((busiest-&gt;group_type &gt; group_fully_busy) &amp;&amp;</a>
<a name="9393"><span class="lineNum">    9393 </span>            :                     !(env-&gt;sd-&gt;flags &amp; SD_SHARE_PKG_RESOURCES)) {</a>
<a name="9394"><span class="lineNum">    9394 </span>            :                         /*</a>
<a name="9395"><span class="lineNum">    9395 </span>            :                          * If busiest is overloaded, try to fill spare</a>
<a name="9396"><span class="lineNum">    9396 </span>            :                          * capacity. This might end up creating spare capacity</a>
<a name="9397"><span class="lineNum">    9397 </span>            :                          * in busiest or busiest still being overloaded but</a>
<a name="9398"><span class="lineNum">    9398 </span>            :                          * there is no simple way to directly compute the</a>
<a name="9399"><span class="lineNum">    9399 </span>            :                          * amount of load to migrate in order to balance the</a>
<a name="9400"><span class="lineNum">    9400 </span>            :                          * system.</a>
<a name="9401"><span class="lineNum">    9401 </span>            :                          */</a>
<a name="9402"><span class="lineNum">    9402 </span>            :                         env-&gt;migration_type = migrate_util;</a>
<a name="9403"><span class="lineNum">    9403 </span>            :                         env-&gt;imbalance = max(local-&gt;group_capacity, local-&gt;group_util) -</a>
<a name="9404"><span class="lineNum">    9404 </span>            :                                          local-&gt;group_util;</a>
<a name="9405"><span class="lineNum">    9405 </span>            : </a>
<a name="9406"><span class="lineNum">    9406 </span>            :                         /*</a>
<a name="9407"><span class="lineNum">    9407 </span>            :                          * In some cases, the group's utilization is max or even</a>
<a name="9408"><span class="lineNum">    9408 </span>            :                          * higher than capacity because of migrations but the</a>
<a name="9409"><span class="lineNum">    9409 </span>            :                          * local CPU is (newly) idle. There is at least one</a>
<a name="9410"><span class="lineNum">    9410 </span>            :                          * waiting task in this overloaded busiest group. Let's</a>
<a name="9411"><span class="lineNum">    9411 </span>            :                          * try to pull it.</a>
<a name="9412"><span class="lineNum">    9412 </span>            :                          */</a>
<a name="9413"><span class="lineNum">    9413 </span>            :                         if (env-&gt;idle != CPU_NOT_IDLE &amp;&amp; env-&gt;imbalance == 0) {</a>
<a name="9414"><span class="lineNum">    9414 </span>            :                                 env-&gt;migration_type = migrate_task;</a>
<a name="9415"><span class="lineNum">    9415 </span>            :                                 env-&gt;imbalance = 1;</a>
<a name="9416"><span class="lineNum">    9416 </span>            :                         }</a>
<a name="9417"><span class="lineNum">    9417 </span>            : </a>
<a name="9418"><span class="lineNum">    9418 </span>            :                         return;</a>
<a name="9419"><span class="lineNum">    9419 </span>            :                 }</a>
<a name="9420"><span class="lineNum">    9420 </span>            : </a>
<a name="9421"><span class="lineNum">    9421 </span>            :                 if (busiest-&gt;group_weight == 1 || sds-&gt;prefer_sibling) {</a>
<a name="9422"><span class="lineNum">    9422 </span>            :                         unsigned int nr_diff = busiest-&gt;sum_nr_running;</a>
<a name="9423"><span class="lineNum">    9423 </span>            :                         /*</a>
<a name="9424"><span class="lineNum">    9424 </span>            :                          * When prefer sibling, evenly spread running tasks on</a>
<a name="9425"><span class="lineNum">    9425 </span>            :                          * groups.</a>
<a name="9426"><span class="lineNum">    9426 </span>            :                          */</a>
<a name="9427"><span class="lineNum">    9427 </span>            :                         env-&gt;migration_type = migrate_task;</a>
<a name="9428"><span class="lineNum">    9428 </span>            :                         lsub_positive(&amp;nr_diff, local-&gt;sum_nr_running);</a>
<a name="9429"><span class="lineNum">    9429 </span>            :                         env-&gt;imbalance = nr_diff &gt;&gt; 1;</a>
<a name="9430"><span class="lineNum">    9430 </span>            :                 } else {</a>
<a name="9431"><span class="lineNum">    9431 </span>            : </a>
<a name="9432"><span class="lineNum">    9432 </span>            :                         /*</a>
<a name="9433"><span class="lineNum">    9433 </span>            :                          * If there is no overload, we just want to even the number of</a>
<a name="9434"><span class="lineNum">    9434 </span>            :                          * idle cpus.</a>
<a name="9435"><span class="lineNum">    9435 </span>            :                          */</a>
<a name="9436"><span class="lineNum">    9436 </span>            :                         env-&gt;migration_type = migrate_task;</a>
<a name="9437"><span class="lineNum">    9437 </span>            :                         env-&gt;imbalance = max_t(long, 0, (local-&gt;idle_cpus -</a>
<a name="9438"><span class="lineNum">    9438 </span>            :                                                  busiest-&gt;idle_cpus) &gt;&gt; 1);</a>
<a name="9439"><span class="lineNum">    9439 </span>            :                 }</a>
<a name="9440"><span class="lineNum">    9440 </span>            : </a>
<a name="9441"><span class="lineNum">    9441 </span>            :                 /* Consider allowing a small imbalance between NUMA groups */</a>
<a name="9442"><span class="lineNum">    9442 </span>            :                 if (env-&gt;sd-&gt;flags &amp; SD_NUMA) {</a>
<a name="9443"><span class="lineNum">    9443 </span>            :                         env-&gt;imbalance = adjust_numa_imbalance(env-&gt;imbalance,</a>
<a name="9444"><span class="lineNum">    9444 </span>            :                                 local-&gt;sum_nr_running + 1, env-&gt;sd-&gt;imb_numa_nr);</a>
<a name="9445"><span class="lineNum">    9445 </span>            :                 }</a>
<a name="9446"><span class="lineNum">    9446 </span>            : </a>
<a name="9447"><span class="lineNum">    9447 </span>            :                 return;</a>
<a name="9448"><span class="lineNum">    9448 </span>            :         }</a>
<a name="9449"><span class="lineNum">    9449 </span>            : </a>
<a name="9450"><span class="lineNum">    9450 </span>            :         /*</a>
<a name="9451"><span class="lineNum">    9451 </span>            :          * Local is fully busy but has to take more load to relieve the</a>
<a name="9452"><span class="lineNum">    9452 </span>            :          * busiest group</a>
<a name="9453"><span class="lineNum">    9453 </span>            :          */</a>
<a name="9454"><span class="lineNum">    9454 </span>            :         if (local-&gt;group_type &lt; group_overloaded) {</a>
<a name="9455"><span class="lineNum">    9455 </span>            :                 /*</a>
<a name="9456"><span class="lineNum">    9456 </span>            :                  * Local will become overloaded so the avg_load metrics are</a>
<a name="9457"><span class="lineNum">    9457 </span>            :                  * finally needed.</a>
<a name="9458"><span class="lineNum">    9458 </span>            :                  */</a>
<a name="9459"><span class="lineNum">    9459 </span>            : </a>
<a name="9460"><span class="lineNum">    9460 </span>            :                 local-&gt;avg_load = (local-&gt;group_load * SCHED_CAPACITY_SCALE) /</a>
<a name="9461"><span class="lineNum">    9461 </span>            :                                   local-&gt;group_capacity;</a>
<a name="9462"><span class="lineNum">    9462 </span>            : </a>
<a name="9463"><span class="lineNum">    9463 </span>            :                 sds-&gt;avg_load = (sds-&gt;total_load * SCHED_CAPACITY_SCALE) /</a>
<a name="9464"><span class="lineNum">    9464 </span>            :                                 sds-&gt;total_capacity;</a>
<a name="9465"><span class="lineNum">    9465 </span>            :                 /*</a>
<a name="9466"><span class="lineNum">    9466 </span>            :                  * If the local group is more loaded than the selected</a>
<a name="9467"><span class="lineNum">    9467 </span>            :                  * busiest group don't try to pull any tasks.</a>
<a name="9468"><span class="lineNum">    9468 </span>            :                  */</a>
<a name="9469"><span class="lineNum">    9469 </span>            :                 if (local-&gt;avg_load &gt;= busiest-&gt;avg_load) {</a>
<a name="9470"><span class="lineNum">    9470 </span>            :                         env-&gt;imbalance = 0;</a>
<a name="9471"><span class="lineNum">    9471 </span>            :                         return;</a>
<a name="9472"><span class="lineNum">    9472 </span>            :                 }</a>
<a name="9473"><span class="lineNum">    9473 </span>            :         }</a>
<a name="9474"><span class="lineNum">    9474 </span>            : </a>
<a name="9475"><span class="lineNum">    9475 </span>            :         /*</a>
<a name="9476"><span class="lineNum">    9476 </span>            :          * Both group are or will become overloaded and we're trying to get all</a>
<a name="9477"><span class="lineNum">    9477 </span>            :          * the CPUs to the average_load, so we don't want to push ourselves</a>
<a name="9478"><span class="lineNum">    9478 </span>            :          * above the average load, nor do we wish to reduce the max loaded CPU</a>
<a name="9479"><span class="lineNum">    9479 </span>            :          * below the average load. At the same time, we also don't want to</a>
<a name="9480"><span class="lineNum">    9480 </span>            :          * reduce the group load below the group capacity. Thus we look for</a>
<a name="9481"><span class="lineNum">    9481 </span>            :          * the minimum possible imbalance.</a>
<a name="9482"><span class="lineNum">    9482 </span>            :          */</a>
<a name="9483"><span class="lineNum">    9483 </span>            :         env-&gt;migration_type = migrate_load;</a>
<a name="9484"><span class="lineNum">    9484 </span>            :         env-&gt;imbalance = min(</a>
<a name="9485"><span class="lineNum">    9485 </span>            :                 (busiest-&gt;avg_load - sds-&gt;avg_load) * busiest-&gt;group_capacity,</a>
<a name="9486"><span class="lineNum">    9486 </span>            :                 (sds-&gt;avg_load - local-&gt;avg_load) * local-&gt;group_capacity</a>
<a name="9487"><span class="lineNum">    9487 </span>            :         ) / SCHED_CAPACITY_SCALE;</a>
<a name="9488"><span class="lineNum">    9488 </span>            : }</a>
<a name="9489"><span class="lineNum">    9489 </span>            : </a>
<a name="9490"><span class="lineNum">    9490 </span>            : /******* find_busiest_group() helpers end here *********************/</a>
<a name="9491"><span class="lineNum">    9491 </span>            : </a>
<a name="9492"><span class="lineNum">    9492 </span>            : /*</a>
<a name="9493"><span class="lineNum">    9493 </span>            :  * Decision matrix according to the local and busiest group type:</a>
<a name="9494"><span class="lineNum">    9494 </span>            :  *</a>
<a name="9495"><span class="lineNum">    9495 </span>            :  * busiest \ local has_spare fully_busy misfit asym imbalanced overloaded</a>
<a name="9496"><span class="lineNum">    9496 </span>            :  * has_spare        nr_idle   balanced   N/A    N/A  balanced   balanced</a>
<a name="9497"><span class="lineNum">    9497 </span>            :  * fully_busy       nr_idle   nr_idle    N/A    N/A  balanced   balanced</a>
<a name="9498"><span class="lineNum">    9498 </span>            :  * misfit_task      force     N/A        N/A    N/A  force      force</a>
<a name="9499"><span class="lineNum">    9499 </span>            :  * asym_packing     force     force      N/A    N/A  force      force</a>
<a name="9500"><span class="lineNum">    9500 </span>            :  * imbalanced       force     force      N/A    N/A  force      force</a>
<a name="9501"><span class="lineNum">    9501 </span>            :  * overloaded       force     force      N/A    N/A  force      avg_load</a>
<a name="9502"><span class="lineNum">    9502 </span>            :  *</a>
<a name="9503"><span class="lineNum">    9503 </span>            :  * N/A :      Not Applicable because already filtered while updating</a>
<a name="9504"><span class="lineNum">    9504 </span>            :  *            statistics.</a>
<a name="9505"><span class="lineNum">    9505 </span>            :  * balanced : The system is balanced for these 2 groups.</a>
<a name="9506"><span class="lineNum">    9506 </span>            :  * force :    Calculate the imbalance as load migration is probably needed.</a>
<a name="9507"><span class="lineNum">    9507 </span>            :  * avg_load : Only if imbalance is significant enough.</a>
<a name="9508"><span class="lineNum">    9508 </span>            :  * nr_idle :  dst_cpu is not busy and the number of idle CPUs is quite</a>
<a name="9509"><span class="lineNum">    9509 </span>            :  *            different in groups.</a>
<a name="9510"><span class="lineNum">    9510 </span>            :  */</a>
<a name="9511"><span class="lineNum">    9511 </span>            : </a>
<a name="9512"><span class="lineNum">    9512 </span>            : /**</a>
<a name="9513"><span class="lineNum">    9513 </span>            :  * find_busiest_group - Returns the busiest group within the sched_domain</a>
<a name="9514"><span class="lineNum">    9514 </span>            :  * if there is an imbalance.</a>
<a name="9515"><span class="lineNum">    9515 </span>            :  * @env: The load balancing environment.</a>
<a name="9516"><span class="lineNum">    9516 </span>            :  *</a>
<a name="9517"><span class="lineNum">    9517 </span>            :  * Also calculates the amount of runnable load which should be moved</a>
<a name="9518"><span class="lineNum">    9518 </span>            :  * to restore balance.</a>
<a name="9519"><span class="lineNum">    9519 </span>            :  *</a>
<a name="9520"><span class="lineNum">    9520 </span>            :  * Return:      - The busiest group if imbalance exists.</a>
<a name="9521"><span class="lineNum">    9521 </span>            :  */</a>
<a name="9522"><span class="lineNum">    9522 </span>            : static struct sched_group *find_busiest_group(struct lb_env *env)</a>
<a name="9523"><span class="lineNum">    9523 </span>            : {</a>
<a name="9524"><span class="lineNum">    9524 </span>            :         struct sg_lb_stats *local, *busiest;</a>
<a name="9525"><span class="lineNum">    9525 </span>            :         struct sd_lb_stats sds;</a>
<a name="9526"><span class="lineNum">    9526 </span>            : </a>
<a name="9527"><span class="lineNum">    9527 </span>            :         init_sd_lb_stats(&amp;sds);</a>
<a name="9528"><span class="lineNum">    9528 </span>            : </a>
<a name="9529"><span class="lineNum">    9529 </span>            :         /*</a>
<a name="9530"><span class="lineNum">    9530 </span>            :          * Compute the various statistics relevant for load balancing at</a>
<a name="9531"><span class="lineNum">    9531 </span>            :          * this level.</a>
<a name="9532"><span class="lineNum">    9532 </span>            :          */</a>
<a name="9533"><span class="lineNum">    9533 </span>            :         update_sd_lb_stats(env, &amp;sds);</a>
<a name="9534"><span class="lineNum">    9534 </span>            : </a>
<a name="9535"><span class="lineNum">    9535 </span>            :         if (sched_energy_enabled()) {</a>
<a name="9536"><span class="lineNum">    9536 </span>            :                 struct root_domain *rd = env-&gt;dst_rq-&gt;rd;</a>
<a name="9537"><span class="lineNum">    9537 </span>            : </a>
<a name="9538"><span class="lineNum">    9538 </span>            :                 if (rcu_dereference(rd-&gt;pd) &amp;&amp; !READ_ONCE(rd-&gt;overutilized))</a>
<a name="9539"><span class="lineNum">    9539 </span>            :                         goto out_balanced;</a>
<a name="9540"><span class="lineNum">    9540 </span>            :         }</a>
<a name="9541"><span class="lineNum">    9541 </span>            : </a>
<a name="9542"><span class="lineNum">    9542 </span>            :         local = &amp;sds.local_stat;</a>
<a name="9543"><span class="lineNum">    9543 </span>            :         busiest = &amp;sds.busiest_stat;</a>
<a name="9544"><span class="lineNum">    9544 </span>            : </a>
<a name="9545"><span class="lineNum">    9545 </span>            :         /* There is no busy sibling group to pull tasks from */</a>
<a name="9546"><span class="lineNum">    9546 </span>            :         if (!sds.busiest)</a>
<a name="9547"><span class="lineNum">    9547 </span>            :                 goto out_balanced;</a>
<a name="9548"><span class="lineNum">    9548 </span>            : </a>
<a name="9549"><span class="lineNum">    9549 </span>            :         /* Misfit tasks should be dealt with regardless of the avg load */</a>
<a name="9550"><span class="lineNum">    9550 </span>            :         if (busiest-&gt;group_type == group_misfit_task)</a>
<a name="9551"><span class="lineNum">    9551 </span>            :                 goto force_balance;</a>
<a name="9552"><span class="lineNum">    9552 </span>            : </a>
<a name="9553"><span class="lineNum">    9553 </span>            :         /* ASYM feature bypasses nice load balance check */</a>
<a name="9554"><span class="lineNum">    9554 </span>            :         if (busiest-&gt;group_type == group_asym_packing)</a>
<a name="9555"><span class="lineNum">    9555 </span>            :                 goto force_balance;</a>
<a name="9556"><span class="lineNum">    9556 </span>            : </a>
<a name="9557"><span class="lineNum">    9557 </span>            :         /*</a>
<a name="9558"><span class="lineNum">    9558 </span>            :          * If the busiest group is imbalanced the below checks don't</a>
<a name="9559"><span class="lineNum">    9559 </span>            :          * work because they assume all things are equal, which typically</a>
<a name="9560"><span class="lineNum">    9560 </span>            :          * isn't true due to cpus_ptr constraints and the like.</a>
<a name="9561"><span class="lineNum">    9561 </span>            :          */</a>
<a name="9562"><span class="lineNum">    9562 </span>            :         if (busiest-&gt;group_type == group_imbalanced)</a>
<a name="9563"><span class="lineNum">    9563 </span>            :                 goto force_balance;</a>
<a name="9564"><span class="lineNum">    9564 </span>            : </a>
<a name="9565"><span class="lineNum">    9565 </span>            :         /*</a>
<a name="9566"><span class="lineNum">    9566 </span>            :          * If the local group is busier than the selected busiest group</a>
<a name="9567"><span class="lineNum">    9567 </span>            :          * don't try and pull any tasks.</a>
<a name="9568"><span class="lineNum">    9568 </span>            :          */</a>
<a name="9569"><span class="lineNum">    9569 </span>            :         if (local-&gt;group_type &gt; busiest-&gt;group_type)</a>
<a name="9570"><span class="lineNum">    9570 </span>            :                 goto out_balanced;</a>
<a name="9571"><span class="lineNum">    9571 </span>            : </a>
<a name="9572"><span class="lineNum">    9572 </span>            :         /*</a>
<a name="9573"><span class="lineNum">    9573 </span>            :          * When groups are overloaded, use the avg_load to ensure fairness</a>
<a name="9574"><span class="lineNum">    9574 </span>            :          * between tasks.</a>
<a name="9575"><span class="lineNum">    9575 </span>            :          */</a>
<a name="9576"><span class="lineNum">    9576 </span>            :         if (local-&gt;group_type == group_overloaded) {</a>
<a name="9577"><span class="lineNum">    9577 </span>            :                 /*</a>
<a name="9578"><span class="lineNum">    9578 </span>            :                  * If the local group is more loaded than the selected</a>
<a name="9579"><span class="lineNum">    9579 </span>            :                  * busiest group don't try to pull any tasks.</a>
<a name="9580"><span class="lineNum">    9580 </span>            :                  */</a>
<a name="9581"><span class="lineNum">    9581 </span>            :                 if (local-&gt;avg_load &gt;= busiest-&gt;avg_load)</a>
<a name="9582"><span class="lineNum">    9582 </span>            :                         goto out_balanced;</a>
<a name="9583"><span class="lineNum">    9583 </span>            : </a>
<a name="9584"><span class="lineNum">    9584 </span>            :                 /* XXX broken for overlapping NUMA groups */</a>
<a name="9585"><span class="lineNum">    9585 </span>            :                 sds.avg_load = (sds.total_load * SCHED_CAPACITY_SCALE) /</a>
<a name="9586"><span class="lineNum">    9586 </span>            :                                 sds.total_capacity;</a>
<a name="9587"><span class="lineNum">    9587 </span>            : </a>
<a name="9588"><span class="lineNum">    9588 </span>            :                 /*</a>
<a name="9589"><span class="lineNum">    9589 </span>            :                  * Don't pull any tasks if this group is already above the</a>
<a name="9590"><span class="lineNum">    9590 </span>            :                  * domain average load.</a>
<a name="9591"><span class="lineNum">    9591 </span>            :                  */</a>
<a name="9592"><span class="lineNum">    9592 </span>            :                 if (local-&gt;avg_load &gt;= sds.avg_load)</a>
<a name="9593"><span class="lineNum">    9593 </span>            :                         goto out_balanced;</a>
<a name="9594"><span class="lineNum">    9594 </span>            : </a>
<a name="9595"><span class="lineNum">    9595 </span>            :                 /*</a>
<a name="9596"><span class="lineNum">    9596 </span>            :                  * If the busiest group is more loaded, use imbalance_pct to be</a>
<a name="9597"><span class="lineNum">    9597 </span>            :                  * conservative.</a>
<a name="9598"><span class="lineNum">    9598 </span>            :                  */</a>
<a name="9599"><span class="lineNum">    9599 </span>            :                 if (100 * busiest-&gt;avg_load &lt;=</a>
<a name="9600"><span class="lineNum">    9600 </span>            :                                 env-&gt;sd-&gt;imbalance_pct * local-&gt;avg_load)</a>
<a name="9601"><span class="lineNum">    9601 </span>            :                         goto out_balanced;</a>
<a name="9602"><span class="lineNum">    9602 </span>            :         }</a>
<a name="9603"><span class="lineNum">    9603 </span>            : </a>
<a name="9604"><span class="lineNum">    9604 </span>            :         /* Try to move all excess tasks to child's sibling domain */</a>
<a name="9605"><span class="lineNum">    9605 </span>            :         if (sds.prefer_sibling &amp;&amp; local-&gt;group_type == group_has_spare &amp;&amp;</a>
<a name="9606"><span class="lineNum">    9606 </span>            :             busiest-&gt;sum_nr_running &gt; local-&gt;sum_nr_running + 1)</a>
<a name="9607"><span class="lineNum">    9607 </span>            :                 goto force_balance;</a>
<a name="9608"><span class="lineNum">    9608 </span>            : </a>
<a name="9609"><span class="lineNum">    9609 </span>            :         if (busiest-&gt;group_type != group_overloaded) {</a>
<a name="9610"><span class="lineNum">    9610 </span>            :                 if (env-&gt;idle == CPU_NOT_IDLE)</a>
<a name="9611"><span class="lineNum">    9611 </span>            :                         /*</a>
<a name="9612"><span class="lineNum">    9612 </span>            :                          * If the busiest group is not overloaded (and as a</a>
<a name="9613"><span class="lineNum">    9613 </span>            :                          * result the local one too) but this CPU is already</a>
<a name="9614"><span class="lineNum">    9614 </span>            :                          * busy, let another idle CPU try to pull task.</a>
<a name="9615"><span class="lineNum">    9615 </span>            :                          */</a>
<a name="9616"><span class="lineNum">    9616 </span>            :                         goto out_balanced;</a>
<a name="9617"><span class="lineNum">    9617 </span>            : </a>
<a name="9618"><span class="lineNum">    9618 </span>            :                 if (busiest-&gt;group_weight &gt; 1 &amp;&amp;</a>
<a name="9619"><span class="lineNum">    9619 </span>            :                     local-&gt;idle_cpus &lt;= (busiest-&gt;idle_cpus + 1))</a>
<a name="9620"><span class="lineNum">    9620 </span>            :                         /*</a>
<a name="9621"><span class="lineNum">    9621 </span>            :                          * If the busiest group is not overloaded</a>
<a name="9622"><span class="lineNum">    9622 </span>            :                          * and there is no imbalance between this and busiest</a>
<a name="9623"><span class="lineNum">    9623 </span>            :                          * group wrt idle CPUs, it is balanced. The imbalance</a>
<a name="9624"><span class="lineNum">    9624 </span>            :                          * becomes significant if the diff is greater than 1</a>
<a name="9625"><span class="lineNum">    9625 </span>            :                          * otherwise we might end up to just move the imbalance</a>
<a name="9626"><span class="lineNum">    9626 </span>            :                          * on another group. Of course this applies only if</a>
<a name="9627"><span class="lineNum">    9627 </span>            :                          * there is more than 1 CPU per group.</a>
<a name="9628"><span class="lineNum">    9628 </span>            :                          */</a>
<a name="9629"><span class="lineNum">    9629 </span>            :                         goto out_balanced;</a>
<a name="9630"><span class="lineNum">    9630 </span>            : </a>
<a name="9631"><span class="lineNum">    9631 </span>            :                 if (busiest-&gt;sum_h_nr_running == 1)</a>
<a name="9632"><span class="lineNum">    9632 </span>            :                         /*</a>
<a name="9633"><span class="lineNum">    9633 </span>            :                          * busiest doesn't have any tasks waiting to run</a>
<a name="9634"><span class="lineNum">    9634 </span>            :                          */</a>
<a name="9635"><span class="lineNum">    9635 </span>            :                         goto out_balanced;</a>
<a name="9636"><span class="lineNum">    9636 </span>            :         }</a>
<a name="9637"><span class="lineNum">    9637 </span>            : </a>
<a name="9638"><span class="lineNum">    9638 </span>            : force_balance:</a>
<a name="9639"><span class="lineNum">    9639 </span>            :         /* Looks like there is an imbalance. Compute it */</a>
<a name="9640"><span class="lineNum">    9640 </span>            :         calculate_imbalance(env, &amp;sds);</a>
<a name="9641"><span class="lineNum">    9641 </span>            :         return env-&gt;imbalance ? sds.busiest : NULL;</a>
<a name="9642"><span class="lineNum">    9642 </span>            : </a>
<a name="9643"><span class="lineNum">    9643 </span>            : out_balanced:</a>
<a name="9644"><span class="lineNum">    9644 </span>            :         env-&gt;imbalance = 0;</a>
<a name="9645"><span class="lineNum">    9645 </span>            :         return NULL;</a>
<a name="9646"><span class="lineNum">    9646 </span>            : }</a>
<a name="9647"><span class="lineNum">    9647 </span>            : </a>
<a name="9648"><span class="lineNum">    9648 </span>            : /*</a>
<a name="9649"><span class="lineNum">    9649 </span>            :  * find_busiest_queue - find the busiest runqueue among the CPUs in the group.</a>
<a name="9650"><span class="lineNum">    9650 </span>            :  */</a>
<a name="9651"><span class="lineNum">    9651 </span>            : static struct rq *find_busiest_queue(struct lb_env *env,</a>
<a name="9652"><span class="lineNum">    9652 </span>            :                                      struct sched_group *group)</a>
<a name="9653"><span class="lineNum">    9653 </span>            : {</a>
<a name="9654"><span class="lineNum">    9654 </span>            :         struct rq *busiest = NULL, *rq;</a>
<a name="9655"><span class="lineNum">    9655 </span>            :         unsigned long busiest_util = 0, busiest_load = 0, busiest_capacity = 1;</a>
<a name="9656"><span class="lineNum">    9656 </span>            :         unsigned int busiest_nr = 0;</a>
<a name="9657"><span class="lineNum">    9657 </span>            :         int i;</a>
<a name="9658"><span class="lineNum">    9658 </span>            : </a>
<a name="9659"><span class="lineNum">    9659 </span>            :         for_each_cpu_and(i, sched_group_span(group), env-&gt;cpus) {</a>
<a name="9660"><span class="lineNum">    9660 </span>            :                 unsigned long capacity, load, util;</a>
<a name="9661"><span class="lineNum">    9661 </span>            :                 unsigned int nr_running;</a>
<a name="9662"><span class="lineNum">    9662 </span>            :                 enum fbq_type rt;</a>
<a name="9663"><span class="lineNum">    9663 </span>            : </a>
<a name="9664"><span class="lineNum">    9664 </span>            :                 rq = cpu_rq(i);</a>
<a name="9665"><span class="lineNum">    9665 </span>            :                 rt = fbq_classify_rq(rq);</a>
<a name="9666"><span class="lineNum">    9666 </span>            : </a>
<a name="9667"><span class="lineNum">    9667 </span>            :                 /*</a>
<a name="9668"><span class="lineNum">    9668 </span>            :                  * We classify groups/runqueues into three groups:</a>
<a name="9669"><span class="lineNum">    9669 </span>            :                  *  - regular: there are !numa tasks</a>
<a name="9670"><span class="lineNum">    9670 </span>            :                  *  - remote:  there are numa tasks that run on the 'wrong' node</a>
<a name="9671"><span class="lineNum">    9671 </span>            :                  *  - all:     there is no distinction</a>
<a name="9672"><span class="lineNum">    9672 </span>            :                  *</a>
<a name="9673"><span class="lineNum">    9673 </span>            :                  * In order to avoid migrating ideally placed numa tasks,</a>
<a name="9674"><span class="lineNum">    9674 </span>            :                  * ignore those when there's better options.</a>
<a name="9675"><span class="lineNum">    9675 </span>            :                  *</a>
<a name="9676"><span class="lineNum">    9676 </span>            :                  * If we ignore the actual busiest queue to migrate another</a>
<a name="9677"><span class="lineNum">    9677 </span>            :                  * task, the next balance pass can still reduce the busiest</a>
<a name="9678"><span class="lineNum">    9678 </span>            :                  * queue by moving tasks around inside the node.</a>
<a name="9679"><span class="lineNum">    9679 </span>            :                  *</a>
<a name="9680"><span class="lineNum">    9680 </span>            :                  * If we cannot move enough load due to this classification</a>
<a name="9681"><span class="lineNum">    9681 </span>            :                  * the next pass will adjust the group classification and</a>
<a name="9682"><span class="lineNum">    9682 </span>            :                  * allow migration of more tasks.</a>
<a name="9683"><span class="lineNum">    9683 </span>            :                  *</a>
<a name="9684"><span class="lineNum">    9684 </span>            :                  * Both cases only affect the total convergence complexity.</a>
<a name="9685"><span class="lineNum">    9685 </span>            :                  */</a>
<a name="9686"><span class="lineNum">    9686 </span>            :                 if (rt &gt; env-&gt;fbq_type)</a>
<a name="9687"><span class="lineNum">    9687 </span>            :                         continue;</a>
<a name="9688"><span class="lineNum">    9688 </span>            : </a>
<a name="9689"><span class="lineNum">    9689 </span>            :                 nr_running = rq-&gt;cfs.h_nr_running;</a>
<a name="9690"><span class="lineNum">    9690 </span>            :                 if (!nr_running)</a>
<a name="9691"><span class="lineNum">    9691 </span>            :                         continue;</a>
<a name="9692"><span class="lineNum">    9692 </span>            : </a>
<a name="9693"><span class="lineNum">    9693 </span>            :                 capacity = capacity_of(i);</a>
<a name="9694"><span class="lineNum">    9694 </span>            : </a>
<a name="9695"><span class="lineNum">    9695 </span>            :                 /*</a>
<a name="9696"><span class="lineNum">    9696 </span>            :                  * For ASYM_CPUCAPACITY domains, don't pick a CPU that could</a>
<a name="9697"><span class="lineNum">    9697 </span>            :                  * eventually lead to active_balancing high-&gt;low capacity.</a>
<a name="9698"><span class="lineNum">    9698 </span>            :                  * Higher per-CPU capacity is considered better than balancing</a>
<a name="9699"><span class="lineNum">    9699 </span>            :                  * average load.</a>
<a name="9700"><span class="lineNum">    9700 </span>            :                  */</a>
<a name="9701"><span class="lineNum">    9701 </span>            :                 if (env-&gt;sd-&gt;flags &amp; SD_ASYM_CPUCAPACITY &amp;&amp;</a>
<a name="9702"><span class="lineNum">    9702 </span>            :                     !capacity_greater(capacity_of(env-&gt;dst_cpu), capacity) &amp;&amp;</a>
<a name="9703"><span class="lineNum">    9703 </span>            :                     nr_running == 1)</a>
<a name="9704"><span class="lineNum">    9704 </span>            :                         continue;</a>
<a name="9705"><span class="lineNum">    9705 </span>            : </a>
<a name="9706"><span class="lineNum">    9706 </span>            :                 /* Make sure we only pull tasks from a CPU of lower priority */</a>
<a name="9707"><span class="lineNum">    9707 </span>            :                 if ((env-&gt;sd-&gt;flags &amp; SD_ASYM_PACKING) &amp;&amp;</a>
<a name="9708"><span class="lineNum">    9708 </span>            :                     sched_asym_prefer(i, env-&gt;dst_cpu) &amp;&amp;</a>
<a name="9709"><span class="lineNum">    9709 </span>            :                     nr_running == 1)</a>
<a name="9710"><span class="lineNum">    9710 </span>            :                         continue;</a>
<a name="9711"><span class="lineNum">    9711 </span>            : </a>
<a name="9712"><span class="lineNum">    9712 </span>            :                 switch (env-&gt;migration_type) {</a>
<a name="9713"><span class="lineNum">    9713 </span>            :                 case migrate_load:</a>
<a name="9714"><span class="lineNum">    9714 </span>            :                         /*</a>
<a name="9715"><span class="lineNum">    9715 </span>            :                          * When comparing with load imbalance, use cpu_load()</a>
<a name="9716"><span class="lineNum">    9716 </span>            :                          * which is not scaled with the CPU capacity.</a>
<a name="9717"><span class="lineNum">    9717 </span>            :                          */</a>
<a name="9718"><span class="lineNum">    9718 </span>            :                         load = cpu_load(rq);</a>
<a name="9719"><span class="lineNum">    9719 </span>            : </a>
<a name="9720"><span class="lineNum">    9720 </span>            :                         if (nr_running == 1 &amp;&amp; load &gt; env-&gt;imbalance &amp;&amp;</a>
<a name="9721"><span class="lineNum">    9721 </span>            :                             !check_cpu_capacity(rq, env-&gt;sd))</a>
<a name="9722"><span class="lineNum">    9722 </span>            :                                 break;</a>
<a name="9723"><span class="lineNum">    9723 </span>            : </a>
<a name="9724"><span class="lineNum">    9724 </span>            :                         /*</a>
<a name="9725"><span class="lineNum">    9725 </span>            :                          * For the load comparisons with the other CPUs,</a>
<a name="9726"><span class="lineNum">    9726 </span>            :                          * consider the cpu_load() scaled with the CPU</a>
<a name="9727"><span class="lineNum">    9727 </span>            :                          * capacity, so that the load can be moved away</a>
<a name="9728"><span class="lineNum">    9728 </span>            :                          * from the CPU that is potentially running at a</a>
<a name="9729"><span class="lineNum">    9729 </span>            :                          * lower capacity.</a>
<a name="9730"><span class="lineNum">    9730 </span>            :                          *</a>
<a name="9731"><span class="lineNum">    9731 </span>            :                          * Thus we're looking for max(load_i / capacity_i),</a>
<a name="9732"><span class="lineNum">    9732 </span>            :                          * crosswise multiplication to rid ourselves of the</a>
<a name="9733"><span class="lineNum">    9733 </span>            :                          * division works out to:</a>
<a name="9734"><span class="lineNum">    9734 </span>            :                          * load_i * capacity_j &gt; load_j * capacity_i;</a>
<a name="9735"><span class="lineNum">    9735 </span>            :                          * where j is our previous maximum.</a>
<a name="9736"><span class="lineNum">    9736 </span>            :                          */</a>
<a name="9737"><span class="lineNum">    9737 </span>            :                         if (load * busiest_capacity &gt; busiest_load * capacity) {</a>
<a name="9738"><span class="lineNum">    9738 </span>            :                                 busiest_load = load;</a>
<a name="9739"><span class="lineNum">    9739 </span>            :                                 busiest_capacity = capacity;</a>
<a name="9740"><span class="lineNum">    9740 </span>            :                                 busiest = rq;</a>
<a name="9741"><span class="lineNum">    9741 </span>            :                         }</a>
<a name="9742"><span class="lineNum">    9742 </span>            :                         break;</a>
<a name="9743"><span class="lineNum">    9743 </span>            : </a>
<a name="9744"><span class="lineNum">    9744 </span>            :                 case migrate_util:</a>
<a name="9745"><span class="lineNum">    9745 </span>            :                         util = cpu_util_cfs(i);</a>
<a name="9746"><span class="lineNum">    9746 </span>            : </a>
<a name="9747"><span class="lineNum">    9747 </span>            :                         /*</a>
<a name="9748"><span class="lineNum">    9748 </span>            :                          * Don't try to pull utilization from a CPU with one</a>
<a name="9749"><span class="lineNum">    9749 </span>            :                          * running task. Whatever its utilization, we will fail</a>
<a name="9750"><span class="lineNum">    9750 </span>            :                          * detach the task.</a>
<a name="9751"><span class="lineNum">    9751 </span>            :                          */</a>
<a name="9752"><span class="lineNum">    9752 </span>            :                         if (nr_running &lt;= 1)</a>
<a name="9753"><span class="lineNum">    9753 </span>            :                                 continue;</a>
<a name="9754"><span class="lineNum">    9754 </span>            : </a>
<a name="9755"><span class="lineNum">    9755 </span>            :                         if (busiest_util &lt; util) {</a>
<a name="9756"><span class="lineNum">    9756 </span>            :                                 busiest_util = util;</a>
<a name="9757"><span class="lineNum">    9757 </span>            :                                 busiest = rq;</a>
<a name="9758"><span class="lineNum">    9758 </span>            :                         }</a>
<a name="9759"><span class="lineNum">    9759 </span>            :                         break;</a>
<a name="9760"><span class="lineNum">    9760 </span>            : </a>
<a name="9761"><span class="lineNum">    9761 </span>            :                 case migrate_task:</a>
<a name="9762"><span class="lineNum">    9762 </span>            :                         if (busiest_nr &lt; nr_running) {</a>
<a name="9763"><span class="lineNum">    9763 </span>            :                                 busiest_nr = nr_running;</a>
<a name="9764"><span class="lineNum">    9764 </span>            :                                 busiest = rq;</a>
<a name="9765"><span class="lineNum">    9765 </span>            :                         }</a>
<a name="9766"><span class="lineNum">    9766 </span>            :                         break;</a>
<a name="9767"><span class="lineNum">    9767 </span>            : </a>
<a name="9768"><span class="lineNum">    9768 </span>            :                 case migrate_misfit:</a>
<a name="9769"><span class="lineNum">    9769 </span>            :                         /*</a>
<a name="9770"><span class="lineNum">    9770 </span>            :                          * For ASYM_CPUCAPACITY domains with misfit tasks we</a>
<a name="9771"><span class="lineNum">    9771 </span>            :                          * simply seek the &quot;biggest&quot; misfit task.</a>
<a name="9772"><span class="lineNum">    9772 </span>            :                          */</a>
<a name="9773"><span class="lineNum">    9773 </span>            :                         if (rq-&gt;misfit_task_load &gt; busiest_load) {</a>
<a name="9774"><span class="lineNum">    9774 </span>            :                                 busiest_load = rq-&gt;misfit_task_load;</a>
<a name="9775"><span class="lineNum">    9775 </span>            :                                 busiest = rq;</a>
<a name="9776"><span class="lineNum">    9776 </span>            :                         }</a>
<a name="9777"><span class="lineNum">    9777 </span>            : </a>
<a name="9778"><span class="lineNum">    9778 </span>            :                         break;</a>
<a name="9779"><span class="lineNum">    9779 </span>            : </a>
<a name="9780"><span class="lineNum">    9780 </span>            :                 }</a>
<a name="9781"><span class="lineNum">    9781 </span>            :         }</a>
<a name="9782"><span class="lineNum">    9782 </span>            : </a>
<a name="9783"><span class="lineNum">    9783 </span>            :         return busiest;</a>
<a name="9784"><span class="lineNum">    9784 </span>            : }</a>
<a name="9785"><span class="lineNum">    9785 </span>            : </a>
<a name="9786"><span class="lineNum">    9786 </span>            : /*</a>
<a name="9787"><span class="lineNum">    9787 </span>            :  * Max backoff if we encounter pinned tasks. Pretty arbitrary value, but</a>
<a name="9788"><span class="lineNum">    9788 </span>            :  * so long as it is large enough.</a>
<a name="9789"><span class="lineNum">    9789 </span>            :  */</a>
<a name="9790"><span class="lineNum">    9790 </span>            : #define MAX_PINNED_INTERVAL     512</a>
<a name="9791"><span class="lineNum">    9791 </span>            : </a>
<a name="9792"><span class="lineNum">    9792 </span>            : static inline bool</a>
<a name="9793"><span class="lineNum">    9793 </span>            : asym_active_balance(struct lb_env *env)</a>
<a name="9794"><span class="lineNum">    9794 </span>            : {</a>
<a name="9795"><span class="lineNum">    9795 </span>            :         /*</a>
<a name="9796"><span class="lineNum">    9796 </span>            :          * ASYM_PACKING needs to force migrate tasks from busy but</a>
<a name="9797"><span class="lineNum">    9797 </span>            :          * lower priority CPUs in order to pack all tasks in the</a>
<a name="9798"><span class="lineNum">    9798 </span>            :          * highest priority CPUs.</a>
<a name="9799"><span class="lineNum">    9799 </span>            :          */</a>
<a name="9800"><span class="lineNum">    9800 </span>            :         return env-&gt;idle != CPU_NOT_IDLE &amp;&amp; (env-&gt;sd-&gt;flags &amp; SD_ASYM_PACKING) &amp;&amp;</a>
<a name="9801"><span class="lineNum">    9801 </span>            :                sched_asym_prefer(env-&gt;dst_cpu, env-&gt;src_cpu);</a>
<a name="9802"><span class="lineNum">    9802 </span>            : }</a>
<a name="9803"><span class="lineNum">    9803 </span>            : </a>
<a name="9804"><span class="lineNum">    9804 </span>            : static inline bool</a>
<a name="9805"><span class="lineNum">    9805 </span>            : imbalanced_active_balance(struct lb_env *env)</a>
<a name="9806"><span class="lineNum">    9806 </span>            : {</a>
<a name="9807"><span class="lineNum">    9807 </span>            :         struct sched_domain *sd = env-&gt;sd;</a>
<a name="9808"><span class="lineNum">    9808 </span>            : </a>
<a name="9809"><span class="lineNum">    9809 </span>            :         /*</a>
<a name="9810"><span class="lineNum">    9810 </span>            :          * The imbalanced case includes the case of pinned tasks preventing a fair</a>
<a name="9811"><span class="lineNum">    9811 </span>            :          * distribution of the load on the system but also the even distribution of the</a>
<a name="9812"><span class="lineNum">    9812 </span>            :          * threads on a system with spare capacity</a>
<a name="9813"><span class="lineNum">    9813 </span>            :          */</a>
<a name="9814"><span class="lineNum">    9814 </span>            :         if ((env-&gt;migration_type == migrate_task) &amp;&amp;</a>
<a name="9815"><span class="lineNum">    9815 </span>            :             (sd-&gt;nr_balance_failed &gt; sd-&gt;cache_nice_tries+2))</a>
<a name="9816"><span class="lineNum">    9816 </span>            :                 return 1;</a>
<a name="9817"><span class="lineNum">    9817 </span>            : </a>
<a name="9818"><span class="lineNum">    9818 </span>            :         return 0;</a>
<a name="9819"><span class="lineNum">    9819 </span>            : }</a>
<a name="9820"><span class="lineNum">    9820 </span>            : </a>
<a name="9821"><span class="lineNum">    9821 </span>            : static int need_active_balance(struct lb_env *env)</a>
<a name="9822"><span class="lineNum">    9822 </span>            : {</a>
<a name="9823"><span class="lineNum">    9823 </span>            :         struct sched_domain *sd = env-&gt;sd;</a>
<a name="9824"><span class="lineNum">    9824 </span>            : </a>
<a name="9825"><span class="lineNum">    9825 </span>            :         if (asym_active_balance(env))</a>
<a name="9826"><span class="lineNum">    9826 </span>            :                 return 1;</a>
<a name="9827"><span class="lineNum">    9827 </span>            : </a>
<a name="9828"><span class="lineNum">    9828 </span>            :         if (imbalanced_active_balance(env))</a>
<a name="9829"><span class="lineNum">    9829 </span>            :                 return 1;</a>
<a name="9830"><span class="lineNum">    9830 </span>            : </a>
<a name="9831"><span class="lineNum">    9831 </span>            :         /*</a>
<a name="9832"><span class="lineNum">    9832 </span>            :          * The dst_cpu is idle and the src_cpu CPU has only 1 CFS task.</a>
<a name="9833"><span class="lineNum">    9833 </span>            :          * It's worth migrating the task if the src_cpu's capacity is reduced</a>
<a name="9834"><span class="lineNum">    9834 </span>            :          * because of other sched_class or IRQs if more capacity stays</a>
<a name="9835"><span class="lineNum">    9835 </span>            :          * available on dst_cpu.</a>
<a name="9836"><span class="lineNum">    9836 </span>            :          */</a>
<a name="9837"><span class="lineNum">    9837 </span>            :         if ((env-&gt;idle != CPU_NOT_IDLE) &amp;&amp;</a>
<a name="9838"><span class="lineNum">    9838 </span>            :             (env-&gt;src_rq-&gt;cfs.h_nr_running == 1)) {</a>
<a name="9839"><span class="lineNum">    9839 </span>            :                 if ((check_cpu_capacity(env-&gt;src_rq, sd)) &amp;&amp;</a>
<a name="9840"><span class="lineNum">    9840 </span>            :                     (capacity_of(env-&gt;src_cpu)*sd-&gt;imbalance_pct &lt; capacity_of(env-&gt;dst_cpu)*100))</a>
<a name="9841"><span class="lineNum">    9841 </span>            :                         return 1;</a>
<a name="9842"><span class="lineNum">    9842 </span>            :         }</a>
<a name="9843"><span class="lineNum">    9843 </span>            : </a>
<a name="9844"><span class="lineNum">    9844 </span>            :         if (env-&gt;migration_type == migrate_misfit)</a>
<a name="9845"><span class="lineNum">    9845 </span>            :                 return 1;</a>
<a name="9846"><span class="lineNum">    9846 </span>            : </a>
<a name="9847"><span class="lineNum">    9847 </span>            :         return 0;</a>
<a name="9848"><span class="lineNum">    9848 </span>            : }</a>
<a name="9849"><span class="lineNum">    9849 </span>            : </a>
<a name="9850"><span class="lineNum">    9850 </span>            : static int active_load_balance_cpu_stop(void *data);</a>
<a name="9851"><span class="lineNum">    9851 </span>            : </a>
<a name="9852"><span class="lineNum">    9852 </span>            : static int should_we_balance(struct lb_env *env)</a>
<a name="9853"><span class="lineNum">    9853 </span>            : {</a>
<a name="9854"><span class="lineNum">    9854 </span>            :         struct sched_group *sg = env-&gt;sd-&gt;groups;</a>
<a name="9855"><span class="lineNum">    9855 </span>            :         int cpu;</a>
<a name="9856"><span class="lineNum">    9856 </span>            : </a>
<a name="9857"><span class="lineNum">    9857 </span>            :         /*</a>
<a name="9858"><span class="lineNum">    9858 </span>            :          * Ensure the balancing environment is consistent; can happen</a>
<a name="9859"><span class="lineNum">    9859 </span>            :          * when the softirq triggers 'during' hotplug.</a>
<a name="9860"><span class="lineNum">    9860 </span>            :          */</a>
<a name="9861"><span class="lineNum">    9861 </span>            :         if (!cpumask_test_cpu(env-&gt;dst_cpu, env-&gt;cpus))</a>
<a name="9862"><span class="lineNum">    9862 </span>            :                 return 0;</a>
<a name="9863"><span class="lineNum">    9863 </span>            : </a>
<a name="9864"><span class="lineNum">    9864 </span>            :         /*</a>
<a name="9865"><span class="lineNum">    9865 </span>            :          * In the newly idle case, we will allow all the CPUs</a>
<a name="9866"><span class="lineNum">    9866 </span>            :          * to do the newly idle load balance.</a>
<a name="9867"><span class="lineNum">    9867 </span>            :          */</a>
<a name="9868"><span class="lineNum">    9868 </span>            :         if (env-&gt;idle == CPU_NEWLY_IDLE)</a>
<a name="9869"><span class="lineNum">    9869 </span>            :                 return 1;</a>
<a name="9870"><span class="lineNum">    9870 </span>            : </a>
<a name="9871"><span class="lineNum">    9871 </span>            :         /* Try to find first idle CPU */</a>
<a name="9872"><span class="lineNum">    9872 </span>            :         for_each_cpu_and(cpu, group_balance_mask(sg), env-&gt;cpus) {</a>
<a name="9873"><span class="lineNum">    9873 </span>            :                 if (!idle_cpu(cpu))</a>
<a name="9874"><span class="lineNum">    9874 </span>            :                         continue;</a>
<a name="9875"><span class="lineNum">    9875 </span>            : </a>
<a name="9876"><span class="lineNum">    9876 </span>            :                 /* Are we the first idle CPU? */</a>
<a name="9877"><span class="lineNum">    9877 </span>            :                 return cpu == env-&gt;dst_cpu;</a>
<a name="9878"><span class="lineNum">    9878 </span>            :         }</a>
<a name="9879"><span class="lineNum">    9879 </span>            : </a>
<a name="9880"><span class="lineNum">    9880 </span>            :         /* Are we the first CPU of this group ? */</a>
<a name="9881"><span class="lineNum">    9881 </span>            :         return group_balance_cpu(sg) == env-&gt;dst_cpu;</a>
<a name="9882"><span class="lineNum">    9882 </span>            : }</a>
<a name="9883"><span class="lineNum">    9883 </span>            : </a>
<a name="9884"><span class="lineNum">    9884 </span>            : /*</a>
<a name="9885"><span class="lineNum">    9885 </span>            :  * Check this_cpu to ensure it is balanced within domain. Attempt to move</a>
<a name="9886"><span class="lineNum">    9886 </span>            :  * tasks if there is an imbalance.</a>
<a name="9887"><span class="lineNum">    9887 </span>            :  */</a>
<a name="9888"><span class="lineNum">    9888 </span>            : static int load_balance(int this_cpu, struct rq *this_rq,</a>
<a name="9889"><span class="lineNum">    9889 </span>            :                         struct sched_domain *sd, enum cpu_idle_type idle,</a>
<a name="9890"><span class="lineNum">    9890 </span>            :                         int *continue_balancing)</a>
<a name="9891"><span class="lineNum">    9891 </span>            : {</a>
<a name="9892"><span class="lineNum">    9892 </span>            :         int ld_moved, cur_ld_moved, active_balance = 0;</a>
<a name="9893"><span class="lineNum">    9893 </span>            :         struct sched_domain *sd_parent = sd-&gt;parent;</a>
<a name="9894"><span class="lineNum">    9894 </span>            :         struct sched_group *group;</a>
<a name="9895"><span class="lineNum">    9895 </span>            :         struct rq *busiest;</a>
<a name="9896"><span class="lineNum">    9896 </span>            :         struct rq_flags rf;</a>
<a name="9897"><span class="lineNum">    9897 </span>            :         struct cpumask *cpus = this_cpu_cpumask_var_ptr(load_balance_mask);</a>
<a name="9898"><span class="lineNum">    9898 </span>            : </a>
<a name="9899"><span class="lineNum">    9899 </span>            :         struct lb_env env = {</a>
<a name="9900"><span class="lineNum">    9900 </span>            :                 .sd             = sd,</a>
<a name="9901"><span class="lineNum">    9901 </span>            :                 .dst_cpu        = this_cpu,</a>
<a name="9902"><span class="lineNum">    9902 </span>            :                 .dst_rq         = this_rq,</a>
<a name="9903"><span class="lineNum">    9903 </span>            :                 .dst_grpmask    = sched_group_span(sd-&gt;groups),</a>
<a name="9904"><span class="lineNum">    9904 </span>            :                 .idle           = idle,</a>
<a name="9905"><span class="lineNum">    9905 </span>            :                 .loop_break     = sched_nr_migrate_break,</a>
<a name="9906"><span class="lineNum">    9906 </span>            :                 .cpus           = cpus,</a>
<a name="9907"><span class="lineNum">    9907 </span>            :                 .fbq_type       = all,</a>
<a name="9908"><span class="lineNum">    9908 </span>            :                 .tasks          = LIST_HEAD_INIT(env.tasks),</a>
<a name="9909"><span class="lineNum">    9909 </span>            :         };</a>
<a name="9910"><span class="lineNum">    9910 </span>            : </a>
<a name="9911"><span class="lineNum">    9911 </span>            :         cpumask_and(cpus, sched_domain_span(sd), cpu_active_mask);</a>
<a name="9912"><span class="lineNum">    9912 </span>            : </a>
<a name="9913"><span class="lineNum">    9913 </span>            :         schedstat_inc(sd-&gt;lb_count[idle]);</a>
<a name="9914"><span class="lineNum">    9914 </span>            : </a>
<a name="9915"><span class="lineNum">    9915 </span>            : redo:</a>
<a name="9916"><span class="lineNum">    9916 </span>            :         if (!should_we_balance(&amp;env)) {</a>
<a name="9917"><span class="lineNum">    9917 </span>            :                 *continue_balancing = 0;</a>
<a name="9918"><span class="lineNum">    9918 </span>            :                 goto out_balanced;</a>
<a name="9919"><span class="lineNum">    9919 </span>            :         }</a>
<a name="9920"><span class="lineNum">    9920 </span>            : </a>
<a name="9921"><span class="lineNum">    9921 </span>            :         group = find_busiest_group(&amp;env);</a>
<a name="9922"><span class="lineNum">    9922 </span>            :         if (!group) {</a>
<a name="9923"><span class="lineNum">    9923 </span>            :                 schedstat_inc(sd-&gt;lb_nobusyg[idle]);</a>
<a name="9924"><span class="lineNum">    9924 </span>            :                 goto out_balanced;</a>
<a name="9925"><span class="lineNum">    9925 </span>            :         }</a>
<a name="9926"><span class="lineNum">    9926 </span>            : </a>
<a name="9927"><span class="lineNum">    9927 </span>            :         busiest = find_busiest_queue(&amp;env, group);</a>
<a name="9928"><span class="lineNum">    9928 </span>            :         if (!busiest) {</a>
<a name="9929"><span class="lineNum">    9929 </span>            :                 schedstat_inc(sd-&gt;lb_nobusyq[idle]);</a>
<a name="9930"><span class="lineNum">    9930 </span>            :                 goto out_balanced;</a>
<a name="9931"><span class="lineNum">    9931 </span>            :         }</a>
<a name="9932"><span class="lineNum">    9932 </span>            : </a>
<a name="9933"><span class="lineNum">    9933 </span>            :         BUG_ON(busiest == env.dst_rq);</a>
<a name="9934"><span class="lineNum">    9934 </span>            : </a>
<a name="9935"><span class="lineNum">    9935 </span>            :         schedstat_add(sd-&gt;lb_imbalance[idle], env.imbalance);</a>
<a name="9936"><span class="lineNum">    9936 </span>            : </a>
<a name="9937"><span class="lineNum">    9937 </span>            :         env.src_cpu = busiest-&gt;cpu;</a>
<a name="9938"><span class="lineNum">    9938 </span>            :         env.src_rq = busiest;</a>
<a name="9939"><span class="lineNum">    9939 </span>            : </a>
<a name="9940"><span class="lineNum">    9940 </span>            :         ld_moved = 0;</a>
<a name="9941"><span class="lineNum">    9941 </span>            :         /* Clear this flag as soon as we find a pullable task */</a>
<a name="9942"><span class="lineNum">    9942 </span>            :         env.flags |= LBF_ALL_PINNED;</a>
<a name="9943"><span class="lineNum">    9943 </span>            :         if (busiest-&gt;nr_running &gt; 1) {</a>
<a name="9944"><span class="lineNum">    9944 </span>            :                 /*</a>
<a name="9945"><span class="lineNum">    9945 </span>            :                  * Attempt to move tasks. If find_busiest_group has found</a>
<a name="9946"><span class="lineNum">    9946 </span>            :                  * an imbalance but busiest-&gt;nr_running &lt;= 1, the group is</a>
<a name="9947"><span class="lineNum">    9947 </span>            :                  * still unbalanced. ld_moved simply stays zero, so it is</a>
<a name="9948"><span class="lineNum">    9948 </span>            :                  * correctly treated as an imbalance.</a>
<a name="9949"><span class="lineNum">    9949 </span>            :                  */</a>
<a name="9950"><span class="lineNum">    9950 </span>            :                 env.loop_max  = min(sysctl_sched_nr_migrate, busiest-&gt;nr_running);</a>
<a name="9951"><span class="lineNum">    9951 </span>            : </a>
<a name="9952"><span class="lineNum">    9952 </span>            : more_balance:</a>
<a name="9953"><span class="lineNum">    9953 </span>            :                 rq_lock_irqsave(busiest, &amp;rf);</a>
<a name="9954"><span class="lineNum">    9954 </span>            :                 update_rq_clock(busiest);</a>
<a name="9955"><span class="lineNum">    9955 </span>            : </a>
<a name="9956"><span class="lineNum">    9956 </span>            :                 /*</a>
<a name="9957"><span class="lineNum">    9957 </span>            :                  * cur_ld_moved - load moved in current iteration</a>
<a name="9958"><span class="lineNum">    9958 </span>            :                  * ld_moved     - cumulative load moved across iterations</a>
<a name="9959"><span class="lineNum">    9959 </span>            :                  */</a>
<a name="9960"><span class="lineNum">    9960 </span>            :                 cur_ld_moved = detach_tasks(&amp;env);</a>
<a name="9961"><span class="lineNum">    9961 </span>            : </a>
<a name="9962"><span class="lineNum">    9962 </span>            :                 /*</a>
<a name="9963"><span class="lineNum">    9963 </span>            :                  * We've detached some tasks from busiest_rq. Every</a>
<a name="9964"><span class="lineNum">    9964 </span>            :                  * task is masked &quot;TASK_ON_RQ_MIGRATING&quot;, so we can safely</a>
<a name="9965"><span class="lineNum">    9965 </span>            :                  * unlock busiest-&gt;lock, and we are able to be sure</a>
<a name="9966"><span class="lineNum">    9966 </span>            :                  * that nobody can manipulate the tasks in parallel.</a>
<a name="9967"><span class="lineNum">    9967 </span>            :                  * See task_rq_lock() family for the details.</a>
<a name="9968"><span class="lineNum">    9968 </span>            :                  */</a>
<a name="9969"><span class="lineNum">    9969 </span>            : </a>
<a name="9970"><span class="lineNum">    9970 </span>            :                 rq_unlock(busiest, &amp;rf);</a>
<a name="9971"><span class="lineNum">    9971 </span>            : </a>
<a name="9972"><span class="lineNum">    9972 </span>            :                 if (cur_ld_moved) {</a>
<a name="9973"><span class="lineNum">    9973 </span>            :                         attach_tasks(&amp;env);</a>
<a name="9974"><span class="lineNum">    9974 </span>            :                         ld_moved += cur_ld_moved;</a>
<a name="9975"><span class="lineNum">    9975 </span>            :                 }</a>
<a name="9976"><span class="lineNum">    9976 </span>            : </a>
<a name="9977"><span class="lineNum">    9977 </span>            :                 local_irq_restore(rf.flags);</a>
<a name="9978"><span class="lineNum">    9978 </span>            : </a>
<a name="9979"><span class="lineNum">    9979 </span>            :                 if (env.flags &amp; LBF_NEED_BREAK) {</a>
<a name="9980"><span class="lineNum">    9980 </span>            :                         env.flags &amp;= ~LBF_NEED_BREAK;</a>
<a name="9981"><span class="lineNum">    9981 </span>            :                         goto more_balance;</a>
<a name="9982"><span class="lineNum">    9982 </span>            :                 }</a>
<a name="9983"><span class="lineNum">    9983 </span>            : </a>
<a name="9984"><span class="lineNum">    9984 </span>            :                 /*</a>
<a name="9985"><span class="lineNum">    9985 </span>            :                  * Revisit (affine) tasks on src_cpu that couldn't be moved to</a>
<a name="9986"><span class="lineNum">    9986 </span>            :                  * us and move them to an alternate dst_cpu in our sched_group</a>
<a name="9987"><span class="lineNum">    9987 </span>            :                  * where they can run. The upper limit on how many times we</a>
<a name="9988"><span class="lineNum">    9988 </span>            :                  * iterate on same src_cpu is dependent on number of CPUs in our</a>
<a name="9989"><span class="lineNum">    9989 </span>            :                  * sched_group.</a>
<a name="9990"><span class="lineNum">    9990 </span>            :                  *</a>
<a name="9991"><span class="lineNum">    9991 </span>            :                  * This changes load balance semantics a bit on who can move</a>
<a name="9992"><span class="lineNum">    9992 </span>            :                  * load to a given_cpu. In addition to the given_cpu itself</a>
<a name="9993"><span class="lineNum">    9993 </span>            :                  * (or a ilb_cpu acting on its behalf where given_cpu is</a>
<a name="9994"><span class="lineNum">    9994 </span>            :                  * nohz-idle), we now have balance_cpu in a position to move</a>
<a name="9995"><span class="lineNum">    9995 </span>            :                  * load to given_cpu. In rare situations, this may cause</a>
<a name="9996"><span class="lineNum">    9996 </span>            :                  * conflicts (balance_cpu and given_cpu/ilb_cpu deciding</a>
<a name="9997"><span class="lineNum">    9997 </span>            :                  * _independently_ and at _same_ time to move some load to</a>
<a name="9998"><span class="lineNum">    9998 </span>            :                  * given_cpu) causing excess load to be moved to given_cpu.</a>
<a name="9999"><span class="lineNum">    9999 </span>            :                  * This however should not happen so much in practice and</a>
<a name="10000"><span class="lineNum">   10000 </span>            :                  * moreover subsequent load balance cycles should correct the</a>
<a name="10001"><span class="lineNum">   10001 </span>            :                  * excess load moved.</a>
<a name="10002"><span class="lineNum">   10002 </span>            :                  */</a>
<a name="10003"><span class="lineNum">   10003 </span>            :                 if ((env.flags &amp; LBF_DST_PINNED) &amp;&amp; env.imbalance &gt; 0) {</a>
<a name="10004"><span class="lineNum">   10004 </span>            : </a>
<a name="10005"><span class="lineNum">   10005 </span>            :                         /* Prevent to re-select dst_cpu via env's CPUs */</a>
<a name="10006"><span class="lineNum">   10006 </span>            :                         __cpumask_clear_cpu(env.dst_cpu, env.cpus);</a>
<a name="10007"><span class="lineNum">   10007 </span>            : </a>
<a name="10008"><span class="lineNum">   10008 </span>            :                         env.dst_rq       = cpu_rq(env.new_dst_cpu);</a>
<a name="10009"><span class="lineNum">   10009 </span>            :                         env.dst_cpu      = env.new_dst_cpu;</a>
<a name="10010"><span class="lineNum">   10010 </span>            :                         env.flags       &amp;= ~LBF_DST_PINNED;</a>
<a name="10011"><span class="lineNum">   10011 </span>            :                         env.loop         = 0;</a>
<a name="10012"><span class="lineNum">   10012 </span>            :                         env.loop_break   = sched_nr_migrate_break;</a>
<a name="10013"><span class="lineNum">   10013 </span>            : </a>
<a name="10014"><span class="lineNum">   10014 </span>            :                         /*</a>
<a name="10015"><span class="lineNum">   10015 </span>            :                          * Go back to &quot;more_balance&quot; rather than &quot;redo&quot; since we</a>
<a name="10016"><span class="lineNum">   10016 </span>            :                          * need to continue with same src_cpu.</a>
<a name="10017"><span class="lineNum">   10017 </span>            :                          */</a>
<a name="10018"><span class="lineNum">   10018 </span>            :                         goto more_balance;</a>
<a name="10019"><span class="lineNum">   10019 </span>            :                 }</a>
<a name="10020"><span class="lineNum">   10020 </span>            : </a>
<a name="10021"><span class="lineNum">   10021 </span>            :                 /*</a>
<a name="10022"><span class="lineNum">   10022 </span>            :                  * We failed to reach balance because of affinity.</a>
<a name="10023"><span class="lineNum">   10023 </span>            :                  */</a>
<a name="10024"><span class="lineNum">   10024 </span>            :                 if (sd_parent) {</a>
<a name="10025"><span class="lineNum">   10025 </span>            :                         int *group_imbalance = &amp;sd_parent-&gt;groups-&gt;sgc-&gt;imbalance;</a>
<a name="10026"><span class="lineNum">   10026 </span>            : </a>
<a name="10027"><span class="lineNum">   10027 </span>            :                         if ((env.flags &amp; LBF_SOME_PINNED) &amp;&amp; env.imbalance &gt; 0)</a>
<a name="10028"><span class="lineNum">   10028 </span>            :                                 *group_imbalance = 1;</a>
<a name="10029"><span class="lineNum">   10029 </span>            :                 }</a>
<a name="10030"><span class="lineNum">   10030 </span>            : </a>
<a name="10031"><span class="lineNum">   10031 </span>            :                 /* All tasks on this runqueue were pinned by CPU affinity */</a>
<a name="10032"><span class="lineNum">   10032 </span>            :                 if (unlikely(env.flags &amp; LBF_ALL_PINNED)) {</a>
<a name="10033"><span class="lineNum">   10033 </span>            :                         __cpumask_clear_cpu(cpu_of(busiest), cpus);</a>
<a name="10034"><span class="lineNum">   10034 </span>            :                         /*</a>
<a name="10035"><span class="lineNum">   10035 </span>            :                          * Attempting to continue load balancing at the current</a>
<a name="10036"><span class="lineNum">   10036 </span>            :                          * sched_domain level only makes sense if there are</a>
<a name="10037"><span class="lineNum">   10037 </span>            :                          * active CPUs remaining as possible busiest CPUs to</a>
<a name="10038"><span class="lineNum">   10038 </span>            :                          * pull load from which are not contained within the</a>
<a name="10039"><span class="lineNum">   10039 </span>            :                          * destination group that is receiving any migrated</a>
<a name="10040"><span class="lineNum">   10040 </span>            :                          * load.</a>
<a name="10041"><span class="lineNum">   10041 </span>            :                          */</a>
<a name="10042"><span class="lineNum">   10042 </span>            :                         if (!cpumask_subset(cpus, env.dst_grpmask)) {</a>
<a name="10043"><span class="lineNum">   10043 </span>            :                                 env.loop = 0;</a>
<a name="10044"><span class="lineNum">   10044 </span>            :                                 env.loop_break = sched_nr_migrate_break;</a>
<a name="10045"><span class="lineNum">   10045 </span>            :                                 goto redo;</a>
<a name="10046"><span class="lineNum">   10046 </span>            :                         }</a>
<a name="10047"><span class="lineNum">   10047 </span>            :                         goto out_all_pinned;</a>
<a name="10048"><span class="lineNum">   10048 </span>            :                 }</a>
<a name="10049"><span class="lineNum">   10049 </span>            :         }</a>
<a name="10050"><span class="lineNum">   10050 </span>            : </a>
<a name="10051"><span class="lineNum">   10051 </span>            :         if (!ld_moved) {</a>
<a name="10052"><span class="lineNum">   10052 </span>            :                 schedstat_inc(sd-&gt;lb_failed[idle]);</a>
<a name="10053"><span class="lineNum">   10053 </span>            :                 /*</a>
<a name="10054"><span class="lineNum">   10054 </span>            :                  * Increment the failure counter only on periodic balance.</a>
<a name="10055"><span class="lineNum">   10055 </span>            :                  * We do not want newidle balance, which can be very</a>
<a name="10056"><span class="lineNum">   10056 </span>            :                  * frequent, pollute the failure counter causing</a>
<a name="10057"><span class="lineNum">   10057 </span>            :                  * excessive cache_hot migrations and active balances.</a>
<a name="10058"><span class="lineNum">   10058 </span>            :                  */</a>
<a name="10059"><span class="lineNum">   10059 </span>            :                 if (idle != CPU_NEWLY_IDLE)</a>
<a name="10060"><span class="lineNum">   10060 </span>            :                         sd-&gt;nr_balance_failed++;</a>
<a name="10061"><span class="lineNum">   10061 </span>            : </a>
<a name="10062"><span class="lineNum">   10062 </span>            :                 if (need_active_balance(&amp;env)) {</a>
<a name="10063"><span class="lineNum">   10063 </span>            :                         unsigned long flags;</a>
<a name="10064"><span class="lineNum">   10064 </span>            : </a>
<a name="10065"><span class="lineNum">   10065 </span>            :                         raw_spin_rq_lock_irqsave(busiest, flags);</a>
<a name="10066"><span class="lineNum">   10066 </span>            : </a>
<a name="10067"><span class="lineNum">   10067 </span>            :                         /*</a>
<a name="10068"><span class="lineNum">   10068 </span>            :                          * Don't kick the active_load_balance_cpu_stop,</a>
<a name="10069"><span class="lineNum">   10069 </span>            :                          * if the curr task on busiest CPU can't be</a>
<a name="10070"><span class="lineNum">   10070 </span>            :                          * moved to this_cpu:</a>
<a name="10071"><span class="lineNum">   10071 </span>            :                          */</a>
<a name="10072"><span class="lineNum">   10072 </span>            :                         if (!cpumask_test_cpu(this_cpu, busiest-&gt;curr-&gt;cpus_ptr)) {</a>
<a name="10073"><span class="lineNum">   10073 </span>            :                                 raw_spin_rq_unlock_irqrestore(busiest, flags);</a>
<a name="10074"><span class="lineNum">   10074 </span>            :                                 goto out_one_pinned;</a>
<a name="10075"><span class="lineNum">   10075 </span>            :                         }</a>
<a name="10076"><span class="lineNum">   10076 </span>            : </a>
<a name="10077"><span class="lineNum">   10077 </span>            :                         /* Record that we found at least one task that could run on this_cpu */</a>
<a name="10078"><span class="lineNum">   10078 </span>            :                         env.flags &amp;= ~LBF_ALL_PINNED;</a>
<a name="10079"><span class="lineNum">   10079 </span>            : </a>
<a name="10080"><span class="lineNum">   10080 </span>            :                         /*</a>
<a name="10081"><span class="lineNum">   10081 </span>            :                          * -&gt;active_balance synchronizes accesses to</a>
<a name="10082"><span class="lineNum">   10082 </span>            :                          * -&gt;active_balance_work.  Once set, it's cleared</a>
<a name="10083"><span class="lineNum">   10083 </span>            :                          * only after active load balance is finished.</a>
<a name="10084"><span class="lineNum">   10084 </span>            :                          */</a>
<a name="10085"><span class="lineNum">   10085 </span>            :                         if (!busiest-&gt;active_balance) {</a>
<a name="10086"><span class="lineNum">   10086 </span>            :                                 busiest-&gt;active_balance = 1;</a>
<a name="10087"><span class="lineNum">   10087 </span>            :                                 busiest-&gt;push_cpu = this_cpu;</a>
<a name="10088"><span class="lineNum">   10088 </span>            :                                 active_balance = 1;</a>
<a name="10089"><span class="lineNum">   10089 </span>            :                         }</a>
<a name="10090"><span class="lineNum">   10090 </span>            :                         raw_spin_rq_unlock_irqrestore(busiest, flags);</a>
<a name="10091"><span class="lineNum">   10091 </span>            : </a>
<a name="10092"><span class="lineNum">   10092 </span>            :                         if (active_balance) {</a>
<a name="10093"><span class="lineNum">   10093 </span>            :                                 stop_one_cpu_nowait(cpu_of(busiest),</a>
<a name="10094"><span class="lineNum">   10094 </span>            :                                         active_load_balance_cpu_stop, busiest,</a>
<a name="10095"><span class="lineNum">   10095 </span>            :                                         &amp;busiest-&gt;active_balance_work);</a>
<a name="10096"><span class="lineNum">   10096 </span>            :                         }</a>
<a name="10097"><span class="lineNum">   10097 </span>            :                 }</a>
<a name="10098"><span class="lineNum">   10098 </span>            :         } else {</a>
<a name="10099"><span class="lineNum">   10099 </span>            :                 sd-&gt;nr_balance_failed = 0;</a>
<a name="10100"><span class="lineNum">   10100 </span>            :         }</a>
<a name="10101"><span class="lineNum">   10101 </span>            : </a>
<a name="10102"><span class="lineNum">   10102 </span>            :         if (likely(!active_balance) || need_active_balance(&amp;env)) {</a>
<a name="10103"><span class="lineNum">   10103 </span>            :                 /* We were unbalanced, so reset the balancing interval */</a>
<a name="10104"><span class="lineNum">   10104 </span>            :                 sd-&gt;balance_interval = sd-&gt;min_interval;</a>
<a name="10105"><span class="lineNum">   10105 </span>            :         }</a>
<a name="10106"><span class="lineNum">   10106 </span>            : </a>
<a name="10107"><span class="lineNum">   10107 </span>            :         goto out;</a>
<a name="10108"><span class="lineNum">   10108 </span>            : </a>
<a name="10109"><span class="lineNum">   10109 </span>            : out_balanced:</a>
<a name="10110"><span class="lineNum">   10110 </span>            :         /*</a>
<a name="10111"><span class="lineNum">   10111 </span>            :          * We reach balance although we may have faced some affinity</a>
<a name="10112"><span class="lineNum">   10112 </span>            :          * constraints. Clear the imbalance flag only if other tasks got</a>
<a name="10113"><span class="lineNum">   10113 </span>            :          * a chance to move and fix the imbalance.</a>
<a name="10114"><span class="lineNum">   10114 </span>            :          */</a>
<a name="10115"><span class="lineNum">   10115 </span>            :         if (sd_parent &amp;&amp; !(env.flags &amp; LBF_ALL_PINNED)) {</a>
<a name="10116"><span class="lineNum">   10116 </span>            :                 int *group_imbalance = &amp;sd_parent-&gt;groups-&gt;sgc-&gt;imbalance;</a>
<a name="10117"><span class="lineNum">   10117 </span>            : </a>
<a name="10118"><span class="lineNum">   10118 </span>            :                 if (*group_imbalance)</a>
<a name="10119"><span class="lineNum">   10119 </span>            :                         *group_imbalance = 0;</a>
<a name="10120"><span class="lineNum">   10120 </span>            :         }</a>
<a name="10121"><span class="lineNum">   10121 </span>            : </a>
<a name="10122"><span class="lineNum">   10122 </span>            : out_all_pinned:</a>
<a name="10123"><span class="lineNum">   10123 </span>            :         /*</a>
<a name="10124"><span class="lineNum">   10124 </span>            :          * We reach balance because all tasks are pinned at this level so</a>
<a name="10125"><span class="lineNum">   10125 </span>            :          * we can't migrate them. Let the imbalance flag set so parent level</a>
<a name="10126"><span class="lineNum">   10126 </span>            :          * can try to migrate them.</a>
<a name="10127"><span class="lineNum">   10127 </span>            :          */</a>
<a name="10128"><span class="lineNum">   10128 </span>            :         schedstat_inc(sd-&gt;lb_balanced[idle]);</a>
<a name="10129"><span class="lineNum">   10129 </span>            : </a>
<a name="10130"><span class="lineNum">   10130 </span>            :         sd-&gt;nr_balance_failed = 0;</a>
<a name="10131"><span class="lineNum">   10131 </span>            : </a>
<a name="10132"><span class="lineNum">   10132 </span>            : out_one_pinned:</a>
<a name="10133"><span class="lineNum">   10133 </span>            :         ld_moved = 0;</a>
<a name="10134"><span class="lineNum">   10134 </span>            : </a>
<a name="10135"><span class="lineNum">   10135 </span>            :         /*</a>
<a name="10136"><span class="lineNum">   10136 </span>            :          * newidle_balance() disregards balance intervals, so we could</a>
<a name="10137"><span class="lineNum">   10137 </span>            :          * repeatedly reach this code, which would lead to balance_interval</a>
<a name="10138"><span class="lineNum">   10138 </span>            :          * skyrocketing in a short amount of time. Skip the balance_interval</a>
<a name="10139"><span class="lineNum">   10139 </span>            :          * increase logic to avoid that.</a>
<a name="10140"><span class="lineNum">   10140 </span>            :          */</a>
<a name="10141"><span class="lineNum">   10141 </span>            :         if (env.idle == CPU_NEWLY_IDLE)</a>
<a name="10142"><span class="lineNum">   10142 </span>            :                 goto out;</a>
<a name="10143"><span class="lineNum">   10143 </span>            : </a>
<a name="10144"><span class="lineNum">   10144 </span>            :         /* tune up the balancing interval */</a>
<a name="10145"><span class="lineNum">   10145 </span>            :         if ((env.flags &amp; LBF_ALL_PINNED &amp;&amp;</a>
<a name="10146"><span class="lineNum">   10146 </span>            :              sd-&gt;balance_interval &lt; MAX_PINNED_INTERVAL) ||</a>
<a name="10147"><span class="lineNum">   10147 </span>            :             sd-&gt;balance_interval &lt; sd-&gt;max_interval)</a>
<a name="10148"><span class="lineNum">   10148 </span>            :                 sd-&gt;balance_interval *= 2;</a>
<a name="10149"><span class="lineNum">   10149 </span>            : out:</a>
<a name="10150"><span class="lineNum">   10150 </span>            :         return ld_moved;</a>
<a name="10151"><span class="lineNum">   10151 </span>            : }</a>
<a name="10152"><span class="lineNum">   10152 </span>            : </a>
<a name="10153"><span class="lineNum">   10153 </span>            : static inline unsigned long</a>
<a name="10154"><span class="lineNum">   10154 </span>            : get_sd_balance_interval(struct sched_domain *sd, int cpu_busy)</a>
<a name="10155"><span class="lineNum">   10155 </span>            : {</a>
<a name="10156"><span class="lineNum">   10156 </span>            :         unsigned long interval = sd-&gt;balance_interval;</a>
<a name="10157"><span class="lineNum">   10157 </span>            : </a>
<a name="10158"><span class="lineNum">   10158 </span>            :         if (cpu_busy)</a>
<a name="10159"><span class="lineNum">   10159 </span>            :                 interval *= sd-&gt;busy_factor;</a>
<a name="10160"><span class="lineNum">   10160 </span>            : </a>
<a name="10161"><span class="lineNum">   10161 </span>            :         /* scale ms to jiffies */</a>
<a name="10162"><span class="lineNum">   10162 </span>            :         interval = msecs_to_jiffies(interval);</a>
<a name="10163"><span class="lineNum">   10163 </span>            : </a>
<a name="10164"><span class="lineNum">   10164 </span>            :         /*</a>
<a name="10165"><span class="lineNum">   10165 </span>            :          * Reduce likelihood of busy balancing at higher domains racing with</a>
<a name="10166"><span class="lineNum">   10166 </span>            :          * balancing at lower domains by preventing their balancing periods</a>
<a name="10167"><span class="lineNum">   10167 </span>            :          * from being multiples of each other.</a>
<a name="10168"><span class="lineNum">   10168 </span>            :          */</a>
<a name="10169"><span class="lineNum">   10169 </span>            :         if (cpu_busy)</a>
<a name="10170"><span class="lineNum">   10170 </span>            :                 interval -= 1;</a>
<a name="10171"><span class="lineNum">   10171 </span>            : </a>
<a name="10172"><span class="lineNum">   10172 </span>            :         interval = clamp(interval, 1UL, max_load_balance_interval);</a>
<a name="10173"><span class="lineNum">   10173 </span>            : </a>
<a name="10174"><span class="lineNum">   10174 </span>            :         return interval;</a>
<a name="10175"><span class="lineNum">   10175 </span>            : }</a>
<a name="10176"><span class="lineNum">   10176 </span>            : </a>
<a name="10177"><span class="lineNum">   10177 </span>            : static inline void</a>
<a name="10178"><span class="lineNum">   10178 </span>            : update_next_balance(struct sched_domain *sd, unsigned long *next_balance)</a>
<a name="10179"><span class="lineNum">   10179 </span>            : {</a>
<a name="10180"><span class="lineNum">   10180 </span>            :         unsigned long interval, next;</a>
<a name="10181"><span class="lineNum">   10181 </span>            : </a>
<a name="10182"><span class="lineNum">   10182 </span>            :         /* used by idle balance, so cpu_busy = 0 */</a>
<a name="10183"><span class="lineNum">   10183 </span>            :         interval = get_sd_balance_interval(sd, 0);</a>
<a name="10184"><span class="lineNum">   10184 </span>            :         next = sd-&gt;last_balance + interval;</a>
<a name="10185"><span class="lineNum">   10185 </span>            : </a>
<a name="10186"><span class="lineNum">   10186 </span>            :         if (time_after(*next_balance, next))</a>
<a name="10187"><span class="lineNum">   10187 </span>            :                 *next_balance = next;</a>
<a name="10188"><span class="lineNum">   10188 </span>            : }</a>
<a name="10189"><span class="lineNum">   10189 </span>            : </a>
<a name="10190"><span class="lineNum">   10190 </span>            : /*</a>
<a name="10191"><span class="lineNum">   10191 </span>            :  * active_load_balance_cpu_stop is run by the CPU stopper. It pushes</a>
<a name="10192"><span class="lineNum">   10192 </span>            :  * running tasks off the busiest CPU onto idle CPUs. It requires at</a>
<a name="10193"><span class="lineNum">   10193 </span>            :  * least 1 task to be running on each physical CPU where possible, and</a>
<a name="10194"><span class="lineNum">   10194 </span>            :  * avoids physical / logical imbalances.</a>
<a name="10195"><span class="lineNum">   10195 </span>            :  */</a>
<a name="10196"><span class="lineNum">   10196 </span>            : static int active_load_balance_cpu_stop(void *data)</a>
<a name="10197"><span class="lineNum">   10197 </span>            : {</a>
<a name="10198"><span class="lineNum">   10198 </span>            :         struct rq *busiest_rq = data;</a>
<a name="10199"><span class="lineNum">   10199 </span>            :         int busiest_cpu = cpu_of(busiest_rq);</a>
<a name="10200"><span class="lineNum">   10200 </span>            :         int target_cpu = busiest_rq-&gt;push_cpu;</a>
<a name="10201"><span class="lineNum">   10201 </span>            :         struct rq *target_rq = cpu_rq(target_cpu);</a>
<a name="10202"><span class="lineNum">   10202 </span>            :         struct sched_domain *sd;</a>
<a name="10203"><span class="lineNum">   10203 </span>            :         struct task_struct *p = NULL;</a>
<a name="10204"><span class="lineNum">   10204 </span>            :         struct rq_flags rf;</a>
<a name="10205"><span class="lineNum">   10205 </span>            : </a>
<a name="10206"><span class="lineNum">   10206 </span>            :         rq_lock_irq(busiest_rq, &amp;rf);</a>
<a name="10207"><span class="lineNum">   10207 </span>            :         /*</a>
<a name="10208"><span class="lineNum">   10208 </span>            :          * Between queueing the stop-work and running it is a hole in which</a>
<a name="10209"><span class="lineNum">   10209 </span>            :          * CPUs can become inactive. We should not move tasks from or to</a>
<a name="10210"><span class="lineNum">   10210 </span>            :          * inactive CPUs.</a>
<a name="10211"><span class="lineNum">   10211 </span>            :          */</a>
<a name="10212"><span class="lineNum">   10212 </span>            :         if (!cpu_active(busiest_cpu) || !cpu_active(target_cpu))</a>
<a name="10213"><span class="lineNum">   10213 </span>            :                 goto out_unlock;</a>
<a name="10214"><span class="lineNum">   10214 </span>            : </a>
<a name="10215"><span class="lineNum">   10215 </span>            :         /* Make sure the requested CPU hasn't gone down in the meantime: */</a>
<a name="10216"><span class="lineNum">   10216 </span>            :         if (unlikely(busiest_cpu != smp_processor_id() ||</a>
<a name="10217"><span class="lineNum">   10217 </span>            :                      !busiest_rq-&gt;active_balance))</a>
<a name="10218"><span class="lineNum">   10218 </span>            :                 goto out_unlock;</a>
<a name="10219"><span class="lineNum">   10219 </span>            : </a>
<a name="10220"><span class="lineNum">   10220 </span>            :         /* Is there any task to move? */</a>
<a name="10221"><span class="lineNum">   10221 </span>            :         if (busiest_rq-&gt;nr_running &lt;= 1)</a>
<a name="10222"><span class="lineNum">   10222 </span>            :                 goto out_unlock;</a>
<a name="10223"><span class="lineNum">   10223 </span>            : </a>
<a name="10224"><span class="lineNum">   10224 </span>            :         /*</a>
<a name="10225"><span class="lineNum">   10225 </span>            :          * This condition is &quot;impossible&quot;, if it occurs</a>
<a name="10226"><span class="lineNum">   10226 </span>            :          * we need to fix it. Originally reported by</a>
<a name="10227"><span class="lineNum">   10227 </span>            :          * Bjorn Helgaas on a 128-CPU setup.</a>
<a name="10228"><span class="lineNum">   10228 </span>            :          */</a>
<a name="10229"><span class="lineNum">   10229 </span>            :         BUG_ON(busiest_rq == target_rq);</a>
<a name="10230"><span class="lineNum">   10230 </span>            : </a>
<a name="10231"><span class="lineNum">   10231 </span>            :         /* Search for an sd spanning us and the target CPU. */</a>
<a name="10232"><span class="lineNum">   10232 </span>            :         rcu_read_lock();</a>
<a name="10233"><span class="lineNum">   10233 </span>            :         for_each_domain(target_cpu, sd) {</a>
<a name="10234"><span class="lineNum">   10234 </span>            :                 if (cpumask_test_cpu(busiest_cpu, sched_domain_span(sd)))</a>
<a name="10235"><span class="lineNum">   10235 </span>            :                         break;</a>
<a name="10236"><span class="lineNum">   10236 </span>            :         }</a>
<a name="10237"><span class="lineNum">   10237 </span>            : </a>
<a name="10238"><span class="lineNum">   10238 </span>            :         if (likely(sd)) {</a>
<a name="10239"><span class="lineNum">   10239 </span>            :                 struct lb_env env = {</a>
<a name="10240"><span class="lineNum">   10240 </span>            :                         .sd             = sd,</a>
<a name="10241"><span class="lineNum">   10241 </span>            :                         .dst_cpu        = target_cpu,</a>
<a name="10242"><span class="lineNum">   10242 </span>            :                         .dst_rq         = target_rq,</a>
<a name="10243"><span class="lineNum">   10243 </span>            :                         .src_cpu        = busiest_rq-&gt;cpu,</a>
<a name="10244"><span class="lineNum">   10244 </span>            :                         .src_rq         = busiest_rq,</a>
<a name="10245"><span class="lineNum">   10245 </span>            :                         .idle           = CPU_IDLE,</a>
<a name="10246"><span class="lineNum">   10246 </span>            :                         .flags          = LBF_ACTIVE_LB,</a>
<a name="10247"><span class="lineNum">   10247 </span>            :                 };</a>
<a name="10248"><span class="lineNum">   10248 </span>            : </a>
<a name="10249"><span class="lineNum">   10249 </span>            :                 schedstat_inc(sd-&gt;alb_count);</a>
<a name="10250"><span class="lineNum">   10250 </span>            :                 update_rq_clock(busiest_rq);</a>
<a name="10251"><span class="lineNum">   10251 </span>            : </a>
<a name="10252"><span class="lineNum">   10252 </span>            :                 p = detach_one_task(&amp;env);</a>
<a name="10253"><span class="lineNum">   10253 </span>            :                 if (p) {</a>
<a name="10254"><span class="lineNum">   10254 </span>            :                         schedstat_inc(sd-&gt;alb_pushed);</a>
<a name="10255"><span class="lineNum">   10255 </span>            :                         /* Active balancing done, reset the failure counter. */</a>
<a name="10256"><span class="lineNum">   10256 </span>            :                         sd-&gt;nr_balance_failed = 0;</a>
<a name="10257"><span class="lineNum">   10257 </span>            :                 } else {</a>
<a name="10258"><span class="lineNum">   10258 </span>            :                         schedstat_inc(sd-&gt;alb_failed);</a>
<a name="10259"><span class="lineNum">   10259 </span>            :                 }</a>
<a name="10260"><span class="lineNum">   10260 </span>            :         }</a>
<a name="10261"><span class="lineNum">   10261 </span>            :         rcu_read_unlock();</a>
<a name="10262"><span class="lineNum">   10262 </span>            : out_unlock:</a>
<a name="10263"><span class="lineNum">   10263 </span>            :         busiest_rq-&gt;active_balance = 0;</a>
<a name="10264"><span class="lineNum">   10264 </span>            :         rq_unlock(busiest_rq, &amp;rf);</a>
<a name="10265"><span class="lineNum">   10265 </span>            : </a>
<a name="10266"><span class="lineNum">   10266 </span>            :         if (p)</a>
<a name="10267"><span class="lineNum">   10267 </span>            :                 attach_one_task(target_rq, p);</a>
<a name="10268"><span class="lineNum">   10268 </span>            : </a>
<a name="10269"><span class="lineNum">   10269 </span>            :         local_irq_enable();</a>
<a name="10270"><span class="lineNum">   10270 </span>            : </a>
<a name="10271"><span class="lineNum">   10271 </span>            :         return 0;</a>
<a name="10272"><span class="lineNum">   10272 </span>            : }</a>
<a name="10273"><span class="lineNum">   10273 </span>            : </a>
<a name="10274"><span class="lineNum">   10274 </span>            : static DEFINE_SPINLOCK(balancing);</a>
<a name="10275"><span class="lineNum">   10275 </span>            : </a>
<a name="10276"><span class="lineNum">   10276 </span>            : /*</a>
<a name="10277"><span class="lineNum">   10277 </span>            :  * Scale the max load_balance interval with the number of CPUs in the system.</a>
<a name="10278"><span class="lineNum">   10278 </span>            :  * This trades load-balance latency on larger machines for less cross talk.</a>
<a name="10279"><span class="lineNum">   10279 </span>            :  */</a>
<a name="10280"><span class="lineNum">   10280 </span>            : void update_max_interval(void)</a>
<a name="10281"><span class="lineNum">   10281 </span>            : {</a>
<a name="10282"><span class="lineNum">   10282 </span>            :         max_load_balance_interval = HZ*num_online_cpus()/10;</a>
<a name="10283"><span class="lineNum">   10283 </span>            : }</a>
<a name="10284"><span class="lineNum">   10284 </span>            : </a>
<a name="10285"><span class="lineNum">   10285 </span>            : static inline bool update_newidle_cost(struct sched_domain *sd, u64 cost)</a>
<a name="10286"><span class="lineNum">   10286 </span>            : {</a>
<a name="10287"><span class="lineNum">   10287 </span>            :         if (cost &gt; sd-&gt;max_newidle_lb_cost) {</a>
<a name="10288"><span class="lineNum">   10288 </span>            :                 /*</a>
<a name="10289"><span class="lineNum">   10289 </span>            :                  * Track max cost of a domain to make sure to not delay the</a>
<a name="10290"><span class="lineNum">   10290 </span>            :                  * next wakeup on the CPU.</a>
<a name="10291"><span class="lineNum">   10291 </span>            :                  */</a>
<a name="10292"><span class="lineNum">   10292 </span>            :                 sd-&gt;max_newidle_lb_cost = cost;</a>
<a name="10293"><span class="lineNum">   10293 </span>            :                 sd-&gt;last_decay_max_lb_cost = jiffies;</a>
<a name="10294"><span class="lineNum">   10294 </span>            :         } else if (time_after(jiffies, sd-&gt;last_decay_max_lb_cost + HZ)) {</a>
<a name="10295"><span class="lineNum">   10295 </span>            :                 /*</a>
<a name="10296"><span class="lineNum">   10296 </span>            :                  * Decay the newidle max times by ~1% per second to ensure that</a>
<a name="10297"><span class="lineNum">   10297 </span>            :                  * it is not outdated and the current max cost is actually</a>
<a name="10298"><span class="lineNum">   10298 </span>            :                  * shorter.</a>
<a name="10299"><span class="lineNum">   10299 </span>            :                  */</a>
<a name="10300"><span class="lineNum">   10300 </span>            :                 sd-&gt;max_newidle_lb_cost = (sd-&gt;max_newidle_lb_cost * 253) / 256;</a>
<a name="10301"><span class="lineNum">   10301 </span>            :                 sd-&gt;last_decay_max_lb_cost = jiffies;</a>
<a name="10302"><span class="lineNum">   10302 </span>            : </a>
<a name="10303"><span class="lineNum">   10303 </span>            :                 return true;</a>
<a name="10304"><span class="lineNum">   10304 </span>            :         }</a>
<a name="10305"><span class="lineNum">   10305 </span>            : </a>
<a name="10306"><span class="lineNum">   10306 </span>            :         return false;</a>
<a name="10307"><span class="lineNum">   10307 </span>            : }</a>
<a name="10308"><span class="lineNum">   10308 </span>            : </a>
<a name="10309"><span class="lineNum">   10309 </span>            : /*</a>
<a name="10310"><span class="lineNum">   10310 </span>            :  * It checks each scheduling domain to see if it is due to be balanced,</a>
<a name="10311"><span class="lineNum">   10311 </span>            :  * and initiates a balancing operation if so.</a>
<a name="10312"><span class="lineNum">   10312 </span>            :  *</a>
<a name="10313"><span class="lineNum">   10313 </span>            :  * Balancing parameters are set up in init_sched_domains.</a>
<a name="10314"><span class="lineNum">   10314 </span>            :  */</a>
<a name="10315"><span class="lineNum">   10315 </span>            : static void rebalance_domains(struct rq *rq, enum cpu_idle_type idle)</a>
<a name="10316"><span class="lineNum">   10316 </span>            : {</a>
<a name="10317"><span class="lineNum">   10317 </span>            :         int continue_balancing = 1;</a>
<a name="10318"><span class="lineNum">   10318 </span>            :         int cpu = rq-&gt;cpu;</a>
<a name="10319"><span class="lineNum">   10319 </span>            :         int busy = idle != CPU_IDLE &amp;&amp; !sched_idle_cpu(cpu);</a>
<a name="10320"><span class="lineNum">   10320 </span>            :         unsigned long interval;</a>
<a name="10321"><span class="lineNum">   10321 </span>            :         struct sched_domain *sd;</a>
<a name="10322"><span class="lineNum">   10322 </span>            :         /* Earliest time when we have to do rebalance again */</a>
<a name="10323"><span class="lineNum">   10323 </span>            :         unsigned long next_balance = jiffies + 60*HZ;</a>
<a name="10324"><span class="lineNum">   10324 </span>            :         int update_next_balance = 0;</a>
<a name="10325"><span class="lineNum">   10325 </span>            :         int need_serialize, need_decay = 0;</a>
<a name="10326"><span class="lineNum">   10326 </span>            :         u64 max_cost = 0;</a>
<a name="10327"><span class="lineNum">   10327 </span>            : </a>
<a name="10328"><span class="lineNum">   10328 </span>            :         rcu_read_lock();</a>
<a name="10329"><span class="lineNum">   10329 </span>            :         for_each_domain(cpu, sd) {</a>
<a name="10330"><span class="lineNum">   10330 </span>            :                 /*</a>
<a name="10331"><span class="lineNum">   10331 </span>            :                  * Decay the newidle max times here because this is a regular</a>
<a name="10332"><span class="lineNum">   10332 </span>            :                  * visit to all the domains.</a>
<a name="10333"><span class="lineNum">   10333 </span>            :                  */</a>
<a name="10334"><span class="lineNum">   10334 </span>            :                 need_decay = update_newidle_cost(sd, 0);</a>
<a name="10335"><span class="lineNum">   10335 </span>            :                 max_cost += sd-&gt;max_newidle_lb_cost;</a>
<a name="10336"><span class="lineNum">   10336 </span>            : </a>
<a name="10337"><span class="lineNum">   10337 </span>            :                 /*</a>
<a name="10338"><span class="lineNum">   10338 </span>            :                  * Stop the load balance at this level. There is another</a>
<a name="10339"><span class="lineNum">   10339 </span>            :                  * CPU in our sched group which is doing load balancing more</a>
<a name="10340"><span class="lineNum">   10340 </span>            :                  * actively.</a>
<a name="10341"><span class="lineNum">   10341 </span>            :                  */</a>
<a name="10342"><span class="lineNum">   10342 </span>            :                 if (!continue_balancing) {</a>
<a name="10343"><span class="lineNum">   10343 </span>            :                         if (need_decay)</a>
<a name="10344"><span class="lineNum">   10344 </span>            :                                 continue;</a>
<a name="10345"><span class="lineNum">   10345 </span>            :                         break;</a>
<a name="10346"><span class="lineNum">   10346 </span>            :                 }</a>
<a name="10347"><span class="lineNum">   10347 </span>            : </a>
<a name="10348"><span class="lineNum">   10348 </span>            :                 interval = get_sd_balance_interval(sd, busy);</a>
<a name="10349"><span class="lineNum">   10349 </span>            : </a>
<a name="10350"><span class="lineNum">   10350 </span>            :                 need_serialize = sd-&gt;flags &amp; SD_SERIALIZE;</a>
<a name="10351"><span class="lineNum">   10351 </span>            :                 if (need_serialize) {</a>
<a name="10352"><span class="lineNum">   10352 </span>            :                         if (!spin_trylock(&amp;balancing))</a>
<a name="10353"><span class="lineNum">   10353 </span>            :                                 goto out;</a>
<a name="10354"><span class="lineNum">   10354 </span>            :                 }</a>
<a name="10355"><span class="lineNum">   10355 </span>            : </a>
<a name="10356"><span class="lineNum">   10356 </span>            :                 if (time_after_eq(jiffies, sd-&gt;last_balance + interval)) {</a>
<a name="10357"><span class="lineNum">   10357 </span>            :                         if (load_balance(cpu, rq, sd, idle, &amp;continue_balancing)) {</a>
<a name="10358"><span class="lineNum">   10358 </span>            :                                 /*</a>
<a name="10359"><span class="lineNum">   10359 </span>            :                                  * The LBF_DST_PINNED logic could have changed</a>
<a name="10360"><span class="lineNum">   10360 </span>            :                                  * env-&gt;dst_cpu, so we can't know our idle</a>
<a name="10361"><span class="lineNum">   10361 </span>            :                                  * state even if we migrated tasks. Update it.</a>
<a name="10362"><span class="lineNum">   10362 </span>            :                                  */</a>
<a name="10363"><span class="lineNum">   10363 </span>            :                                 idle = idle_cpu(cpu) ? CPU_IDLE : CPU_NOT_IDLE;</a>
<a name="10364"><span class="lineNum">   10364 </span>            :                                 busy = idle != CPU_IDLE &amp;&amp; !sched_idle_cpu(cpu);</a>
<a name="10365"><span class="lineNum">   10365 </span>            :                         }</a>
<a name="10366"><span class="lineNum">   10366 </span>            :                         sd-&gt;last_balance = jiffies;</a>
<a name="10367"><span class="lineNum">   10367 </span>            :                         interval = get_sd_balance_interval(sd, busy);</a>
<a name="10368"><span class="lineNum">   10368 </span>            :                 }</a>
<a name="10369"><span class="lineNum">   10369 </span>            :                 if (need_serialize)</a>
<a name="10370"><span class="lineNum">   10370 </span>            :                         spin_unlock(&amp;balancing);</a>
<a name="10371"><span class="lineNum">   10371 </span>            : out:</a>
<a name="10372"><span class="lineNum">   10372 </span>            :                 if (time_after(next_balance, sd-&gt;last_balance + interval)) {</a>
<a name="10373"><span class="lineNum">   10373 </span>            :                         next_balance = sd-&gt;last_balance + interval;</a>
<a name="10374"><span class="lineNum">   10374 </span>            :                         update_next_balance = 1;</a>
<a name="10375"><span class="lineNum">   10375 </span>            :                 }</a>
<a name="10376"><span class="lineNum">   10376 </span>            :         }</a>
<a name="10377"><span class="lineNum">   10377 </span>            :         if (need_decay) {</a>
<a name="10378"><span class="lineNum">   10378 </span>            :                 /*</a>
<a name="10379"><span class="lineNum">   10379 </span>            :                  * Ensure the rq-wide value also decays but keep it at a</a>
<a name="10380"><span class="lineNum">   10380 </span>            :                  * reasonable floor to avoid funnies with rq-&gt;avg_idle.</a>
<a name="10381"><span class="lineNum">   10381 </span>            :                  */</a>
<a name="10382"><span class="lineNum">   10382 </span>            :                 rq-&gt;max_idle_balance_cost =</a>
<a name="10383"><span class="lineNum">   10383 </span>            :                         max((u64)sysctl_sched_migration_cost, max_cost);</a>
<a name="10384"><span class="lineNum">   10384 </span>            :         }</a>
<a name="10385"><span class="lineNum">   10385 </span>            :         rcu_read_unlock();</a>
<a name="10386"><span class="lineNum">   10386 </span>            : </a>
<a name="10387"><span class="lineNum">   10387 </span>            :         /*</a>
<a name="10388"><span class="lineNum">   10388 </span>            :          * next_balance will be updated only when there is a need.</a>
<a name="10389"><span class="lineNum">   10389 </span>            :          * When the cpu is attached to null domain for ex, it will not be</a>
<a name="10390"><span class="lineNum">   10390 </span>            :          * updated.</a>
<a name="10391"><span class="lineNum">   10391 </span>            :          */</a>
<a name="10392"><span class="lineNum">   10392 </span>            :         if (likely(update_next_balance))</a>
<a name="10393"><span class="lineNum">   10393 </span>            :                 rq-&gt;next_balance = next_balance;</a>
<a name="10394"><span class="lineNum">   10394 </span>            : </a>
<a name="10395"><span class="lineNum">   10395 </span>            : }</a>
<a name="10396"><span class="lineNum">   10396 </span>            : </a>
<a name="10397"><span class="lineNum">   10397 </span>            : static inline int on_null_domain(struct rq *rq)</a>
<a name="10398"><span class="lineNum">   10398 </span>            : {</a>
<a name="10399"><span class="lineNum">   10399 </span>            :         return unlikely(!rcu_dereference_sched(rq-&gt;sd));</a>
<a name="10400"><span class="lineNum">   10400 </span>            : }</a>
<a name="10401"><span class="lineNum">   10401 </span>            : </a>
<a name="10402"><span class="lineNum">   10402 </span>            : #ifdef CONFIG_NO_HZ_COMMON</a>
<a name="10403"><span class="lineNum">   10403 </span>            : /*</a>
<a name="10404"><span class="lineNum">   10404 </span>            :  * idle load balancing details</a>
<a name="10405"><span class="lineNum">   10405 </span>            :  * - When one of the busy CPUs notice that there may be an idle rebalancing</a>
<a name="10406"><span class="lineNum">   10406 </span>            :  *   needed, they will kick the idle load balancer, which then does idle</a>
<a name="10407"><span class="lineNum">   10407 </span>            :  *   load balancing for all the idle CPUs.</a>
<a name="10408"><span class="lineNum">   10408 </span>            :  * - HK_TYPE_MISC CPUs are used for this task, because HK_TYPE_SCHED not set</a>
<a name="10409"><span class="lineNum">   10409 </span>            :  *   anywhere yet.</a>
<a name="10410"><span class="lineNum">   10410 </span>            :  */</a>
<a name="10411"><span class="lineNum">   10411 </span>            : </a>
<a name="10412"><span class="lineNum">   10412 </span>            : static inline int find_new_ilb(void)</a>
<a name="10413"><span class="lineNum">   10413 </span>            : {</a>
<a name="10414"><span class="lineNum">   10414 </span>            :         int ilb;</a>
<a name="10415"><span class="lineNum">   10415 </span>            :         const struct cpumask *hk_mask;</a>
<a name="10416"><span class="lineNum">   10416 </span>            : </a>
<a name="10417"><span class="lineNum">   10417 </span>            :         hk_mask = housekeeping_cpumask(HK_TYPE_MISC);</a>
<a name="10418"><span class="lineNum">   10418 </span>            : </a>
<a name="10419"><span class="lineNum">   10419 </span>            :         for_each_cpu_and(ilb, nohz.idle_cpus_mask, hk_mask) {</a>
<a name="10420"><span class="lineNum">   10420 </span>            : </a>
<a name="10421"><span class="lineNum">   10421 </span>            :                 if (ilb == smp_processor_id())</a>
<a name="10422"><span class="lineNum">   10422 </span>            :                         continue;</a>
<a name="10423"><span class="lineNum">   10423 </span>            : </a>
<a name="10424"><span class="lineNum">   10424 </span>            :                 if (idle_cpu(ilb))</a>
<a name="10425"><span class="lineNum">   10425 </span>            :                         return ilb;</a>
<a name="10426"><span class="lineNum">   10426 </span>            :         }</a>
<a name="10427"><span class="lineNum">   10427 </span>            : </a>
<a name="10428"><span class="lineNum">   10428 </span>            :         return nr_cpu_ids;</a>
<a name="10429"><span class="lineNum">   10429 </span>            : }</a>
<a name="10430"><span class="lineNum">   10430 </span>            : </a>
<a name="10431"><span class="lineNum">   10431 </span>            : /*</a>
<a name="10432"><span class="lineNum">   10432 </span>            :  * Kick a CPU to do the nohz balancing, if it is time for it. We pick any</a>
<a name="10433"><span class="lineNum">   10433 </span>            :  * idle CPU in the HK_TYPE_MISC housekeeping set (if there is one).</a>
<a name="10434"><span class="lineNum">   10434 </span>            :  */</a>
<a name="10435"><span class="lineNum">   10435 </span>            : static void kick_ilb(unsigned int flags)</a>
<a name="10436"><span class="lineNum">   10436 </span>            : {</a>
<a name="10437"><span class="lineNum">   10437 </span>            :         int ilb_cpu;</a>
<a name="10438"><span class="lineNum">   10438 </span>            : </a>
<a name="10439"><span class="lineNum">   10439 </span>            :         /*</a>
<a name="10440"><span class="lineNum">   10440 </span>            :          * Increase nohz.next_balance only when if full ilb is triggered but</a>
<a name="10441"><span class="lineNum">   10441 </span>            :          * not if we only update stats.</a>
<a name="10442"><span class="lineNum">   10442 </span>            :          */</a>
<a name="10443"><span class="lineNum">   10443 </span>            :         if (flags &amp; NOHZ_BALANCE_KICK)</a>
<a name="10444"><span class="lineNum">   10444 </span>            :                 nohz.next_balance = jiffies+1;</a>
<a name="10445"><span class="lineNum">   10445 </span>            : </a>
<a name="10446"><span class="lineNum">   10446 </span>            :         ilb_cpu = find_new_ilb();</a>
<a name="10447"><span class="lineNum">   10447 </span>            : </a>
<a name="10448"><span class="lineNum">   10448 </span>            :         if (ilb_cpu &gt;= nr_cpu_ids)</a>
<a name="10449"><span class="lineNum">   10449 </span>            :                 return;</a>
<a name="10450"><span class="lineNum">   10450 </span>            : </a>
<a name="10451"><span class="lineNum">   10451 </span>            :         /*</a>
<a name="10452"><span class="lineNum">   10452 </span>            :          * Access to rq::nohz_csd is serialized by NOHZ_KICK_MASK; he who sets</a>
<a name="10453"><span class="lineNum">   10453 </span>            :          * the first flag owns it; cleared by nohz_csd_func().</a>
<a name="10454"><span class="lineNum">   10454 </span>            :          */</a>
<a name="10455"><span class="lineNum">   10455 </span>            :         flags = atomic_fetch_or(flags, nohz_flags(ilb_cpu));</a>
<a name="10456"><span class="lineNum">   10456 </span>            :         if (flags &amp; NOHZ_KICK_MASK)</a>
<a name="10457"><span class="lineNum">   10457 </span>            :                 return;</a>
<a name="10458"><span class="lineNum">   10458 </span>            : </a>
<a name="10459"><span class="lineNum">   10459 </span>            :         /*</a>
<a name="10460"><span class="lineNum">   10460 </span>            :          * This way we generate an IPI on the target CPU which</a>
<a name="10461"><span class="lineNum">   10461 </span>            :          * is idle. And the softirq performing nohz idle load balance</a>
<a name="10462"><span class="lineNum">   10462 </span>            :          * will be run before returning from the IPI.</a>
<a name="10463"><span class="lineNum">   10463 </span>            :          */</a>
<a name="10464"><span class="lineNum">   10464 </span>            :         smp_call_function_single_async(ilb_cpu, &amp;cpu_rq(ilb_cpu)-&gt;nohz_csd);</a>
<a name="10465"><span class="lineNum">   10465 </span>            : }</a>
<a name="10466"><span class="lineNum">   10466 </span>            : </a>
<a name="10467"><span class="lineNum">   10467 </span>            : /*</a>
<a name="10468"><span class="lineNum">   10468 </span>            :  * Current decision point for kicking the idle load balancer in the presence</a>
<a name="10469"><span class="lineNum">   10469 </span>            :  * of idle CPUs in the system.</a>
<a name="10470"><span class="lineNum">   10470 </span>            :  */</a>
<a name="10471"><span class="lineNum">   10471 </span>            : static void nohz_balancer_kick(struct rq *rq)</a>
<a name="10472"><span class="lineNum">   10472 </span>            : {</a>
<a name="10473"><span class="lineNum">   10473 </span>            :         unsigned long now = jiffies;</a>
<a name="10474"><span class="lineNum">   10474 </span>            :         struct sched_domain_shared *sds;</a>
<a name="10475"><span class="lineNum">   10475 </span>            :         struct sched_domain *sd;</a>
<a name="10476"><span class="lineNum">   10476 </span>            :         int nr_busy, i, cpu = rq-&gt;cpu;</a>
<a name="10477"><span class="lineNum">   10477 </span>            :         unsigned int flags = 0;</a>
<a name="10478"><span class="lineNum">   10478 </span>            : </a>
<a name="10479"><span class="lineNum">   10479 </span>            :         if (unlikely(rq-&gt;idle_balance))</a>
<a name="10480"><span class="lineNum">   10480 </span>            :                 return;</a>
<a name="10481"><span class="lineNum">   10481 </span>            : </a>
<a name="10482"><span class="lineNum">   10482 </span>            :         /*</a>
<a name="10483"><span class="lineNum">   10483 </span>            :          * We may be recently in ticked or tickless idle mode. At the first</a>
<a name="10484"><span class="lineNum">   10484 </span>            :          * busy tick after returning from idle, we will update the busy stats.</a>
<a name="10485"><span class="lineNum">   10485 </span>            :          */</a>
<a name="10486"><span class="lineNum">   10486 </span>            :         nohz_balance_exit_idle(rq);</a>
<a name="10487"><span class="lineNum">   10487 </span>            : </a>
<a name="10488"><span class="lineNum">   10488 </span>            :         /*</a>
<a name="10489"><span class="lineNum">   10489 </span>            :          * None are in tickless mode and hence no need for NOHZ idle load</a>
<a name="10490"><span class="lineNum">   10490 </span>            :          * balancing.</a>
<a name="10491"><span class="lineNum">   10491 </span>            :          */</a>
<a name="10492"><span class="lineNum">   10492 </span>            :         if (likely(!atomic_read(&amp;nohz.nr_cpus)))</a>
<a name="10493"><span class="lineNum">   10493 </span>            :                 return;</a>
<a name="10494"><span class="lineNum">   10494 </span>            : </a>
<a name="10495"><span class="lineNum">   10495 </span>            :         if (READ_ONCE(nohz.has_blocked) &amp;&amp;</a>
<a name="10496"><span class="lineNum">   10496 </span>            :             time_after(now, READ_ONCE(nohz.next_blocked)))</a>
<a name="10497"><span class="lineNum">   10497 </span>            :                 flags = NOHZ_STATS_KICK;</a>
<a name="10498"><span class="lineNum">   10498 </span>            : </a>
<a name="10499"><span class="lineNum">   10499 </span>            :         if (time_before(now, nohz.next_balance))</a>
<a name="10500"><span class="lineNum">   10500 </span>            :                 goto out;</a>
<a name="10501"><span class="lineNum">   10501 </span>            : </a>
<a name="10502"><span class="lineNum">   10502 </span>            :         if (rq-&gt;nr_running &gt;= 2) {</a>
<a name="10503"><span class="lineNum">   10503 </span>            :                 flags = NOHZ_STATS_KICK | NOHZ_BALANCE_KICK;</a>
<a name="10504"><span class="lineNum">   10504 </span>            :                 goto out;</a>
<a name="10505"><span class="lineNum">   10505 </span>            :         }</a>
<a name="10506"><span class="lineNum">   10506 </span>            : </a>
<a name="10507"><span class="lineNum">   10507 </span>            :         rcu_read_lock();</a>
<a name="10508"><span class="lineNum">   10508 </span>            : </a>
<a name="10509"><span class="lineNum">   10509 </span>            :         sd = rcu_dereference(rq-&gt;sd);</a>
<a name="10510"><span class="lineNum">   10510 </span>            :         if (sd) {</a>
<a name="10511"><span class="lineNum">   10511 </span>            :                 /*</a>
<a name="10512"><span class="lineNum">   10512 </span>            :                  * If there's a CFS task and the current CPU has reduced</a>
<a name="10513"><span class="lineNum">   10513 </span>            :                  * capacity; kick the ILB to see if there's a better CPU to run</a>
<a name="10514"><span class="lineNum">   10514 </span>            :                  * on.</a>
<a name="10515"><span class="lineNum">   10515 </span>            :                  */</a>
<a name="10516"><span class="lineNum">   10516 </span>            :                 if (rq-&gt;cfs.h_nr_running &gt;= 1 &amp;&amp; check_cpu_capacity(rq, sd)) {</a>
<a name="10517"><span class="lineNum">   10517 </span>            :                         flags = NOHZ_STATS_KICK | NOHZ_BALANCE_KICK;</a>
<a name="10518"><span class="lineNum">   10518 </span>            :                         goto unlock;</a>
<a name="10519"><span class="lineNum">   10519 </span>            :                 }</a>
<a name="10520"><span class="lineNum">   10520 </span>            :         }</a>
<a name="10521"><span class="lineNum">   10521 </span>            : </a>
<a name="10522"><span class="lineNum">   10522 </span>            :         sd = rcu_dereference(per_cpu(sd_asym_packing, cpu));</a>
<a name="10523"><span class="lineNum">   10523 </span>            :         if (sd) {</a>
<a name="10524"><span class="lineNum">   10524 </span>            :                 /*</a>
<a name="10525"><span class="lineNum">   10525 </span>            :                  * When ASYM_PACKING; see if there's a more preferred CPU</a>
<a name="10526"><span class="lineNum">   10526 </span>            :                  * currently idle; in which case, kick the ILB to move tasks</a>
<a name="10527"><span class="lineNum">   10527 </span>            :                  * around.</a>
<a name="10528"><span class="lineNum">   10528 </span>            :                  */</a>
<a name="10529"><span class="lineNum">   10529 </span>            :                 for_each_cpu_and(i, sched_domain_span(sd), nohz.idle_cpus_mask) {</a>
<a name="10530"><span class="lineNum">   10530 </span>            :                         if (sched_asym_prefer(i, cpu)) {</a>
<a name="10531"><span class="lineNum">   10531 </span>            :                                 flags = NOHZ_STATS_KICK | NOHZ_BALANCE_KICK;</a>
<a name="10532"><span class="lineNum">   10532 </span>            :                                 goto unlock;</a>
<a name="10533"><span class="lineNum">   10533 </span>            :                         }</a>
<a name="10534"><span class="lineNum">   10534 </span>            :                 }</a>
<a name="10535"><span class="lineNum">   10535 </span>            :         }</a>
<a name="10536"><span class="lineNum">   10536 </span>            : </a>
<a name="10537"><span class="lineNum">   10537 </span>            :         sd = rcu_dereference(per_cpu(sd_asym_cpucapacity, cpu));</a>
<a name="10538"><span class="lineNum">   10538 </span>            :         if (sd) {</a>
<a name="10539"><span class="lineNum">   10539 </span>            :                 /*</a>
<a name="10540"><span class="lineNum">   10540 </span>            :                  * When ASYM_CPUCAPACITY; see if there's a higher capacity CPU</a>
<a name="10541"><span class="lineNum">   10541 </span>            :                  * to run the misfit task on.</a>
<a name="10542"><span class="lineNum">   10542 </span>            :                  */</a>
<a name="10543"><span class="lineNum">   10543 </span>            :                 if (check_misfit_status(rq, sd)) {</a>
<a name="10544"><span class="lineNum">   10544 </span>            :                         flags = NOHZ_STATS_KICK | NOHZ_BALANCE_KICK;</a>
<a name="10545"><span class="lineNum">   10545 </span>            :                         goto unlock;</a>
<a name="10546"><span class="lineNum">   10546 </span>            :                 }</a>
<a name="10547"><span class="lineNum">   10547 </span>            : </a>
<a name="10548"><span class="lineNum">   10548 </span>            :                 /*</a>
<a name="10549"><span class="lineNum">   10549 </span>            :                  * For asymmetric systems, we do not want to nicely balance</a>
<a name="10550"><span class="lineNum">   10550 </span>            :                  * cache use, instead we want to embrace asymmetry and only</a>
<a name="10551"><span class="lineNum">   10551 </span>            :                  * ensure tasks have enough CPU capacity.</a>
<a name="10552"><span class="lineNum">   10552 </span>            :                  *</a>
<a name="10553"><span class="lineNum">   10553 </span>            :                  * Skip the LLC logic because it's not relevant in that case.</a>
<a name="10554"><span class="lineNum">   10554 </span>            :                  */</a>
<a name="10555"><span class="lineNum">   10555 </span>            :                 goto unlock;</a>
<a name="10556"><span class="lineNum">   10556 </span>            :         }</a>
<a name="10557"><span class="lineNum">   10557 </span>            : </a>
<a name="10558"><span class="lineNum">   10558 </span>            :         sds = rcu_dereference(per_cpu(sd_llc_shared, cpu));</a>
<a name="10559"><span class="lineNum">   10559 </span>            :         if (sds) {</a>
<a name="10560"><span class="lineNum">   10560 </span>            :                 /*</a>
<a name="10561"><span class="lineNum">   10561 </span>            :                  * If there is an imbalance between LLC domains (IOW we could</a>
<a name="10562"><span class="lineNum">   10562 </span>            :                  * increase the overall cache use), we need some less-loaded LLC</a>
<a name="10563"><span class="lineNum">   10563 </span>            :                  * domain to pull some load. Likewise, we may need to spread</a>
<a name="10564"><span class="lineNum">   10564 </span>            :                  * load within the current LLC domain (e.g. packed SMT cores but</a>
<a name="10565"><span class="lineNum">   10565 </span>            :                  * other CPUs are idle). We can't really know from here how busy</a>
<a name="10566"><span class="lineNum">   10566 </span>            :                  * the others are - so just get a nohz balance going if it looks</a>
<a name="10567"><span class="lineNum">   10567 </span>            :                  * like this LLC domain has tasks we could move.</a>
<a name="10568"><span class="lineNum">   10568 </span>            :                  */</a>
<a name="10569"><span class="lineNum">   10569 </span>            :                 nr_busy = atomic_read(&amp;sds-&gt;nr_busy_cpus);</a>
<a name="10570"><span class="lineNum">   10570 </span>            :                 if (nr_busy &gt; 1) {</a>
<a name="10571"><span class="lineNum">   10571 </span>            :                         flags = NOHZ_STATS_KICK | NOHZ_BALANCE_KICK;</a>
<a name="10572"><span class="lineNum">   10572 </span>            :                         goto unlock;</a>
<a name="10573"><span class="lineNum">   10573 </span>            :                 }</a>
<a name="10574"><span class="lineNum">   10574 </span>            :         }</a>
<a name="10575"><span class="lineNum">   10575 </span>            : unlock:</a>
<a name="10576"><span class="lineNum">   10576 </span>            :         rcu_read_unlock();</a>
<a name="10577"><span class="lineNum">   10577 </span>            : out:</a>
<a name="10578"><span class="lineNum">   10578 </span>            :         if (READ_ONCE(nohz.needs_update))</a>
<a name="10579"><span class="lineNum">   10579 </span>            :                 flags |= NOHZ_NEXT_KICK;</a>
<a name="10580"><span class="lineNum">   10580 </span>            : </a>
<a name="10581"><span class="lineNum">   10581 </span>            :         if (flags)</a>
<a name="10582"><span class="lineNum">   10582 </span>            :                 kick_ilb(flags);</a>
<a name="10583"><span class="lineNum">   10583 </span>            : }</a>
<a name="10584"><span class="lineNum">   10584 </span>            : </a>
<a name="10585"><span class="lineNum">   10585 </span>            : static void set_cpu_sd_state_busy(int cpu)</a>
<a name="10586"><span class="lineNum">   10586 </span>            : {</a>
<a name="10587"><span class="lineNum">   10587 </span>            :         struct sched_domain *sd;</a>
<a name="10588"><span class="lineNum">   10588 </span>            : </a>
<a name="10589"><span class="lineNum">   10589 </span>            :         rcu_read_lock();</a>
<a name="10590"><span class="lineNum">   10590 </span>            :         sd = rcu_dereference(per_cpu(sd_llc, cpu));</a>
<a name="10591"><span class="lineNum">   10591 </span>            : </a>
<a name="10592"><span class="lineNum">   10592 </span>            :         if (!sd || !sd-&gt;nohz_idle)</a>
<a name="10593"><span class="lineNum">   10593 </span>            :                 goto unlock;</a>
<a name="10594"><span class="lineNum">   10594 </span>            :         sd-&gt;nohz_idle = 0;</a>
<a name="10595"><span class="lineNum">   10595 </span>            : </a>
<a name="10596"><span class="lineNum">   10596 </span>            :         atomic_inc(&amp;sd-&gt;shared-&gt;nr_busy_cpus);</a>
<a name="10597"><span class="lineNum">   10597 </span>            : unlock:</a>
<a name="10598"><span class="lineNum">   10598 </span>            :         rcu_read_unlock();</a>
<a name="10599"><span class="lineNum">   10599 </span>            : }</a>
<a name="10600"><span class="lineNum">   10600 </span>            : </a>
<a name="10601"><span class="lineNum">   10601 </span>            : void nohz_balance_exit_idle(struct rq *rq)</a>
<a name="10602"><span class="lineNum">   10602 </span>            : {</a>
<a name="10603"><span class="lineNum">   10603 </span>            :         SCHED_WARN_ON(rq != this_rq());</a>
<a name="10604"><span class="lineNum">   10604 </span>            : </a>
<a name="10605"><span class="lineNum">   10605 </span>            :         if (likely(!rq-&gt;nohz_tick_stopped))</a>
<a name="10606"><span class="lineNum">   10606 </span>            :                 return;</a>
<a name="10607"><span class="lineNum">   10607 </span>            : </a>
<a name="10608"><span class="lineNum">   10608 </span>            :         rq-&gt;nohz_tick_stopped = 0;</a>
<a name="10609"><span class="lineNum">   10609 </span>            :         cpumask_clear_cpu(rq-&gt;cpu, nohz.idle_cpus_mask);</a>
<a name="10610"><span class="lineNum">   10610 </span>            :         atomic_dec(&amp;nohz.nr_cpus);</a>
<a name="10611"><span class="lineNum">   10611 </span>            : </a>
<a name="10612"><span class="lineNum">   10612 </span>            :         set_cpu_sd_state_busy(rq-&gt;cpu);</a>
<a name="10613"><span class="lineNum">   10613 </span>            : }</a>
<a name="10614"><span class="lineNum">   10614 </span>            : </a>
<a name="10615"><span class="lineNum">   10615 </span>            : static void set_cpu_sd_state_idle(int cpu)</a>
<a name="10616"><span class="lineNum">   10616 </span>            : {</a>
<a name="10617"><span class="lineNum">   10617 </span>            :         struct sched_domain *sd;</a>
<a name="10618"><span class="lineNum">   10618 </span>            : </a>
<a name="10619"><span class="lineNum">   10619 </span>            :         rcu_read_lock();</a>
<a name="10620"><span class="lineNum">   10620 </span>            :         sd = rcu_dereference(per_cpu(sd_llc, cpu));</a>
<a name="10621"><span class="lineNum">   10621 </span>            : </a>
<a name="10622"><span class="lineNum">   10622 </span>            :         if (!sd || sd-&gt;nohz_idle)</a>
<a name="10623"><span class="lineNum">   10623 </span>            :                 goto unlock;</a>
<a name="10624"><span class="lineNum">   10624 </span>            :         sd-&gt;nohz_idle = 1;</a>
<a name="10625"><span class="lineNum">   10625 </span>            : </a>
<a name="10626"><span class="lineNum">   10626 </span>            :         atomic_dec(&amp;sd-&gt;shared-&gt;nr_busy_cpus);</a>
<a name="10627"><span class="lineNum">   10627 </span>            : unlock:</a>
<a name="10628"><span class="lineNum">   10628 </span>            :         rcu_read_unlock();</a>
<a name="10629"><span class="lineNum">   10629 </span>            : }</a>
<a name="10630"><span class="lineNum">   10630 </span>            : </a>
<a name="10631"><span class="lineNum">   10631 </span>            : /*</a>
<a name="10632"><span class="lineNum">   10632 </span>            :  * This routine will record that the CPU is going idle with tick stopped.</a>
<a name="10633"><span class="lineNum">   10633 </span>            :  * This info will be used in performing idle load balancing in the future.</a>
<a name="10634"><span class="lineNum">   10634 </span>            :  */</a>
<a name="10635"><span class="lineNum">   10635 </span>            : void nohz_balance_enter_idle(int cpu)</a>
<a name="10636"><span class="lineNum">   10636 </span>            : {</a>
<a name="10637"><span class="lineNum">   10637 </span>            :         struct rq *rq = cpu_rq(cpu);</a>
<a name="10638"><span class="lineNum">   10638 </span>            : </a>
<a name="10639"><span class="lineNum">   10639 </span>            :         SCHED_WARN_ON(cpu != smp_processor_id());</a>
<a name="10640"><span class="lineNum">   10640 </span>            : </a>
<a name="10641"><span class="lineNum">   10641 </span>            :         /* If this CPU is going down, then nothing needs to be done: */</a>
<a name="10642"><span class="lineNum">   10642 </span>            :         if (!cpu_active(cpu))</a>
<a name="10643"><span class="lineNum">   10643 </span>            :                 return;</a>
<a name="10644"><span class="lineNum">   10644 </span>            : </a>
<a name="10645"><span class="lineNum">   10645 </span>            :         /* Spare idle load balancing on CPUs that don't want to be disturbed: */</a>
<a name="10646"><span class="lineNum">   10646 </span>            :         if (!housekeeping_cpu(cpu, HK_TYPE_SCHED))</a>
<a name="10647"><span class="lineNum">   10647 </span>            :                 return;</a>
<a name="10648"><span class="lineNum">   10648 </span>            : </a>
<a name="10649"><span class="lineNum">   10649 </span>            :         /*</a>
<a name="10650"><span class="lineNum">   10650 </span>            :          * Can be set safely without rq-&gt;lock held</a>
<a name="10651"><span class="lineNum">   10651 </span>            :          * If a clear happens, it will have evaluated last additions because</a>
<a name="10652"><span class="lineNum">   10652 </span>            :          * rq-&gt;lock is held during the check and the clear</a>
<a name="10653"><span class="lineNum">   10653 </span>            :          */</a>
<a name="10654"><span class="lineNum">   10654 </span>            :         rq-&gt;has_blocked_load = 1;</a>
<a name="10655"><span class="lineNum">   10655 </span>            : </a>
<a name="10656"><span class="lineNum">   10656 </span>            :         /*</a>
<a name="10657"><span class="lineNum">   10657 </span>            :          * The tick is still stopped but load could have been added in the</a>
<a name="10658"><span class="lineNum">   10658 </span>            :          * meantime. We set the nohz.has_blocked flag to trig a check of the</a>
<a name="10659"><span class="lineNum">   10659 </span>            :          * *_avg. The CPU is already part of nohz.idle_cpus_mask so the clear</a>
<a name="10660"><span class="lineNum">   10660 </span>            :          * of nohz.has_blocked can only happen after checking the new load</a>
<a name="10661"><span class="lineNum">   10661 </span>            :          */</a>
<a name="10662"><span class="lineNum">   10662 </span>            :         if (rq-&gt;nohz_tick_stopped)</a>
<a name="10663"><span class="lineNum">   10663 </span>            :                 goto out;</a>
<a name="10664"><span class="lineNum">   10664 </span>            : </a>
<a name="10665"><span class="lineNum">   10665 </span>            :         /* If we're a completely isolated CPU, we don't play: */</a>
<a name="10666"><span class="lineNum">   10666 </span>            :         if (on_null_domain(rq))</a>
<a name="10667"><span class="lineNum">   10667 </span>            :                 return;</a>
<a name="10668"><span class="lineNum">   10668 </span>            : </a>
<a name="10669"><span class="lineNum">   10669 </span>            :         rq-&gt;nohz_tick_stopped = 1;</a>
<a name="10670"><span class="lineNum">   10670 </span>            : </a>
<a name="10671"><span class="lineNum">   10671 </span>            :         cpumask_set_cpu(cpu, nohz.idle_cpus_mask);</a>
<a name="10672"><span class="lineNum">   10672 </span>            :         atomic_inc(&amp;nohz.nr_cpus);</a>
<a name="10673"><span class="lineNum">   10673 </span>            : </a>
<a name="10674"><span class="lineNum">   10674 </span>            :         /*</a>
<a name="10675"><span class="lineNum">   10675 </span>            :          * Ensures that if nohz_idle_balance() fails to observe our</a>
<a name="10676"><span class="lineNum">   10676 </span>            :          * @idle_cpus_mask store, it must observe the @has_blocked</a>
<a name="10677"><span class="lineNum">   10677 </span>            :          * and @needs_update stores.</a>
<a name="10678"><span class="lineNum">   10678 </span>            :          */</a>
<a name="10679"><span class="lineNum">   10679 </span>            :         smp_mb__after_atomic();</a>
<a name="10680"><span class="lineNum">   10680 </span>            : </a>
<a name="10681"><span class="lineNum">   10681 </span>            :         set_cpu_sd_state_idle(cpu);</a>
<a name="10682"><span class="lineNum">   10682 </span>            : </a>
<a name="10683"><span class="lineNum">   10683 </span>            :         WRITE_ONCE(nohz.needs_update, 1);</a>
<a name="10684"><span class="lineNum">   10684 </span>            : out:</a>
<a name="10685"><span class="lineNum">   10685 </span>            :         /*</a>
<a name="10686"><span class="lineNum">   10686 </span>            :          * Each time a cpu enter idle, we assume that it has blocked load and</a>
<a name="10687"><span class="lineNum">   10687 </span>            :          * enable the periodic update of the load of idle cpus</a>
<a name="10688"><span class="lineNum">   10688 </span>            :          */</a>
<a name="10689"><span class="lineNum">   10689 </span>            :         WRITE_ONCE(nohz.has_blocked, 1);</a>
<a name="10690"><span class="lineNum">   10690 </span>            : }</a>
<a name="10691"><span class="lineNum">   10691 </span>            : </a>
<a name="10692"><span class="lineNum">   10692 </span>            : static bool update_nohz_stats(struct rq *rq)</a>
<a name="10693"><span class="lineNum">   10693 </span>            : {</a>
<a name="10694"><span class="lineNum">   10694 </span>            :         unsigned int cpu = rq-&gt;cpu;</a>
<a name="10695"><span class="lineNum">   10695 </span>            : </a>
<a name="10696"><span class="lineNum">   10696 </span>            :         if (!rq-&gt;has_blocked_load)</a>
<a name="10697"><span class="lineNum">   10697 </span>            :                 return false;</a>
<a name="10698"><span class="lineNum">   10698 </span>            : </a>
<a name="10699"><span class="lineNum">   10699 </span>            :         if (!cpumask_test_cpu(cpu, nohz.idle_cpus_mask))</a>
<a name="10700"><span class="lineNum">   10700 </span>            :                 return false;</a>
<a name="10701"><span class="lineNum">   10701 </span>            : </a>
<a name="10702"><span class="lineNum">   10702 </span>            :         if (!time_after(jiffies, READ_ONCE(rq-&gt;last_blocked_load_update_tick)))</a>
<a name="10703"><span class="lineNum">   10703 </span>            :                 return true;</a>
<a name="10704"><span class="lineNum">   10704 </span>            : </a>
<a name="10705"><span class="lineNum">   10705 </span>            :         update_blocked_averages(cpu);</a>
<a name="10706"><span class="lineNum">   10706 </span>            : </a>
<a name="10707"><span class="lineNum">   10707 </span>            :         return rq-&gt;has_blocked_load;</a>
<a name="10708"><span class="lineNum">   10708 </span>            : }</a>
<a name="10709"><span class="lineNum">   10709 </span>            : </a>
<a name="10710"><span class="lineNum">   10710 </span>            : /*</a>
<a name="10711"><span class="lineNum">   10711 </span>            :  * Internal function that runs load balance for all idle cpus. The load balance</a>
<a name="10712"><span class="lineNum">   10712 </span>            :  * can be a simple update of blocked load or a complete load balance with</a>
<a name="10713"><span class="lineNum">   10713 </span>            :  * tasks movement depending of flags.</a>
<a name="10714"><span class="lineNum">   10714 </span>            :  */</a>
<a name="10715"><span class="lineNum">   10715 </span>            : static void _nohz_idle_balance(struct rq *this_rq, unsigned int flags,</a>
<a name="10716"><span class="lineNum">   10716 </span>            :                                enum cpu_idle_type idle)</a>
<a name="10717"><span class="lineNum">   10717 </span>            : {</a>
<a name="10718"><span class="lineNum">   10718 </span>            :         /* Earliest time when we have to do rebalance again */</a>
<a name="10719"><span class="lineNum">   10719 </span>            :         unsigned long now = jiffies;</a>
<a name="10720"><span class="lineNum">   10720 </span>            :         unsigned long next_balance = now + 60*HZ;</a>
<a name="10721"><span class="lineNum">   10721 </span>            :         bool has_blocked_load = false;</a>
<a name="10722"><span class="lineNum">   10722 </span>            :         int update_next_balance = 0;</a>
<a name="10723"><span class="lineNum">   10723 </span>            :         int this_cpu = this_rq-&gt;cpu;</a>
<a name="10724"><span class="lineNum">   10724 </span>            :         int balance_cpu;</a>
<a name="10725"><span class="lineNum">   10725 </span>            :         struct rq *rq;</a>
<a name="10726"><span class="lineNum">   10726 </span>            : </a>
<a name="10727"><span class="lineNum">   10727 </span>            :         SCHED_WARN_ON((flags &amp; NOHZ_KICK_MASK) == NOHZ_BALANCE_KICK);</a>
<a name="10728"><span class="lineNum">   10728 </span>            : </a>
<a name="10729"><span class="lineNum">   10729 </span>            :         /*</a>
<a name="10730"><span class="lineNum">   10730 </span>            :          * We assume there will be no idle load after this update and clear</a>
<a name="10731"><span class="lineNum">   10731 </span>            :          * the has_blocked flag. If a cpu enters idle in the mean time, it will</a>
<a name="10732"><span class="lineNum">   10732 </span>            :          * set the has_blocked flag and trigger another update of idle load.</a>
<a name="10733"><span class="lineNum">   10733 </span>            :          * Because a cpu that becomes idle, is added to idle_cpus_mask before</a>
<a name="10734"><span class="lineNum">   10734 </span>            :          * setting the flag, we are sure to not clear the state and not</a>
<a name="10735"><span class="lineNum">   10735 </span>            :          * check the load of an idle cpu.</a>
<a name="10736"><span class="lineNum">   10736 </span>            :          *</a>
<a name="10737"><span class="lineNum">   10737 </span>            :          * Same applies to idle_cpus_mask vs needs_update.</a>
<a name="10738"><span class="lineNum">   10738 </span>            :          */</a>
<a name="10739"><span class="lineNum">   10739 </span>            :         if (flags &amp; NOHZ_STATS_KICK)</a>
<a name="10740"><span class="lineNum">   10740 </span>            :                 WRITE_ONCE(nohz.has_blocked, 0);</a>
<a name="10741"><span class="lineNum">   10741 </span>            :         if (flags &amp; NOHZ_NEXT_KICK)</a>
<a name="10742"><span class="lineNum">   10742 </span>            :                 WRITE_ONCE(nohz.needs_update, 0);</a>
<a name="10743"><span class="lineNum">   10743 </span>            : </a>
<a name="10744"><span class="lineNum">   10744 </span>            :         /*</a>
<a name="10745"><span class="lineNum">   10745 </span>            :          * Ensures that if we miss the CPU, we must see the has_blocked</a>
<a name="10746"><span class="lineNum">   10746 </span>            :          * store from nohz_balance_enter_idle().</a>
<a name="10747"><span class="lineNum">   10747 </span>            :          */</a>
<a name="10748"><span class="lineNum">   10748 </span>            :         smp_mb();</a>
<a name="10749"><span class="lineNum">   10749 </span>            : </a>
<a name="10750"><span class="lineNum">   10750 </span>            :         /*</a>
<a name="10751"><span class="lineNum">   10751 </span>            :          * Start with the next CPU after this_cpu so we will end with this_cpu and let a</a>
<a name="10752"><span class="lineNum">   10752 </span>            :          * chance for other idle cpu to pull load.</a>
<a name="10753"><span class="lineNum">   10753 </span>            :          */</a>
<a name="10754"><span class="lineNum">   10754 </span>            :         for_each_cpu_wrap(balance_cpu,  nohz.idle_cpus_mask, this_cpu+1) {</a>
<a name="10755"><span class="lineNum">   10755 </span>            :                 if (!idle_cpu(balance_cpu))</a>
<a name="10756"><span class="lineNum">   10756 </span>            :                         continue;</a>
<a name="10757"><span class="lineNum">   10757 </span>            : </a>
<a name="10758"><span class="lineNum">   10758 </span>            :                 /*</a>
<a name="10759"><span class="lineNum">   10759 </span>            :                  * If this CPU gets work to do, stop the load balancing</a>
<a name="10760"><span class="lineNum">   10760 </span>            :                  * work being done for other CPUs. Next load</a>
<a name="10761"><span class="lineNum">   10761 </span>            :                  * balancing owner will pick it up.</a>
<a name="10762"><span class="lineNum">   10762 </span>            :                  */</a>
<a name="10763"><span class="lineNum">   10763 </span>            :                 if (need_resched()) {</a>
<a name="10764"><span class="lineNum">   10764 </span>            :                         if (flags &amp; NOHZ_STATS_KICK)</a>
<a name="10765"><span class="lineNum">   10765 </span>            :                                 has_blocked_load = true;</a>
<a name="10766"><span class="lineNum">   10766 </span>            :                         if (flags &amp; NOHZ_NEXT_KICK)</a>
<a name="10767"><span class="lineNum">   10767 </span>            :                                 WRITE_ONCE(nohz.needs_update, 1);</a>
<a name="10768"><span class="lineNum">   10768 </span>            :                         goto abort;</a>
<a name="10769"><span class="lineNum">   10769 </span>            :                 }</a>
<a name="10770"><span class="lineNum">   10770 </span>            : </a>
<a name="10771"><span class="lineNum">   10771 </span>            :                 rq = cpu_rq(balance_cpu);</a>
<a name="10772"><span class="lineNum">   10772 </span>            : </a>
<a name="10773"><span class="lineNum">   10773 </span>            :                 if (flags &amp; NOHZ_STATS_KICK)</a>
<a name="10774"><span class="lineNum">   10774 </span>            :                         has_blocked_load |= update_nohz_stats(rq);</a>
<a name="10775"><span class="lineNum">   10775 </span>            : </a>
<a name="10776"><span class="lineNum">   10776 </span>            :                 /*</a>
<a name="10777"><span class="lineNum">   10777 </span>            :                  * If time for next balance is due,</a>
<a name="10778"><span class="lineNum">   10778 </span>            :                  * do the balance.</a>
<a name="10779"><span class="lineNum">   10779 </span>            :                  */</a>
<a name="10780"><span class="lineNum">   10780 </span>            :                 if (time_after_eq(jiffies, rq-&gt;next_balance)) {</a>
<a name="10781"><span class="lineNum">   10781 </span>            :                         struct rq_flags rf;</a>
<a name="10782"><span class="lineNum">   10782 </span>            : </a>
<a name="10783"><span class="lineNum">   10783 </span>            :                         rq_lock_irqsave(rq, &amp;rf);</a>
<a name="10784"><span class="lineNum">   10784 </span>            :                         update_rq_clock(rq);</a>
<a name="10785"><span class="lineNum">   10785 </span>            :                         rq_unlock_irqrestore(rq, &amp;rf);</a>
<a name="10786"><span class="lineNum">   10786 </span>            : </a>
<a name="10787"><span class="lineNum">   10787 </span>            :                         if (flags &amp; NOHZ_BALANCE_KICK)</a>
<a name="10788"><span class="lineNum">   10788 </span>            :                                 rebalance_domains(rq, CPU_IDLE);</a>
<a name="10789"><span class="lineNum">   10789 </span>            :                 }</a>
<a name="10790"><span class="lineNum">   10790 </span>            : </a>
<a name="10791"><span class="lineNum">   10791 </span>            :                 if (time_after(next_balance, rq-&gt;next_balance)) {</a>
<a name="10792"><span class="lineNum">   10792 </span>            :                         next_balance = rq-&gt;next_balance;</a>
<a name="10793"><span class="lineNum">   10793 </span>            :                         update_next_balance = 1;</a>
<a name="10794"><span class="lineNum">   10794 </span>            :                 }</a>
<a name="10795"><span class="lineNum">   10795 </span>            :         }</a>
<a name="10796"><span class="lineNum">   10796 </span>            : </a>
<a name="10797"><span class="lineNum">   10797 </span>            :         /*</a>
<a name="10798"><span class="lineNum">   10798 </span>            :          * next_balance will be updated only when there is a need.</a>
<a name="10799"><span class="lineNum">   10799 </span>            :          * When the CPU is attached to null domain for ex, it will not be</a>
<a name="10800"><span class="lineNum">   10800 </span>            :          * updated.</a>
<a name="10801"><span class="lineNum">   10801 </span>            :          */</a>
<a name="10802"><span class="lineNum">   10802 </span>            :         if (likely(update_next_balance))</a>
<a name="10803"><span class="lineNum">   10803 </span>            :                 nohz.next_balance = next_balance;</a>
<a name="10804"><span class="lineNum">   10804 </span>            : </a>
<a name="10805"><span class="lineNum">   10805 </span>            :         if (flags &amp; NOHZ_STATS_KICK)</a>
<a name="10806"><span class="lineNum">   10806 </span>            :                 WRITE_ONCE(nohz.next_blocked,</a>
<a name="10807"><span class="lineNum">   10807 </span>            :                            now + msecs_to_jiffies(LOAD_AVG_PERIOD));</a>
<a name="10808"><span class="lineNum">   10808 </span>            : </a>
<a name="10809"><span class="lineNum">   10809 </span>            : abort:</a>
<a name="10810"><span class="lineNum">   10810 </span>            :         /* There is still blocked load, enable periodic update */</a>
<a name="10811"><span class="lineNum">   10811 </span>            :         if (has_blocked_load)</a>
<a name="10812"><span class="lineNum">   10812 </span>            :                 WRITE_ONCE(nohz.has_blocked, 1);</a>
<a name="10813"><span class="lineNum">   10813 </span>            : }</a>
<a name="10814"><span class="lineNum">   10814 </span>            : </a>
<a name="10815"><span class="lineNum">   10815 </span>            : /*</a>
<a name="10816"><span class="lineNum">   10816 </span>            :  * In CONFIG_NO_HZ_COMMON case, the idle balance kickee will do the</a>
<a name="10817"><span class="lineNum">   10817 </span>            :  * rebalancing for all the cpus for whom scheduler ticks are stopped.</a>
<a name="10818"><span class="lineNum">   10818 </span>            :  */</a>
<a name="10819"><span class="lineNum">   10819 </span>            : static bool nohz_idle_balance(struct rq *this_rq, enum cpu_idle_type idle)</a>
<a name="10820"><span class="lineNum">   10820 </span>            : {</a>
<a name="10821"><span class="lineNum">   10821 </span>            :         unsigned int flags = this_rq-&gt;nohz_idle_balance;</a>
<a name="10822"><span class="lineNum">   10822 </span>            : </a>
<a name="10823"><span class="lineNum">   10823 </span>            :         if (!flags)</a>
<a name="10824"><span class="lineNum">   10824 </span>            :                 return false;</a>
<a name="10825"><span class="lineNum">   10825 </span>            : </a>
<a name="10826"><span class="lineNum">   10826 </span>            :         this_rq-&gt;nohz_idle_balance = 0;</a>
<a name="10827"><span class="lineNum">   10827 </span>            : </a>
<a name="10828"><span class="lineNum">   10828 </span>            :         if (idle != CPU_IDLE)</a>
<a name="10829"><span class="lineNum">   10829 </span>            :                 return false;</a>
<a name="10830"><span class="lineNum">   10830 </span>            : </a>
<a name="10831"><span class="lineNum">   10831 </span>            :         _nohz_idle_balance(this_rq, flags, idle);</a>
<a name="10832"><span class="lineNum">   10832 </span>            : </a>
<a name="10833"><span class="lineNum">   10833 </span>            :         return true;</a>
<a name="10834"><span class="lineNum">   10834 </span>            : }</a>
<a name="10835"><span class="lineNum">   10835 </span>            : </a>
<a name="10836"><span class="lineNum">   10836 </span>            : /*</a>
<a name="10837"><span class="lineNum">   10837 </span>            :  * Check if we need to run the ILB for updating blocked load before entering</a>
<a name="10838"><span class="lineNum">   10838 </span>            :  * idle state.</a>
<a name="10839"><span class="lineNum">   10839 </span>            :  */</a>
<a name="10840"><span class="lineNum">   10840 </span>            : void nohz_run_idle_balance(int cpu)</a>
<a name="10841"><span class="lineNum">   10841 </span>            : {</a>
<a name="10842"><span class="lineNum">   10842 </span>            :         unsigned int flags;</a>
<a name="10843"><span class="lineNum">   10843 </span>            : </a>
<a name="10844"><span class="lineNum">   10844 </span>            :         flags = atomic_fetch_andnot(NOHZ_NEWILB_KICK, nohz_flags(cpu));</a>
<a name="10845"><span class="lineNum">   10845 </span>            : </a>
<a name="10846"><span class="lineNum">   10846 </span>            :         /*</a>
<a name="10847"><span class="lineNum">   10847 </span>            :          * Update the blocked load only if no SCHED_SOFTIRQ is about to happen</a>
<a name="10848"><span class="lineNum">   10848 </span>            :          * (ie NOHZ_STATS_KICK set) and will do the same.</a>
<a name="10849"><span class="lineNum">   10849 </span>            :          */</a>
<a name="10850"><span class="lineNum">   10850 </span>            :         if ((flags == NOHZ_NEWILB_KICK) &amp;&amp; !need_resched())</a>
<a name="10851"><span class="lineNum">   10851 </span>            :                 _nohz_idle_balance(cpu_rq(cpu), NOHZ_STATS_KICK, CPU_IDLE);</a>
<a name="10852"><span class="lineNum">   10852 </span>            : }</a>
<a name="10853"><span class="lineNum">   10853 </span>            : </a>
<a name="10854"><span class="lineNum">   10854 </span>            : static void nohz_newidle_balance(struct rq *this_rq)</a>
<a name="10855"><span class="lineNum">   10855 </span>            : {</a>
<a name="10856"><span class="lineNum">   10856 </span>            :         int this_cpu = this_rq-&gt;cpu;</a>
<a name="10857"><span class="lineNum">   10857 </span>            : </a>
<a name="10858"><span class="lineNum">   10858 </span>            :         /*</a>
<a name="10859"><span class="lineNum">   10859 </span>            :          * This CPU doesn't want to be disturbed by scheduler</a>
<a name="10860"><span class="lineNum">   10860 </span>            :          * housekeeping</a>
<a name="10861"><span class="lineNum">   10861 </span>            :          */</a>
<a name="10862"><span class="lineNum">   10862 </span>            :         if (!housekeeping_cpu(this_cpu, HK_TYPE_SCHED))</a>
<a name="10863"><span class="lineNum">   10863 </span>            :                 return;</a>
<a name="10864"><span class="lineNum">   10864 </span>            : </a>
<a name="10865"><span class="lineNum">   10865 </span>            :         /* Will wake up very soon. No time for doing anything else*/</a>
<a name="10866"><span class="lineNum">   10866 </span>            :         if (this_rq-&gt;avg_idle &lt; sysctl_sched_migration_cost)</a>
<a name="10867"><span class="lineNum">   10867 </span>            :                 return;</a>
<a name="10868"><span class="lineNum">   10868 </span>            : </a>
<a name="10869"><span class="lineNum">   10869 </span>            :         /* Don't need to update blocked load of idle CPUs*/</a>
<a name="10870"><span class="lineNum">   10870 </span>            :         if (!READ_ONCE(nohz.has_blocked) ||</a>
<a name="10871"><span class="lineNum">   10871 </span>            :             time_before(jiffies, READ_ONCE(nohz.next_blocked)))</a>
<a name="10872"><span class="lineNum">   10872 </span>            :                 return;</a>
<a name="10873"><span class="lineNum">   10873 </span>            : </a>
<a name="10874"><span class="lineNum">   10874 </span>            :         /*</a>
<a name="10875"><span class="lineNum">   10875 </span>            :          * Set the need to trigger ILB in order to update blocked load</a>
<a name="10876"><span class="lineNum">   10876 </span>            :          * before entering idle state.</a>
<a name="10877"><span class="lineNum">   10877 </span>            :          */</a>
<a name="10878"><span class="lineNum">   10878 </span>            :         atomic_or(NOHZ_NEWILB_KICK, nohz_flags(this_cpu));</a>
<a name="10879"><span class="lineNum">   10879 </span>            : }</a>
<a name="10880"><span class="lineNum">   10880 </span>            : </a>
<a name="10881"><span class="lineNum">   10881 </span>            : #else /* !CONFIG_NO_HZ_COMMON */</a>
<a name="10882"><span class="lineNum">   10882 </span>            : static inline void nohz_balancer_kick(struct rq *rq) { }</a>
<a name="10883"><span class="lineNum">   10883 </span>            : </a>
<a name="10884"><span class="lineNum">   10884 </span>            : static inline bool nohz_idle_balance(struct rq *this_rq, enum cpu_idle_type idle)</a>
<a name="10885"><span class="lineNum">   10885 </span>            : {</a>
<a name="10886"><span class="lineNum">   10886 </span>            :         return false;</a>
<a name="10887"><span class="lineNum">   10887 </span>            : }</a>
<a name="10888"><span class="lineNum">   10888 </span>            : </a>
<a name="10889"><span class="lineNum">   10889 </span>            : static inline void nohz_newidle_balance(struct rq *this_rq) { }</a>
<a name="10890"><span class="lineNum">   10890 </span>            : #endif /* CONFIG_NO_HZ_COMMON */</a>
<a name="10891"><span class="lineNum">   10891 </span>            : </a>
<a name="10892"><span class="lineNum">   10892 </span>            : /*</a>
<a name="10893"><span class="lineNum">   10893 </span>            :  * newidle_balance is called by schedule() if this_cpu is about to become</a>
<a name="10894"><span class="lineNum">   10894 </span>            :  * idle. Attempts to pull tasks from other CPUs.</a>
<a name="10895"><span class="lineNum">   10895 </span>            :  *</a>
<a name="10896"><span class="lineNum">   10896 </span>            :  * Returns:</a>
<a name="10897"><span class="lineNum">   10897 </span>            :  *   &lt; 0 - we released the lock and there are !fair tasks present</a>
<a name="10898"><span class="lineNum">   10898 </span>            :  *     0 - failed, no new tasks</a>
<a name="10899"><span class="lineNum">   10899 </span>            :  *   &gt; 0 - success, new (fair) tasks present</a>
<a name="10900"><span class="lineNum">   10900 </span>            :  */</a>
<a name="10901"><span class="lineNum">   10901 </span>            : static int newidle_balance(struct rq *this_rq, struct rq_flags *rf)</a>
<a name="10902"><span class="lineNum">   10902 </span>            : {</a>
<a name="10903"><span class="lineNum">   10903 </span>            :         unsigned long next_balance = jiffies + HZ;</a>
<a name="10904"><span class="lineNum">   10904 </span>            :         int this_cpu = this_rq-&gt;cpu;</a>
<a name="10905"><span class="lineNum">   10905 </span>            :         u64 t0, t1, curr_cost = 0;</a>
<a name="10906"><span class="lineNum">   10906 </span>            :         struct sched_domain *sd;</a>
<a name="10907"><span class="lineNum">   10907 </span>            :         int pulled_task = 0;</a>
<a name="10908"><span class="lineNum">   10908 </span>            : </a>
<a name="10909"><span class="lineNum">   10909 </span>            :         update_misfit_status(NULL, this_rq);</a>
<a name="10910"><span class="lineNum">   10910 </span>            : </a>
<a name="10911"><span class="lineNum">   10911 </span>            :         /*</a>
<a name="10912"><span class="lineNum">   10912 </span>            :          * There is a task waiting to run. No need to search for one.</a>
<a name="10913"><span class="lineNum">   10913 </span>            :          * Return 0; the task will be enqueued when switching to idle.</a>
<a name="10914"><span class="lineNum">   10914 </span>            :          */</a>
<a name="10915"><span class="lineNum">   10915 </span>            :         if (this_rq-&gt;ttwu_pending)</a>
<a name="10916"><span class="lineNum">   10916 </span>            :                 return 0;</a>
<a name="10917"><span class="lineNum">   10917 </span>            : </a>
<a name="10918"><span class="lineNum">   10918 </span>            :         /*</a>
<a name="10919"><span class="lineNum">   10919 </span>            :          * We must set idle_stamp _before_ calling idle_balance(), such that we</a>
<a name="10920"><span class="lineNum">   10920 </span>            :          * measure the duration of idle_balance() as idle time.</a>
<a name="10921"><span class="lineNum">   10921 </span>            :          */</a>
<a name="10922"><span class="lineNum">   10922 </span>            :         this_rq-&gt;idle_stamp = rq_clock(this_rq);</a>
<a name="10923"><span class="lineNum">   10923 </span>            : </a>
<a name="10924"><span class="lineNum">   10924 </span>            :         /*</a>
<a name="10925"><span class="lineNum">   10925 </span>            :          * Do not pull tasks towards !active CPUs...</a>
<a name="10926"><span class="lineNum">   10926 </span>            :          */</a>
<a name="10927"><span class="lineNum">   10927 </span>            :         if (!cpu_active(this_cpu))</a>
<a name="10928"><span class="lineNum">   10928 </span>            :                 return 0;</a>
<a name="10929"><span class="lineNum">   10929 </span>            : </a>
<a name="10930"><span class="lineNum">   10930 </span>            :         /*</a>
<a name="10931"><span class="lineNum">   10931 </span>            :          * This is OK, because current is on_cpu, which avoids it being picked</a>
<a name="10932"><span class="lineNum">   10932 </span>            :          * for load-balance and preemption/IRQs are still disabled avoiding</a>
<a name="10933"><span class="lineNum">   10933 </span>            :          * further scheduler activity on it and we're being very careful to</a>
<a name="10934"><span class="lineNum">   10934 </span>            :          * re-start the picking loop.</a>
<a name="10935"><span class="lineNum">   10935 </span>            :          */</a>
<a name="10936"><span class="lineNum">   10936 </span>            :         rq_unpin_lock(this_rq, rf);</a>
<a name="10937"><span class="lineNum">   10937 </span>            : </a>
<a name="10938"><span class="lineNum">   10938 </span>            :         rcu_read_lock();</a>
<a name="10939"><span class="lineNum">   10939 </span>            :         sd = rcu_dereference_check_sched_domain(this_rq-&gt;sd);</a>
<a name="10940"><span class="lineNum">   10940 </span>            : </a>
<a name="10941"><span class="lineNum">   10941 </span>            :         if (!READ_ONCE(this_rq-&gt;rd-&gt;overload) ||</a>
<a name="10942"><span class="lineNum">   10942 </span>            :             (sd &amp;&amp; this_rq-&gt;avg_idle &lt; sd-&gt;max_newidle_lb_cost)) {</a>
<a name="10943"><span class="lineNum">   10943 </span>            : </a>
<a name="10944"><span class="lineNum">   10944 </span>            :                 if (sd)</a>
<a name="10945"><span class="lineNum">   10945 </span>            :                         update_next_balance(sd, &amp;next_balance);</a>
<a name="10946"><span class="lineNum">   10946 </span>            :                 rcu_read_unlock();</a>
<a name="10947"><span class="lineNum">   10947 </span>            : </a>
<a name="10948"><span class="lineNum">   10948 </span>            :                 goto out;</a>
<a name="10949"><span class="lineNum">   10949 </span>            :         }</a>
<a name="10950"><span class="lineNum">   10950 </span>            :         rcu_read_unlock();</a>
<a name="10951"><span class="lineNum">   10951 </span>            : </a>
<a name="10952"><span class="lineNum">   10952 </span>            :         raw_spin_rq_unlock(this_rq);</a>
<a name="10953"><span class="lineNum">   10953 </span>            : </a>
<a name="10954"><span class="lineNum">   10954 </span>            :         t0 = sched_clock_cpu(this_cpu);</a>
<a name="10955"><span class="lineNum">   10955 </span>            :         update_blocked_averages(this_cpu);</a>
<a name="10956"><span class="lineNum">   10956 </span>            : </a>
<a name="10957"><span class="lineNum">   10957 </span>            :         rcu_read_lock();</a>
<a name="10958"><span class="lineNum">   10958 </span>            :         for_each_domain(this_cpu, sd) {</a>
<a name="10959"><span class="lineNum">   10959 </span>            :                 int continue_balancing = 1;</a>
<a name="10960"><span class="lineNum">   10960 </span>            :                 u64 domain_cost;</a>
<a name="10961"><span class="lineNum">   10961 </span>            : </a>
<a name="10962"><span class="lineNum">   10962 </span>            :                 update_next_balance(sd, &amp;next_balance);</a>
<a name="10963"><span class="lineNum">   10963 </span>            : </a>
<a name="10964"><span class="lineNum">   10964 </span>            :                 if (this_rq-&gt;avg_idle &lt; curr_cost + sd-&gt;max_newidle_lb_cost)</a>
<a name="10965"><span class="lineNum">   10965 </span>            :                         break;</a>
<a name="10966"><span class="lineNum">   10966 </span>            : </a>
<a name="10967"><span class="lineNum">   10967 </span>            :                 if (sd-&gt;flags &amp; SD_BALANCE_NEWIDLE) {</a>
<a name="10968"><span class="lineNum">   10968 </span>            : </a>
<a name="10969"><span class="lineNum">   10969 </span>            :                         pulled_task = load_balance(this_cpu, this_rq,</a>
<a name="10970"><span class="lineNum">   10970 </span>            :                                                    sd, CPU_NEWLY_IDLE,</a>
<a name="10971"><span class="lineNum">   10971 </span>            :                                                    &amp;continue_balancing);</a>
<a name="10972"><span class="lineNum">   10972 </span>            : </a>
<a name="10973"><span class="lineNum">   10973 </span>            :                         t1 = sched_clock_cpu(this_cpu);</a>
<a name="10974"><span class="lineNum">   10974 </span>            :                         domain_cost = t1 - t0;</a>
<a name="10975"><span class="lineNum">   10975 </span>            :                         update_newidle_cost(sd, domain_cost);</a>
<a name="10976"><span class="lineNum">   10976 </span>            : </a>
<a name="10977"><span class="lineNum">   10977 </span>            :                         curr_cost += domain_cost;</a>
<a name="10978"><span class="lineNum">   10978 </span>            :                         t0 = t1;</a>
<a name="10979"><span class="lineNum">   10979 </span>            :                 }</a>
<a name="10980"><span class="lineNum">   10980 </span>            : </a>
<a name="10981"><span class="lineNum">   10981 </span>            :                 /*</a>
<a name="10982"><span class="lineNum">   10982 </span>            :                  * Stop searching for tasks to pull if there are</a>
<a name="10983"><span class="lineNum">   10983 </span>            :                  * now runnable tasks on this rq.</a>
<a name="10984"><span class="lineNum">   10984 </span>            :                  */</a>
<a name="10985"><span class="lineNum">   10985 </span>            :                 if (pulled_task || this_rq-&gt;nr_running &gt; 0 ||</a>
<a name="10986"><span class="lineNum">   10986 </span>            :                     this_rq-&gt;ttwu_pending)</a>
<a name="10987"><span class="lineNum">   10987 </span>            :                         break;</a>
<a name="10988"><span class="lineNum">   10988 </span>            :         }</a>
<a name="10989"><span class="lineNum">   10989 </span>            :         rcu_read_unlock();</a>
<a name="10990"><span class="lineNum">   10990 </span>            : </a>
<a name="10991"><span class="lineNum">   10991 </span>            :         raw_spin_rq_lock(this_rq);</a>
<a name="10992"><span class="lineNum">   10992 </span>            : </a>
<a name="10993"><span class="lineNum">   10993 </span>            :         if (curr_cost &gt; this_rq-&gt;max_idle_balance_cost)</a>
<a name="10994"><span class="lineNum">   10994 </span>            :                 this_rq-&gt;max_idle_balance_cost = curr_cost;</a>
<a name="10995"><span class="lineNum">   10995 </span>            : </a>
<a name="10996"><span class="lineNum">   10996 </span>            :         /*</a>
<a name="10997"><span class="lineNum">   10997 </span>            :          * While browsing the domains, we released the rq lock, a task could</a>
<a name="10998"><span class="lineNum">   10998 </span>            :          * have been enqueued in the meantime. Since we're not going idle,</a>
<a name="10999"><span class="lineNum">   10999 </span>            :          * pretend we pulled a task.</a>
<a name="11000"><span class="lineNum">   11000 </span>            :          */</a>
<a name="11001"><span class="lineNum">   11001 </span>            :         if (this_rq-&gt;cfs.h_nr_running &amp;&amp; !pulled_task)</a>
<a name="11002"><span class="lineNum">   11002 </span>            :                 pulled_task = 1;</a>
<a name="11003"><span class="lineNum">   11003 </span>            : </a>
<a name="11004"><span class="lineNum">   11004 </span>            :         /* Is there a task of a high priority class? */</a>
<a name="11005"><span class="lineNum">   11005 </span>            :         if (this_rq-&gt;nr_running != this_rq-&gt;cfs.h_nr_running)</a>
<a name="11006"><span class="lineNum">   11006 </span>            :                 pulled_task = -1;</a>
<a name="11007"><span class="lineNum">   11007 </span>            : </a>
<a name="11008"><span class="lineNum">   11008 </span>            : out:</a>
<a name="11009"><span class="lineNum">   11009 </span>            :         /* Move the next balance forward */</a>
<a name="11010"><span class="lineNum">   11010 </span>            :         if (time_after(this_rq-&gt;next_balance, next_balance))</a>
<a name="11011"><span class="lineNum">   11011 </span>            :                 this_rq-&gt;next_balance = next_balance;</a>
<a name="11012"><span class="lineNum">   11012 </span>            : </a>
<a name="11013"><span class="lineNum">   11013 </span>            :         if (pulled_task)</a>
<a name="11014"><span class="lineNum">   11014 </span>            :                 this_rq-&gt;idle_stamp = 0;</a>
<a name="11015"><span class="lineNum">   11015 </span>            :         else</a>
<a name="11016"><span class="lineNum">   11016 </span>            :                 nohz_newidle_balance(this_rq);</a>
<a name="11017"><span class="lineNum">   11017 </span>            : </a>
<a name="11018"><span class="lineNum">   11018 </span>            :         rq_repin_lock(this_rq, rf);</a>
<a name="11019"><span class="lineNum">   11019 </span>            : </a>
<a name="11020"><span class="lineNum">   11020 </span>            :         return pulled_task;</a>
<a name="11021"><span class="lineNum">   11021 </span>            : }</a>
<a name="11022"><span class="lineNum">   11022 </span>            : </a>
<a name="11023"><span class="lineNum">   11023 </span>            : /*</a>
<a name="11024"><span class="lineNum">   11024 </span>            :  * run_rebalance_domains is triggered when needed from the scheduler tick.</a>
<a name="11025"><span class="lineNum">   11025 </span>            :  * Also triggered for nohz idle balancing (with nohz_balancing_kick set).</a>
<a name="11026"><span class="lineNum">   11026 </span>            :  */</a>
<a name="11027"><span class="lineNum">   11027 </span>            : static __latent_entropy void run_rebalance_domains(struct softirq_action *h)</a>
<a name="11028"><span class="lineNum">   11028 </span>            : {</a>
<a name="11029"><span class="lineNum">   11029 </span>            :         struct rq *this_rq = this_rq();</a>
<a name="11030"><span class="lineNum">   11030 </span>            :         enum cpu_idle_type idle = this_rq-&gt;idle_balance ?</a>
<a name="11031"><span class="lineNum">   11031 </span>            :                                                 CPU_IDLE : CPU_NOT_IDLE;</a>
<a name="11032"><span class="lineNum">   11032 </span>            : </a>
<a name="11033"><span class="lineNum">   11033 </span>            :         /*</a>
<a name="11034"><span class="lineNum">   11034 </span>            :          * If this CPU has a pending nohz_balance_kick, then do the</a>
<a name="11035"><span class="lineNum">   11035 </span>            :          * balancing on behalf of the other idle CPUs whose ticks are</a>
<a name="11036"><span class="lineNum">   11036 </span>            :          * stopped. Do nohz_idle_balance *before* rebalance_domains to</a>
<a name="11037"><span class="lineNum">   11037 </span>            :          * give the idle CPUs a chance to load balance. Else we may</a>
<a name="11038"><span class="lineNum">   11038 </span>            :          * load balance only within the local sched_domain hierarchy</a>
<a name="11039"><span class="lineNum">   11039 </span>            :          * and abort nohz_idle_balance altogether if we pull some load.</a>
<a name="11040"><span class="lineNum">   11040 </span>            :          */</a>
<a name="11041"><span class="lineNum">   11041 </span>            :         if (nohz_idle_balance(this_rq, idle))</a>
<a name="11042"><span class="lineNum">   11042 </span>            :                 return;</a>
<a name="11043"><span class="lineNum">   11043 </span>            : </a>
<a name="11044"><span class="lineNum">   11044 </span>            :         /* normal load balance */</a>
<a name="11045"><span class="lineNum">   11045 </span>            :         update_blocked_averages(this_rq-&gt;cpu);</a>
<a name="11046"><span class="lineNum">   11046 </span>            :         rebalance_domains(this_rq, idle);</a>
<a name="11047"><span class="lineNum">   11047 </span>            : }</a>
<a name="11048"><span class="lineNum">   11048 </span>            : </a>
<a name="11049"><span class="lineNum">   11049 </span>            : /*</a>
<a name="11050"><span class="lineNum">   11050 </span>            :  * Trigger the SCHED_SOFTIRQ if it is time to do periodic load balancing.</a>
<a name="11051"><span class="lineNum">   11051 </span>            :  */</a>
<a name="11052"><span class="lineNum">   11052 </span>            : void trigger_load_balance(struct rq *rq)</a>
<a name="11053"><span class="lineNum">   11053 </span>            : {</a>
<a name="11054"><span class="lineNum">   11054 </span>            :         /*</a>
<a name="11055"><span class="lineNum">   11055 </span>            :          * Don't need to rebalance while attached to NULL domain or</a>
<a name="11056"><span class="lineNum">   11056 </span>            :          * runqueue CPU is not active</a>
<a name="11057"><span class="lineNum">   11057 </span>            :          */</a>
<a name="11058"><span class="lineNum">   11058 </span>            :         if (unlikely(on_null_domain(rq) || !cpu_active(cpu_of(rq))))</a>
<a name="11059"><span class="lineNum">   11059 </span>            :                 return;</a>
<a name="11060"><span class="lineNum">   11060 </span>            : </a>
<a name="11061"><span class="lineNum">   11061 </span>            :         if (time_after_eq(jiffies, rq-&gt;next_balance))</a>
<a name="11062"><span class="lineNum">   11062 </span>            :                 raise_softirq(SCHED_SOFTIRQ);</a>
<a name="11063"><span class="lineNum">   11063 </span>            : </a>
<a name="11064"><span class="lineNum">   11064 </span>            :         nohz_balancer_kick(rq);</a>
<a name="11065"><span class="lineNum">   11065 </span>            : }</a>
<a name="11066"><span class="lineNum">   11066 </span>            : </a>
<a name="11067"><span class="lineNum">   11067 </span>            : static void rq_online_fair(struct rq *rq)</a>
<a name="11068"><span class="lineNum">   11068 </span>            : {</a>
<a name="11069"><span class="lineNum">   11069 </span>            :         update_sysctl();</a>
<a name="11070"><span class="lineNum">   11070 </span>            : </a>
<a name="11071"><span class="lineNum">   11071 </span>            :         update_runtime_enabled(rq);</a>
<a name="11072"><span class="lineNum">   11072 </span>            : }</a>
<a name="11073"><span class="lineNum">   11073 </span>            : </a>
<a name="11074"><span class="lineNum">   11074 </span>            : static void rq_offline_fair(struct rq *rq)</a>
<a name="11075"><span class="lineNum">   11075 </span>            : {</a>
<a name="11076"><span class="lineNum">   11076 </span>            :         update_sysctl();</a>
<a name="11077"><span class="lineNum">   11077 </span>            : </a>
<a name="11078"><span class="lineNum">   11078 </span>            :         /* Ensure any throttled groups are reachable by pick_next_task */</a>
<a name="11079"><span class="lineNum">   11079 </span>            :         unthrottle_offline_cfs_rqs(rq);</a>
<a name="11080"><span class="lineNum">   11080 </span>            : }</a>
<a name="11081"><span class="lineNum">   11081 </span>            : </a>
<a name="11082"><span class="lineNum">   11082 </span>            : #endif /* CONFIG_SMP */</a>
<a name="11083"><span class="lineNum">   11083 </span>            : </a>
<a name="11084"><span class="lineNum">   11084 </span>            : #ifdef CONFIG_SCHED_CORE</a>
<a name="11085"><span class="lineNum">   11085 </span>            : static inline bool</a>
<a name="11086"><span class="lineNum">   11086 </span>            : __entity_slice_used(struct sched_entity *se, int min_nr_tasks)</a>
<a name="11087"><span class="lineNum">   11087 </span>            : {</a>
<a name="11088"><span class="lineNum">   11088 </span>            :         u64 slice = sched_slice(cfs_rq_of(se), se);</a>
<a name="11089"><span class="lineNum">   11089 </span>            :         u64 rtime = se-&gt;sum_exec_runtime - se-&gt;prev_sum_exec_runtime;</a>
<a name="11090"><span class="lineNum">   11090 </span>            : </a>
<a name="11091"><span class="lineNum">   11091 </span>            :         return (rtime * min_nr_tasks &gt; slice);</a>
<a name="11092"><span class="lineNum">   11092 </span>            : }</a>
<a name="11093"><span class="lineNum">   11093 </span>            : </a>
<a name="11094"><span class="lineNum">   11094 </span>            : #define MIN_NR_TASKS_DURING_FORCEIDLE   2</a>
<a name="11095"><span class="lineNum">   11095 </span>            : static inline void task_tick_core(struct rq *rq, struct task_struct *curr)</a>
<a name="11096"><span class="lineNum">   11096 </span>            : {</a>
<a name="11097"><span class="lineNum">   11097 </span>            :         if (!sched_core_enabled(rq))</a>
<a name="11098"><span class="lineNum">   11098 </span>            :                 return;</a>
<a name="11099"><span class="lineNum">   11099 </span>            : </a>
<a name="11100"><span class="lineNum">   11100 </span>            :         /*</a>
<a name="11101"><span class="lineNum">   11101 </span>            :          * If runqueue has only one task which used up its slice and</a>
<a name="11102"><span class="lineNum">   11102 </span>            :          * if the sibling is forced idle, then trigger schedule to</a>
<a name="11103"><span class="lineNum">   11103 </span>            :          * give forced idle task a chance.</a>
<a name="11104"><span class="lineNum">   11104 </span>            :          *</a>
<a name="11105"><span class="lineNum">   11105 </span>            :          * sched_slice() considers only this active rq and it gets the</a>
<a name="11106"><span class="lineNum">   11106 </span>            :          * whole slice. But during force idle, we have siblings acting</a>
<a name="11107"><span class="lineNum">   11107 </span>            :          * like a single runqueue and hence we need to consider runnable</a>
<a name="11108"><span class="lineNum">   11108 </span>            :          * tasks on this CPU and the forced idle CPU. Ideally, we should</a>
<a name="11109"><span class="lineNum">   11109 </span>            :          * go through the forced idle rq, but that would be a perf hit.</a>
<a name="11110"><span class="lineNum">   11110 </span>            :          * We can assume that the forced idle CPU has at least</a>
<a name="11111"><span class="lineNum">   11111 </span>            :          * MIN_NR_TASKS_DURING_FORCEIDLE - 1 tasks and use that to check</a>
<a name="11112"><span class="lineNum">   11112 </span>            :          * if we need to give up the CPU.</a>
<a name="11113"><span class="lineNum">   11113 </span>            :          */</a>
<a name="11114"><span class="lineNum">   11114 </span>            :         if (rq-&gt;core-&gt;core_forceidle_count &amp;&amp; rq-&gt;cfs.nr_running == 1 &amp;&amp;</a>
<a name="11115"><span class="lineNum">   11115 </span>            :             __entity_slice_used(&amp;curr-&gt;se, MIN_NR_TASKS_DURING_FORCEIDLE))</a>
<a name="11116"><span class="lineNum">   11116 </span>            :                 resched_curr(rq);</a>
<a name="11117"><span class="lineNum">   11117 </span>            : }</a>
<a name="11118"><span class="lineNum">   11118 </span>            : </a>
<a name="11119"><span class="lineNum">   11119 </span>            : /*</a>
<a name="11120"><span class="lineNum">   11120 </span>            :  * se_fi_update - Update the cfs_rq-&gt;min_vruntime_fi in a CFS hierarchy if needed.</a>
<a name="11121"><span class="lineNum">   11121 </span>            :  */</a>
<a name="11122"><span class="lineNum">   11122 </span>            : static void se_fi_update(struct sched_entity *se, unsigned int fi_seq, bool forceidle)</a>
<a name="11123"><span class="lineNum">   11123 </span>            : {</a>
<a name="11124"><span class="lineNum">   11124 </span>            :         for_each_sched_entity(se) {</a>
<a name="11125"><span class="lineNum">   11125 </span>            :                 struct cfs_rq *cfs_rq = cfs_rq_of(se);</a>
<a name="11126"><span class="lineNum">   11126 </span>            : </a>
<a name="11127"><span class="lineNum">   11127 </span>            :                 if (forceidle) {</a>
<a name="11128"><span class="lineNum">   11128 </span>            :                         if (cfs_rq-&gt;forceidle_seq == fi_seq)</a>
<a name="11129"><span class="lineNum">   11129 </span>            :                                 break;</a>
<a name="11130"><span class="lineNum">   11130 </span>            :                         cfs_rq-&gt;forceidle_seq = fi_seq;</a>
<a name="11131"><span class="lineNum">   11131 </span>            :                 }</a>
<a name="11132"><span class="lineNum">   11132 </span>            : </a>
<a name="11133"><span class="lineNum">   11133 </span>            :                 cfs_rq-&gt;min_vruntime_fi = cfs_rq-&gt;min_vruntime;</a>
<a name="11134"><span class="lineNum">   11134 </span>            :         }</a>
<a name="11135"><span class="lineNum">   11135 </span>            : }</a>
<a name="11136"><span class="lineNum">   11136 </span>            : </a>
<a name="11137"><span class="lineNum">   11137 </span>            : void task_vruntime_update(struct rq *rq, struct task_struct *p, bool in_fi)</a>
<a name="11138"><span class="lineNum">   11138 </span>            : {</a>
<a name="11139"><span class="lineNum">   11139 </span>            :         struct sched_entity *se = &amp;p-&gt;se;</a>
<a name="11140"><span class="lineNum">   11140 </span>            : </a>
<a name="11141"><span class="lineNum">   11141 </span>            :         if (p-&gt;sched_class != &amp;fair_sched_class)</a>
<a name="11142"><span class="lineNum">   11142 </span>            :                 return;</a>
<a name="11143"><span class="lineNum">   11143 </span>            : </a>
<a name="11144"><span class="lineNum">   11144 </span>            :         se_fi_update(se, rq-&gt;core-&gt;core_forceidle_seq, in_fi);</a>
<a name="11145"><span class="lineNum">   11145 </span>            : }</a>
<a name="11146"><span class="lineNum">   11146 </span>            : </a>
<a name="11147"><span class="lineNum">   11147 </span>            : bool cfs_prio_less(struct task_struct *a, struct task_struct *b, bool in_fi)</a>
<a name="11148"><span class="lineNum">   11148 </span>            : {</a>
<a name="11149"><span class="lineNum">   11149 </span>            :         struct rq *rq = task_rq(a);</a>
<a name="11150"><span class="lineNum">   11150 </span>            :         struct sched_entity *sea = &amp;a-&gt;se;</a>
<a name="11151"><span class="lineNum">   11151 </span>            :         struct sched_entity *seb = &amp;b-&gt;se;</a>
<a name="11152"><span class="lineNum">   11152 </span>            :         struct cfs_rq *cfs_rqa;</a>
<a name="11153"><span class="lineNum">   11153 </span>            :         struct cfs_rq *cfs_rqb;</a>
<a name="11154"><span class="lineNum">   11154 </span>            :         s64 delta;</a>
<a name="11155"><span class="lineNum">   11155 </span>            : </a>
<a name="11156"><span class="lineNum">   11156 </span>            :         SCHED_WARN_ON(task_rq(b)-&gt;core != rq-&gt;core);</a>
<a name="11157"><span class="lineNum">   11157 </span>            : </a>
<a name="11158"><span class="lineNum">   11158 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="11159"><span class="lineNum">   11159 </span>            :         /*</a>
<a name="11160"><span class="lineNum">   11160 </span>            :          * Find an se in the hierarchy for tasks a and b, such that the se's</a>
<a name="11161"><span class="lineNum">   11161 </span>            :          * are immediate siblings.</a>
<a name="11162"><span class="lineNum">   11162 </span>            :          */</a>
<a name="11163"><span class="lineNum">   11163 </span>            :         while (sea-&gt;cfs_rq-&gt;tg != seb-&gt;cfs_rq-&gt;tg) {</a>
<a name="11164"><span class="lineNum">   11164 </span>            :                 int sea_depth = sea-&gt;depth;</a>
<a name="11165"><span class="lineNum">   11165 </span>            :                 int seb_depth = seb-&gt;depth;</a>
<a name="11166"><span class="lineNum">   11166 </span>            : </a>
<a name="11167"><span class="lineNum">   11167 </span>            :                 if (sea_depth &gt;= seb_depth)</a>
<a name="11168"><span class="lineNum">   11168 </span>            :                         sea = parent_entity(sea);</a>
<a name="11169"><span class="lineNum">   11169 </span>            :                 if (sea_depth &lt;= seb_depth)</a>
<a name="11170"><span class="lineNum">   11170 </span>            :                         seb = parent_entity(seb);</a>
<a name="11171"><span class="lineNum">   11171 </span>            :         }</a>
<a name="11172"><span class="lineNum">   11172 </span>            : </a>
<a name="11173"><span class="lineNum">   11173 </span>            :         se_fi_update(sea, rq-&gt;core-&gt;core_forceidle_seq, in_fi);</a>
<a name="11174"><span class="lineNum">   11174 </span>            :         se_fi_update(seb, rq-&gt;core-&gt;core_forceidle_seq, in_fi);</a>
<a name="11175"><span class="lineNum">   11175 </span>            : </a>
<a name="11176"><span class="lineNum">   11176 </span>            :         cfs_rqa = sea-&gt;cfs_rq;</a>
<a name="11177"><span class="lineNum">   11177 </span>            :         cfs_rqb = seb-&gt;cfs_rq;</a>
<a name="11178"><span class="lineNum">   11178 </span>            : #else</a>
<a name="11179"><span class="lineNum">   11179 </span>            :         cfs_rqa = &amp;task_rq(a)-&gt;cfs;</a>
<a name="11180"><span class="lineNum">   11180 </span>            :         cfs_rqb = &amp;task_rq(b)-&gt;cfs;</a>
<a name="11181"><span class="lineNum">   11181 </span>            : #endif</a>
<a name="11182"><span class="lineNum">   11182 </span>            : </a>
<a name="11183"><span class="lineNum">   11183 </span>            :         /*</a>
<a name="11184"><span class="lineNum">   11184 </span>            :          * Find delta after normalizing se's vruntime with its cfs_rq's</a>
<a name="11185"><span class="lineNum">   11185 </span>            :          * min_vruntime_fi, which would have been updated in prior calls</a>
<a name="11186"><span class="lineNum">   11186 </span>            :          * to se_fi_update().</a>
<a name="11187"><span class="lineNum">   11187 </span>            :          */</a>
<a name="11188"><span class="lineNum">   11188 </span>            :         delta = (s64)(sea-&gt;vruntime - seb-&gt;vruntime) +</a>
<a name="11189"><span class="lineNum">   11189 </span>            :                 (s64)(cfs_rqb-&gt;min_vruntime_fi - cfs_rqa-&gt;min_vruntime_fi);</a>
<a name="11190"><span class="lineNum">   11190 </span>            : </a>
<a name="11191"><span class="lineNum">   11191 </span>            :         return delta &gt; 0;</a>
<a name="11192"><span class="lineNum">   11192 </span>            : }</a>
<a name="11193"><span class="lineNum">   11193 </span>            : #else</a>
<a name="11194"><span class="lineNum">   11194 </span>            : static inline void task_tick_core(struct rq *rq, struct task_struct *curr) {}</a>
<a name="11195"><span class="lineNum">   11195 </span>            : #endif</a>
<a name="11196"><span class="lineNum">   11196 </span>            : </a>
<a name="11197"><span class="lineNum">   11197 </span>            : /*</a>
<a name="11198"><span class="lineNum">   11198 </span>            :  * scheduler tick hitting a task of our scheduling class.</a>
<a name="11199"><span class="lineNum">   11199 </span>            :  *</a>
<a name="11200"><span class="lineNum">   11200 </span>            :  * NOTE: This function can be called remotely by the tick offload that</a>
<a name="11201"><span class="lineNum">   11201 </span>            :  * goes along full dynticks. Therefore no local assumption can be made</a>
<a name="11202"><span class="lineNum">   11202 </span>            :  * and everything must be accessed through the @rq and @curr passed in</a>
<a name="11203"><span class="lineNum">   11203 </span>            :  * parameters.</a>
<a name="11204"><span class="lineNum">   11204 </span>            :  */</a>
<a name="11205"><span class="lineNum">   11205 </span><span class="lineCov">          2 : static void task_tick_fair(struct rq *rq, struct task_struct *curr, int queued)</span></a>
<a name="11206"><span class="lineNum">   11206 </span>            : {</a>
<a name="11207"><span class="lineNum">   11207 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="11208"><span class="lineNum">   11208 </span><span class="lineCov">          2 :         struct sched_entity *se = &amp;curr-&gt;se;</span></a>
<a name="11209"><span class="lineNum">   11209 </span>            : </a>
<a name="11210"><span class="lineNum">   11210 </span><span class="lineCov">          4 :         for_each_sched_entity(se) {</span></a>
<a name="11211"><span class="lineNum">   11211 </span><span class="lineCov">          4 :                 cfs_rq = cfs_rq_of(se);</span></a>
<a name="11212"><span class="lineNum">   11212 </span><span class="lineCov">          2 :                 entity_tick(cfs_rq, se, queued);</span></a>
<a name="11213"><span class="lineNum">   11213 </span>            :         }</a>
<a name="11214"><span class="lineNum">   11214 </span>            : </a>
<a name="11215"><span class="lineNum">   11215 </span><span class="lineCov">          2 :         if (static_branch_unlikely(&amp;sched_numa_balancing))</span></a>
<a name="11216"><span class="lineNum">   11216 </span>            :                 task_tick_numa(rq, curr);</a>
<a name="11217"><span class="lineNum">   11217 </span>            : </a>
<a name="11218"><span class="lineNum">   11218 </span><span class="lineCov">          2 :         update_misfit_status(curr, rq);</span></a>
<a name="11219"><span class="lineNum">   11219 </span><span class="lineCov">          2 :         update_overutilized_status(task_rq(curr));</span></a>
<a name="11220"><span class="lineNum">   11220 </span>            : </a>
<a name="11221"><span class="lineNum">   11221 </span><span class="lineCov">          2 :         task_tick_core(rq, curr);</span></a>
<a name="11222"><span class="lineNum">   11222 </span><span class="lineCov">          2 : }</span></a>
<a name="11223"><span class="lineNum">   11223 </span>            : </a>
<a name="11224"><span class="lineNum">   11224 </span>            : /*</a>
<a name="11225"><span class="lineNum">   11225 </span>            :  * called on fork with the child task as argument from the parent's context</a>
<a name="11226"><span class="lineNum">   11226 </span>            :  *  - child not yet on the tasklist</a>
<a name="11227"><span class="lineNum">   11227 </span>            :  *  - preemption disabled</a>
<a name="11228"><span class="lineNum">   11228 </span>            :  */</a>
<a name="11229"><span class="lineNum">   11229 </span><span class="lineCov">        107 : static void task_fork_fair(struct task_struct *p)</span></a>
<a name="11230"><span class="lineNum">   11230 </span>            : {</a>
<a name="11231"><span class="lineNum">   11231 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="11232"><span class="lineNum">   11232 </span><span class="lineCov">        107 :         struct sched_entity *se = &amp;p-&gt;se, *curr;</span></a>
<a name="11233"><span class="lineNum">   11233 </span><span class="lineCov">        107 :         struct rq *rq = this_rq();</span></a>
<a name="11234"><span class="lineNum">   11234 </span>            :         struct rq_flags rf;</a>
<a name="11235"><span class="lineNum">   11235 </span>            : </a>
<a name="11236"><span class="lineNum">   11236 </span><span class="lineCov">        107 :         rq_lock(rq, &amp;rf);</span></a>
<a name="11237"><span class="lineNum">   11237 </span><span class="lineCov">        107 :         update_rq_clock(rq);</span></a>
<a name="11238"><span class="lineNum">   11238 </span>            : </a>
<a name="11239"><span class="lineNum">   11239 </span><span class="lineCov">        214 :         cfs_rq = task_cfs_rq(current);</span></a>
<a name="11240"><span class="lineNum">   11240 </span><span class="lineCov">        107 :         curr = cfs_rq-&gt;curr;</span></a>
<a name="11241"><span class="lineNum">   11241 </span><span class="lineCov">        107 :         if (curr) {</span></a>
<a name="11242"><span class="lineNum">   11242 </span><span class="lineCov">        105 :                 update_curr(cfs_rq);</span></a>
<a name="11243"><span class="lineNum">   11243 </span><span class="lineCov">        105 :                 se-&gt;vruntime = curr-&gt;vruntime;</span></a>
<a name="11244"><span class="lineNum">   11244 </span>            :         }</a>
<a name="11245"><span class="lineNum">   11245 </span><span class="lineCov">        107 :         place_entity(cfs_rq, se, 1);</span></a>
<a name="11246"><span class="lineNum">   11246 </span>            : </a>
<a name="11247"><span class="lineNum">   11247 </span><span class="lineCov">        107 :         if (sysctl_sched_child_runs_first &amp;&amp; curr &amp;&amp; entity_before(curr, se)) {</span></a>
<a name="11248"><span class="lineNum">   11248 </span>            :                 /*</a>
<a name="11249"><span class="lineNum">   11249 </span>            :                  * Upon rescheduling, sched_class::put_prev_task() will place</a>
<a name="11250"><span class="lineNum">   11250 </span>            :                  * 'current' within the tree based on its new key value.</a>
<a name="11251"><span class="lineNum">   11251 </span>            :                  */</a>
<a name="11252"><span class="lineNum">   11252 </span><span class="lineNoCov">          0 :                 swap(curr-&gt;vruntime, se-&gt;vruntime);</span></a>
<a name="11253"><span class="lineNum">   11253 </span><span class="lineNoCov">          0 :                 resched_curr(rq);</span></a>
<a name="11254"><span class="lineNum">   11254 </span>            :         }</a>
<a name="11255"><span class="lineNum">   11255 </span>            : </a>
<a name="11256"><span class="lineNum">   11256 </span><span class="lineCov">        107 :         se-&gt;vruntime -= cfs_rq-&gt;min_vruntime;</span></a>
<a name="11257"><span class="lineNum">   11257 </span><span class="lineCov">        107 :         rq_unlock(rq, &amp;rf);</span></a>
<a name="11258"><span class="lineNum">   11258 </span><span class="lineCov">        107 : }</span></a>
<a name="11259"><span class="lineNum">   11259 </span>            : </a>
<a name="11260"><span class="lineNum">   11260 </span>            : /*</a>
<a name="11261"><span class="lineNum">   11261 </span>            :  * Priority of the task has changed. Check to see if we preempt</a>
<a name="11262"><span class="lineNum">   11262 </span>            :  * the current task.</a>
<a name="11263"><span class="lineNum">   11263 </span>            :  */</a>
<a name="11264"><span class="lineNum">   11264 </span>            : static void</a>
<a name="11265"><span class="lineNum">   11265 </span><span class="lineCov">          4 : prio_changed_fair(struct rq *rq, struct task_struct *p, int oldprio)</span></a>
<a name="11266"><span class="lineNum">   11266 </span>            : {</a>
<a name="11267"><span class="lineNum">   11267 </span><span class="lineCov">          4 :         if (!task_on_rq_queued(p))</span></a>
<a name="11268"><span class="lineNum">   11268 </span>            :                 return;</a>
<a name="11269"><span class="lineNum">   11269 </span>            : </a>
<a name="11270"><span class="lineNum">   11270 </span><span class="lineCov">          3 :         if (rq-&gt;cfs.nr_running == 1)</span></a>
<a name="11271"><span class="lineNum">   11271 </span>            :                 return;</a>
<a name="11272"><span class="lineNum">   11272 </span>            : </a>
<a name="11273"><span class="lineNum">   11273 </span>            :         /*</a>
<a name="11274"><span class="lineNum">   11274 </span>            :          * Reschedule if we are currently running on this runqueue and</a>
<a name="11275"><span class="lineNum">   11275 </span>            :          * our priority decreased, or if we are not currently running on</a>
<a name="11276"><span class="lineNum">   11276 </span>            :          * this runqueue and our priority is higher than the current's</a>
<a name="11277"><span class="lineNum">   11277 </span>            :          */</a>
<a name="11278"><span class="lineNum">   11278 </span><span class="lineCov">          3 :         if (task_current(rq, p)) {</span></a>
<a name="11279"><span class="lineNum">   11279 </span><span class="lineCov">          3 :                 if (p-&gt;prio &gt; oldprio)</span></a>
<a name="11280"><span class="lineNum">   11280 </span><span class="lineNoCov">          0 :                         resched_curr(rq);</span></a>
<a name="11281"><span class="lineNum">   11281 </span>            :         } else</a>
<a name="11282"><span class="lineNum">   11282 </span><span class="lineNoCov">          0 :                 check_preempt_curr(rq, p, 0);</span></a>
<a name="11283"><span class="lineNum">   11283 </span>            : }</a>
<a name="11284"><span class="lineNum">   11284 </span>            : </a>
<a name="11285"><span class="lineNum">   11285 </span>            : static inline bool vruntime_normalized(struct task_struct *p)</a>
<a name="11286"><span class="lineNum">   11286 </span>            : {</a>
<a name="11287"><span class="lineNum">   11287 </span><span class="lineNoCov">          0 :         struct sched_entity *se = &amp;p-&gt;se;</span></a>
<a name="11288"><span class="lineNum">   11288 </span>            : </a>
<a name="11289"><span class="lineNum">   11289 </span>            :         /*</a>
<a name="11290"><span class="lineNum">   11290 </span>            :          * In both the TASK_ON_RQ_QUEUED and TASK_ON_RQ_MIGRATING cases,</a>
<a name="11291"><span class="lineNum">   11291 </span>            :          * the dequeue_entity(.flags=0) will already have normalized the</a>
<a name="11292"><span class="lineNum">   11292 </span>            :          * vruntime.</a>
<a name="11293"><span class="lineNum">   11293 </span>            :          */</a>
<a name="11294"><span class="lineNum">   11294 </span><span class="lineNoCov">          0 :         if (p-&gt;on_rq)</span></a>
<a name="11295"><span class="lineNum">   11295 </span>            :                 return true;</a>
<a name="11296"><span class="lineNum">   11296 </span>            : </a>
<a name="11297"><span class="lineNum">   11297 </span>            :         /*</a>
<a name="11298"><span class="lineNum">   11298 </span>            :          * When !on_rq, vruntime of the task has usually NOT been normalized.</a>
<a name="11299"><span class="lineNum">   11299 </span>            :          * But there are some cases where it has already been normalized:</a>
<a name="11300"><span class="lineNum">   11300 </span>            :          *</a>
<a name="11301"><span class="lineNum">   11301 </span>            :          * - A forked child which is waiting for being woken up by</a>
<a name="11302"><span class="lineNum">   11302 </span>            :          *   wake_up_new_task().</a>
<a name="11303"><span class="lineNum">   11303 </span>            :          * - A task which has been woken up by try_to_wake_up() and</a>
<a name="11304"><span class="lineNum">   11304 </span>            :          *   waiting for actually being woken up by sched_ttwu_pending().</a>
<a name="11305"><span class="lineNum">   11305 </span>            :          */</a>
<a name="11306"><span class="lineNum">   11306 </span><span class="lineNoCov">          0 :         if (!se-&gt;sum_exec_runtime ||</span></a>
<a name="11307"><span class="lineNum">   11307 </span><span class="lineNoCov">          0 :             (READ_ONCE(p-&gt;__state) == TASK_WAKING &amp;&amp; p-&gt;sched_remote_wakeup))</span></a>
<a name="11308"><span class="lineNum">   11308 </span>            :                 return true;</a>
<a name="11309"><span class="lineNum">   11309 </span>            : </a>
<a name="11310"><span class="lineNum">   11310 </span>            :         return false;</a>
<a name="11311"><span class="lineNum">   11311 </span>            : }</a>
<a name="11312"><span class="lineNum">   11312 </span>            : </a>
<a name="11313"><span class="lineNum">   11313 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="11314"><span class="lineNum">   11314 </span>            : /*</a>
<a name="11315"><span class="lineNum">   11315 </span>            :  * Propagate the changes of the sched_entity across the tg tree to make it</a>
<a name="11316"><span class="lineNum">   11316 </span>            :  * visible to the root</a>
<a name="11317"><span class="lineNum">   11317 </span>            :  */</a>
<a name="11318"><span class="lineNum">   11318 </span>            : static void propagate_entity_cfs_rq(struct sched_entity *se)</a>
<a name="11319"><span class="lineNum">   11319 </span>            : {</a>
<a name="11320"><span class="lineNum">   11320 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="11321"><span class="lineNum">   11321 </span>            : </a>
<a name="11322"><span class="lineNum">   11322 </span>            :         list_add_leaf_cfs_rq(cfs_rq_of(se));</a>
<a name="11323"><span class="lineNum">   11323 </span>            : </a>
<a name="11324"><span class="lineNum">   11324 </span>            :         /* Start to propagate at parent */</a>
<a name="11325"><span class="lineNum">   11325 </span>            :         se = se-&gt;parent;</a>
<a name="11326"><span class="lineNum">   11326 </span>            : </a>
<a name="11327"><span class="lineNum">   11327 </span>            :         for_each_sched_entity(se) {</a>
<a name="11328"><span class="lineNum">   11328 </span>            :                 cfs_rq = cfs_rq_of(se);</a>
<a name="11329"><span class="lineNum">   11329 </span>            : </a>
<a name="11330"><span class="lineNum">   11330 </span>            :                 if (!cfs_rq_throttled(cfs_rq)){</a>
<a name="11331"><span class="lineNum">   11331 </span>            :                         update_load_avg(cfs_rq, se, UPDATE_TG);</a>
<a name="11332"><span class="lineNum">   11332 </span>            :                         list_add_leaf_cfs_rq(cfs_rq);</a>
<a name="11333"><span class="lineNum">   11333 </span>            :                         continue;</a>
<a name="11334"><span class="lineNum">   11334 </span>            :                 }</a>
<a name="11335"><span class="lineNum">   11335 </span>            : </a>
<a name="11336"><span class="lineNum">   11336 </span>            :                 if (list_add_leaf_cfs_rq(cfs_rq))</a>
<a name="11337"><span class="lineNum">   11337 </span>            :                         break;</a>
<a name="11338"><span class="lineNum">   11338 </span>            :         }</a>
<a name="11339"><span class="lineNum">   11339 </span>            : }</a>
<a name="11340"><span class="lineNum">   11340 </span>            : #else</a>
<a name="11341"><span class="lineNum">   11341 </span>            : static void propagate_entity_cfs_rq(struct sched_entity *se) { }</a>
<a name="11342"><span class="lineNum">   11342 </span>            : #endif</a>
<a name="11343"><span class="lineNum">   11343 </span>            : </a>
<a name="11344"><span class="lineNum">   11344 </span>            : static void detach_entity_cfs_rq(struct sched_entity *se)</a>
<a name="11345"><span class="lineNum">   11345 </span>            : {</a>
<a name="11346"><span class="lineNum">   11346 </span><span class="lineNoCov">          0 :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="11347"><span class="lineNum">   11347 </span>            : </a>
<a name="11348"><span class="lineNum">   11348 </span>            :         /* Catch up with the cfs_rq and remove our load when we leave */</a>
<a name="11349"><span class="lineNum">   11349 </span><span class="lineNoCov">          0 :         update_load_avg(cfs_rq, se, 0);</span></a>
<a name="11350"><span class="lineNum">   11350 </span><span class="lineNoCov">          0 :         detach_entity_load_avg(cfs_rq, se);</span></a>
<a name="11351"><span class="lineNum">   11351 </span>            :         update_tg_load_avg(cfs_rq);</a>
<a name="11352"><span class="lineNum">   11352 </span><span class="lineNoCov">          0 :         propagate_entity_cfs_rq(se);</span></a>
<a name="11353"><span class="lineNum">   11353 </span>            : }</a>
<a name="11354"><span class="lineNum">   11354 </span>            : </a>
<a name="11355"><span class="lineNum">   11355 </span>            : static void attach_entity_cfs_rq(struct sched_entity *se)</a>
<a name="11356"><span class="lineNum">   11356 </span>            : {</a>
<a name="11357"><span class="lineNum">   11357 </span><span class="lineNoCov">          0 :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="11358"><span class="lineNum">   11358 </span>            : </a>
<a name="11359"><span class="lineNum">   11359 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="11360"><span class="lineNum">   11360 </span>            :         /*</a>
<a name="11361"><span class="lineNum">   11361 </span>            :          * Since the real-depth could have been changed (only FAIR</a>
<a name="11362"><span class="lineNum">   11362 </span>            :          * class maintain depth value), reset depth properly.</a>
<a name="11363"><span class="lineNum">   11363 </span>            :          */</a>
<a name="11364"><span class="lineNum">   11364 </span>            :         se-&gt;depth = se-&gt;parent ? se-&gt;parent-&gt;depth + 1 : 0;</a>
<a name="11365"><span class="lineNum">   11365 </span>            : #endif</a>
<a name="11366"><span class="lineNum">   11366 </span>            : </a>
<a name="11367"><span class="lineNum">   11367 </span>            :         /* Synchronize entity with its cfs_rq */</a>
<a name="11368"><span class="lineNum">   11368 </span><span class="lineNoCov">          0 :         update_load_avg(cfs_rq, se, sched_feat(ATTACH_AGE_LOAD) ? 0 : SKIP_AGE_LOAD);</span></a>
<a name="11369"><span class="lineNum">   11369 </span><span class="lineNoCov">          0 :         attach_entity_load_avg(cfs_rq, se);</span></a>
<a name="11370"><span class="lineNum">   11370 </span>            :         update_tg_load_avg(cfs_rq);</a>
<a name="11371"><span class="lineNum">   11371 </span><span class="lineNoCov">          0 :         propagate_entity_cfs_rq(se);</span></a>
<a name="11372"><span class="lineNum">   11372 </span>            : }</a>
<a name="11373"><span class="lineNum">   11373 </span>            : </a>
<a name="11374"><span class="lineNum">   11374 </span><span class="lineNoCov">          0 : static void detach_task_cfs_rq(struct task_struct *p)</span></a>
<a name="11375"><span class="lineNum">   11375 </span>            : {</a>
<a name="11376"><span class="lineNum">   11376 </span><span class="lineNoCov">          0 :         struct sched_entity *se = &amp;p-&gt;se;</span></a>
<a name="11377"><span class="lineNum">   11377 </span><span class="lineNoCov">          0 :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="11378"><span class="lineNum">   11378 </span>            : </a>
<a name="11379"><span class="lineNum">   11379 </span><span class="lineNoCov">          0 :         if (!vruntime_normalized(p)) {</span></a>
<a name="11380"><span class="lineNum">   11380 </span>            :                 /*</a>
<a name="11381"><span class="lineNum">   11381 </span>            :                  * Fix up our vruntime so that the current sleep doesn't</a>
<a name="11382"><span class="lineNum">   11382 </span>            :                  * cause 'unlimited' sleep bonus.</a>
<a name="11383"><span class="lineNum">   11383 </span>            :                  */</a>
<a name="11384"><span class="lineNum">   11384 </span><span class="lineNoCov">          0 :                 place_entity(cfs_rq, se, 0);</span></a>
<a name="11385"><span class="lineNum">   11385 </span><span class="lineNoCov">          0 :                 se-&gt;vruntime -= cfs_rq-&gt;min_vruntime;</span></a>
<a name="11386"><span class="lineNum">   11386 </span>            :         }</a>
<a name="11387"><span class="lineNum">   11387 </span>            : </a>
<a name="11388"><span class="lineNum">   11388 </span><span class="lineNoCov">          0 :         detach_entity_cfs_rq(se);</span></a>
<a name="11389"><span class="lineNum">   11389 </span><span class="lineNoCov">          0 : }</span></a>
<a name="11390"><span class="lineNum">   11390 </span>            : </a>
<a name="11391"><span class="lineNum">   11391 </span>            : static void attach_task_cfs_rq(struct task_struct *p)</a>
<a name="11392"><span class="lineNum">   11392 </span>            : {</a>
<a name="11393"><span class="lineNum">   11393 </span><span class="lineNoCov">          0 :         struct sched_entity *se = &amp;p-&gt;se;</span></a>
<a name="11394"><span class="lineNum">   11394 </span><span class="lineNoCov">          0 :         struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="11395"><span class="lineNum">   11395 </span>            : </a>
<a name="11396"><span class="lineNum">   11396 </span><span class="lineNoCov">          0 :         attach_entity_cfs_rq(se);</span></a>
<a name="11397"><span class="lineNum">   11397 </span>            : </a>
<a name="11398"><span class="lineNum">   11398 </span><span class="lineNoCov">          0 :         if (!vruntime_normalized(p))</span></a>
<a name="11399"><span class="lineNum">   11399 </span><span class="lineNoCov">          0 :                 se-&gt;vruntime += cfs_rq-&gt;min_vruntime;</span></a>
<a name="11400"><span class="lineNum">   11400 </span>            : }</a>
<a name="11401"><span class="lineNum">   11401 </span>            : </a>
<a name="11402"><span class="lineNum">   11402 </span><span class="lineNoCov">          0 : static void switched_from_fair(struct rq *rq, struct task_struct *p)</span></a>
<a name="11403"><span class="lineNum">   11403 </span>            : {</a>
<a name="11404"><span class="lineNum">   11404 </span><span class="lineNoCov">          0 :         detach_task_cfs_rq(p);</span></a>
<a name="11405"><span class="lineNum">   11405 </span><span class="lineNoCov">          0 : }</span></a>
<a name="11406"><span class="lineNum">   11406 </span>            : </a>
<a name="11407"><span class="lineNum">   11407 </span><span class="lineNoCov">          0 : static void switched_to_fair(struct rq *rq, struct task_struct *p)</span></a>
<a name="11408"><span class="lineNum">   11408 </span>            : {</a>
<a name="11409"><span class="lineNum">   11409 </span><span class="lineNoCov">          0 :         attach_task_cfs_rq(p);</span></a>
<a name="11410"><span class="lineNum">   11410 </span>            : </a>
<a name="11411"><span class="lineNum">   11411 </span><span class="lineNoCov">          0 :         if (task_on_rq_queued(p)) {</span></a>
<a name="11412"><span class="lineNum">   11412 </span>            :                 /*</a>
<a name="11413"><span class="lineNum">   11413 </span>            :                  * We were most likely switched from sched_rt, so</a>
<a name="11414"><span class="lineNum">   11414 </span>            :                  * kick off the schedule if running, otherwise just see</a>
<a name="11415"><span class="lineNum">   11415 </span>            :                  * if we can still preempt the current task.</a>
<a name="11416"><span class="lineNum">   11416 </span>            :                  */</a>
<a name="11417"><span class="lineNum">   11417 </span><span class="lineNoCov">          0 :                 if (task_current(rq, p))</span></a>
<a name="11418"><span class="lineNum">   11418 </span><span class="lineNoCov">          0 :                         resched_curr(rq);</span></a>
<a name="11419"><span class="lineNum">   11419 </span>            :                 else</a>
<a name="11420"><span class="lineNum">   11420 </span><span class="lineNoCov">          0 :                         check_preempt_curr(rq, p, 0);</span></a>
<a name="11421"><span class="lineNum">   11421 </span>            :         }</a>
<a name="11422"><span class="lineNum">   11422 </span><span class="lineNoCov">          0 : }</span></a>
<a name="11423"><span class="lineNum">   11423 </span>            : </a>
<a name="11424"><span class="lineNum">   11424 </span>            : /* Account for a task changing its policy or group.</a>
<a name="11425"><span class="lineNum">   11425 </span>            :  *</a>
<a name="11426"><span class="lineNum">   11426 </span>            :  * This routine is mostly called to set cfs_rq-&gt;curr field when a task</a>
<a name="11427"><span class="lineNum">   11427 </span>            :  * migrates between groups/classes.</a>
<a name="11428"><span class="lineNum">   11428 </span>            :  */</a>
<a name="11429"><span class="lineNum">   11429 </span><span class="lineCov">          3 : static void set_next_task_fair(struct rq *rq, struct task_struct *p, bool first)</span></a>
<a name="11430"><span class="lineNum">   11430 </span>            : {</a>
<a name="11431"><span class="lineNum">   11431 </span><span class="lineCov">          3 :         struct sched_entity *se = &amp;p-&gt;se;</span></a>
<a name="11432"><span class="lineNum">   11432 </span>            : </a>
<a name="11433"><span class="lineNum">   11433 </span>            : #ifdef CONFIG_SMP</a>
<a name="11434"><span class="lineNum">   11434 </span>            :         if (task_on_rq_queued(p)) {</a>
<a name="11435"><span class="lineNum">   11435 </span>            :                 /*</a>
<a name="11436"><span class="lineNum">   11436 </span>            :                  * Move the next running task to the front of the list, so our</a>
<a name="11437"><span class="lineNum">   11437 </span>            :                  * cfs_tasks list becomes MRU one.</a>
<a name="11438"><span class="lineNum">   11438 </span>            :                  */</a>
<a name="11439"><span class="lineNum">   11439 </span>            :                 list_move(&amp;se-&gt;group_node, &amp;rq-&gt;cfs_tasks);</a>
<a name="11440"><span class="lineNum">   11440 </span>            :         }</a>
<a name="11441"><span class="lineNum">   11441 </span>            : #endif</a>
<a name="11442"><span class="lineNum">   11442 </span>            : </a>
<a name="11443"><span class="lineNum">   11443 </span><span class="lineCov">          6 :         for_each_sched_entity(se) {</span></a>
<a name="11444"><span class="lineNum">   11444 </span><span class="lineCov">          6 :                 struct cfs_rq *cfs_rq = cfs_rq_of(se);</span></a>
<a name="11445"><span class="lineNum">   11445 </span>            : </a>
<a name="11446"><span class="lineNum">   11446 </span><span class="lineCov">          3 :                 set_next_entity(cfs_rq, se);</span></a>
<a name="11447"><span class="lineNum">   11447 </span>            :                 /* ensure bandwidth has been allocated on our new cfs_rq */</a>
<a name="11448"><span class="lineNum">   11448 </span><span class="lineCov">          3 :                 account_cfs_rq_runtime(cfs_rq, 0);</span></a>
<a name="11449"><span class="lineNum">   11449 </span>            :         }</a>
<a name="11450"><span class="lineNum">   11450 </span><span class="lineCov">          3 : }</span></a>
<a name="11451"><span class="lineNum">   11451 </span>            : </a>
<a name="11452"><span class="lineNum">   11452 </span><span class="lineCov">          1 : void init_cfs_rq(struct cfs_rq *cfs_rq)</span></a>
<a name="11453"><span class="lineNum">   11453 </span>            : {</a>
<a name="11454"><span class="lineNum">   11454 </span><span class="lineCov">          1 :         cfs_rq-&gt;tasks_timeline = RB_ROOT_CACHED;</span></a>
<a name="11455"><span class="lineNum">   11455 </span><span class="lineCov">          1 :         cfs_rq-&gt;min_vruntime = (u64)(-(1LL &lt;&lt; 20));</span></a>
<a name="11456"><span class="lineNum">   11456 </span>            : #ifndef CONFIG_64BIT</a>
<a name="11457"><span class="lineNum">   11457 </span>            :         cfs_rq-&gt;min_vruntime_copy = cfs_rq-&gt;min_vruntime;</a>
<a name="11458"><span class="lineNum">   11458 </span>            : #endif</a>
<a name="11459"><span class="lineNum">   11459 </span>            : #ifdef CONFIG_SMP</a>
<a name="11460"><span class="lineNum">   11460 </span>            :         raw_spin_lock_init(&amp;cfs_rq-&gt;removed.lock);</a>
<a name="11461"><span class="lineNum">   11461 </span>            : #endif</a>
<a name="11462"><span class="lineNum">   11462 </span><span class="lineCov">          1 : }</span></a>
<a name="11463"><span class="lineNum">   11463 </span>            : </a>
<a name="11464"><span class="lineNum">   11464 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="11465"><span class="lineNum">   11465 </span>            : static void task_set_group_fair(struct task_struct *p)</a>
<a name="11466"><span class="lineNum">   11466 </span>            : {</a>
<a name="11467"><span class="lineNum">   11467 </span>            :         struct sched_entity *se = &amp;p-&gt;se;</a>
<a name="11468"><span class="lineNum">   11468 </span>            : </a>
<a name="11469"><span class="lineNum">   11469 </span>            :         set_task_rq(p, task_cpu(p));</a>
<a name="11470"><span class="lineNum">   11470 </span>            :         se-&gt;depth = se-&gt;parent ? se-&gt;parent-&gt;depth + 1 : 0;</a>
<a name="11471"><span class="lineNum">   11471 </span>            : }</a>
<a name="11472"><span class="lineNum">   11472 </span>            : </a>
<a name="11473"><span class="lineNum">   11473 </span>            : static void task_move_group_fair(struct task_struct *p)</a>
<a name="11474"><span class="lineNum">   11474 </span>            : {</a>
<a name="11475"><span class="lineNum">   11475 </span>            :         detach_task_cfs_rq(p);</a>
<a name="11476"><span class="lineNum">   11476 </span>            :         set_task_rq(p, task_cpu(p));</a>
<a name="11477"><span class="lineNum">   11477 </span>            : </a>
<a name="11478"><span class="lineNum">   11478 </span>            : #ifdef CONFIG_SMP</a>
<a name="11479"><span class="lineNum">   11479 </span>            :         /* Tell se's cfs_rq has been changed -- migrated */</a>
<a name="11480"><span class="lineNum">   11480 </span>            :         p-&gt;se.avg.last_update_time = 0;</a>
<a name="11481"><span class="lineNum">   11481 </span>            : #endif</a>
<a name="11482"><span class="lineNum">   11482 </span>            :         attach_task_cfs_rq(p);</a>
<a name="11483"><span class="lineNum">   11483 </span>            : }</a>
<a name="11484"><span class="lineNum">   11484 </span>            : </a>
<a name="11485"><span class="lineNum">   11485 </span>            : static void task_change_group_fair(struct task_struct *p, int type)</a>
<a name="11486"><span class="lineNum">   11486 </span>            : {</a>
<a name="11487"><span class="lineNum">   11487 </span>            :         switch (type) {</a>
<a name="11488"><span class="lineNum">   11488 </span>            :         case TASK_SET_GROUP:</a>
<a name="11489"><span class="lineNum">   11489 </span>            :                 task_set_group_fair(p);</a>
<a name="11490"><span class="lineNum">   11490 </span>            :                 break;</a>
<a name="11491"><span class="lineNum">   11491 </span>            : </a>
<a name="11492"><span class="lineNum">   11492 </span>            :         case TASK_MOVE_GROUP:</a>
<a name="11493"><span class="lineNum">   11493 </span>            :                 task_move_group_fair(p);</a>
<a name="11494"><span class="lineNum">   11494 </span>            :                 break;</a>
<a name="11495"><span class="lineNum">   11495 </span>            :         }</a>
<a name="11496"><span class="lineNum">   11496 </span>            : }</a>
<a name="11497"><span class="lineNum">   11497 </span>            : </a>
<a name="11498"><span class="lineNum">   11498 </span>            : void free_fair_sched_group(struct task_group *tg)</a>
<a name="11499"><span class="lineNum">   11499 </span>            : {</a>
<a name="11500"><span class="lineNum">   11500 </span>            :         int i;</a>
<a name="11501"><span class="lineNum">   11501 </span>            : </a>
<a name="11502"><span class="lineNum">   11502 </span>            :         for_each_possible_cpu(i) {</a>
<a name="11503"><span class="lineNum">   11503 </span>            :                 if (tg-&gt;cfs_rq)</a>
<a name="11504"><span class="lineNum">   11504 </span>            :                         kfree(tg-&gt;cfs_rq[i]);</a>
<a name="11505"><span class="lineNum">   11505 </span>            :                 if (tg-&gt;se)</a>
<a name="11506"><span class="lineNum">   11506 </span>            :                         kfree(tg-&gt;se[i]);</a>
<a name="11507"><span class="lineNum">   11507 </span>            :         }</a>
<a name="11508"><span class="lineNum">   11508 </span>            : </a>
<a name="11509"><span class="lineNum">   11509 </span>            :         kfree(tg-&gt;cfs_rq);</a>
<a name="11510"><span class="lineNum">   11510 </span>            :         kfree(tg-&gt;se);</a>
<a name="11511"><span class="lineNum">   11511 </span>            : }</a>
<a name="11512"><span class="lineNum">   11512 </span>            : </a>
<a name="11513"><span class="lineNum">   11513 </span>            : int alloc_fair_sched_group(struct task_group *tg, struct task_group *parent)</a>
<a name="11514"><span class="lineNum">   11514 </span>            : {</a>
<a name="11515"><span class="lineNum">   11515 </span>            :         struct sched_entity *se;</a>
<a name="11516"><span class="lineNum">   11516 </span>            :         struct cfs_rq *cfs_rq;</a>
<a name="11517"><span class="lineNum">   11517 </span>            :         int i;</a>
<a name="11518"><span class="lineNum">   11518 </span>            : </a>
<a name="11519"><span class="lineNum">   11519 </span>            :         tg-&gt;cfs_rq = kcalloc(nr_cpu_ids, sizeof(cfs_rq), GFP_KERNEL);</a>
<a name="11520"><span class="lineNum">   11520 </span>            :         if (!tg-&gt;cfs_rq)</a>
<a name="11521"><span class="lineNum">   11521 </span>            :                 goto err;</a>
<a name="11522"><span class="lineNum">   11522 </span>            :         tg-&gt;se = kcalloc(nr_cpu_ids, sizeof(se), GFP_KERNEL);</a>
<a name="11523"><span class="lineNum">   11523 </span>            :         if (!tg-&gt;se)</a>
<a name="11524"><span class="lineNum">   11524 </span>            :                 goto err;</a>
<a name="11525"><span class="lineNum">   11525 </span>            : </a>
<a name="11526"><span class="lineNum">   11526 </span>            :         tg-&gt;shares = NICE_0_LOAD;</a>
<a name="11527"><span class="lineNum">   11527 </span>            : </a>
<a name="11528"><span class="lineNum">   11528 </span>            :         init_cfs_bandwidth(tg_cfs_bandwidth(tg));</a>
<a name="11529"><span class="lineNum">   11529 </span>            : </a>
<a name="11530"><span class="lineNum">   11530 </span>            :         for_each_possible_cpu(i) {</a>
<a name="11531"><span class="lineNum">   11531 </span>            :                 cfs_rq = kzalloc_node(sizeof(struct cfs_rq),</a>
<a name="11532"><span class="lineNum">   11532 </span>            :                                       GFP_KERNEL, cpu_to_node(i));</a>
<a name="11533"><span class="lineNum">   11533 </span>            :                 if (!cfs_rq)</a>
<a name="11534"><span class="lineNum">   11534 </span>            :                         goto err;</a>
<a name="11535"><span class="lineNum">   11535 </span>            : </a>
<a name="11536"><span class="lineNum">   11536 </span>            :                 se = kzalloc_node(sizeof(struct sched_entity_stats),</a>
<a name="11537"><span class="lineNum">   11537 </span>            :                                   GFP_KERNEL, cpu_to_node(i));</a>
<a name="11538"><span class="lineNum">   11538 </span>            :                 if (!se)</a>
<a name="11539"><span class="lineNum">   11539 </span>            :                         goto err_free_rq;</a>
<a name="11540"><span class="lineNum">   11540 </span>            : </a>
<a name="11541"><span class="lineNum">   11541 </span>            :                 init_cfs_rq(cfs_rq);</a>
<a name="11542"><span class="lineNum">   11542 </span>            :                 init_tg_cfs_entry(tg, cfs_rq, se, i, parent-&gt;se[i]);</a>
<a name="11543"><span class="lineNum">   11543 </span>            :                 init_entity_runnable_average(se);</a>
<a name="11544"><span class="lineNum">   11544 </span>            :         }</a>
<a name="11545"><span class="lineNum">   11545 </span>            : </a>
<a name="11546"><span class="lineNum">   11546 </span>            :         return 1;</a>
<a name="11547"><span class="lineNum">   11547 </span>            : </a>
<a name="11548"><span class="lineNum">   11548 </span>            : err_free_rq:</a>
<a name="11549"><span class="lineNum">   11549 </span>            :         kfree(cfs_rq);</a>
<a name="11550"><span class="lineNum">   11550 </span>            : err:</a>
<a name="11551"><span class="lineNum">   11551 </span>            :         return 0;</a>
<a name="11552"><span class="lineNum">   11552 </span>            : }</a>
<a name="11553"><span class="lineNum">   11553 </span>            : </a>
<a name="11554"><span class="lineNum">   11554 </span>            : void online_fair_sched_group(struct task_group *tg)</a>
<a name="11555"><span class="lineNum">   11555 </span>            : {</a>
<a name="11556"><span class="lineNum">   11556 </span>            :         struct sched_entity *se;</a>
<a name="11557"><span class="lineNum">   11557 </span>            :         struct rq_flags rf;</a>
<a name="11558"><span class="lineNum">   11558 </span>            :         struct rq *rq;</a>
<a name="11559"><span class="lineNum">   11559 </span>            :         int i;</a>
<a name="11560"><span class="lineNum">   11560 </span>            : </a>
<a name="11561"><span class="lineNum">   11561 </span>            :         for_each_possible_cpu(i) {</a>
<a name="11562"><span class="lineNum">   11562 </span>            :                 rq = cpu_rq(i);</a>
<a name="11563"><span class="lineNum">   11563 </span>            :                 se = tg-&gt;se[i];</a>
<a name="11564"><span class="lineNum">   11564 </span>            :                 rq_lock_irq(rq, &amp;rf);</a>
<a name="11565"><span class="lineNum">   11565 </span>            :                 update_rq_clock(rq);</a>
<a name="11566"><span class="lineNum">   11566 </span>            :                 attach_entity_cfs_rq(se);</a>
<a name="11567"><span class="lineNum">   11567 </span>            :                 sync_throttle(tg, i);</a>
<a name="11568"><span class="lineNum">   11568 </span>            :                 rq_unlock_irq(rq, &amp;rf);</a>
<a name="11569"><span class="lineNum">   11569 </span>            :         }</a>
<a name="11570"><span class="lineNum">   11570 </span>            : }</a>
<a name="11571"><span class="lineNum">   11571 </span>            : </a>
<a name="11572"><span class="lineNum">   11572 </span>            : void unregister_fair_sched_group(struct task_group *tg)</a>
<a name="11573"><span class="lineNum">   11573 </span>            : {</a>
<a name="11574"><span class="lineNum">   11574 </span>            :         unsigned long flags;</a>
<a name="11575"><span class="lineNum">   11575 </span>            :         struct rq *rq;</a>
<a name="11576"><span class="lineNum">   11576 </span>            :         int cpu;</a>
<a name="11577"><span class="lineNum">   11577 </span>            : </a>
<a name="11578"><span class="lineNum">   11578 </span>            :         destroy_cfs_bandwidth(tg_cfs_bandwidth(tg));</a>
<a name="11579"><span class="lineNum">   11579 </span>            : </a>
<a name="11580"><span class="lineNum">   11580 </span>            :         for_each_possible_cpu(cpu) {</a>
<a name="11581"><span class="lineNum">   11581 </span>            :                 if (tg-&gt;se[cpu])</a>
<a name="11582"><span class="lineNum">   11582 </span>            :                         remove_entity_load_avg(tg-&gt;se[cpu]);</a>
<a name="11583"><span class="lineNum">   11583 </span>            : </a>
<a name="11584"><span class="lineNum">   11584 </span>            :                 /*</a>
<a name="11585"><span class="lineNum">   11585 </span>            :                  * Only empty task groups can be destroyed; so we can speculatively</a>
<a name="11586"><span class="lineNum">   11586 </span>            :                  * check on_list without danger of it being re-added.</a>
<a name="11587"><span class="lineNum">   11587 </span>            :                  */</a>
<a name="11588"><span class="lineNum">   11588 </span>            :                 if (!tg-&gt;cfs_rq[cpu]-&gt;on_list)</a>
<a name="11589"><span class="lineNum">   11589 </span>            :                         continue;</a>
<a name="11590"><span class="lineNum">   11590 </span>            : </a>
<a name="11591"><span class="lineNum">   11591 </span>            :                 rq = cpu_rq(cpu);</a>
<a name="11592"><span class="lineNum">   11592 </span>            : </a>
<a name="11593"><span class="lineNum">   11593 </span>            :                 raw_spin_rq_lock_irqsave(rq, flags);</a>
<a name="11594"><span class="lineNum">   11594 </span>            :                 list_del_leaf_cfs_rq(tg-&gt;cfs_rq[cpu]);</a>
<a name="11595"><span class="lineNum">   11595 </span>            :                 raw_spin_rq_unlock_irqrestore(rq, flags);</a>
<a name="11596"><span class="lineNum">   11596 </span>            :         }</a>
<a name="11597"><span class="lineNum">   11597 </span>            : }</a>
<a name="11598"><span class="lineNum">   11598 </span>            : </a>
<a name="11599"><span class="lineNum">   11599 </span>            : void init_tg_cfs_entry(struct task_group *tg, struct cfs_rq *cfs_rq,</a>
<a name="11600"><span class="lineNum">   11600 </span>            :                         struct sched_entity *se, int cpu,</a>
<a name="11601"><span class="lineNum">   11601 </span>            :                         struct sched_entity *parent)</a>
<a name="11602"><span class="lineNum">   11602 </span>            : {</a>
<a name="11603"><span class="lineNum">   11603 </span>            :         struct rq *rq = cpu_rq(cpu);</a>
<a name="11604"><span class="lineNum">   11604 </span>            : </a>
<a name="11605"><span class="lineNum">   11605 </span>            :         cfs_rq-&gt;tg = tg;</a>
<a name="11606"><span class="lineNum">   11606 </span>            :         cfs_rq-&gt;rq = rq;</a>
<a name="11607"><span class="lineNum">   11607 </span>            :         init_cfs_rq_runtime(cfs_rq);</a>
<a name="11608"><span class="lineNum">   11608 </span>            : </a>
<a name="11609"><span class="lineNum">   11609 </span>            :         tg-&gt;cfs_rq[cpu] = cfs_rq;</a>
<a name="11610"><span class="lineNum">   11610 </span>            :         tg-&gt;se[cpu] = se;</a>
<a name="11611"><span class="lineNum">   11611 </span>            : </a>
<a name="11612"><span class="lineNum">   11612 </span>            :         /* se could be NULL for root_task_group */</a>
<a name="11613"><span class="lineNum">   11613 </span>            :         if (!se)</a>
<a name="11614"><span class="lineNum">   11614 </span>            :                 return;</a>
<a name="11615"><span class="lineNum">   11615 </span>            : </a>
<a name="11616"><span class="lineNum">   11616 </span>            :         if (!parent) {</a>
<a name="11617"><span class="lineNum">   11617 </span>            :                 se-&gt;cfs_rq = &amp;rq-&gt;cfs;</a>
<a name="11618"><span class="lineNum">   11618 </span>            :                 se-&gt;depth = 0;</a>
<a name="11619"><span class="lineNum">   11619 </span>            :         } else {</a>
<a name="11620"><span class="lineNum">   11620 </span>            :                 se-&gt;cfs_rq = parent-&gt;my_q;</a>
<a name="11621"><span class="lineNum">   11621 </span>            :                 se-&gt;depth = parent-&gt;depth + 1;</a>
<a name="11622"><span class="lineNum">   11622 </span>            :         }</a>
<a name="11623"><span class="lineNum">   11623 </span>            : </a>
<a name="11624"><span class="lineNum">   11624 </span>            :         se-&gt;my_q = cfs_rq;</a>
<a name="11625"><span class="lineNum">   11625 </span>            :         /* guarantee group entities always have weight */</a>
<a name="11626"><span class="lineNum">   11626 </span>            :         update_load_set(&amp;se-&gt;load, NICE_0_LOAD);</a>
<a name="11627"><span class="lineNum">   11627 </span>            :         se-&gt;parent = parent;</a>
<a name="11628"><span class="lineNum">   11628 </span>            : }</a>
<a name="11629"><span class="lineNum">   11629 </span>            : </a>
<a name="11630"><span class="lineNum">   11630 </span>            : static DEFINE_MUTEX(shares_mutex);</a>
<a name="11631"><span class="lineNum">   11631 </span>            : </a>
<a name="11632"><span class="lineNum">   11632 </span>            : static int __sched_group_set_shares(struct task_group *tg, unsigned long shares)</a>
<a name="11633"><span class="lineNum">   11633 </span>            : {</a>
<a name="11634"><span class="lineNum">   11634 </span>            :         int i;</a>
<a name="11635"><span class="lineNum">   11635 </span>            : </a>
<a name="11636"><span class="lineNum">   11636 </span>            :         lockdep_assert_held(&amp;shares_mutex);</a>
<a name="11637"><span class="lineNum">   11637 </span>            : </a>
<a name="11638"><span class="lineNum">   11638 </span>            :         /*</a>
<a name="11639"><span class="lineNum">   11639 </span>            :          * We can't change the weight of the root cgroup.</a>
<a name="11640"><span class="lineNum">   11640 </span>            :          */</a>
<a name="11641"><span class="lineNum">   11641 </span>            :         if (!tg-&gt;se[0])</a>
<a name="11642"><span class="lineNum">   11642 </span>            :                 return -EINVAL;</a>
<a name="11643"><span class="lineNum">   11643 </span>            : </a>
<a name="11644"><span class="lineNum">   11644 </span>            :         shares = clamp(shares, scale_load(MIN_SHARES), scale_load(MAX_SHARES));</a>
<a name="11645"><span class="lineNum">   11645 </span>            : </a>
<a name="11646"><span class="lineNum">   11646 </span>            :         if (tg-&gt;shares == shares)</a>
<a name="11647"><span class="lineNum">   11647 </span>            :                 return 0;</a>
<a name="11648"><span class="lineNum">   11648 </span>            : </a>
<a name="11649"><span class="lineNum">   11649 </span>            :         tg-&gt;shares = shares;</a>
<a name="11650"><span class="lineNum">   11650 </span>            :         for_each_possible_cpu(i) {</a>
<a name="11651"><span class="lineNum">   11651 </span>            :                 struct rq *rq = cpu_rq(i);</a>
<a name="11652"><span class="lineNum">   11652 </span>            :                 struct sched_entity *se = tg-&gt;se[i];</a>
<a name="11653"><span class="lineNum">   11653 </span>            :                 struct rq_flags rf;</a>
<a name="11654"><span class="lineNum">   11654 </span>            : </a>
<a name="11655"><span class="lineNum">   11655 </span>            :                 /* Propagate contribution to hierarchy */</a>
<a name="11656"><span class="lineNum">   11656 </span>            :                 rq_lock_irqsave(rq, &amp;rf);</a>
<a name="11657"><span class="lineNum">   11657 </span>            :                 update_rq_clock(rq);</a>
<a name="11658"><span class="lineNum">   11658 </span>            :                 for_each_sched_entity(se) {</a>
<a name="11659"><span class="lineNum">   11659 </span>            :                         update_load_avg(cfs_rq_of(se), se, UPDATE_TG);</a>
<a name="11660"><span class="lineNum">   11660 </span>            :                         update_cfs_group(se);</a>
<a name="11661"><span class="lineNum">   11661 </span>            :                 }</a>
<a name="11662"><span class="lineNum">   11662 </span>            :                 rq_unlock_irqrestore(rq, &amp;rf);</a>
<a name="11663"><span class="lineNum">   11663 </span>            :         }</a>
<a name="11664"><span class="lineNum">   11664 </span>            : </a>
<a name="11665"><span class="lineNum">   11665 </span>            :         return 0;</a>
<a name="11666"><span class="lineNum">   11666 </span>            : }</a>
<a name="11667"><span class="lineNum">   11667 </span>            : </a>
<a name="11668"><span class="lineNum">   11668 </span>            : int sched_group_set_shares(struct task_group *tg, unsigned long shares)</a>
<a name="11669"><span class="lineNum">   11669 </span>            : {</a>
<a name="11670"><span class="lineNum">   11670 </span>            :         int ret;</a>
<a name="11671"><span class="lineNum">   11671 </span>            : </a>
<a name="11672"><span class="lineNum">   11672 </span>            :         mutex_lock(&amp;shares_mutex);</a>
<a name="11673"><span class="lineNum">   11673 </span>            :         if (tg_is_idle(tg))</a>
<a name="11674"><span class="lineNum">   11674 </span>            :                 ret = -EINVAL;</a>
<a name="11675"><span class="lineNum">   11675 </span>            :         else</a>
<a name="11676"><span class="lineNum">   11676 </span>            :                 ret = __sched_group_set_shares(tg, shares);</a>
<a name="11677"><span class="lineNum">   11677 </span>            :         mutex_unlock(&amp;shares_mutex);</a>
<a name="11678"><span class="lineNum">   11678 </span>            : </a>
<a name="11679"><span class="lineNum">   11679 </span>            :         return ret;</a>
<a name="11680"><span class="lineNum">   11680 </span>            : }</a>
<a name="11681"><span class="lineNum">   11681 </span>            : </a>
<a name="11682"><span class="lineNum">   11682 </span>            : int sched_group_set_idle(struct task_group *tg, long idle)</a>
<a name="11683"><span class="lineNum">   11683 </span>            : {</a>
<a name="11684"><span class="lineNum">   11684 </span>            :         int i;</a>
<a name="11685"><span class="lineNum">   11685 </span>            : </a>
<a name="11686"><span class="lineNum">   11686 </span>            :         if (tg == &amp;root_task_group)</a>
<a name="11687"><span class="lineNum">   11687 </span>            :                 return -EINVAL;</a>
<a name="11688"><span class="lineNum">   11688 </span>            : </a>
<a name="11689"><span class="lineNum">   11689 </span>            :         if (idle &lt; 0 || idle &gt; 1)</a>
<a name="11690"><span class="lineNum">   11690 </span>            :                 return -EINVAL;</a>
<a name="11691"><span class="lineNum">   11691 </span>            : </a>
<a name="11692"><span class="lineNum">   11692 </span>            :         mutex_lock(&amp;shares_mutex);</a>
<a name="11693"><span class="lineNum">   11693 </span>            : </a>
<a name="11694"><span class="lineNum">   11694 </span>            :         if (tg-&gt;idle == idle) {</a>
<a name="11695"><span class="lineNum">   11695 </span>            :                 mutex_unlock(&amp;shares_mutex);</a>
<a name="11696"><span class="lineNum">   11696 </span>            :                 return 0;</a>
<a name="11697"><span class="lineNum">   11697 </span>            :         }</a>
<a name="11698"><span class="lineNum">   11698 </span>            : </a>
<a name="11699"><span class="lineNum">   11699 </span>            :         tg-&gt;idle = idle;</a>
<a name="11700"><span class="lineNum">   11700 </span>            : </a>
<a name="11701"><span class="lineNum">   11701 </span>            :         for_each_possible_cpu(i) {</a>
<a name="11702"><span class="lineNum">   11702 </span>            :                 struct rq *rq = cpu_rq(i);</a>
<a name="11703"><span class="lineNum">   11703 </span>            :                 struct sched_entity *se = tg-&gt;se[i];</a>
<a name="11704"><span class="lineNum">   11704 </span>            :                 struct cfs_rq *parent_cfs_rq, *grp_cfs_rq = tg-&gt;cfs_rq[i];</a>
<a name="11705"><span class="lineNum">   11705 </span>            :                 bool was_idle = cfs_rq_is_idle(grp_cfs_rq);</a>
<a name="11706"><span class="lineNum">   11706 </span>            :                 long idle_task_delta;</a>
<a name="11707"><span class="lineNum">   11707 </span>            :                 struct rq_flags rf;</a>
<a name="11708"><span class="lineNum">   11708 </span>            : </a>
<a name="11709"><span class="lineNum">   11709 </span>            :                 rq_lock_irqsave(rq, &amp;rf);</a>
<a name="11710"><span class="lineNum">   11710 </span>            : </a>
<a name="11711"><span class="lineNum">   11711 </span>            :                 grp_cfs_rq-&gt;idle = idle;</a>
<a name="11712"><span class="lineNum">   11712 </span>            :                 if (WARN_ON_ONCE(was_idle == cfs_rq_is_idle(grp_cfs_rq)))</a>
<a name="11713"><span class="lineNum">   11713 </span>            :                         goto next_cpu;</a>
<a name="11714"><span class="lineNum">   11714 </span>            : </a>
<a name="11715"><span class="lineNum">   11715 </span>            :                 if (se-&gt;on_rq) {</a>
<a name="11716"><span class="lineNum">   11716 </span>            :                         parent_cfs_rq = cfs_rq_of(se);</a>
<a name="11717"><span class="lineNum">   11717 </span>            :                         if (cfs_rq_is_idle(grp_cfs_rq))</a>
<a name="11718"><span class="lineNum">   11718 </span>            :                                 parent_cfs_rq-&gt;idle_nr_running++;</a>
<a name="11719"><span class="lineNum">   11719 </span>            :                         else</a>
<a name="11720"><span class="lineNum">   11720 </span>            :                                 parent_cfs_rq-&gt;idle_nr_running--;</a>
<a name="11721"><span class="lineNum">   11721 </span>            :                 }</a>
<a name="11722"><span class="lineNum">   11722 </span>            : </a>
<a name="11723"><span class="lineNum">   11723 </span>            :                 idle_task_delta = grp_cfs_rq-&gt;h_nr_running -</a>
<a name="11724"><span class="lineNum">   11724 </span>            :                                   grp_cfs_rq-&gt;idle_h_nr_running;</a>
<a name="11725"><span class="lineNum">   11725 </span>            :                 if (!cfs_rq_is_idle(grp_cfs_rq))</a>
<a name="11726"><span class="lineNum">   11726 </span>            :                         idle_task_delta *= -1;</a>
<a name="11727"><span class="lineNum">   11727 </span>            : </a>
<a name="11728"><span class="lineNum">   11728 </span>            :                 for_each_sched_entity(se) {</a>
<a name="11729"><span class="lineNum">   11729 </span>            :                         struct cfs_rq *cfs_rq = cfs_rq_of(se);</a>
<a name="11730"><span class="lineNum">   11730 </span>            : </a>
<a name="11731"><span class="lineNum">   11731 </span>            :                         if (!se-&gt;on_rq)</a>
<a name="11732"><span class="lineNum">   11732 </span>            :                                 break;</a>
<a name="11733"><span class="lineNum">   11733 </span>            : </a>
<a name="11734"><span class="lineNum">   11734 </span>            :                         cfs_rq-&gt;idle_h_nr_running += idle_task_delta;</a>
<a name="11735"><span class="lineNum">   11735 </span>            : </a>
<a name="11736"><span class="lineNum">   11736 </span>            :                         /* Already accounted at parent level and above. */</a>
<a name="11737"><span class="lineNum">   11737 </span>            :                         if (cfs_rq_is_idle(cfs_rq))</a>
<a name="11738"><span class="lineNum">   11738 </span>            :                                 break;</a>
<a name="11739"><span class="lineNum">   11739 </span>            :                 }</a>
<a name="11740"><span class="lineNum">   11740 </span>            : </a>
<a name="11741"><span class="lineNum">   11741 </span>            : next_cpu:</a>
<a name="11742"><span class="lineNum">   11742 </span>            :                 rq_unlock_irqrestore(rq, &amp;rf);</a>
<a name="11743"><span class="lineNum">   11743 </span>            :         }</a>
<a name="11744"><span class="lineNum">   11744 </span>            : </a>
<a name="11745"><span class="lineNum">   11745 </span>            :         /* Idle groups have minimum weight. */</a>
<a name="11746"><span class="lineNum">   11746 </span>            :         if (tg_is_idle(tg))</a>
<a name="11747"><span class="lineNum">   11747 </span>            :                 __sched_group_set_shares(tg, scale_load(WEIGHT_IDLEPRIO));</a>
<a name="11748"><span class="lineNum">   11748 </span>            :         else</a>
<a name="11749"><span class="lineNum">   11749 </span>            :                 __sched_group_set_shares(tg, NICE_0_LOAD);</a>
<a name="11750"><span class="lineNum">   11750 </span>            : </a>
<a name="11751"><span class="lineNum">   11751 </span>            :         mutex_unlock(&amp;shares_mutex);</a>
<a name="11752"><span class="lineNum">   11752 </span>            :         return 0;</a>
<a name="11753"><span class="lineNum">   11753 </span>            : }</a>
<a name="11754"><span class="lineNum">   11754 </span>            : </a>
<a name="11755"><span class="lineNum">   11755 </span>            : #else /* CONFIG_FAIR_GROUP_SCHED */</a>
<a name="11756"><span class="lineNum">   11756 </span>            : </a>
<a name="11757"><span class="lineNum">   11757 </span><span class="lineNoCov">          0 : void free_fair_sched_group(struct task_group *tg) { }</span></a>
<a name="11758"><span class="lineNum">   11758 </span>            : </a>
<a name="11759"><span class="lineNum">   11759 </span><span class="lineNoCov">          0 : int alloc_fair_sched_group(struct task_group *tg, struct task_group *parent)</span></a>
<a name="11760"><span class="lineNum">   11760 </span>            : {</a>
<a name="11761"><span class="lineNum">   11761 </span><span class="lineNoCov">          0 :         return 1;</span></a>
<a name="11762"><span class="lineNum">   11762 </span>            : }</a>
<a name="11763"><span class="lineNum">   11763 </span>            : </a>
<a name="11764"><span class="lineNum">   11764 </span><span class="lineNoCov">          0 : void online_fair_sched_group(struct task_group *tg) { }</span></a>
<a name="11765"><span class="lineNum">   11765 </span>            : </a>
<a name="11766"><span class="lineNum">   11766 </span><span class="lineNoCov">          0 : void unregister_fair_sched_group(struct task_group *tg) { }</span></a>
<a name="11767"><span class="lineNum">   11767 </span>            : </a>
<a name="11768"><span class="lineNum">   11768 </span>            : #endif /* CONFIG_FAIR_GROUP_SCHED */</a>
<a name="11769"><span class="lineNum">   11769 </span>            : </a>
<a name="11770"><span class="lineNum">   11770 </span>            : </a>
<a name="11771"><span class="lineNum">   11771 </span><span class="lineNoCov">          0 : static unsigned int get_rr_interval_fair(struct rq *rq, struct task_struct *task)</span></a>
<a name="11772"><span class="lineNum">   11772 </span>            : {</a>
<a name="11773"><span class="lineNum">   11773 </span><span class="lineNoCov">          0 :         struct sched_entity *se = &amp;task-&gt;se;</span></a>
<a name="11774"><span class="lineNum">   11774 </span><span class="lineNoCov">          0 :         unsigned int rr_interval = 0;</span></a>
<a name="11775"><span class="lineNum">   11775 </span>            : </a>
<a name="11776"><span class="lineNum">   11776 </span>            :         /*</a>
<a name="11777"><span class="lineNum">   11777 </span>            :          * Time slice is 0 for SCHED_OTHER tasks that are on an otherwise</a>
<a name="11778"><span class="lineNum">   11778 </span>            :          * idle runqueue:</a>
<a name="11779"><span class="lineNum">   11779 </span>            :          */</a>
<a name="11780"><span class="lineNum">   11780 </span><span class="lineNoCov">          0 :         if (rq-&gt;cfs.load.weight)</span></a>
<a name="11781"><span class="lineNum">   11781 </span><span class="lineNoCov">          0 :                 rr_interval = NS_TO_JIFFIES(sched_slice(cfs_rq_of(se), se));</span></a>
<a name="11782"><span class="lineNum">   11782 </span>            : </a>
<a name="11783"><span class="lineNum">   11783 </span><span class="lineNoCov">          0 :         return rr_interval;</span></a>
<a name="11784"><span class="lineNum">   11784 </span>            : }</a>
<a name="11785"><span class="lineNum">   11785 </span>            : </a>
<a name="11786"><span class="lineNum">   11786 </span>            : /*</a>
<a name="11787"><span class="lineNum">   11787 </span>            :  * All the scheduling class methods:</a>
<a name="11788"><span class="lineNum">   11788 </span>            :  */</a>
<a name="11789"><span class="lineNum">   11789 </span>            : DEFINE_SCHED_CLASS(fair) = {</a>
<a name="11790"><span class="lineNum">   11790 </span>            : </a>
<a name="11791"><span class="lineNum">   11791 </span>            :         .enqueue_task           = enqueue_task_fair,</a>
<a name="11792"><span class="lineNum">   11792 </span>            :         .dequeue_task           = dequeue_task_fair,</a>
<a name="11793"><span class="lineNum">   11793 </span>            :         .yield_task             = yield_task_fair,</a>
<a name="11794"><span class="lineNum">   11794 </span>            :         .yield_to_task          = yield_to_task_fair,</a>
<a name="11795"><span class="lineNum">   11795 </span>            : </a>
<a name="11796"><span class="lineNum">   11796 </span>            :         .check_preempt_curr     = check_preempt_wakeup,</a>
<a name="11797"><span class="lineNum">   11797 </span>            : </a>
<a name="11798"><span class="lineNum">   11798 </span>            :         .pick_next_task         = __pick_next_task_fair,</a>
<a name="11799"><span class="lineNum">   11799 </span>            :         .put_prev_task          = put_prev_task_fair,</a>
<a name="11800"><span class="lineNum">   11800 </span>            :         .set_next_task          = set_next_task_fair,</a>
<a name="11801"><span class="lineNum">   11801 </span>            : </a>
<a name="11802"><span class="lineNum">   11802 </span>            : #ifdef CONFIG_SMP</a>
<a name="11803"><span class="lineNum">   11803 </span>            :         .balance                = balance_fair,</a>
<a name="11804"><span class="lineNum">   11804 </span>            :         .pick_task              = pick_task_fair,</a>
<a name="11805"><span class="lineNum">   11805 </span>            :         .select_task_rq         = select_task_rq_fair,</a>
<a name="11806"><span class="lineNum">   11806 </span>            :         .migrate_task_rq        = migrate_task_rq_fair,</a>
<a name="11807"><span class="lineNum">   11807 </span>            : </a>
<a name="11808"><span class="lineNum">   11808 </span>            :         .rq_online              = rq_online_fair,</a>
<a name="11809"><span class="lineNum">   11809 </span>            :         .rq_offline             = rq_offline_fair,</a>
<a name="11810"><span class="lineNum">   11810 </span>            : </a>
<a name="11811"><span class="lineNum">   11811 </span>            :         .task_dead              = task_dead_fair,</a>
<a name="11812"><span class="lineNum">   11812 </span>            :         .set_cpus_allowed       = set_cpus_allowed_common,</a>
<a name="11813"><span class="lineNum">   11813 </span>            : #endif</a>
<a name="11814"><span class="lineNum">   11814 </span>            : </a>
<a name="11815"><span class="lineNum">   11815 </span>            :         .task_tick              = task_tick_fair,</a>
<a name="11816"><span class="lineNum">   11816 </span>            :         .task_fork              = task_fork_fair,</a>
<a name="11817"><span class="lineNum">   11817 </span>            : </a>
<a name="11818"><span class="lineNum">   11818 </span>            :         .prio_changed           = prio_changed_fair,</a>
<a name="11819"><span class="lineNum">   11819 </span>            :         .switched_from          = switched_from_fair,</a>
<a name="11820"><span class="lineNum">   11820 </span>            :         .switched_to            = switched_to_fair,</a>
<a name="11821"><span class="lineNum">   11821 </span>            : </a>
<a name="11822"><span class="lineNum">   11822 </span>            :         .get_rr_interval        = get_rr_interval_fair,</a>
<a name="11823"><span class="lineNum">   11823 </span>            : </a>
<a name="11824"><span class="lineNum">   11824 </span>            :         .update_curr            = update_curr_fair,</a>
<a name="11825"><span class="lineNum">   11825 </span>            : </a>
<a name="11826"><span class="lineNum">   11826 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED</a>
<a name="11827"><span class="lineNum">   11827 </span>            :         .task_change_group      = task_change_group_fair,</a>
<a name="11828"><span class="lineNum">   11828 </span>            : #endif</a>
<a name="11829"><span class="lineNum">   11829 </span>            : </a>
<a name="11830"><span class="lineNum">   11830 </span>            : #ifdef CONFIG_UCLAMP_TASK</a>
<a name="11831"><span class="lineNum">   11831 </span>            :         .uclamp_enabled         = 1,</a>
<a name="11832"><span class="lineNum">   11832 </span>            : #endif</a>
<a name="11833"><span class="lineNum">   11833 </span>            : };</a>
<a name="11834"><span class="lineNum">   11834 </span>            : </a>
<a name="11835"><span class="lineNum">   11835 </span>            : #ifdef CONFIG_SCHED_DEBUG</a>
<a name="11836"><span class="lineNum">   11836 </span><span class="lineNoCov">          0 : void print_cfs_stats(struct seq_file *m, int cpu)</span></a>
<a name="11837"><span class="lineNum">   11837 </span>            : {</a>
<a name="11838"><span class="lineNum">   11838 </span>            :         struct cfs_rq *cfs_rq, *pos;</a>
<a name="11839"><span class="lineNum">   11839 </span>            : </a>
<a name="11840"><span class="lineNum">   11840 </span>            :         rcu_read_lock();</a>
<a name="11841"><span class="lineNum">   11841 </span><span class="lineNoCov">          0 :         for_each_leaf_cfs_rq_safe(cpu_rq(cpu), cfs_rq, pos)</span></a>
<a name="11842"><span class="lineNum">   11842 </span><span class="lineNoCov">          0 :                 print_cfs_rq(m, cpu, cfs_rq);</span></a>
<a name="11843"><span class="lineNum">   11843 </span>            :         rcu_read_unlock();</a>
<a name="11844"><span class="lineNum">   11844 </span><span class="lineNoCov">          0 : }</span></a>
<a name="11845"><span class="lineNum">   11845 </span>            : </a>
<a name="11846"><span class="lineNum">   11846 </span>            : #ifdef CONFIG_NUMA_BALANCING</a>
<a name="11847"><span class="lineNum">   11847 </span>            : void show_numa_stats(struct task_struct *p, struct seq_file *m)</a>
<a name="11848"><span class="lineNum">   11848 </span>            : {</a>
<a name="11849"><span class="lineNum">   11849 </span>            :         int node;</a>
<a name="11850"><span class="lineNum">   11850 </span>            :         unsigned long tsf = 0, tpf = 0, gsf = 0, gpf = 0;</a>
<a name="11851"><span class="lineNum">   11851 </span>            :         struct numa_group *ng;</a>
<a name="11852"><span class="lineNum">   11852 </span>            : </a>
<a name="11853"><span class="lineNum">   11853 </span>            :         rcu_read_lock();</a>
<a name="11854"><span class="lineNum">   11854 </span>            :         ng = rcu_dereference(p-&gt;numa_group);</a>
<a name="11855"><span class="lineNum">   11855 </span>            :         for_each_online_node(node) {</a>
<a name="11856"><span class="lineNum">   11856 </span>            :                 if (p-&gt;numa_faults) {</a>
<a name="11857"><span class="lineNum">   11857 </span>            :                         tsf = p-&gt;numa_faults[task_faults_idx(NUMA_MEM, node, 0)];</a>
<a name="11858"><span class="lineNum">   11858 </span>            :                         tpf = p-&gt;numa_faults[task_faults_idx(NUMA_MEM, node, 1)];</a>
<a name="11859"><span class="lineNum">   11859 </span>            :                 }</a>
<a name="11860"><span class="lineNum">   11860 </span>            :                 if (ng) {</a>
<a name="11861"><span class="lineNum">   11861 </span>            :                         gsf = ng-&gt;faults[task_faults_idx(NUMA_MEM, node, 0)],</a>
<a name="11862"><span class="lineNum">   11862 </span>            :                         gpf = ng-&gt;faults[task_faults_idx(NUMA_MEM, node, 1)];</a>
<a name="11863"><span class="lineNum">   11863 </span>            :                 }</a>
<a name="11864"><span class="lineNum">   11864 </span>            :                 print_numa_stats(m, node, tsf, tpf, gsf, gpf);</a>
<a name="11865"><span class="lineNum">   11865 </span>            :         }</a>
<a name="11866"><span class="lineNum">   11866 </span>            :         rcu_read_unlock();</a>
<a name="11867"><span class="lineNum">   11867 </span>            : }</a>
<a name="11868"><span class="lineNum">   11868 </span>            : #endif /* CONFIG_NUMA_BALANCING */</a>
<a name="11869"><span class="lineNum">   11869 </span>            : #endif /* CONFIG_SCHED_DEBUG */</a>
<a name="11870"><span class="lineNum">   11870 </span>            : </a>
<a name="11871"><span class="lineNum">   11871 </span><span class="lineCov">          1 : __init void init_sched_fair_class(void)</span></a>
<a name="11872"><span class="lineNum">   11872 </span>            : {</a>
<a name="11873"><span class="lineNum">   11873 </span>            : #ifdef CONFIG_SMP</a>
<a name="11874"><span class="lineNum">   11874 </span>            :         open_softirq(SCHED_SOFTIRQ, run_rebalance_domains);</a>
<a name="11875"><span class="lineNum">   11875 </span>            : </a>
<a name="11876"><span class="lineNum">   11876 </span>            : #ifdef CONFIG_NO_HZ_COMMON</a>
<a name="11877"><span class="lineNum">   11877 </span>            :         nohz.next_balance = jiffies;</a>
<a name="11878"><span class="lineNum">   11878 </span>            :         nohz.next_blocked = jiffies;</a>
<a name="11879"><span class="lineNum">   11879 </span>            :         zalloc_cpumask_var(&amp;nohz.idle_cpus_mask, GFP_NOWAIT);</a>
<a name="11880"><span class="lineNum">   11880 </span>            : #endif</a>
<a name="11881"><span class="lineNum">   11881 </span>            : #endif /* SMP */</a>
<a name="11882"><span class="lineNum">   11882 </span>            : </a>
<a name="11883"><span class="lineNum">   11883 </span><span class="lineCov">          1 : }</span></a>
<a name="11884"><span class="lineNum">   11884 </span>            : </a>
<a name="11885"><span class="lineNum">   11885 </span>            : /*</a>
<a name="11886"><span class="lineNum">   11886 </span>            :  * Helper functions to facilitate extracting info from tracepoints.</a>
<a name="11887"><span class="lineNum">   11887 </span>            :  */</a>
<a name="11888"><span class="lineNum">   11888 </span>            : </a>
<a name="11889"><span class="lineNum">   11889 </span><span class="lineNoCov">          0 : const struct sched_avg *sched_trace_cfs_rq_avg(struct cfs_rq *cfs_rq)</span></a>
<a name="11890"><span class="lineNum">   11890 </span>            : {</a>
<a name="11891"><span class="lineNum">   11891 </span>            : #ifdef CONFIG_SMP</a>
<a name="11892"><span class="lineNum">   11892 </span>            :         return cfs_rq ? &amp;cfs_rq-&gt;avg : NULL;</a>
<a name="11893"><span class="lineNum">   11893 </span>            : #else</a>
<a name="11894"><span class="lineNum">   11894 </span><span class="lineNoCov">          0 :         return NULL;</span></a>
<a name="11895"><span class="lineNum">   11895 </span>            : #endif</a>
<a name="11896"><span class="lineNum">   11896 </span>            : }</a>
<a name="11897"><span class="lineNum">   11897 </span>            : EXPORT_SYMBOL_GPL(sched_trace_cfs_rq_avg);</a>
<a name="11898"><span class="lineNum">   11898 </span>            : </a>
<a name="11899"><span class="lineNum">   11899 </span><span class="lineNoCov">          0 : char *sched_trace_cfs_rq_path(struct cfs_rq *cfs_rq, char *str, int len)</span></a>
<a name="11900"><span class="lineNum">   11900 </span>            : {</a>
<a name="11901"><span class="lineNum">   11901 </span><span class="lineNoCov">          0 :         if (!cfs_rq) {</span></a>
<a name="11902"><span class="lineNum">   11902 </span><span class="lineNoCov">          0 :                 if (str)</span></a>
<a name="11903"><span class="lineNum">   11903 </span><span class="lineNoCov">          0 :                         strlcpy(str, &quot;(null)&quot;, len);</span></a>
<a name="11904"><span class="lineNum">   11904 </span>            :                 else</a>
<a name="11905"><span class="lineNum">   11905 </span>            :                         return NULL;</a>
<a name="11906"><span class="lineNum">   11906 </span>            :         }</a>
<a name="11907"><span class="lineNum">   11907 </span>            : </a>
<a name="11908"><span class="lineNum">   11908 </span><span class="lineNoCov">          0 :         cfs_rq_tg_path(cfs_rq, str, len);</span></a>
<a name="11909"><span class="lineNum">   11909 </span>            :         return str;</a>
<a name="11910"><span class="lineNum">   11910 </span>            : }</a>
<a name="11911"><span class="lineNum">   11911 </span>            : EXPORT_SYMBOL_GPL(sched_trace_cfs_rq_path);</a>
<a name="11912"><span class="lineNum">   11912 </span>            : </a>
<a name="11913"><span class="lineNum">   11913 </span><span class="lineNoCov">          0 : int sched_trace_cfs_rq_cpu(struct cfs_rq *cfs_rq)</span></a>
<a name="11914"><span class="lineNum">   11914 </span>            : {</a>
<a name="11915"><span class="lineNum">   11915 </span><span class="lineNoCov">          0 :         return cfs_rq ? cpu_of(rq_of(cfs_rq)) : -1;</span></a>
<a name="11916"><span class="lineNum">   11916 </span>            : }</a>
<a name="11917"><span class="lineNum">   11917 </span>            : EXPORT_SYMBOL_GPL(sched_trace_cfs_rq_cpu);</a>
<a name="11918"><span class="lineNum">   11918 </span>            : </a>
<a name="11919"><span class="lineNum">   11919 </span><span class="lineNoCov">          0 : const struct sched_avg *sched_trace_rq_avg_rt(struct rq *rq)</span></a>
<a name="11920"><span class="lineNum">   11920 </span>            : {</a>
<a name="11921"><span class="lineNum">   11921 </span>            : #ifdef CONFIG_SMP</a>
<a name="11922"><span class="lineNum">   11922 </span>            :         return rq ? &amp;rq-&gt;avg_rt : NULL;</a>
<a name="11923"><span class="lineNum">   11923 </span>            : #else</a>
<a name="11924"><span class="lineNum">   11924 </span><span class="lineNoCov">          0 :         return NULL;</span></a>
<a name="11925"><span class="lineNum">   11925 </span>            : #endif</a>
<a name="11926"><span class="lineNum">   11926 </span>            : }</a>
<a name="11927"><span class="lineNum">   11927 </span>            : EXPORT_SYMBOL_GPL(sched_trace_rq_avg_rt);</a>
<a name="11928"><span class="lineNum">   11928 </span>            : </a>
<a name="11929"><span class="lineNum">   11929 </span><span class="lineNoCov">          0 : const struct sched_avg *sched_trace_rq_avg_dl(struct rq *rq)</span></a>
<a name="11930"><span class="lineNum">   11930 </span>            : {</a>
<a name="11931"><span class="lineNum">   11931 </span>            : #ifdef CONFIG_SMP</a>
<a name="11932"><span class="lineNum">   11932 </span>            :         return rq ? &amp;rq-&gt;avg_dl : NULL;</a>
<a name="11933"><span class="lineNum">   11933 </span>            : #else</a>
<a name="11934"><span class="lineNum">   11934 </span><span class="lineNoCov">          0 :         return NULL;</span></a>
<a name="11935"><span class="lineNum">   11935 </span>            : #endif</a>
<a name="11936"><span class="lineNum">   11936 </span>            : }</a>
<a name="11937"><span class="lineNum">   11937 </span>            : EXPORT_SYMBOL_GPL(sched_trace_rq_avg_dl);</a>
<a name="11938"><span class="lineNum">   11938 </span>            : </a>
<a name="11939"><span class="lineNum">   11939 </span><span class="lineNoCov">          0 : const struct sched_avg *sched_trace_rq_avg_irq(struct rq *rq)</span></a>
<a name="11940"><span class="lineNum">   11940 </span>            : {</a>
<a name="11941"><span class="lineNum">   11941 </span>            : #if defined(CONFIG_SMP) &amp;&amp; defined(CONFIG_HAVE_SCHED_AVG_IRQ)</a>
<a name="11942"><span class="lineNum">   11942 </span>            :         return rq ? &amp;rq-&gt;avg_irq : NULL;</a>
<a name="11943"><span class="lineNum">   11943 </span>            : #else</a>
<a name="11944"><span class="lineNum">   11944 </span><span class="lineNoCov">          0 :         return NULL;</span></a>
<a name="11945"><span class="lineNum">   11945 </span>            : #endif</a>
<a name="11946"><span class="lineNum">   11946 </span>            : }</a>
<a name="11947"><span class="lineNum">   11947 </span>            : EXPORT_SYMBOL_GPL(sched_trace_rq_avg_irq);</a>
<a name="11948"><span class="lineNum">   11948 </span>            : </a>
<a name="11949"><span class="lineNum">   11949 </span><span class="lineNoCov">          0 : int sched_trace_rq_cpu(struct rq *rq)</span></a>
<a name="11950"><span class="lineNum">   11950 </span>            : {</a>
<a name="11951"><span class="lineNum">   11951 </span><span class="lineNoCov">          0 :         return rq ? cpu_of(rq) : -1;</span></a>
<a name="11952"><span class="lineNum">   11952 </span>            : }</a>
<a name="11953"><span class="lineNum">   11953 </span>            : EXPORT_SYMBOL_GPL(sched_trace_rq_cpu);</a>
<a name="11954"><span class="lineNum">   11954 </span>            : </a>
<a name="11955"><span class="lineNum">   11955 </span><span class="lineNoCov">          0 : int sched_trace_rq_cpu_capacity(struct rq *rq)</span></a>
<a name="11956"><span class="lineNum">   11956 </span>            : {</a>
<a name="11957"><span class="lineNum">   11957 </span>            :         return rq ?</a>
<a name="11958"><span class="lineNum">   11958 </span>            : #ifdef CONFIG_SMP</a>
<a name="11959"><span class="lineNum">   11959 </span>            :                 rq-&gt;cpu_capacity</a>
<a name="11960"><span class="lineNum">   11960 </span>            : #else</a>
<a name="11961"><span class="lineNum">   11961 </span>            :                 SCHED_CAPACITY_SCALE</a>
<a name="11962"><span class="lineNum">   11962 </span>            : #endif</a>
<a name="11963"><span class="lineNum">   11963 </span><span class="lineNoCov">          0 :                 : -1;</span></a>
<a name="11964"><span class="lineNum">   11964 </span>            : }</a>
<a name="11965"><span class="lineNum">   11965 </span>            : EXPORT_SYMBOL_GPL(sched_trace_rq_cpu_capacity);</a>
<a name="11966"><span class="lineNum">   11966 </span>            : </a>
<a name="11967"><span class="lineNum">   11967 </span><span class="lineNoCov">          0 : const struct cpumask *sched_trace_rd_span(struct root_domain *rd)</span></a>
<a name="11968"><span class="lineNum">   11968 </span>            : {</a>
<a name="11969"><span class="lineNum">   11969 </span>            : #ifdef CONFIG_SMP</a>
<a name="11970"><span class="lineNum">   11970 </span>            :         return rd ? rd-&gt;span : NULL;</a>
<a name="11971"><span class="lineNum">   11971 </span>            : #else</a>
<a name="11972"><span class="lineNum">   11972 </span><span class="lineNoCov">          0 :         return NULL;</span></a>
<a name="11973"><span class="lineNum">   11973 </span>            : #endif</a>
<a name="11974"><span class="lineNum">   11974 </span>            : }</a>
<a name="11975"><span class="lineNum">   11975 </span>            : EXPORT_SYMBOL_GPL(sched_trace_rd_span);</a>
<a name="11976"><span class="lineNum">   11976 </span>            : </a>
<a name="11977"><span class="lineNum">   11977 </span><span class="lineNoCov">          0 : int sched_trace_rq_nr_running(struct rq *rq)</span></a>
<a name="11978"><span class="lineNum">   11978 </span>            : {</a>
<a name="11979"><span class="lineNum">   11979 </span><span class="lineNoCov">          0 :         return rq ? rq-&gt;nr_running : -1;</span></a>
<a name="11980"><span class="lineNum">   11980 </span>            : }</a>
<a name="11981"><span class="lineNum">   11981 </span>            : EXPORT_SYMBOL_GPL(sched_trace_rq_nr_running);</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.14</a></td></tr>
  </table>
  <br>

</body>
</html>
